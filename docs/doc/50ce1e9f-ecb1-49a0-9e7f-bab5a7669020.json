{
    "summary": "The code downloads, extracts and provides label information for 19228 videos' feature frames in \"activitynet_1.3_annotations.json\" for PaddleVideo model pre-training, using decompressed data from \"bmn_feat.tar.gz\". Users need to modify `feat_path` and `file_path` in the configuration file.",
    "details": [
        {
            "comment": "ActivityNet is a large-scale dataset for video understanding tasks like action localization and recognition. The code provides instructions on how to download the processed ActivityNet 1.3 dataset, consisting of videos with corresponding labels, durations, and frames. Users can choose between two methods: downloading precompressed packages or clicking provided hyperlinks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/dataset/ActivityNet.md\":0-23",
            "content": "[\u7b80\u4f53\u4e2d\u6587](../../zh-CN/dataset/ActivityNet.md) | English\n# ActivityNet data preparation\n- [Introduction](#Introduction)\n- [Download](#Download)\n## Introduction\nActivityNet is a dataset for large-scale video understanding tasks, which can be used for tasks such as action localization, action recognition, etc.\n## Download\n1. The BMN model uses the processed ActivityNet 1.3 dataset. There are two ways to use it:\n    - Using our processed ActivityNet 1.3 dataset (compressed package is about 5.5G), each video has corresponding action labels, duration intervals, duration frames, duration seconds and other information\n        Download with the following command:\n        ```bash\n        wget https://paddlemodels.bj.bcebos.com/video_detection/bmn_feat.tar.gz # Download the processed video feature data\n        wget https://paddlemodels.bj.bcebos.com/video_detection/activitynet_1.3_annotations.json # Download the processed label data\n        ```\n        Or click the following hyperlinks to download:\n        [Video feature data](https://paddlemodels.bj.bcebos.com/video_detection/bmn_feat.tar.gz)"
        },
        {
            "comment": "The code is explaining how to download and extract video feature data from the \"activitynet_1.3_annotations.json\" file for a model in PaddleVideo. It mentions decompressing the \"bmn_feat.tar.gz\" file, extracting features by yourself using TSN, and providing the necessary files and instructions to download and pre-train the TSN model. The \"activitynet_1.3_annotations.json\" file contains information about video annotations for training purposes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/dataset/ActivityNet.md\":24-44",
            "content": "        [Video feature data](https://paddlemodels.bj.bcebos.com/video_detection/activitynet_1.3_annotations.json)\n        then decompression `bmn_feat.tar.gz`\n        ```bash\n        tar -xf bmn_feat.tar.gz\n        ```\n    - Extract features by yourself\n        First refer to [Download Instructions](https://github.com/activitynet/ActivityNet/tree/master/Crawler) to download the original dataset. When training this model, you need to use TSN to extract features from the source files first. You can [self-extract](https://github.com/yjxiong/temporal-segment-networks) video frame and optical flow information, and the pre-trained TSN model can be downloaded from [here](https://github.com/ yjxiong/anet2016-cuhk) download.\n    The information in the `activitynet_1.3_annotations.json` tag file is as follows:\n    ```json\n    {\n        \"v_QOlSCBRmfWY\": {\n            \"duration_second\": 82.73,\n            \"subset\": \"training\",\n            \"duration_frame\": 2067,\n            \"annotations\": [{\n                \"segment\": [6.195294851794072, 77.73085420904837],"
        },
        {
            "comment": "The code represents a dictionary containing label information and video feature frame data for 19228 videos. Each key represents a video, and the corresponding value is another dictionary with 'duration_second', 'subset', 'duration_frame', 'feature_frame' keys, and an array of 'annotations' which includes 'segment' (time range) and 'label' information. The code also mentions that there will be 19228 video feature npy files obtained from the activitynet_1.3_annotations.json file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/dataset/ActivityNet.md\":45-76",
            "content": "                \"label\": \"Ballet\"\n            }],\n            \"feature_frame\": 2064\n        },\n        \"v_ehGHCYKzyZ8\": {\n            \"duration_second\": 61.7189999999999994,\n            \"subset\": \"training\",\n            \"duration_frame\": 1822,\n            \"annotations\": [{\n                \"segment\": [43.95990729267573, 45.401932082395355],\n                \"label\": \"Doing crunches\"\n            }],\n            \"feature_frame\": 1808\n        },\n        ...,\n        ...\n    }\n    ```\n    In the end, `19228` video feature npy files are obtained, corresponding to the `19228` label information in the `activitynet_1.3_annotations.json` file.\n2. Create a new `data/bmn_data` folder, and then unzip the video feature data after downloading and put it in this folder, and finally it should be organized into the following form:\n    ```\n    PaddleVideo\n    \u251c\u2500\u2500 data\n    \u2502   \u251c\u2500\u2500 bmn_data\n    \u2502   \u2502   \u251c\u2500\u2500 fix_feat_100\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 v___c8enCfzqw.npy\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 v___dXUJsj3yo.npy\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 ...\n    \u2502   \u2502   \u2502\n    \u2502   \u2502   \u2514\u2500\u2500 activitynet_1.3_annotations.json"
        },
        {
            "comment": "In the code, it is instructing to modify two fields in the configuration file. The `feat_path` field needs updating with the feature directory path, and the `file_path` should be specified for the label file path. This ensures proper data access during program execution.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/dataset/ActivityNet.md\":77-79",
            "content": "    ```\n3. Finally, modify the `feat_path` field in the configuration file configs/localization/bmn.yaml to specify the feature directory path, and the `file_path` field to specify the label file path."
        }
    ]
}