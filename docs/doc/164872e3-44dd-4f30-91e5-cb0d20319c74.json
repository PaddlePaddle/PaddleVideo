{
    "summary": "The code presents a CTRGCN backbone for video models, initializes a CTRGC model with batch normalization layers and NTUGraph class, defines a neural network model with TCN_GCN_unit, and includes a final layer 10 (l10) to process input and return output.",
    "details": [
        {
            "comment": "This code imports necessary libraries, defines a convolution initialization function and a batch normalization initialization function. It also sets up scale values for the batch normalization function and registers backbone models in the registry.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":0-30",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as F\nimport numpy as np\nfrom ..registry import BACKBONES\nfrom ..weight_init import weight_init_\ndef conv_init(conv):\n    if conv.weight is not None:\n        weight_init_(conv.weight, 'kaiming_normal_', mode='fan_in')\n    if conv.bias is not None:\n        nn.initializer.Constant(value=0.0)(conv.bias)\ndef bn_init(bn, scale):\n    nn.initializer.Constant(value=float(scale))(bn.weight)"
        },
        {
            "comment": "Defines a CTRGC class, a type of convolutional neural network layer. It has two reductions: rel_reduction (defaults to 8) and mid_reduction (defaults to 1). Depending on the input channels, it assigns different channel numbers for rel_channels (always 8 if in_channels is 3 or 9; otherwise based on rel_reduction). It also initializes a Conv2D layer with the assigned channel numbers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":31-65",
            "content": "    nn.initializer.Constant(value=0.0)(bn.bias)\ndef einsum(x1, x3):\n    \"\"\"paddle.einsum only support in dynamic graph mode.\n    x1 : n c u v\n    x2 : n c t v\n    \"\"\"\n    n, c, u, v1 = x1.shape\n    n, c, t, v3 = x3.shape\n    assert (v1 == v3), \"Args of einsum not match!\"\n    x1 = paddle.transpose(x1, perm=[0, 1, 3, 2])  # n c v u\n    y = paddle.matmul(x3, x1)\n    # out: n c t u\n    return y\nclass CTRGC(nn.Layer):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 rel_reduction=8,\n                 mid_reduction=1):\n        super(CTRGC, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        if in_channels == 3 or in_channels == 9:\n            self.rel_channels = 8\n            self.mid_channels = 16\n        else:\n            self.rel_channels = in_channels // rel_reduction\n            self.mid_channels = in_channels // mid_reduction\n        self.conv1 = nn.Conv2D(self.in_channels,\n                               self.rel_channels,"
        },
        {
            "comment": "This code defines a Convolutional Temporal Relational Graph Convolutional Network (CTRGCN) backbone for a video model. It initializes weights and performs forward pass calculations. It uses convolution layers, tanh activation function, and optionally includes an additional input A.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":66-92",
            "content": "                               kernel_size=1)\n        self.conv2 = nn.Conv2D(self.in_channels,\n                               self.rel_channels,\n                               kernel_size=1)\n        self.conv3 = nn.Conv2D(self.in_channels,\n                               self.out_channels,\n                               kernel_size=1)\n        self.conv4 = nn.Conv2D(self.rel_channels,\n                               self.out_channels,\n                               kernel_size=1)\n        self.tanh = nn.Tanh()\n    def init_weights(self):\n        \"\"\"Initiate the parameters.\n        \"\"\"\n        for m in self.sublayers():\n            if isinstance(m, nn.Conv2D):\n                conv_init(m)\n            elif isinstance(m, nn.BatchNorm2D):\n                bn_init(m, 1)\n    def forward(self, x, A=None, alpha=1):\n        x1, x2, x3 = self.conv1(x).mean(-2), self.conv2(x).mean(-2), self.conv3(\n            x)\n        x1 = self.tanh(x1.unsqueeze(-1) - x2.unsqueeze(-2))\n        x1 = self.conv4(x1) * alpha + (\n            A.unsqueeze(0).unsqueeze(0) if A is not None else 0)  # N,C,V,V"
        },
        {
            "comment": "Code snippet defines a class TemporalConv, which is a 2D convolutional layer for temporal data. It inherits from the paddle.nn.Layer and includes an instance of nn.Conv2D and nn.BatchNorm2D layers. The MultiScale_TemporalConv class is also defined but its implementation is missing, suggesting it extends TemporalConv with multiple temporal convolution blocks for multi-scale processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":93-126",
            "content": "        # We only support 'paddle.einsum()' in dynamic graph mode, if use in infer model please implement self.\n        # x1 = paddle.einsum('ncuv,nctv->nctu', x1, x3)\n        x1 = einsum(x1, x3)\n        return x1\nclass TemporalConv(nn.Layer):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 kernel_size,\n                 stride=1,\n                 dilation=1):\n        super(TemporalConv, self).__init__()\n        pad = (kernel_size + (kernel_size - 1) * (dilation - 1) - 1) // 2\n        self.conv = nn.Conv2D(in_channels,\n                              out_channels,\n                              kernel_size=(kernel_size, 1),\n                              padding=(pad, 0),\n                              stride=(stride, 1),\n                              dilation=(dilation, 1))\n        self.bn = nn.BatchNorm2D(out_channels)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return x\nclass MultiScale_TemporalConv(nn.Layer):\n    def __init__(self,"
        },
        {
            "comment": "This code defines a MultiScale_TemporalConv layer with multiple branches of temporal convolution. The number of branches is determined by the dilations, and out channels should be multiples of the number of branches for correct operation. Each branch has its own kernel size, and there are Conv2D layers followed by BatchNorm2D for each branch.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":127-154",
            "content": "                 in_channels,\n                 out_channels,\n                 kernel_size=3,\n                 stride=1,\n                 dilations=[1, 2, 3, 4],\n                 residual=True,\n                 residual_kernel_size=1):\n        super(MultiScale_TemporalConv, self).__init__()\n        assert out_channels % (\n            len(dilations) +\n            2) == 0, '# out channels should be multiples of # branches'\n        # Multiple branches of temporal convolution\n        self.num_branches = len(dilations) + 2\n        branch_channels = out_channels // self.num_branches\n        if type(kernel_size) == list:\n            assert len(kernel_size) == len(dilations)\n        else:\n            kernel_size = [kernel_size] * len(dilations)\n        # Temporal Convolution branches\n        self.branches = nn.LayerList([\n            nn.Sequential(\n                nn.Conv2D(in_channels,\n                          branch_channels,\n                          kernel_size=1,\n                          padding=0),\n                nn.BatchNorm2D(branch_channels),"
        },
        {
            "comment": "This code defines a Conv-Temporal RGN backbone model for video analysis. It consists of multiple branches with various convolutional and pooling layers, including TemporalConv and MaxPool2D operations. The branches are appended to the model and initialized with respective settings such as kernel size, dilation rate, etc.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":155-181",
            "content": "                nn.ReLU(),\n                TemporalConv(branch_channels,\n                             branch_channels,\n                             kernel_size=ks,\n                             stride=stride,\n                             dilation=dilation),\n            ) for ks, dilation in zip(kernel_size, dilations)\n        ])\n        # Additional Max & 1x1 branch\n        self.branches.append(\n            nn.Sequential(\n                nn.Conv2D(in_channels,\n                          branch_channels,\n                          kernel_size=1,\n                          padding=0), nn.BatchNorm2D(branch_channels),\n                nn.ReLU(),\n                nn.MaxPool2D(kernel_size=(3, 1),\n                             stride=(stride, 1),\n                             padding=(1, 0)), nn.BatchNorm2D(branch_channels)))\n        self.branches.append(\n            nn.Sequential(\n                nn.Conv2D(in_channels,\n                          branch_channels,\n                          kernel_size=1,\n                          padding=0,"
        },
        {
            "comment": "This code defines a class for a Conv-Temporal Residual Group Convolutional Network (CTRGCN) backbone. The class contains a constructor that sets up the architecture, an initialization function to set the weights, and a forward pass function for feeding data into the model. It performs residual connections using temporal convolutions and has batch normalization layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":182-210",
            "content": "                          stride=(stride, 1)), nn.BatchNorm2D(branch_channels)))\n        # Residual connection\n        if not residual:\n            self.residual = lambda x: 0\n        elif (in_channels == out_channels) and (stride == 1):\n            self.residual = lambda x: x\n        else:\n            self.residual = TemporalConv(in_channels,\n                                         out_channels,\n                                         kernel_size=residual_kernel_size,\n                                         stride=stride)\n    def init_weights(self):\n        \"\"\"Initiate the parameters.\n        \"\"\"\n        # initialize\n        for m in self.sublayers():\n            if isinstance(m, nn.Conv2D):\n                conv_init(m)\n            elif isinstance(m, nn.BatchNorm2D):\n                weight_init_(m.weight, 'Normal', std=0.02, mean=1.0)\n                nn.initializer.Constant(value=0.0)(m.bias)\n    def forward(self, x):\n        # Input dim: (N,C,T,V)\n        res = self.residual(x)\n        branch_outs = []\n        for tempconv in self.branches:"
        },
        {
            "comment": "This code defines two classes: \"unit_tcn\" and \"unit_gcn\". The \"unit_tcn\" class is a Temporal Convolutional Network unit that performs temporal convolution with batch normalization and ReLU activation. The \"unit_gcn\" class is a Graph Convolutional Network unit that takes input channels, output channels, adjacency matrix A, coefficient embedding, adaptive flag, and residual flag as parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":211-249",
            "content": "            out = tempconv(x)\n            branch_outs.append(out)\n        out = paddle.concat(branch_outs, axis=1)\n        out += res\n        return out\nclass unit_tcn(nn.Layer):\n    def __init__(self, in_channels, out_channels, kernel_size=9, stride=1):\n        super(unit_tcn, self).__init__()\n        pad = int((kernel_size - 1) / 2)\n        self.conv = nn.Conv2D(in_channels,\n                              out_channels,\n                              kernel_size=(kernel_size, 1),\n                              padding=(pad, 0),\n                              stride=(stride, 1))\n        self.bn = nn.BatchNorm2D(out_channels)\n        self.relu = nn.ReLU()\n        conv_init(self.conv)\n        bn_init(self.bn, 1)\n    def forward(self, x):\n        x = self.bn(self.conv(x))\n        return x\nclass unit_gcn(nn.Layer):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 A,\n                 coff_embedding=4,\n                 adaptive=True,\n                 residual=True):\n        super(unit_gcn, self).__init__()"
        },
        {
            "comment": "This code initializes a CTRGC model with specified input and output channels. It also includes optional residual connection, batch normalization, and adaptive parameterization. The number of subsets is determined by the shape of A. If adaptive is set to True, it creates a trainable parameter for the subset of weights.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":250-275",
            "content": "        inter_channels = out_channels // coff_embedding\n        self.inter_c = inter_channels\n        self.out_c = out_channels\n        self.in_c = in_channels\n        self.adaptive = adaptive\n        self.num_subset = A.shape[0]\n        self.convs = nn.LayerList()\n        for i in range(self.num_subset):\n            self.convs.append(CTRGC(in_channels, out_channels))\n        if residual:\n            if in_channels != out_channels:\n                self.down = nn.Sequential(\n                    nn.Conv2D(in_channels, out_channels, 1),\n                    nn.BatchNorm2D(out_channels))\n            else:\n                self.down = lambda x: x\n        else:\n            self.down = lambda x: 0\n        if self.adaptive:\n            pa_param = paddle.ParamAttr(\n                initializer=paddle.nn.initializer.Assign(A.astype(np.float32)))\n            self.PA = paddle.create_parameter(shape=A.shape,\n                                              dtype='float32',\n                                              attr=pa_param)"
        },
        {
            "comment": "This code initializes the parameters A and alpha, sets up batch normalization (bn) layers with Softmax and ReLU activation functions, initializes weights using conv_init and bn_init functions, and defines a forward pass that adapts A based on the adaptive flag.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":276-305",
            "content": "        else:\n            A_tensor = paddle.to_tensor(A, dtype=\"float32\")\n            self.A = paddle.create_parameter(\n                shape=A_tensor.shape,\n                dtype='float32',\n                default_initializer=paddle.nn.initializer.Assign(A_tensor))\n            self.A.stop_gradient = True\n        alpha_tensor = paddle.to_tensor(np.zeros(1), dtype=\"float32\")\n        self.alpha = paddle.create_parameter(\n            shape=alpha_tensor.shape,\n            dtype='float32',\n            default_initializer=paddle.nn.initializer.Assign(alpha_tensor))\n        self.bn = nn.BatchNorm2D(out_channels)\n        self.soft = nn.Softmax(-2)\n        self.relu = nn.ReLU()\n    def init_weights(self):\n        for m in self.sublayers():\n            if isinstance(m, nn.Conv2D):\n                conv_init(m)\n            elif isinstance(m, nn.BatchNorm2D):\n                bn_init(m, 1)\n        bn_init(self.bn, 1e-6)\n    def forward(self, x):\n        y = None\n        if self.adaptive:\n            A = self.PA\n        else:\n            A = self.A.cuda(x.get_device())"
        },
        {
            "comment": "This code defines a TCN_GCN_unit class, which is a combination of Graph Convolutional Network (GCN) and Temporal Convolution units. The unit takes input channels, output channels, adjacency matrix A, stride, residual connection, adaptive flag, kernel size, and dilations as parameters. It initializes the GCN and TemporalConv layers, followed by a ReLU activation function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":306-334",
            "content": "        for i in range(self.num_subset):\n            z = self.convs[i](x, A[i], self.alpha)\n            y = z + y if y is not None else z\n        y = self.bn(y)\n        y += self.down(x)\n        y = self.relu(y)\n        return y\nclass TCN_GCN_unit(nn.Layer):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 A,\n                 stride=1,\n                 residual=True,\n                 adaptive=True,\n                 kernel_size=5,\n                 dilations=[1, 2]):\n        super(TCN_GCN_unit, self).__init__()\n        self.gcn1 = unit_gcn(in_channels, out_channels, A, adaptive=adaptive)\n        self.tcn1 = MultiScale_TemporalConv(out_channels,\n                                            out_channels,\n                                            kernel_size=kernel_size,\n                                            stride=stride,\n                                            dilations=dilations,\n                                            residual=False)\n        self.relu = nn.ReLU()"
        },
        {
            "comment": "The code defines a `CTRGCN` class with a `forward` method and an `NTUDGraph` class. The `forward` method takes input `x`, applies `relu` activation and adds the residual output of a `unit_tcn` layer or simply passes through if specified conditions are met. The `NTUDGraph` initializes with a fixed number of nodes, self-links, and inward connections.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":335-362",
            "content": "        if not residual:\n            self.residual = lambda x: 0\n        elif (in_channels == out_channels) and (stride == 1):\n            self.residual = lambda x: x\n        else:\n            self.residual = unit_tcn(in_channels,\n                                     out_channels,\n                                     kernel_size=1,\n                                     stride=stride)\n    def forward(self, x):\n        y = self.relu(self.tcn1(self.gcn1(x)) + self.residual(x))\n        return y\nclass NTUDGraph:\n    def __init__(self, labeling_mode='spatial'):\n        num_node = 25\n        self_link = [(i, i) for i in range(num_node)]\n        inward_ori_index = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21), (6, 5),\n                            (7, 6), (8, 7), (9, 21), (10, 9), (11, 10),\n                            (12, 11), (13, 1), (14, 13), (15, 14), (16, 15),\n                            (17, 1), (18, 17), (19, 18), (20, 19), (22, 23),\n                            (23, 8), (24, 25), (25, 12)]\n        inward = [(i - 1, j - 1) for (i, j) in inward_ori_index]"
        },
        {
            "comment": "Function `get_adjacency_matrix` generates adjacency matrices for the model. The function takes a parameter `labeling_mode`, which is optional. It initializes a set of variables: `inward`, `outward`, and `neighbor`. These variables store the connections between nodes in both directions. Then, it calls other helper functions to generate normalized adjacency matrices for self-links, inward edges, outward edges, and finally returns an array containing all these matrices. This is useful for inputting into a model that requires specific formatted input data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":363-396",
            "content": "        outward = [(j, i) for (i, j) in inward]\n        neighbor = inward + outward\n        self.num_node = num_node\n        self.self_link = self_link\n        self.inward = inward\n        self.outward = outward\n        self.neighbor = neighbor\n        self.A = self.get_adjacency_matrix(labeling_mode)\n    def edge2mat(self, link, num_node):\n        A = np.zeros((num_node, num_node))\n        for i, j in link:\n            A[j, i] = 1\n        return A\n    def normalize_digraph(self, A):\n        Dl = np.sum(A, 0)\n        h, w = A.shape\n        Dn = np.zeros((w, w))\n        for i in range(w):\n            if Dl[i] > 0:\n                Dn[i, i] = Dl[i]**(-1)\n        AD = np.dot(A, Dn)\n        return AD\n    def get_spatial_graph(self, num_node, self_link, inward, outward):\n        I = self.edge2mat(self_link, num_node)\n        In = self.normalize_digraph(self.edge2mat(inward, num_node))\n        Out = self.normalize_digraph(self.edge2mat(outward, num_node))\n        A = np.stack((I, In, Out))\n        return A\n    def get_adjacency_matrix(self, labeling_mode=None):"
        },
        {
            "comment": "This code is part of the CTRGCN class in the PaddleVideo library, which represents a specific type of model for skeleton-based action recognition. The function within this code block is used to return an adjacency matrix (A) based on a given labeling mode. If no labeling mode is specified, it returns the adjacency matrix from the instance variables. If the labeling mode is set to 'spatial', it calls another function to generate a spatial adjacency graph. Otherwise, if an invalid labeling mode is provided, it raises a ValueError exception.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":397-425",
            "content": "        if labeling_mode is None:\n            return self.A\n        if labeling_mode == 'spatial':\n            A = self.get_spatial_graph(self.num_node, self.self_link,\n                                       self.inward, self.outward)\n        else:\n            raise ValueError()\n        return A\n@BACKBONES.register()\nclass CTRGCN(nn.Layer):\n    \"\"\"\n    CTR-GCN model from:\n    `\"Channel-wise Topology Refinement Graph Convolution for Skeleton-Based Action Recognition\" <https://arxiv.org/abs/2107.12213>`_\n    Args:\n        num_point: int, numbers of sketeton point.\n        num_person: int, numbers of person.\n        base_channel: int, model's hidden dim.\n        graph: str, sketeton adjacency matrix name.\n        graph_args: dict, sketeton adjacency graph class args.\n        in_channels: int, channels of vertex coordinate. 2 for (x,y), 3 for (x,y,z). Default 3.\n        adaptive: bool, if adjacency matrix can adaptive.\n    \"\"\"\n    def __init__(self,\n                 num_point=25,\n                 num_person=2,\n                 base_channel=64,"
        },
        {
            "comment": "This code defines the CTRGCN class, which initializes its graph and layers based on input parameters. It includes a batch normalization layer (data_bn) and three TCN_GCN_unit layers (l1, l2, l3). The graph is determined by the 'graph' parameter, with NTUDGraph used if 'ntu_rgb_d'. If another graph is provided, it raises a ValueError.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":426-454",
            "content": "                 graph='ntu_rgb_d',\n                 graph_args=dict(),\n                 in_channels=3,\n                 adaptive=True):\n        super(CTRGCN, self).__init__()\n        if graph == 'ntu_rgb_d':\n            self.graph = NTUDGraph(**graph_args)\n        else:\n            raise ValueError()\n        A = self.graph.A  # 3,25,25\n        self.num_point = num_point\n        self.data_bn = nn.BatchNorm1D(num_person * in_channels * num_point)\n        self.base_channel = base_channel\n        self.l1 = TCN_GCN_unit(in_channels,\n                               self.base_channel,\n                               A,\n                               residual=False,\n                               adaptive=adaptive)\n        self.l2 = TCN_GCN_unit(self.base_channel,\n                               self.base_channel,\n                               A,\n                               adaptive=adaptive)\n        self.l3 = TCN_GCN_unit(self.base_channel,\n                               self.base_channel,\n                               A,"
        },
        {
            "comment": "The code initializes six TCN_GCN_unit layers, each with different configurations, for a CTRGCN model. The first layer (l4) has the base channel as input and output. Following layers (l5 to l8) increase the number of channels or apply strides. This represents a deep TCN-GCN architecture with progressively increasing depth and downsampling.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":455-476",
            "content": "                               adaptive=adaptive)\n        self.l4 = TCN_GCN_unit(self.base_channel,\n                               self.base_channel,\n                               A,\n                               adaptive=adaptive)\n        self.l5 = TCN_GCN_unit(self.base_channel,\n                               self.base_channel * 2,\n                               A,\n                               stride=2,\n                               adaptive=adaptive)\n        self.l6 = TCN_GCN_unit(self.base_channel * 2,\n                               self.base_channel * 2,\n                               A,\n                               adaptive=adaptive)\n        self.l7 = TCN_GCN_unit(self.base_channel * 2,\n                               self.base_channel * 2,\n                               A,\n                               adaptive=adaptive)\n        self.l8 = TCN_GCN_unit(self.base_channel * 2,\n                               self.base_channel * 4,\n                               A,\n                               stride=2,"
        },
        {
            "comment": "This code defines a neural network model with multiple layers. It uses Paddle's TCN_GCN_unit in the last two layers. The init_weights function initializes batch normalization for the data_bn layer, and the forward function processes input through multiple layers before returning the final output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":477-510",
            "content": "                               adaptive=adaptive)\n        self.l9 = TCN_GCN_unit(self.base_channel * 4,\n                               self.base_channel * 4,\n                               A,\n                               adaptive=adaptive)\n        self.l10 = TCN_GCN_unit(self.base_channel * 4,\n                                self.base_channel * 4,\n                                A,\n                                adaptive=adaptive)\n    def init_weights(self):\n        bn_init(self.data_bn, 1)\n    def forward(self, x):\n        N, C, T, V, M = x.shape\n        x = paddle.transpose(x, perm=[0, 4, 3, 1, 2])\n        x = paddle.reshape(x, (N, M * V * C, T))\n        x = self.data_bn(x)\n        x = paddle.reshape(x, (N, M, V, C, T))\n        x = paddle.transpose(x, perm=(0, 1, 3, 4, 2))\n        x = paddle.reshape(x, (N * M, C, T, V))\n        x = self.l1(x)\n        x = self.l2(x)\n        x = self.l3(x)\n        x = self.l4(x)\n        x = self.l5(x)\n        x = self.l6(x)\n        x = self.l7(x)\n        x = self.l8(x)\n        x = self.l9(x)"
        },
        {
            "comment": "This code represents the final step of a neural network function. It applies layer 10 (l10) to input x, and returns both the updated x and the original N, M values. This function seems to be part of a larger model, as it references previous layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/ctrgcn.py\":511-513",
            "content": "        x = self.l10(x)\n        return x, N, M"
        }
    ]
}