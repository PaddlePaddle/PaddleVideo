{
    "summary": "TransNetV2 is a deep learning-based video segmentation model for shot transition detection, using DDCNN V2 structure, RGB color histograms, and frame similarity. The provided code demonstrates usage of predict.py to infer predictions on input files, with output probabilities and lens boundaries.",
    "details": [
        {
            "comment": "TransNetV2 is a video segmentation model based on deep learning using DDCNN V2 structure for feature learning, RGB color histograms, and video frame similarity for effective feature extraction. This code supports inference only, with training and testing to be provided later. Suitable for industrial applications, more details are available in the paper.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/partition/transnetv2.md\":0-27",
            "content": "[\u7b80\u4f53\u4e2d\u6587](../../../zh-CN/model_zoo/partition/transnetv2.md) | English\n# TransNetV2\n## Contents\n- [Introduction](#Introduction)\n- [Data](#Data)\n- [Train](#Train)\n- [Test](#Test)\n- [Inference](#Inference)\n- [Details](#Details)\n- [Reference](#Reference)\nBefore getting started, you need to install additional dependencies as follows:\n```bash\npython -m pip install ffmpeg-python==0.2.0\n```\n## Introduction\nTransNetV2 is a video segmentation model based on deep learning. It performs feature learning through the DDCNN V2 structure, and adds RGB color histograms and video frame similarity for more effective feature extraction, and finally obtains whether each frame is a shot boundary frame Probability, thereby completing the video segmentation. The algorithm has good effect and efficient calculation, which is very suitable for industrial landing.\n![](../../../images/transnetv2.png)\nThis code currently only supports model inference, and model training and testing will be provided in the future.\nPlease refer to the pap"
        },
        {
            "comment": "This code provides instructions to load and export the TransNet V2 inference model for shot transition detection. It mentions the required weights trained on ClipShots and TRECVID IACC.3 dataset, as well as the URL to download them using wget command. The script also outlines how to use `export_model.py` tool to generate the `TransNetV2.pdmodel` and `TransNetV2.pdiparams` files for prediction purposes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/partition/transnetv2.md\":27-61",
            "content": "er for details. [TransNet V2: An effective deep network architecture for fast shot transition detection](https://arxiv.org/abs/2008.04838)\n## Data\ncoming soon\n## Train\ncoming soon\n## Test\ncoming soon\n## Inference\nLoad the TransNetV2 weights trained on ClipShots and TRECVID IACC.3 dataset [TransNetV2_shots.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.2/TransNetV2_shots.pdparams), or download through the command line\n```bash\nwget https://videotag.bj.bcebos.com/PaddleVideo-release2.2/TransNetV2_shots.pdparams\n```\n### export inference model\n```bash\npython3.7 tools/export_model.py -c configs/partitioners/transnetv2/transnetv2.yaml -p data/TransNetV2_shots.pdparams -o inference/TransNetV2\n```\nThe above command will generate the model structure file`TransNetV2.pdmodel`and the model weight file`TransNetV2.pdiparams`required for prediction.\nFor the meaning of each parameter, please refer to [Model Reasoning Method](https://github.com/PaddlePaddle/PaddleVideo/blob/release/2.0/docs/zh-CN/start.md#2-Model Reasoning)"
        },
        {
            "comment": "This code snippet demonstrates the usage of predict.py to infer TransNetV2 model predictions for a given input file (example.avi). The model configuration is specified in transnetv2.yaml, and the trained model files are provided as inputs. Prediction probability per frame is output to example_predictions.txt and lens boundary is output to example_scenes.txt. Visualization can be enabled for better interpretation of results.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/partition/transnetv2.md\":63-79",
            "content": "### infer\n```bash\npython3.7 tools/predict.py --input_file data/example.avi \\\n                           --config configs/partitioners/transnetv2/transnetv2.yaml \\\n                           --model_file inference/TransNetV2/TransNetV2.pdmodel \\\n                           --params_file inference/TransNetV2/TransNetV2.pdiparams \\\n                           --use_gpu=True \\\n                           --use_tensorrt=False\n```\nBy defining the `output_path` parameters in `transnetv2.yaml`, the prediction probability of each frame can be output to `{output_path}/example_predictions.txt`, and the predicted lens boundary is output to `{output_path}/example_scenes.txt`.\nBy defining the `visualize` parameter in `transnetv2.yaml`, the predicted results can be visualized, and the visual results are saved to `{output_path}/example_vis.png`.\n## Reference\n- [TransNet V2: An effective deep network architecture for fast shot transition detection](https://arxiv.org/abs/2008.04838), Tom\u00e1\u0161 Sou\u010dek, Jakub Loko\u010d"
        }
    ]
}