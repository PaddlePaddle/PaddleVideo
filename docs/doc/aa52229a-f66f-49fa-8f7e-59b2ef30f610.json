{
    "summary": "The README guides using PaddleVideo's Fight Recognition model for detecting fight and non-fight videos across four datasets. It includes data preparation, training, evaluation, exporting, quickstart guidance, and GPU usage control.",
    "details": [
        {
            "comment": "This README provides an overview of the Fight Recognition model using PaddleVideo, including sections on quick start, data preparation, model training, evaluation, and model export. The PP-TSM model is used for fight recognition and can be adapted from the existing PP-TSM video classification model training process. Quickstart instructions and download links are provided, along with information on where to find additional usage guidance.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":0-28",
            "content": "# \u6253\u67b6\u8bc6\u522b\u6a21\u578b\n## \u5185\u5bb9\n- [1 \u5feb\u901f\u5f00\u59cb](#\u5feb\u901f\u5f00\u59cb)\n- [2 \u6570\u636e\u51c6\u5907](#\u6570\u636e\u51c6\u5907)\n    - [2.1 \u6570\u636e\u96c6\u4e0b\u8f7d](#\u6570\u636e\u96c6\u4e0b\u8f7d)\n    - [2.2 \u89c6\u9891\u62bd\u5e27](#\u89c6\u9891\u62bd\u5e27)\n    - [2.3 \u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u5212\u5206](#\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u5212\u5206)\n    - [2.4 \u89c6\u9891\u88c1\u526a](#\u89c6\u9891\u88c1\u526a)\n- [3 \u6a21\u578b\u8bad\u7ec3](#\u6a21\u578b\u8bad\u7ec3)\n- [4 \u6a21\u578b\u8bc4\u4f30](#\u6a21\u578b\u8bc4\u4f30)\n- [5 \u6a21\u578b\u5bfc\u51fa](#\u6a21\u578b\u5bfc\u51fa)\n\u5b9e\u65f6\u884c\u4eba\u5206\u6790\u5de5\u5177[PP-Human](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4/deploy/pphuman)\u4e2d\u96c6\u6210\u4e86\u89c6\u9891\u5206\u7c7b\u7684\u6253\u67b6\u8bc6\u522b\u6a21\u5757\u3002\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u57fa\u4e8e[PaddleVideo](https://github.com/PaddlePaddle/PaddleVideo/)\uff0c\u5b8c\u6210\u6253\u67b6\u8bc6\u522b\u6a21\u578b\u7684\u8bad\u7ec3\u6d41\u7a0b\u3002\n\u76ee\u524d\u6253\u67b6\u8bc6\u522b\u6a21\u578b\u4f7f\u7528\u7684\u662f[PP-TSM](https://github.com/PaddlePaddle/PaddleVideo/blob/63c88a435e98c6fcaf353429d2df6cc24b8113ba/docs/zh-CN/model_zoo/recognition/pp-tsm.md)\uff0c\u5e76\u5728PP-TSM\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u8bad\u7ec3\u6d41\u7a0b\u7684\u57fa\u7840\u4e0a\u4fee\u6539\u9002\u914d\uff0c\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3\u3002\n\u8bf7\u5148\u53c2\u8003[\u4f7f\u7528\u8bf4\u660e](https://github.com/XYZ-916/PaddleVideo/blob/develop/docs/zh-CN/usage.md)\u4e86\u89e3PaddleVideo\u6a21\u578b\u5e93\u7684\u4f7f\u7528\u3002\n<a name=\"\u5feb\u901f\u5f00\u59cb\"></a>\n## 1 \u5feb\u901f\u5f00\u59cb\n\u6253\u67b6\u8bc6\u522b\u9759\u6001\u56fe\u6a21\u578b\u83b7\u53d6[https://videotag.bj.bcebos.com/PaddleVideo-release2.3/ppTSM_fight.zip](https://videotag.bj.bcebos.com/PaddleVideo-release2.3/ppTSM_fight.zip)\u3002\n\u6253\u67b6\u8bc6\u522b[demo](https://videotag.bj.bcebos.com/PaddleVideo-release2.3/fight_demo.mp4)\u3002\n\u9996\u5148\u9700\u8981\u5c06\u4e0b\u8f7d\u597d\u7684\u9759\u6001\u56fe\u6a21\u578b\u89e3\u538b\u5e76\u653e\u5230`inference`\u76ee\u5f55\u4e0b\uff0c\u7136\u540e\u6267\u884c\u4e0b\u9762\u7684\u547d\u4ee4\u5373\u53ef\u76f4\u63a5\u5224\u65ad\u4e00\u4e2a\u7ed9\u5b9a\u7684\u89c6\u9891\u4e2d\u662f\u5426\u5b58\u5728\u6253\u67b6\u884c\u4e3a\uff1a"
        },
        {
            "comment": "This code is executing a Python script named \"predict.py\" in PaddleVideo's root directory, to predict fight events from a video file named 'fight.avi'. It uses the pre-trained pptsm_fight_frames_dense model and sets GPU usage and TensorRT as False.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":30-54",
            "content": "```\ncd ${PaddleVideo_root}\npython tools/predict.py --input_file fight.avi \\\n                           --config pptsm_fight_frames_dense.yaml \\\n                           --model_file inference/ppTSM/ppTSM.pdmodel \\\n                           --params_file inference/ppTSM/ppTSM.pdiparams \\\n                           --use_gpu=True \\\n                           --use_tensorrt=False\n```\n<a name=\"\u6570\u636e\u51c6\u5907\"></a>\n## 2 \u6570\u636e\u51c6\u5907\nPP-TSM\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u9891\u7247\u6bb5\u8fdb\u884c\u9884\u6d4b\u7684\u6a21\u578b\u3002\u5728PaddleVideo\u4e2d\uff0c\u8bad\u7ec3\u6570\u636e\u4e3a`.mp4`\u3001`.avi`\u7b49\u683c\u5f0f\u89c6\u9891\u6216\u8005\u662f\u62bd\u5e27\u540e\u7684\u89c6\u9891\u5e27\u5e8f\u5217\uff0c\u6807\u7b7e\u5219\u53ef\u4ee5\u662f`.txt`\u683c\u5f0f\u5b58\u50a8\u7684\u6587\u4ef6\u3002\n<a name=\"\u6570\u636e\u96c6\u4e0b\u8f7d\"></a>\n### 2.1 \u6570\u636e\u96c6\u4e0b\u8f7d\n\u672c\u9879\u76ee\u57fa\u4e8e6\u4e2a\u516c\u5f00\u7684\u6253\u67b6\u3001\u66b4\u529b\u884c\u4e3a\u76f8\u5173\u6570\u636e\u96c6\u5408\u5e76\u540e\u7684\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002\u516c\u5f00\u6570\u636e\u96c6\u5177\u4f53\u4fe1\u606f\u5982\u4e0b\uff1a\n| \u6570\u636e\u96c6 | \u4e0b\u8f7d\u8fde\u63a5 | \u7b80\u4ecb | \u6807\u6ce8 | \u6570\u91cf | \u65f6\u957f |\n| ---- | ---- | ---------- | ---- | ---- | ---------- |\n|  Surveillance Camera Fight Dataset| https://github.com/sayibet/fight-detection-surv-dataset | \u88c1\u526a\u89c6\u9891\uff0c\u76d1\u63a7\u89c6\u89d2 | \u89c6\u9891\u7ea7\u522b | \u6253\u67b6\uff1a150\uff1b\u975e\u6253\u67b6\uff1a150 | 2s |\n| A Dataset for Automatic Violence Detection in Videos | https://github.com/airtlab/A-Dataset-for-Automatic-Violence-Detection-in-Videos | \u88c1\u526a\u89c6\u9891\uff0c\u5ba4\u5185\u81ea\u884c\u5f55\u5236 | \u89c6\u9891\u7ea7\u522b | \u66b4\u529b\u884c\u4e3a\uff1a115\u4e2a\u573a\u666f\uff0c2\u4e2a\u673a\u4f4d\uff0c\u5171230 \uff1b\u975e\u66b4\u529b\u884c\u4e3a\uff1a60\u4e2a\u573a\u666f\uff0c2\u4e2a\u673a\u4f4d\uff0c\u5171120 | \u51e0\u79d2\u949f |"
        },
        {
            "comment": "Code comments:\n- Hockey Fight Detection Dataset: URL, clipped videos, non-realistic scenarios, video level, 500 fight and 500 non-fight videos, 2s duration.\n- Video Fight Detection Dataset: URL, clipped videos, non-realistic scenarios, video level, 100 fights and 101 non-fights, 2s duration.\n- Real Life Violence Situations Dataset: URL, clipped videos, non-realistic scenarios, video level, 1000 fights and 1000 non-fights, a few seconds duration.\n- UBI Abnormal Event Detection Dataset: URL, unclipped videos, surveillance angle, frame level, 216 fights, 784 non-fights, 7,840 frames total, original video durations varying from a few seconds to a few minutes.\n- Extracting rawframes for faster training by running a script in PaddleVideo_root.\n- Split dataset into fight and non-fight videos stored in fight and nofight directories respectively.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":55-74",
            "content": "| Hockey Fight Detection Dataset | https://www.kaggle.com/datasets/yassershrief/hockey-fight-vidoes?resource=download | \u88c1\u526a\u89c6\u9891\uff0c\u975e\u771f\u5b9e\u573a\u666f | \u89c6\u9891\u7ea7\u522b | \u6253\u67b6\uff1a500\uff1b\u975e\u6253\u67b6\uff1a500 | 2s |\n| Video Fight Detection Dataset | https://www.kaggle.com/datasets/naveenk903/movies-fight-detection-dataset | \u88c1\u526a\u89c6\u9891\uff0c\u975e\u771f\u5b9e\u573a\u666f | \u89c6\u9891\u7ea7\u522b | \u6253\u67b6\uff1a100\uff1b\u975e\u6253\u67b6\uff1a101 | 2s |\n| Real Life Violence Situations Dataset | https://www.kaggle.com/datasets/mohamedmustafa/real-life-violence-situations-dataset | \u88c1\u526a\u89c6\u9891\uff0c\u975e\u771f\u5b9e\u573a\u666f | \u89c6\u9891\u7ea7\u522b | \u66b4\u529b\u884c\u4e3a\uff1a1000\uff1b\u975e\u66b4\u529b\u884c\u4e3a\uff1a1000 | \u51e0\u79d2\u949f |\n| UBI Abnormal Event Detection Dataset| http://socia-lab.di.ubi.pt/EventDetection/ | \u672a\u88c1\u526a\u89c6\u9891\uff0c\u76d1\u63a7\u89c6\u89d2 | \u5e27\u7ea7\u522b | \u6253\u67b6\uff1a216\uff1b\u975e\u6253\u67b6\uff1a784\uff1b\u88c1\u526a\u540e\u4e8c\u6b21\u6807\u6ce8\uff1a\u6253\u67b61976\uff0c\u975e\u6253\u67b61630 | \u539f\u89c6\u9891\u51e0\u79d2\u5230\u51e0\u5206\u949f\u4e0d\u7b49\uff0c\u88c1\u526a\u540e2s |\n\u6253\u67b6\uff08\u66b4\u529b\u884c\u4e3a\uff09\u89c6\u98913956\u4e2a\uff0c\u975e\u6253\u67b6\uff08\u975e\u66b4\u529b\u884c\u4e3a\uff09\u89c6\u98913501\u4e2a\uff0c\u51717457\u4e2a\u89c6\u9891\uff0c\u6bcf\u4e2a\u89c6\u9891\u51e0\u79d2\u949f\u3002\n<a name=\"\u89c6\u9891\u62bd\u5e27\"></a>\n### 2.2 \u89c6\u9891\u62bd\u5e27\n\u4e3a\u4e86\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u5c06\u89c6\u9891\u8fdb\u884c\u62bd\u5e27\u3002\n```bash\ncd ${PaddleVideo_root}\npython data/ucf101/extract_rawframes.py dataset/ rawframes/ --level 2 --ext mp4\n```\n\u5176\u4e2d\uff0c\u89c6\u9891\u5b58\u653e\u5728`dataset`\u76ee\u5f55\u4e0b\uff0c\u6253\u67b6\uff08\u66b4\u529b\uff09\u89c6\u9891\u5b58\u653e\u5728`dataset/fight`\u4e2d\uff1b\u975e\u6253\u67b6\uff08\u975e\u66b4\u529b\uff09\u89c6\u9891\u5b58\u653e\u5728`dataset/nofight`\u4e2d\u3002`rawframes`\u76ee\u5f55\u5b58\u653e\u62bd\u53d6\u7684\u89c6\u9891\u5e27\u3002\n<a name=\"\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u5212\u5206\"></a>\n### 2.3 \u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u5212\u5206"
        },
        {
            "comment": "The code reads data from three datasets: Surveillance Camera Fight Dataset, A Dataset for Automatic Violence Detection in Videos, and UBI Abnormal Event Detection Dataset. It also allows for splitting the data into training and testing sets with an 80:20 ratio. The 'get_list' function retrieves the list of files and counts them, while the 'fight_splits' function takes the video dictionary and train percent as inputs to split the data into training and testing sets.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":76-117",
            "content": "\u672c\u9879\u76ee\u9a8c\u8bc1\u96c61500\u6761\uff0c\u6765\u81eaSurveillance Camera Fight Dataset\u3001A Dataset for Automatic Violence Detection in Videos\u3001UBI Abnormal Event Detection Dataset\u4e09\u4e2a\u6570\u636e\u96c6\u3002\n\u4e5f\u53ef\u6839\u636e\u4e0b\u9762\u7684\u4ee3\u7801\u5c06\u6570\u636e\u6309\u71670.8:0.2\u7684\u6bd4\u4f8b\u5212\u5206\u6210\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff1a\n```python\nimport os\nimport glob\nimport random\nimport fnmatch\nimport re\nclass_id = {\n    \"nofight\":0,\n    \"fight\":1\n}\ndef get_list(path,key_func=lambda x: x[-11:], rgb_prefix='img_', level=1):\n    if level == 1:\n        frame_folders = glob.glob(os.path.join(path, '*'))\n    elif level == 2:\n        frame_folders = glob.glob(os.path.join(path, '*', '*'))\n    else:\n        raise ValueError('level can be only 1 or 2')\n    def count_files(directory):\n        lst = os.listdir(directory)\n        cnt = len(fnmatch.filter(lst, rgb_prefix + '*'))\n        return cnt\n    # check RGB\n    video_dict = {}\n    for f in frame_folders:\n        cnt = count_files(f)\n        k = key_func(f)\n        if level==2:\n            k = k.split(\"/\")[0]\n        video_dict[f]=str(cnt)+\" \"+str(class_id[k])\n    return video_dict\ndef fight_splits(video_dict, train_percent=0.8):"
        },
        {
            "comment": "This code generates two lists, one for training and one for validation, based on a provided video dictionary. It then shuffles the list of videos and splits them into train and val lists. The code also defines a key function depending on the level parameter. Finally, it prints the lengths of both lists, writes them to separate files \"fight_train_list.txt\" and \"fight_val_list.txt\", and calls the fight_splits() function with the video dictionary and train percentage as parameters. These two files will contain the labels for training and validation sets, where fight (label 1) and non-fight (label 0) videos are listed separately.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":118-159",
            "content": "    videos = list(video_dict.keys())\n    train_num = int(len(videos)*train_percent)\n    train_list = []\n    val_list = []\n    random.shuffle(videos)\n    for i in range(train_num):\n        train_list.append(videos[i]+\" \"+str(video_dict[videos[i]]))\n    for i in range(train_num,len(videos)):\n        val_list.append(videos[i]+\" \"+str(video_dict[videos[i]]))\n    print(\"train:\",len(train_list),\",val:\",len(val_list))\n    with open(\"fight_train_list.txt\",\"w\") as f:\n        for item in train_list:\n            f.write(item+\"\\n\")\n    with open(\"fight_val_list.txt\",\"w\") as f:\n        for item in val_list:\n            f.write(item+\"\\n\")\nframe_dir = \"rawframes\"\nlevel = 2\ntrain_percent = 0.8\nif level == 2:\n    def key_func(x):\n        return '/'.join(x.split('/')[-2:])\nelse:\n    def key_func(x):\n        return x.split('/')[-1]\nvideo_dict = get_list(frame_dir, key_func=key_func, level=level)  \nprint(\"number:\",len(video_dict))\nfight_splits(video_dict, train_percent)\n```\n\u6700\u7ec8\u751f\u6210fight_train_list.txt\u548cfight_val_list.txt\u4e24\u4e2a\u6587\u4ef6\u3002\u6253\u67b6\u7684\u6807\u7b7e\u4e3a1\uff0c\u975e\u6253\u67b6\u7684\u6807\u7b7e\u4e3a0\u3002"
        },
        {
            "comment": "The code defines a function `cut_video` which takes a video path, start and stop frame numbers, and a saved video path. It uses OpenCV to read the input video, determine its FPS, total frames, and size. The function then creates a new VideoWriter object with the specified output file name, fourcc codec, and same FPS as the input video. It writes only the frames between the start and stop frame numbers to the new video file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":161-191",
            "content": "<a name=\"\u89c6\u9891\u88c1\u526a\"></a>\n### 2.4 \u89c6\u9891\u88c1\u526a\n\u5bf9\u4e8e\u672a\u88c1\u526a\u7684\u89c6\u9891\uff0c\u9700\u8981\u5148\u8fdb\u884c\u88c1\u526a\u624d\u80fd\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\uff0c\u8fd9\u4e2a\u7ed9\u51fa\u89c6\u9891\u88c1\u526a\u7684\u51fd\u6570`cut_video`\uff0c\u8f93\u5165\u4e3a\u89c6\u9891\u8def\u5f84\uff0c\u88c1\u526a\u7684\u8d77\u59cb\u5e27\u548c\u7ed3\u675f\u5e27\u4ee5\u53ca\u88c1\u526a\u540e\u7684\u89c6\u9891\u4fdd\u5b58\u8def\u5f84\u3002\n```python\nimport cv2\ndef cut_video(video_path, frameToStart, frametoStop, saved_video_path):\n    cap = cv2.VideoCapture(video_path)\n    FPS = cap.get(cv2.CAP_PROP_FPS)\n    #print(\"FPS:\",FPS)\n    TOTAL_FRAME = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # \u83b7\u53d6\u89c6\u9891\u603b\u5e27\u6570\n    #print(\"TOTAL_FRAME:\",TOTAL_FRAME)\n    size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    #print(\"size:\",size)\n    videoWriter =cv2.VideoWriter(saved_video_path,apiPreference = 0,fourcc = cv2.VideoWriter_fourcc(*'mp4v'),fps=FPS,\n            frameSize=(int(size[0]),int(size[1])))\n    COUNT = 0\n    while True:\n            success, frame = cap.read()\n            if success:\n                COUNT += 1\n                if COUNT <= frametoStop and COUNT > frameToStart:  # \u9009\u53d6\u8d77\u59cb\u5e27\n                    videoWriter.write(frame)\n            else:\n                print(\"cap.read failed!\")\n                break\n            if COUNT > frametoStop:"
        },
        {
            "comment": "This code represents the final part of the model training process. The first line is a break statement which implies the end of a loop or condition block. Following that, it releases the `cap` and `videoWriter` objects, suggesting they were used for capturing and writing video data respectively. The last line prints out the saved video path.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":192-244",
            "content": "                break\n    cap.release()\n    videoWriter.release()\n    print(saved_video_path)\n```\n<a name=\"\u6a21\u578b\u8bad\u7ec3\"></a>\n## 3 \u6a21\u578b\u8bad\u7ec3\n\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\uff1a\n```bash\nwget https://videotag.bj.bcebos.com/PaddleVideo/PretrainModel/ResNet50_vd_ssld_v2_pretrained.pdparams\n```\n\u6a21\u578b\u8bad\u7ec3\uff1a\n```bash\n# \u5355\u5361\u8bad\u7ec3\ncd ${PaddleVideo_root}\npython main.py --validate -c pptsm_fight_frames_dense.yaml\n```\n```bash\ncd ${PaddleVideo_root}\n# \u591a\u5361\u8bad\u7ec3\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npython -B -m paddle.distributed.launch --gpus=\u201c0,1,2,3\u201d \\\n   --log_dir=log_pptsm_dense  main.py  --validate \\\n   -c pptsm_fight_frames_dense.yaml\n```\n<a name=\"\u6a21\u578b\u8bc4\u4f30\"></a>\n## 4 \u6a21\u578b\u8bc4\u4f30\n\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e0b\u8f7d\uff1a[https://videotag.bj.bcebos.com/PaddleVideo-release2.3/ppTSM_fight.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.3/ppTSM_fight.pdparams)\n\u6a21\u578b\u8bc4\u4f30\uff1a\n```bash\ncd ${PaddleVideo_root}\npython main.py --test -c pptsm_fight_frames_dense.yaml \\\n   -w ppTSM_fight_best.pdparams\n```\n\u5176\u4e2d`ppTSM_fight_best.pdparams`\u4e3a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u3002\n<a name=\"\u6a21\u578b\u5bfc\u51fa\"></a>\n## 5 \u6a21\u578b\u5bfc\u51fa\n\u5bfc\u51fainference\u6a21\u578b\uff1a\n```bash\ncd ${PaddleVideo_root}\npython tools/export_model.py -c pptsm_fight_frames_dense.yaml \\"
        },
        {
            "comment": "This code is loading a pre-trained model, \"ppTSM_fight_best.pdparams\", and saving the inference output to the \"inference/ppTSM\" directory.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FightRecognition/README.md\":245-247",
            "content": "                                -p ppTSM_fight_best.pdparams \\\n                                -o inference/ppTSM\n```"
        }
    ]
}