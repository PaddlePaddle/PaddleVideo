{
    "summary": "This script sets environment variables for GPU usage and then runs the \"inference.py\" Python script from the \"scenario_lib\" directory, specifying a model name (AttentionLstmErnie), configuration file path (./conf/conf.txt), saving inference models path (inference_models_save), and output file for results (output.json).",
    "details": [
        {
            "comment": "This script sets environment variables for GPU usage and then runs the \"inference.py\" Python script from the \"scenario_lib\" directory, specifying a model name (AttentionLstmErnie), configuration file path (./conf/conf.txt), saving inference models path (inference_models_save), and output file for results (output.json).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/inference.sh\":0-11",
            "content": "# inference sh \nexport CUDA_VISIBLE_DEVICES=0\nexport FLAGS_eager_delete_tensor_gb=0.0\nexport FLAGS_sync_nccl_allreduce=1\nexport FLAGS_fast_eager_deletion_mode=1\nexport FLAGS_fraction_of_gpu_memory_to_use=0.5\nexport FLAGS_reallocate_gpu_memory_in_mb=0\nexport FLAGS_memory_fraction_of_eager_deletion=1\npython scenario_lib/inference.py --model_name=AttentionLstmErnie \\\n--config=./conf/conf.txt \\\n--save_inference_model=inference_models_save \\\n--output='output.json'"
        }
    ]
}