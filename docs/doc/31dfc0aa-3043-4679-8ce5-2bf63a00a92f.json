{
    "summary": "This code handles video sequence object detection, converting results to CSV format and evaluating AVA metrics using error handling, utility functions, and GPU-based processing.",
    "details": [
        {
            "comment": "This code imports necessary libraries and modules for evaluating AVA (Activity-driven Visual Attention) metrics. It also includes a license notice, time management functions, and error handling measures. The code uses defaultdict from collections and eval_recalls function from the same repository to perform evaluation tasks related to object detection in video sequences. Additionally, it incorporates paddlevideo's get_logger() function for logging, dist library for distributed processing, and numpy for numerical operations.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":0-30",
            "content": "# copyright (c) 2021 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport csv\nimport heapq\nimport logging\nimport time\nfrom collections import defaultdict\nfrom .ava_evaluation import object_detection_evaluation as det_eval\nfrom .ava_evaluation import standard_fields\nfrom .recall import eval_recalls\nimport shutil\nimport pickle\nimport time\nimport os\nimport os.path as osp\nfrom paddlevideo.utils import get_logger, get_dist_info\nimport paddle.distributed as dist\nimport sys\nimport numpy as np"
        },
        {
            "comment": "The code defines two functions: \"det2csv\" and \"results2csv\". \"det2csv\" takes in information, dataset length, results, and custom classes (if any), and returns a list of tuples representing the results in CSV format. It loops through each entry, extracts relevant data, converts tensors to numpy arrays if needed, and appends the information to the csv_results list. \"results2csv\" checks if the results are organized by class or not, then calls either \"det2csv\" or performs CSV conversion directly using it.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":31-63",
            "content": "from pathlib import Path\nfrom datetime import datetime\nimport paddle\ndef det2csv(info, dataset_len, results, custom_classes):\n    csv_results = []\n    for idx in range(dataset_len):\n        video_id = info[idx]['video_id']\n        timestamp = info[idx]['timestamp']\n        result = results[idx]\n        for label, _ in enumerate(result):\n            for bbox in result[label]:\n                if type(bbox) == paddle.Tensor:\n                    bbox = bbox.numpy()\n                bbox_ = tuple(bbox.tolist())\n                if custom_classes is not None:\n                    actual_label = custom_classes[label + 1]\n                else:\n                    actual_label = label + 1\n                csv_results.append((\n                    video_id,\n                    timestamp,\n                ) + bbox_[:4] + (actual_label, ) + bbox_[4:])\n    return csv_results\n# results is organized by class\ndef results2csv(info, dataset_len, results, out_file, custom_classes=None):\n    if isinstance(results[0], list):\n        csv_results = det2csv(info, dataset_len, results, custom_classes)"
        },
        {
            "comment": "This code snippet contains several utility functions used for video analysis. The \"tostr\" function converts a float to a string representation with 3 decimal places, while the \"print_time\" function calculates and prints the time elapsed since a given start point. The \"make_image_key\" function generates a unique identifier for a video ID and timestamp, and \"read_csv\" function loads boxes and class labels from a CSV file in AVA format.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":65-96",
            "content": "    # save space for float\n    def tostr(item):\n        if isinstance(item, float):\n            return f'{item:.3f}'\n        return str(item)\n    with open(out_file, 'w') as f:\n        for csv_result in csv_results:\n            f.write(','.join(map(lambda x: tostr(x), csv_result)))\n            f.write('\\n')\ndef print_time(message, start):\n    print('==> %g seconds to %s' % (time.time() - start, message))\ndef make_image_key(video_id, timestamp):\n    \"\"\"Returns a unique identifier for a video id & timestamp.\"\"\"\n    return f'{video_id},{int(timestamp):04d}'\ndef read_csv(csv_file, class_whitelist=None, capacity=0):\n    \"\"\"Loads boxes and class labels from a CSV file in the AVA format.\n    CSV file format described at https://research.google.com/ava/download.html.\n    Args:\n        csv_file: A file object.\n        class_whitelist: If provided, boxes corresponding to (integer) class\n        labels not in this set are skipped.\n        capacity: Maximum number of labeled boxes allowed for each example.\n        Default is 0 where there is no limit."
        },
        {
            "comment": "This code reads a CSV file with video frame data, and for each row, it creates dictionaries for boxes, labels, and scores. It checks the class whitelist before adding the data to the respective lists. If scores are not provided in the CSV, they default to 1.0. The time taken for this process is measured at the beginning with start = time.time().",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":98-119",
            "content": "    Returns:\n        boxes: A dictionary mapping each unique image key (string) to a list of\n        boxes, given as coordinates [y1, x1, y2, x2].\n        labels: A dictionary mapping each unique image key (string) to a list\n        of integer class lables, matching the corresponding box in `boxes`.\n        scores: A dictionary mapping each unique image key (string) to a list\n        of score values lables, matching the corresponding label in `labels`.\n        If scores are not provided in the csv, then they will default to 1.0.\n    \"\"\"\n    start = time.time()\n    entries = defaultdict(list)\n    boxes = defaultdict(list)\n    labels = defaultdict(list)\n    scores = defaultdict(list)\n    reader = csv.reader(csv_file)\n    for row in reader:\n        assert len(row) in [7, 8], 'Wrong number of columns: ' + row\n        image_key = make_image_key(row[0], row[1])\n        x1, y1, x2, y2 = [float(n) for n in row[2:6]]\n        action_id = int(row[6])\n        if class_whitelist and action_id not in class_whitelist:\n            continue"
        },
        {
            "comment": "This code reads a CSV file containing object detection results and stores them in three lists: boxes, labels, and scores. The code also handles exclusions by reading a separate CSV file that contains excluded timestamps. The score is determined based on the length of each row in the CSV file and added to the corresponding image key's entry in the entries dictionary if the capacity allows or if the score is higher than the current highest score for that image key. The code then sorts the entries by descending scores and appends them to the boxes, labels, and scores lists for each image key.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":121-146",
            "content": "        score = 1.0\n        if len(row) == 8:\n            score = float(row[7])\n        if capacity < 1 or len(entries[image_key]) < capacity:\n            heapq.heappush(entries[image_key],\n                           (score, action_id, y1, x1, y2, x2))\n        elif score > entries[image_key][0][0]:\n            heapq.heapreplace(entries[image_key],\n                              (score, action_id, y1, x1, y2, x2))\n    for image_key in entries:\n        # Evaluation API assumes boxes with descending scores\n        entry = sorted(entries[image_key], key=lambda tup: -tup[0])\n        for item in entry:\n            score, action_id, y1, x1, y2, x2 = item\n            boxes[image_key].append([y1, x1, y2, x2])\n            labels[image_key].append(action_id)\n            scores[image_key].append(score)\n    print_time('read file ' + csv_file.name, start)\n    return boxes, labels, scores\ndef read_exclusions(exclusions_file):\n    \"\"\"Reads a CSV file of excluded timestamps.\n    Args:\n        exclusions_file: A file object containing a csv of video-id,timestamp."
        },
        {
            "comment": "Function `read_excluded_images` reads an exclusions file and returns a set of image keys to exclude. The input file is read row by row, and for each row the function checks that there are exactly two columns and adds the image key (combination of column 1 and column 2) to the excluded set.\n\nFunction `read_labelmap` reads a labelmap file without using protocol buffers. It iterates over the file line by line. When it encounters a line starting with 'name:', it extracts the class name, and when it encounters a line starting with 'id:' it extracts the class id. The function then appends a dictionary containing the id and name to the labelmap list and adds the id to the set of valid class ids.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":148-180",
            "content": "    Returns:\n        A set of strings containing excluded image keys, e.g.\n        \"aaaaaaaaaaa,0904\",\n        or an empty set if exclusions file is None.\n    \"\"\"\n    excluded = set()\n    if exclusions_file:\n        reader = csv.reader(exclusions_file)\n    for row in reader:\n        assert len(row) == 2, 'Expected only 2 columns, got: ' + row\n        excluded.add(make_image_key(row[0], row[1]))\n    return excluded\ndef read_labelmap(labelmap_file):\n    \"\"\"Reads a labelmap without the dependency on protocol buffers.\n    Args:\n        labelmap_file: A file object containing a label map protocol buffer.\n    Returns:\n        labelmap: The label map in the form used by the\n        object_detection_evaluation\n        module - a list of {\"id\": integer, \"name\": classname } dicts.\n        class_ids: A set containing all of the valid class id integers.\n    \"\"\"\n    labelmap = []\n    class_ids = set()\n    name = ''\n    class_id = ''\n    for line in labelmap_file:\n        if line.startswith('  name:'):\n            name = line.split('\"')[1]"
        },
        {
            "comment": "This function ava_eval() takes several file paths as input and evaluates the results using mean average precision (mAP). It uses a label map to convert class labels from detections to their corresponding IDs. The code checks for 'id' or 'label_id' in each line of the label file, appends the ID and name to the label map, and adds the ID to a set of class_ids. The function also handles custom classes by excluding any category whose ID is not in the custom_classes list. The gt_boxes, gt_labels, and _ are loaded from the ann_file for evaluation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":181-209",
            "content": "        elif line.startswith('  id:') or line.startswith('  label_id:'):\n            class_id = int(line.strip().split(' ')[-1])\n            labelmap.append({'id': class_id, 'name': name})\n            class_ids.add(class_id)\n    return labelmap, class_ids\n# Seems there is at most 100 detections for each image\ndef ava_eval(result_file,\n             result_type,\n             label_file,\n             ann_file,\n             exclude_file,\n             max_dets=(100, ),\n             verbose=True,\n             custom_classes=None):\n    assert result_type in ['mAP']\n    start = time.time()\n    categories, class_whitelist = read_labelmap(open(label_file))\n    if custom_classes is not None:\n        custom_classes = custom_classes[1:]\n        assert set(custom_classes).issubset(set(class_whitelist))\n        class_whitelist = custom_classes\n        categories = [cat for cat in categories if cat['id'] in custom_classes]\n    # loading gt, do not need gt score\n    gt_boxes, gt_labels, _ = read_csv(open(ann_file), class_whitelist, 0)"
        },
        {
            "comment": "The code reads detection results from a file, excludes certain keys if specified in an exclude file, and measures the time taken to read the results. It then checks if the result type is 'proposal' and creates proposals based on the gt_boxes for each image key present in boxes or adds a fake one if no corresponding proposal exists. Proposals include scores.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":210-239",
            "content": "    if verbose:\n        print_time('Reading detection results', start)\n    if exclude_file is not None:\n        excluded_keys = read_exclusions(open(exclude_file))\n    else:\n        excluded_keys = list()\n    start = time.time()\n    boxes, labels, scores = read_csv(open(result_file), class_whitelist, 0)\n    if verbose:\n        print_time('Reading detection results', start)\n    if result_type == 'proposal':\n        gts = [\n            np.array(gt_boxes[image_key], dtype=float) for image_key in gt_boxes\n        ]\n        proposals = []\n        for image_key in gt_boxes:\n            if image_key in boxes:\n                proposals.append(\n                    np.concatenate(\n                        (np.array(boxes[image_key], dtype=float),\n                         np.array(scores[image_key], dtype=float)[:, None]),\n                        axis=1))\n            else:\n                # if no corresponding proposal, add a fake one\n                proposals.append(np.array([0, 0, 1, 1, 1]))\n        # Proposals used here are with scores"
        },
        {
            "comment": "This code calculates the Average Recall (AR) and Recall@0.5 (R@0.5) for different detection numbers using the eval_recalls function. It then prints the results and stores them in a dictionary. If the result type is 'mAP', it initializes a PascalDetectionEvaluator, adds ground truth information for each image key, and calculates the mean average precision (mAP).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":240-264",
            "content": "        recalls = eval_recalls(gts, proposals, np.array(max_dets),\n                               np.arange(0.5, 0.96, 0.05))\n        ar = recalls.mean(axis=1)\n        ret = {}\n        for i, num in enumerate(max_dets):\n            print(f'Recall@0.5@{num}\\t={recalls[i, 0]:.4f}')\n            print(f'AR@{num}\\t={ar[i]:.4f}')\n            ret[f'Recall@0.5@{num}'] = recalls[i, 0]\n            ret[f'AR@{num}'] = ar[i]\n        return ret\n    if result_type == 'mAP':\n        pascal_evaluator = det_eval.PascalDetectionEvaluator(categories)\n        start = time.time()\n        for image_key in gt_boxes:\n            if verbose and image_key in excluded_keys:\n                logging.info(\n                    'Found excluded timestamp in detections: %s.'\n                    'It will be ignored.', image_key)\n                continue\n            pascal_evaluator.add_single_ground_truth_image_info(\n                image_key, {\n                    standard_fields.InputDataFields.groundtruth_boxes:\n                    np.array(gt_boxes[image_key], dtype=float),"
        },
        {
            "comment": "This code adds single detected image information to a Pascal evaluator. It converts groundtruth labels and boxes into appropriate data structures, handles excluded timestamps, and processes detection boxes and classes for evaluation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":265-285",
            "content": "                    standard_fields.InputDataFields.groundtruth_classes:\n                    np.array(gt_labels[image_key], dtype=int),\n                    standard_fields.InputDataFields.groundtruth_difficult:\n                    np.zeros(len(gt_boxes[image_key]), dtype=bool)\n                })\n        if verbose:\n            print_time('Convert groundtruth', start)\n        start = time.time()\n        for image_key in boxes:\n            if verbose and image_key in excluded_keys:\n                logging.info(\n                    'Found excluded timestamp in detections: %s.'\n                    'It will be ignored.', image_key)\n                continue\n            pascal_evaluator.add_single_detected_image_info(\n                image_key, {\n                    standard_fields.DetectionResultFields.detection_boxes:\n                    np.array(boxes[image_key], dtype=float),\n                    standard_fields.DetectionResultFields.detection_classes:\n                    np.array(labels[image_key], dtype=int),"
        },
        {
            "comment": "Code snippet performs AVA evaluation for detection results, and prints or returns specific metrics. It also includes functions for creating directories, dumping objects to files using pickle library, and has a function for time measurement called print_time.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":286-319",
            "content": "                    standard_fields.DetectionResultFields.detection_scores:\n                    np.array(scores[image_key], dtype=float)\n                })\n        if verbose:\n            print_time('convert detections', start)\n        start = time.time()\n        metrics = pascal_evaluator.evaluate()\n        if verbose:\n            print_time('run_evaluator', start)\n        for display_name in metrics:\n            print(f'{display_name}=\\t{metrics[display_name]}')\n        ret = {\n            display_name: metrics[display_name]\n            for display_name in metrics if 'ByCategory' not in display_name\n        }\n        return ret\ndef mkdir_or_exist(dir_name, mode=0o777):\n    if dir_name == '':\n        return\n    dir_name = osp.expanduser(dir_name)\n    os.makedirs(dir_name, mode=mode, exist_ok=True)\ndef dump_to_fileobj(obj, file, **kwargs):\n    kwargs.setdefault('protocol', 2)\n    pickle.dump(obj, file, **kwargs)\ndef dump_to_path(obj, filepath, mode='wb'):\n    with open(filepath, mode) as f:\n        dump_to_fileobj(obj, f)"
        },
        {
            "comment": "This code defines three functions: `load_from_fileobj`, `load_from_path`, and `collect_results_cpu`. The first two are used to load data from files or file paths, respectively. The third function, `collect_results_cpu`, is a CPU-based method for collecting results across multiple GPUs by saving them in a temporary directory ('tmpdir') and having the rank 0 worker collect them. It checks if all parts exist, waits if not, then loads and returns the collected results once they are all available.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":322-356",
            "content": "def load_from_fileobj(file, **kwargs):\n    return pickle.load(file, **kwargs)\ndef load_from_path(filepath, mode='rb'):\n    with open(filepath, mode) as f:\n        return load_from_fileobj(f)\ndef collect_results_cpu(result_part, size):\n    \"\"\"Collect results in cpu mode.\n    It saves the results on different gpus to 'tmpdir' and collects\n    them by the rank 0 worker.\n    \"\"\"\n    tmpdir = osp.join('./', 'collect_results_cpu')\n    #1. load results of all parts from tmp dir\n    mkdir_or_exist(tmpdir)\n    rank, world_size = get_dist_info()\n    dump_to_path(result_part, osp.join(tmpdir, f'part_{rank}.pkl'))\n    dist.barrier()\n    if rank != 0:\n        return None\n    #2. collect all parts\n    while 1:\n        all_exist = True\n        for i in range(world_size):\n            part_file = osp.join(tmpdir, f'part_{i}.pkl')\n            if not Path(part_file).exists():\n                all_exist = False\n        if all_exist:\n            break\n        else:\n            time.sleep(60)\n    time.sleep(120)\n    #3. load results of all parts from tmp dir"
        },
        {
            "comment": "This code is used for evaluating AVA results by splitting the computation across multiple processes, then combining and ordering the partial results before deleting temporary files. It takes in information about the dataset, the evaluation results, custom class labels, and file paths for input and exclusion lists. The code creates a temporary result file, converts the results to a CSV format, performs AVA evaluation on the temporary file, and returns an evaluation result.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":357-383",
            "content": "    part_list = []\n    for i in range(world_size):\n        part_file = osp.join(tmpdir, f'part_{i}.pkl')\n        part_list.append(load_from_path(part_file))\n    #4. sort the results\n    ordered_results = []\n    for res in zip(*part_list):\n        ordered_results.extend(list(res))\n    ordered_results = ordered_results[:\n                                      size]  #the dataloader may pad some samples\n    #5. remove results of all parts from tmp dir, avoid dump_file fail to tmp dir when dir not exists.\n    for i in range(world_size):\n        part_file = osp.join(tmpdir, f'part_{i}.pkl')\n        os.remove(part_file)\n    return ordered_results\ndef ava_evaluate_results(info, dataset_len, results, custom_classes, label_file,\n                         file_path, exclude_file):\n    # need to create a temp result file\n    time_now = datetime.now().strftime('%Y%m%d_%H%M%S')\n    temp_file = f'AVA_{time_now}_result.csv'\n    results2csv(info, dataset_len, results, temp_file)\n    ret = {}\n    eval_result = ava_eval(\n        temp_file,"
        },
        {
            "comment": "This code is computing the mean average precision (mAP) for object detection metrics. It reads from a label file, file path, and excludes certain classes as specified. The results are stored in the 'ret' dictionary before removing a temporary file and returning the final results.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ava_utils.py\":384-393",
            "content": "        'mAP',\n        label_file,\n        file_path,  #ann_file,\n        exclude_file,\n        custom_classes=custom_classes)\n    ret.update(eval_result)\n    os.remove(temp_file)\n    return ret"
        }
    ]
}