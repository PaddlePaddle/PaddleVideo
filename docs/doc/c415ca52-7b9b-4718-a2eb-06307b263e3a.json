{
    "summary": "The code introduces a trainer class for PaddleVideo's T2VLAD application, managing features like multi-epoch training, monitoring performance metrics and model saving during training. It also manages model checkpoints to prevent storage overload.",
    "details": [
        {
            "comment": "This code defines a base class for all trainers. It takes in parameters such as model, loss function, metrics to track, optimizer, and configuration. It also initializes the logger and sets up the necessary components for training.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":0-32",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nimport re\nimport copy\nimport time\nimport paddle\nimport pickle\nimport numpy as np\nfrom pathlib import Path\nfrom abc import abstractmethod\nclass BaseTrainer:\n    \"\"\" Base class for all trainers\n    \"\"\"\n    def __init__(self, model, loss, metrics, optimizer, config, mini_train,\n                 num_keep_ckpts, skip_tboard):\n        self.config = config\n        self.logger = config.get_logger(\n            'trainer', config['trainer']['verbosity'])\n        self.model = model\n        self.loss = loss\n        self.metrics = metrics"
        },
        {
            "comment": "This code is initializing the base trainer object with parameters from a configuration file. It sets optimizer, number of checkpoints to keep, whether to skip TensorBoard logging or not, and overridable properties like skipping the first N saves. It also assigns epochs, save period, monitor mode for model performance evaluation, best score to compare against, starts training from epoch 1, and sets the model directory.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":33-59",
            "content": "        self.optimizer = optimizer\n        self.num_keep_ckpts = num_keep_ckpts\n        self.skip_tboard = skip_tboard or mini_train\n        # This property can be overriden in the subclass\n        self.skip_first_n_saves = 0\n        cfg_trainer = config['trainer']\n        self.epochs = cfg_trainer['epochs']\n        self.save_period = cfg_trainer['save_period']\n        self.monitor = cfg_trainer.get('monitor', 'off')\n        self.save_only_best = cfg_trainer.get(\"save_only_best\", True)\n        self.val_freq = cfg_trainer['val_freq']\n        # configuration to monitor model performance and save best\n        if self.monitor == 'off':\n            self.mnt_mode = 'off'\n            self.mnt_best = 0\n        else:\n            self.mnt_mode, self.mnt_metric = self.monitor.split()\n            assert self.mnt_mode in ['min', 'max']\n            self.mnt_best = np.inf if self.mnt_mode == 'min' else -np.inf\n            self.early_stop = cfg_trainer.get('early_stop', np.inf)\n        self.start_epoch = 1\n        self.model_dir = config.save_dir"
        },
        {
            "comment": "This code defines a base trainer class for PaddleVideo's T2VLAD application. It includes methods to train for multiple epochs, handle resume from a saved state, and log training metrics. The trainer iterates over each epoch and calls the _train_epoch method to perform training logic. If validation frequency is set, it logs results at specified epochs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":61-88",
            "content": "        self.include_optim_in_save_model = config[\"trainer\"].get(\"include_optim_in_save_model\", 1)\n        if config.resume is not None:\n            self._resume_model(config.resume)\n    @abstractmethod\n    def _train_epoch(self, epoch):\n        \"\"\"Training logic for an epoch\n        :param epoch: Current epoch number\n        \"\"\"\n        raise NotImplementedError\n    def train(self):\n        \"\"\"Full training logic.  Responsible for iterating over epochs, early stopping,\n        modeling and logging metrics.\n        \"\"\"\n        for epoch in range(self.start_epoch, self.epochs + 1):\n            result, cached_preds = self._train_epoch(epoch)\n            if epoch % self.val_freq != 0:\n                continue\n            # save logged informations into log dict\n            log = {'epoch': epoch}\n            for key, value in result.items():\n                if key == 'metrics':\n                    log.update({mtr.__name__: value[i]\n                                for i, mtr in enumerate(self.metrics)})\n                elif key == 'val_metrics':"
        },
        {
            "comment": "The code updates the log with metrics values, handles nested metrics, prints logged information to the screen, and checks if the metric improved for monitoring mode.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":89-109",
            "content": "                    log.update({'val_' + mtr.__name__: value[i]\n                                for i, mtr in enumerate(self.metrics)})\n                elif key == 'nested_val_metrics':\n                    # NOTE: currently only supports two layers of nesting\n                    for subkey, subval in value.items():\n                        for subsubkey, subsubval in subval.items():\n                            log[f\"val_{subkey}_{subsubkey}\"] = subsubval\n                else:\n                    log[key] = value\n            # print logged informations to the screen\n            for key, value in log.items():\n                self.logger.info('    {:15s}: {}'.format(str(key), value))\n            # eval model according to configured metric, save best # ckpt as trained_model\n            not_improved_count = 0\n            best = False\n            if self.mnt_mode != 'off':\n                try:\n                    # check whether specified metric improved or not, according to\n                    # specified metric(mnt_metric)"
        },
        {
            "comment": "This code checks if the performance metric (mnt_metric) has improved and updates the best value accordingly. If the metric is not found, it disables performance monitoring and sets improved to False. It also raises a ValueError asking the user to choose a relevant metric.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":110-127",
            "content": "                    lower = log[self.mnt_metric] <= self.mnt_best\n                    higher = log[self.mnt_metric] >= self.mnt_best\n                    improved = (self.mnt_mode == 'min' and lower) or \\\n                               (self.mnt_mode == 'max' and higher)\n                except KeyError:\n                    msg = \"Warning: Metric '{}' not found, perf monitoring is disabled.\"\n                    self.logger.warning(msg.format(self.mnt_metric))\n                    self.mnt_mode = 'off'\n                    improved = False\n                    not_improved_count = 0\n                    raise ValueError(\"Pick a metric that will save models!!!!!!!!\")\n                if improved:\n                    self.mnt_best = log[self.mnt_metric]\n                    # TODO(Samuel): refactor the code so that we don't move the model\n                    # off the GPU or duplicate on the GPU (we should be able to safely\n                    # copy the state dict directly to CPU)\n                    copy_model = copy.deepcopy(self.model)"
        },
        {
            "comment": "This code snippet is responsible for early stopping and saving the best model. If validation performance does not improve after a certain number of epochs (early_stop), training stops. The best model is saved if save_only_best is True and only at the end of the epochs. Otherwise, any model that outperforms the current best metric will be saved intermittently.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":128-150",
            "content": "                    self.best_model = {\"epoch\": epoch, \"model\": copy_model}\n                    not_improved_count = 0\n                    best = True\n                else:\n                    not_improved_count += 1\n                if not_improved_count > self.early_stop:\n                    self.logger.info(\"Val performance didn\\'t improve for {} epochs. \"\n                                     \"Training stops.\".format(self.early_stop))\n                    break\n            if self.save_only_best:\n                if epoch == self.epochs:\n                    best_model = self.best_model\n                    self.model = best_model[\"model\"]\n                    print(f\"saving the best model to disk (epoch {epoch})\")\n                    self._save_model(best_model[\"epoch\"], save_best=True)\n                continue\n            # If modeling is done intermittently, still save models that outperform\n            # the best metric\n            # save_best = best and not self.mnt_metric == \"epoch\"\n            save_best = True"
        },
        {
            "comment": "This code snippet is used to control the frequency and conditions of model saving during training. It checks if the current epoch is less than a specified number (`self.skip_first_n_saves`) and if `self.save_only_best` is set to False. If either condition is true, it skips saving the model at that epoch. If both conditions are false or the first condition is false but the second one is true, it saves the model every `self.save_period` epochs when `save_best` is set to True. Additionally, if this epoch's save is considered the best (`best` is True), it logs all predictions for each key in `cached_preds`.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":152-169",
            "content": "            # Due to the fast runtime/slow HDD combination, modeling can dominate\n            # the total training time, so we optionally skip models for some of\n            # the first epochs\n            if epoch < self.skip_first_n_saves and not self.save_only_best:\n                msg = f\"Skipping model save at epoch {epoch} <= {self.skip_first_n_saves}\"\n                self.logger.info(msg)\n                continue\n            if epoch % self.save_period == 0 and save_best:\n                self._save_model(epoch, save_best=best)\n                print(\"This epoch, the save best :{}\".format(best))\n                if best:\n                    for key, cached in cached_preds.items():\n                        log_dir = Path(self.config.log_dir)\n                        prediction_path = log_dir / f\"{key}_preds.txt\"\n                        prediction_logits_path = log_dir / f\"{key}_preds_logits.npy\"\n                        np.save(prediction_logits_path, cached[\"preds\"])\n                        gt_logits_path = log_dir / f\"{key}_gt_logits.npy\""
        },
        {
            "comment": "Saves the ground-truth labels and predicted classes for each video, writing them to disk in a specified format. It also saves the video names associated with these predictions and logs a message when all preds have been saved.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":170-185",
            "content": "                        np.save(gt_logits_path, cached[\"labels\"].cpu().numpy())\n                        vid_names = []\n                        sort_predict = np.argsort(cached[\"preds\"])[:, ::-1]\n                        with open(str(prediction_path), 'w') as f:\n                            for kk in range(cached[\"preds\"].shape[0]):\n                                pred_classes = [str(v) for v in sort_predict[kk, :]]\n                                vid_name = cached[\"vid_name\"][kk]\n                                if key == \"test\":\n                                    vid_name = vid_name[kk].split('/')[-1] + '.mp4'\n                                row = f\"{vid_name} {' '.join(pred_classes)}\"\n                                print(row, file=f)\n                                vid_names.append(vid_name)\n                        save_name_path = log_dir / f\"{key}_vid_name.pkl\"\n                        with open(save_name_path, 'wb') as f:\n                            pickle.dump(vid_names, f)\n                        self.logger.info(f\"All {key} preds saved\")"
        },
        {
            "comment": "This code is responsible for managing the storage of model checkpoints and purging old or unnecessary models. It keeps track of the number of models to keep (`num_keep_ckpts`) and removes older ones if necessary. The `purge_stale_models()` function checks if all the checkpoints follow the expected format, then purges the oldest models by removing them from storage.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":186-209",
            "content": "                        self.logger.info(f\"Wrote result to: {str(prediction_path)}\")\n            if epoch > self.num_keep_ckpts:\n                self.purge_stale_models()\n    def purge_stale_models(self):\n        \"\"\"Remove models that are no longer neededself.\n        NOTE: This function assumes that the `best` model has already been renamed\n        to have a format that differs from `model-epoch<num>.pth`\n        \"\"\"\n        all_ckpts = list(self.model_dir.glob(\"*.pdparams\"))\n        found_epoch_ckpts = list(self.model_dir.glob(\"model-epoch*.pdparams\"))\n        if len(all_ckpts) <= self.num_keep_ckpts:\n            return\n        msg = \"Expected at the best model to have been renamed to a different format\"\n        if not len(all_ckpts) > len(found_epoch_ckpts):\n            print(\"Warning, purging model, but the best epoch was not saved!\")\n        # assert len(all_ckpts) > len(found_epoch_ckpts), msg\n        # purge the oldest models\n        regex = r\".*model-epoch(\\d+)[.pdparams$\"\n        epochs = [int(re.search(regex, str(x)).groups()[0]) for x in found_epoch_ckpts]"
        },
        {
            "comment": "This code snippet is responsible for saving and removing stale models during the training process. It saves model checkpoints at each epoch, keeps a specified number of the most recent ones, and deletes older checkpoints. The _save_model function saves the model state along with its architecture, current epoch, optimizer state if included, and configuration details into a .pdparams file in the specified directory.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":210-237",
            "content": "        sorted_ckpts = sorted(list(zip(epochs, found_epoch_ckpts)), key=lambda x: -x[0])\n        for epoch, stale_ckpt in sorted_ckpts[self.num_keep_ckpts:]:\n            tic = time.time()\n            stale_ckpt.unlink()\n            msg = f\"removing stale model [epoch {epoch}] [took {time.time() - tic:.2f}s]\"\n            self.logger.info(msg)\n    def _save_model(self, epoch, save_best=False):\n        \"\"\"Saving models\n        :param epoch: current epoch number\n        :param log: logging information of the epoch\n        :param save_best: if True, rename the saved model to 'trained_model.pdparams'\n        \"\"\"\n        arch = type(self.model).__name__\n        state = {\n            'arch': arch,\n            'epoch': epoch,\n            'state_dict': self.model.state_dict(),\n            'monitor_best': self.mnt_best,\n            'config': self.config\n        }\n        if self.include_optim_in_save_model:\n            state[\"optimizer\"] = self.optimizer.state_dict()\n        filename = str(self.model_dir /\n                       'model-epoch{}.pdparams'.format(epoch))"
        },
        {
            "comment": "Saves model with optional best model update after training completion. Allows resuming training from a previously saved state.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/base/base_trainer.py\":238-257",
            "content": "        tic = time.time()\n        self.logger.info(\"Saving model: {} ...\".format(filename))\n        paddle.save(state, filename)\n        self.logger.info(f\"Done in {time.time() - tic:.3f}s\")\n        if save_best:\n            self.logger.info(\"Updating 'best' model: {} ...\".format(filename))\n            best_path = str(self.model_dir / 'trained_model.pdparams')\n            paddle.save(state, best_path)\n            self.logger.info(f\"Done in {time.time() - tic:.3f}s\")\n    def _resume_model(self, resume_path):\n        \"\"\" Resume from saved models\n        :param resume_path: model path to be resumed\n        \"\"\"\n        resume_path = str(resume_path)\n        self.logger.info(\"Loading model: {} ...\".format(resume_path))\n        model = paddle.load(resume_path)\n        self.model.load_dict(model)\n        self.logger.info(f\"model loaded. Resume training from epoch {self.start_epoch}\")"
        }
    ]
}