{
    "summary": "This code sets up PaddleVideo on Linux, supports multi-card training and testing with PaddlePaddle. It provides log format for phases, resumes sessions, fine-tunes with pretrained params and best accuracy achieved. The code launches PaddleVideo in distributed mode with 4 GPUs, tests, exports model, introduces `use_gpu` parameter, and benchmark results are available in benchmark document.",
    "details": [
        {
            "comment": "This code provides instructions for setting up the environment, preparing data using the PaddleVideo library, and explains its supported functions. It also mentions that it only supports Linux operation systems with GPU environments and gives an example of how to run the library. The code outlines the default destination folders for output, log files, and inference files.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/usage.md\":0-27",
            "content": "[\u7b80\u4f53\u4e2d\u6587](../zh-CN/usage.md) | English\n# Usage\n---\nPlease refer to [installation documents](./install.md) to prepare the enviroment, and follow the steps mentioned in the [data preparation documents](./dataset/) to construct dataset, we will take you through the basic functions supported by PaddleVideo, all of it takes the ucf101 dataset with frame format as example.\nPaddleVideo only support linux operation system and GPU running time environment now.\nDefault detination folder of PaddleVideo files. running the [example config](../../configs/example.yaml) as example.\n```\nPaddleVideo\n    \u251c\u2500\u2500 paddlevideo\n    \u251c\u2500\u2500 ... #other source codes\n    \u251c\u2500\u2500 output #ouput destination\n    |    \u251c\u2500\u2500 example\n    |    |   \u251c\u2500\u2500 example_best.pdparams #path_to_weights\n    |    |   \u2514\u2500\u2500 ...  \n    |    \u2514\u2500\u2500 ...  \n    \u251c\u2500\u2500 log  #log file destination.\n    |    \u251c\u2500\u2500 worker.0\n    |    \u251c\u2500\u2500 worker.1\n    |    \u2514\u2500\u2500 ...  \n    \u2514\u2500\u2500 inference #inference files destination.\n         \u251c\u2500\u2500 .pdiparams file\n         \u251c\u2500\u2500 .pdimodel file\n         \u2514\u2500\u2500 .pdiparmas.info file"
        },
        {
            "comment": "This code demonstrates how to train and test a model using PaddlePaddle, a popular deep learning framework. The training process involves running multi-card training scripts or tests by executing the `paddle.distributed.launch` command with appropriate arguments such as GPU selection, script path, and optional configuration file. The configuration file allows for flexible updates like changing batch sizes on the fly. After starting the training, log files are generated for tracking progress and analysis.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/usage.md\":28-70",
            "content": "```\n<a name=\"1\"></a>\n## 1. Train and Test\nStart running multi-cards training scripts or test scripts by `paddle.distributed.launch`, or run the `run.sh` directly.\n```bash\nsh run.sh\n```\nWe put all the start commands in advanced in the ```run.sh```, please uncomment the selected one to run.\n<a name=\"model_train\"></a>\n### 1.1 Train\nSwitch `--validate` on to validating while training.\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npython3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    --validate \\\n    -c ./configs/example.yaml\n```\nIndicating `-c` to set configuration, and one can flexible add `-o` in the script to update it.\n```bash\npython -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    -c ./configs/example.yaml \\\n    --validate \\\n    -o DATASET.batch_size=16\n```\nIndicating `-o DATASET.batch_size=16` can update batch size to 16, please refer to [configuration](tutorials/config.md#config-yaml-details) for more information.\nAfter starting training, log files will generated, "
        },
        {
            "comment": "The code shows log output format for training and validation phases, including time, epoch, batch ID, metrics, elapse time (execution time), and ips (instances per second). It also displays the best accuracy achieved during training.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/usage.md\":70-88",
            "content": "and its format is shown as below, it will output to both the screen and files. Default destination of log is under the `.log/` folder, and stored in the files named like `worker.0`, `worker.1` ...\n[train phase] current time, current epoch/ total epoch, batch id, metrics, elapse time, ips, etc.:\n    [12/28 17:31:26] epoch:[ 1/80 ] train step:0   loss: 0.04656 lr: 0.000100 top1: 1.00000 top5: 1.00000 elapse: 0.326 reader: 0.001s ips: 98.22489 instance/sec.\n[eval phase] current time, current epoch/ total epoch, batch id, metrics, elapse time, ips, etc.:\n    [12/28 17:31:32] epoch:[ 80/80 ] val step:0    loss: 0.20538 top1: 0.88281 top5: 0.99219 elapse: 1.589 reader: 0.000s ips: 20.14003 instance/sec.\n[epoch end] current time, metrics, elapse time, ips, etc.\n    [12/28 17:31:38] END epoch:80  val loss_avg: 0.52208 top1_avg: 0.84398 top5_avg: 0.97393 elapse_avg: 0.234 reader_avg: 0.000 elapse_sum: 7.021s ips: 136.73686 instance/sec.\n[the best Acc]  \n    [12/28 17:28:42] Already save the best model (top1 acc)0.8494"
        },
        {
            "comment": "The code provides instructions on how to use PaddleVideo for three different tasks: resuming a training session, finetuning with pretrained parameters, and testing. In the resume task, the user should indicate \"-o resume_epoch\" to continue from a specific epoch, while in finetuning, \"--weights\" is used to load pretrained parameters. The test mode is activated using \"--test\". PaddleVideo will not load unmatched parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/usage.md\":90-131",
            "content": "<a name=\"model_resume\"></a>\n### 1.2 Resume\nIndicate `-o resume_epoch` to resume, It will training from ```resume_epoch``` epoch, PaddleVideo will auto load optimizers parameters and checkpoints from `./output` folder, as it is the default output destination.\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npython3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    -c ./configs/example.yaml \\\n    --validate \\\n    -o resume_epoch=5\n```\n<a name=\"model_finetune\"></a>\n### 1.3 Finetune\nIndicate `--weights` to load pretrained parameters, PaddleVideo will auto treat it as a finetune mission.\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npython3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    -c ./configs/example.yaml \\\n    --validate \\\n    --weights=./outputs/example/path_to_weights\n```\nNote: PaddleVideo will NOT load shape unmatched parameters.\n<a name=\"model_test\"></a>\n### 1.4 Test\nSwitch `--test` on to start test mode, and indicate `--weights` to load pretrained model.\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3"
        },
        {
            "comment": "This code is launching PaddleVideo in distributed mode with four GPUs, running the main.py script with a specified configuration file, and performing testing using weights from a particular path. Then it exports the model for inference by specifying the configuration file, pretrained weights, and output directory. Lastly, it uses the PaddleInference engine to infer a video using the exported model files, input video file, and optional TensorRT acceleration.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/usage.md\":133-173",
            "content": "python3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    -c ./configs/example.yaml \\\n    --test \\\n    --weights=./output/example/path_to_weights\n```\n<a name=\"model_inference\"></a>\n## 2. Infer\nFirst, export model.\nIndicate `-c` to set configuration, `-p` to load pretrained model, `-o` to set inference files destination.\n```bash\npython tools/export_model.py \\\n    -c ./configs/example.yaml \\\n    -p ./output/example/path_to_weights \\\n    -o ./inference\n```\nIt will generate `model_name.pdmodel` , `model_name.pdiparams` and `model_name.pdiparames.info`.\nSecond, start PaddleInference engine to infer a video.\n```bash\npython tools/predict.py \\\n    --input_file \"data/example.avi\" \\\n    --model_file \"./inference/example.pdmodel\" \\\n    --params_file \"./inference/example.pdiparams\" \\\n    --use_gpu=True \\\n    --use_tensorrt=False\n```\nAttributes:\n+ `input_file`: input file path or input directory, which contains input files(s).\n+ `model_file`: pdmodel file path.\n+ `params_file`: pdiparams file path.\n+ `use_tensorrt`: use tensorrt to acclerate or not, default: False."
        },
        {
            "comment": "This code snippet is referring to the `use_gpu` parameter in PaddleVideo, which enables or disables GPU usage for inferencing. The default setting is set to True and benchmark results are available in the [benchmark](./benchmark.md) document.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/usage.md\":174-176",
            "content": "+ `use_gpu`: use gpu to infer or not, default: True.\nbenchmark results are shown in th [benchmark](./benchmark.md)."
        }
    ]
}