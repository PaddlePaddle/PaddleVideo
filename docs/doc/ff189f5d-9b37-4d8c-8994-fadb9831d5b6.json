{
    "summary": "The code initializes a pre-trained PaddleVideo model for PP-Care using TSM and ResNet50 weights, executes the application, and provides accuracy metrics while referencing relevant research papers on video understanding.",
    "details": [
        {
            "comment": "Introduction to video models for 3DMRI, data preparation, model training, testing, inference details, and references. Install SimpleITK dependency. Uses PaddleVideo models for 3DMRI classification. Dataset includes PD and Con cases; train/test split is 300:78. Format as *.nii or *.nii.gz. Downloaded from a Baidu link.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PP-Care/Readme.md\":0-54",
            "content": "# Video models for 3DMRI\n## \u5185\u5bb9\n- [\u6a21\u578b\u7b80\u4ecb](#\u6a21\u578b\u7b80\u4ecb)\n- [\u6570\u636e\u51c6\u5907](#\u6570\u636e\u51c6\u5907)\n- [\u6a21\u578b\u8bad\u7ec3](#\u6a21\u578b\u8bad\u7ec3)\n- [\u6a21\u578b\u6d4b\u8bd5](#\u6a21\u578b\u6d4b\u8bd5)\n- [\u6a21\u578b\u63a8\u7406](#\u6a21\u578b\u63a8\u7406)\n- [\u5b9e\u73b0\u7ec6\u8282](#\u5b9e\u73b0\u7ec6\u8282)\n- [\u53c2\u8003\u8bba\u6587](#\u53c2\u8003\u8bba\u6587)\n\u5728\u5f00\u59cb\u4f7f\u7528\u4e4b\u524d\uff0c\u60a8\u9700\u8981\u6309\u7167\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5\u989d\u5916\u7684\u4f9d\u8d56\u5305\uff1a\n```bash\npython -m pip install SimpleITK\n```\n## \u6a21\u578b\u7b80\u4ecb\n\u76ee\u524d\u5bf9\u4e8e\u533b\u5b663D\u6570\u636e\u5982MRI\uff0c\u5e76\u65e0\u592a\u597d\u7684\u5904\u7406\u624b\u6bb5\uff0c\u5927\u591a\u65702D\u6a21\u578b\u65e0\u6cd5\u83b7\u5f973D\u7a7a\u95f4\u5c42\u9762\u7684\u7279\u5f81\uff0c\u800c\u5e38\u7528\u76843D\u6a21\u578b\u53c8\u9700\u8981\u8f83\u5927\u7684\u8ba1\u7b97\u6210\u672c\u3002\u800c\u540c\u65f6\uff0c3D\u533b\u5b66\u6570\u636e\u4e0e\u5e38\u89c1\u7684\u89c6\u9891\u6570\u636e\u6709\u4e00\u5b9a\u76f8\u4f3c\u4e4b\u5904\uff0c\u6211\u4eec\u5c1d\u8bd5\u4e86\u901a\u8fc7PaddleVideo\u4e2d\u7684\u5e38\u89c1\u6a21\u578b\u89e3\u51b3\u533b\u5b663DMRI\u6570\u636e\u7684\u5206\u7c7b\u95ee\u9898\uff0c\u83b7\u5f97\u4e86\u8f83\u597d\u7684\u7ed3\u679c\u3002\u76ee\u524d\u652f\u6301PP-TSN\u3001PP-TSM\u3001Slowfast\u548cTimesformer\u5bf93DMRI\u7684\u76f4\u63a5\u8bad\u7ec3\u3002\n## \u6570\u636e\u51c6\u5907\n\u6570\u636e\u96c6\u5305\u62ec\u5e15\u91d1\u68ee\u60a3\u8005(PD)\u4e0e\u6b63\u5e38(Con)\u4e24\u79cd\u7c7b\u578b\u5171378\u4e2acase\uff0c\u8bad\u7ec3\u96c6\uff1a\u6d4b\u8bd5\u96c6=300\uff1a78\uff0c\u4f7f\u7528\u6570\u636e\u5747\u4e3a\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5305\u62ec*neurocon*, *taowu*, *PPMI*\u548c*OASIS-1*\uff08\u7ecf\u8fc7\u9009\u53d6\uff09\uff0c\u5e76\u7ecf\u8fc7\u4e00\u5b9a\u683c\u5f0f\u8f6c\u6362\uff0c\u6570\u636e\u6700\u540e\u7684\u683c\u5f0f\u5747\u4e3a*name.nii*\u6216*name.nii.gz*\uff0c\u8def\u5f84\u4e0elabel\u4fe1\u606f\u901a\u8fc7txt\u6587\u4ef6\u4fdd\u5b58\uff0c\u6570\u636e\u96c6\u53ef\u4ee5\u901a\u8fc7\u767e\u5ea6\u7f51\u76d8\u4e0b\u8f7d\uff1a[\u4e0b\u8f7d\u94fe\u63a5](https://pan.baidu.com/s/1eIsHHqnkKNG5x9CGjRONEA?pwd=avug)\n- \u6570\u636e\u96c6label\u683c\u5f0f\n```\n{\n   \"0\": \"Con\",\n   \"1\": \"PD\"\n}\n```\n- \u6570\u636e\u96c6\u4fe1\u606f\u6587\u4ef6\u683c\u5f0f\n```\n{\n   path1 label1\n   path2 label2\n   ...\n}\n```\n- \u6570\u636e\u4fdd\u5b58\u683c\u5f0f\n```\n{\n   |--  datasets\n      |--  neurocon\n      |--  taowu\n      |--  PPMI\n      |--  OASIS-1\n}\n```\n## \u6a21\u578b\u8bad\u7ec3\n#### \u4e0b\u8f7d\u5e76\u6dfb\u52a0\u9884\u8bad\u7ec3\u6a21\u578b\n1. \u5bf9\u4e8ePP-TSN\u4e0ePP-TSM\uff0c\u9664\u4e86\u53ef\u4ee5\u4f7f\u7528ImageNet1000\u4e0a\u8bad\u7ec3\u597d\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u89c1[PP-TSN\u9884\u8bad\u7ec3\u6a21\u578b](../../../docs/zh-CN/model_zoo/recognition/pp-tsn.md)\u4e0e[PP-"
        },
        {
            "comment": "This code provides instructions on how to initialize a pre-trained model for PaddleVideo's PP-Care application. It mentions downloading a pre-trained TSM model, initializing the backbone with ResNet50 weights trained on MRI data, and filling in the weight path in the YAML configuration file. The code also explains how to train and test the model using specific commands for PP-TSN_MRI as an example.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PP-Care/Readme.md\":54-80",
            "content": "TSM\u9884\u8bad\u7ec3\u6a21\u578b](../../../docs/zh-CN/model_zoo/recognition/pp-tsm.md))\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u5728MRI\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684ResNet50\u6743\u91cd\u5ea7\u4f4dBackbone\u521d\u59cb\u5316\u53c2\u6570\uff0c\u901a\u8fc7\u767e\u5ea6\u7f51\u76d8\u4e0b\u8f7d: [\u4e0b\u8f7d\u94fe\u63a5](https://pan.baidu.com/s/1eIsHHqnkKNG5x9CGjRONEA?pwd=avug)\u3002\u5bf9\u4e8eSlowfast\u4e0eTimeSformer\uff0c\u76ee\u524d\u53ea\u652f\u6301\u662f\u4f7f\u7528\u81ea\u7136\u6570\u636e\u96c6\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u89c1[Slowfast\u9884\u8bad\u7ec3\u6a21\u578b](../../../docs/zh-CN/model_zoo/recognition/slowfast.md)\u4e0e[Timesformer\u9884\u8bad\u7ec3\u6a21\u578b](../../../docs/zh-CN/model_zoo/recognition/timesformer.md)\n2. \u6253\u5f00`PaddleVideo/applications/PP-Care/configs/XXX.yaml`\uff0c\u5c06\u4e0b\u8f7d\u597d\u7684\u6743\u91cd\u8def\u5f84\u586b\u5199\u5230\u4e0b\u65b9`pretrained:`\u4e4b\u540e\uff0c\u4ee5pptsn_MRI\u4e3a\u4f8b\n   ```yaml\n   MODEL:\n       framework: \"RecognizerMRI\"\n       backbone:\n           name: \"ResNetTSN_MRI\"\n           pretrained: \u5c06\u8def\u5f84\u586b\u5199\u5230\u6b64\u5904\n   ```\n#### \u5f00\u59cb\u8bad\u7ec3\n- \u8bad\u7ec3\u4f7f\u7528\u663e\u5361\u6570\u91cf\u4e0e\u8f93\u51fa\u8def\u5f84\u7b49\u4fe1\u606f\u5747\u53ef\u4ee5\u9009\u62e9\uff0c\u4ee5PP-TSN_MRI\u76844\u5361\u8bad\u7ec3\u4e3a\u4f8b\uff0c\u8bad\u7ec3\u542f\u52a8\u547d\u4ee4\u5982\u4e0b\n  ```bash\n  python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3\" --log_dir=log_pptsn_MRI main.py  --validate -c applications/PP-Care/configs/pptsn_MRI.yaml\n  ```\n## \u6a21\u578b\u6d4b\u8bd5\n\u7531\u4e8e\u5404\u6a21\u578b\u5747\u5b58\u5728\u968f\u673a\u91c7\u6837\u90e8\u5206\uff0c\u4e14\u91c7\u6837\u65b9\u5f0f\u5b58\u5728\u4e0d\u540c\uff0c\u6240\u4ee5\u8bad\u7ec3\u65e5\u5fd7\u4e2d\u8bb0\u5f55\u7684\u9a8c\u8bc1\u6307\u6807`topk Acc`\u4e0d\u4ee3\u8868\u6700\u7ec8\u7684\u6d4b\u8bd5\u5206\u6570\uff0c\u56e0\u6b64\u5728\u8bad\u7ec3\u5b8c\u6210\u4e4b\u540e\u53ef\u4ee5\u7528\u6d4b\u8bd5\u6a21\u5f0f\u5bf9\u6700\u597d\u7684\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u83b7\u53d6\u6700\u7ec8\u7684\u6307\u6807\uff0c\u4ee5PP-TSN_MRI\u4e3a\u4f8b\uff0c\u547d\u4ee4\u5982\u4e0b\uff1a\n```bash\npython3.7 -B -m paddle.distributed.laun"
        },
        {
            "comment": "The given code executes a PaddleVideo application, PP-Care, using specific configurations and trained model weights. It tests the ResNet50 backbone with PP-TSN and PP-TSM heads on 3DMRI validation data and reports accuracy metrics. The optimized models can be downloaded from a Baidu disk link provided.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PP-Care/Readme.md\":80-105",
            "content": "ch --gpus=\"0,1,2,3\" --log_dir=log_pptsn_MRI main.py  --test -c applications/PP-Care/configs/pptsn_MRI.yaml -w \"output/ppTSN_MRI/ppTSN_MRI_best.pdparams\"\n```\n\u5f53\u6d4b\u8bd5\u914d\u7f6e\u91c7\u7528.yaml\u4e2d\u53c2\u6570\u65f6\uff0c\u57283DMRI\u6570\u636e\u7684validation\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u6307\u6807\u5982\u4e0b\uff1a\n|      backbone      |     head     |  Acc  |\n| :----------------: | :----------: | :---: |\n|      ResNet50      |    PP-TSN    | 91.07 |\n|      ResNet50      |    PP-TSM    | 90.83 |\n|     3DResNet50     |   Slowfast   | 91.07 |\n| Vision Transformer |  Timesformer | 88.33 |\n\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u767e\u5ea6\u7f51\u76d8\u4e0b\u8f7d\uff1a[\u4e0b\u8f7d\u94fe\u63a5](https://pan.baidu.com/s/1eIsHHqnkKNG5x9CGjRONEA?pwd=avug)\n## \u6a21\u578b\u4f18\u5316\n\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u6a21\u578b\u4f18\u5316\u7b56\u7565\n- \u53ef\u4ee5\u6839\u636eMRI\u6570\u636e\u5206\u5e03\uff0c\u8c03\u6574\u91c7\u6837\u7387\n- \u672c\u6a21\u578b\u76ee\u524d\u672a\u52a0\u5165\u8fc7\u591a\u7684\u6570\u636e\u9884\u5904\u7406\u7b56\u7565\uff0c\u9488\u5bf9\u4e0d\u540c\u6570\u636e\u7279\u6027\uff0c\u5728\u672c\u6a21\u578b\u57fa\u7840\u4e0a\u52a0\u5165\u4e00\u5b9a\u7684\u9884\u5904\u7406\u624b\u6bb5\u53ef\u80fd\u4f1a\u4f7f\u7ed3\u679c\u7ee7\u7eed\u63d0\u5347\n- \u7531\u4e8e\u6570\u636e\u91cf\u4e0e\u4efb\u52a1\u96be\u5ea6\u9650\u5236\uff0c\u672c\u6a21\u578b\u76ee\u524d\u5728\u51c6\u786e\u7387\u4e0a\u7684\u8868\u73b0\u4e0e3DResNet\u5e76\u65e0\u663e\u8457\u533a\u522b\uff0c\u4f46\u5bf9\u4e8e\u65f6\u95f4\u4e0e\u7a7a\u95f4\u7684\u9700\u6c42\u5747\u8fdc\u5c0f\u4e8e3D\u6a21\u578b\n## \u53c2\u8003\u8bba\u6587\n- [Temporal Segment Networks: Towards Good Practices for Deep Action Recognition](https://arxiv.org/pdf/1608.00859.pdf), Limin Wang, Yuanjun Xiong, Zhe Wang\n- [TSM: Temporal Shift Module for Efficient Video Understanding](https://arxiv.org/pdf/1811.08383.pdf), Ji Lin, Chuang Gan, Song Han"
        },
        {
            "comment": "This code snippet contains the references for various important research papers related to video understanding using neural networks. These papers cover topics like knowledge distillation, slow-fast networks, and efficient training methods for video models.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PP-Care/Readme.md\":106-109",
            "content": "- [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531), Geoffrey Hinton, Oriol Vinyals, Jeff Dean\n- [SlowFast Networks for Video Recognition](https://arxiv.org/abs/1812.03982), Feichtenhofer C, Fan H, Malik J, et al.\n- [A Multigrid Method for Efficiently Training Video Models](https://arxiv.org/abs/1912.00998), Chao-Yuan Wu, Ross Girshick, et al.\n- [Is Space-Time Attention All You Need for Video Understanding?](https://arxiv.org/pdf/2102.05095.pdf), Gedas Bertasius, Heng Wang, Lorenzo Torresani"
        }
    ]
}