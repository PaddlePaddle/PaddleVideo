{
    "summary": "This code defines image augmentation and resizing functions for AVA dataset in PaddleVideo library using operations like resizing, lazy initialization, and RandomRescale/Resize transforms. It creates classes for ground truth bounding boxes and proposals, cropping and flipping entity boxes, and includes Flip and Normalize classes for image processing and normalization.",
    "details": [
        {
            "comment": "This code is part of the PaddleVideo library and contains a module for image augmentations in the AVA dataset. It imports necessary libraries, defines conversion dictionaries for interpolation methods between PIL and OpenCV, and sets up registry entries for the PIPELINES module.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":0-33",
            "content": "#  Copyright (c) 2021 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport random\nimport numpy as np\nimport math\nfrom PIL import Image\nfrom ..registry import PIPELINES\nfrom collections.abc import Sequence\nimport cv2\npillow_interp_codes = {\n    'nearest': Image.NEAREST,\n    'bilinear': Image.BILINEAR,\n    'bicubic': Image.BICUBIC,\n    'box': Image.BOX,\n    'lanczos': Image.LANCZOS,\n    'hamming': Image.HAMMING\n}\ncv2_interp_codes = {\n    'nearest': cv2.INTER_NEAREST,\n    'bilinear': cv2.INTER_LINEAR,"
        },
        {
            "comment": "This function initializes the lazy operation properly, ensuring a non-lazy operation is not accidentally mixed in. If 'img_shape' is not in results, it adds 'img_shape'. If 'lazy' is set to True and 'lazy' does not exist in results, it creates a new dictionary for lazy operation containing 'original_shape', 'img_shape', 'crop_bbox', 'flip', 'flip_direction', and 'interpolation'.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":34-63",
            "content": "    'bicubic': cv2.INTER_CUBIC,\n    'area': cv2.INTER_AREA,\n    'lanczos': cv2.INTER_LANCZOS4\n}\ndef _init_lazy_if_proper(results, lazy):\n    \"\"\"Initialize lazy operation properly.\n    Make sure that a lazy operation is properly initialized,\n    and avoid a non-lazy operation accidentally getting mixed in.\n    Required keys in results are \"imgs\" if \"img_shape\" not in results,\n    otherwise, Required keys in results are \"img_shape\", add or modified keys\n    are \"img_shape\", \"lazy\".\n    Add or modified keys in \"lazy\" are \"original_shape\", \"crop_bbox\", \"flip\",\n    \"flip_direction\", \"interpolation\".\n    Args:\n        results (dict): A dict stores data pipeline result.\n        lazy (bool): Determine whether to apply lazy operation. Default: False.\n    \"\"\"\n    if 'img_shape' not in results:\n        results['img_shape'] = results['imgs'][0].shape[:2]\n    if lazy:\n        if 'lazy' not in results:\n            img_h, img_w = results['img_shape']\n            lazyop = dict()\n            lazyop['original_shape'] = results['img_shape']"
        },
        {
            "comment": "This code defines functions for image augmentations in the AVA dataset pipeline. The \"_scale_size\" function scales a size by a ratio, while \"rescale_size\" calculates the new size to be rescaled based on an input scale factor or maximum size. The code also includes the initialization of crop parameters and flipping options for lazy operations in the results dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":64-95",
            "content": "            lazyop['crop_bbox'] = np.array([0, 0, img_w, img_h],\n                                           dtype=np.float32)\n            lazyop['flip'] = False\n            lazyop['flip_direction'] = None\n            lazyop['interpolation'] = None\n            results['lazy'] = lazyop\n    else:\n        assert 'lazy' not in results, 'Use Fuse after lazy operations'\ndef _scale_size(size, scale):\n    \"\"\"Rescale a size by a ratio.\n    Args:\n        size (tuple[int]): (w, h).\n        scale (float): Scaling factor.\n    Returns:\n        tuple[int]: scaled size.\n    \"\"\"\n    w, h = size\n    return int(w * float(scale) + 0.5), int(h * float(scale) + 0.5)\ndef rescale_size(old_size, scale, return_scale=False):\n    \"\"\"Calculate the new size to be rescaled to.\n    Args:\n        old_size (tuple[int]): The old size (w, h) of image.\n        scale (float | tuple[int]): The scaling factor or maximum size.\n            If it is a float number, then the image will be rescaled by this\n            factor, else if it is a tuple of 2 integers, then the image will"
        },
        {
            "comment": "Function \"imresize\" resizes an image based on the provided scale factor. If the scale is a number, it's used directly as the scaling factor. If it's a tuple of ints, it sets max and min edge sizes for resizing. Returns new resized size or both size and scaling factor if requested.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":96-129",
            "content": "            be rescaled as large as possible within the scale.\n        return_scale (bool): Whether to return the scaling factor besides the\n            rescaled image size.\n    Returns:\n        tuple[int]: The new rescaled image size.\n    \"\"\"\n    w, h = old_size\n    if isinstance(scale, (float, int)):\n        if scale <= 0:\n            raise ValueError(f'Invalid scale {scale}, must be positive.')\n        scale_factor = scale\n    elif isinstance(scale, tuple):\n        max_long_edge = max(scale)\n        max_short_edge = min(scale)\n        scale_factor = min(max_long_edge / max(h, w),\n                           max_short_edge / min(h, w))\n    else:\n        raise TypeError(\n            f'Scale must be a number or tuple of int, but got {type(scale)}')\n    new_size = _scale_size((w, h), scale_factor)\n    if return_scale:\n        return new_size, scale_factor\n    else:\n        return new_size\ndef imresize(img,\n             size,\n             return_scale=False,\n             interpolation='bilinear',\n             out=None,"
        },
        {
            "comment": "This code defines a function for resizing an image to a given size. It supports two backends: 'cv2' and 'pillow'. If the backend is not specified, it defaults to 'cv2'. The function first gets the original image's height and width, checks if the backend is valid, handles unsupported backends, asserts the image type for 'pillow' backend, resizes the image using either OpenCV or Pillow library based on the backend, and finally returns the resized image along with scale factors if return_scale is True. The EntityBoxRescale class registers a pipeline to rescale entity boxes and proposals according to the image shape.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":130-159",
            "content": "             backend=None):\n    \"\"\"Resize image to a given size.  \"\"\"\n    h, w = img.shape[:2]\n    if backend is None:\n        backend = 'cv2'\n    if backend not in ['cv2', 'pillow']:\n        raise ValueError(f'backend: {backend} is not supported for resize.'\n                         f\"Supported backends are 'cv2', 'pillow'\")\n    if backend == 'pillow':\n        assert img.dtype == np.uint8, 'Pillow backend only support uint8 type'\n        pil_image = Image.fromarray(img)\n        pil_image = pil_image.resize(size, pillow_interp_codes[interpolation])\n        resized_img = np.array(pil_image)\n    else:\n        resized_img = cv2.resize(\n            img, size, dst=out, interpolation=cv2_interp_codes[interpolation])\n    if not return_scale:\n        return resized_img\n    else:\n        w_scale = size[0] / w\n        h_scale = size[1] / h\n        return resized_img, w_scale, h_scale\n@PIPELINES.register()\nclass EntityBoxRescale:\n    \"\"\"Rescale the entity box and proposals according to the image shape.\n    Required keys are \"proposals\", \"gt_bboxes\", added or modified keys are"
        },
        {
            "comment": "The code defines a class called EntityBoxCrop that scales the ground truth bounding boxes (gt_bboxes) and proposals, if present, by a given scale factor. It ensures that the number of columns in the proposals is 4. This class can be registered as a pipeline for video augmentation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":160-192",
            "content": "    \"gt_bboxes\". If original \"proposals\" is not None, \"proposals\" and\n    will be added or modified.\n    Args:\n        scale_factor (np.ndarray): The scale factor used entity_box rescaling.\n    \"\"\"\n    def __init__(self, scale_factor):\n        self.scale_factor = scale_factor\n    def __call__(self, results):\n        scale_factor = np.concatenate([self.scale_factor, self.scale_factor])\n        if 'gt_bboxes' in results:\n            gt_bboxes = results['gt_bboxes']\n            results['gt_bboxes'] = gt_bboxes * scale_factor\n        if 'proposals' in results:\n            proposals = results['proposals']\n            if proposals is not None:\n                assert proposals.shape[1] == 4, (\n                    'proposals shape should be in '\n                    f'(n, 4), but got {proposals.shape}')\n                results['proposals'] = proposals * scale_factor\n        return results\n    def __repr__(self):\n        return f'{self.__class__.__name__}(scale_factor={self.scale_factor})'\n@PIPELINES.register()\nclass EntityBoxCrop:"
        },
        {
            "comment": "This code initializes an object that crops the entity boxes and proposals according to the cropped images. The required keys are \"proposals\" and \"gt_bboxes\", while \"gt_bboxes\" is added or modified. If original \"proposals\" is not None, \"proposals\" will be modified. The crop_bbox argument specifies the bbox used to crop the original image.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":193-223",
            "content": "    \"\"\"Crop the entity boxes and proposals according to the cropped images.\n    Required keys are \"proposals\", \"gt_bboxes\", added or modified keys are\n    \"gt_bboxes\". If original \"proposals\" is not None, \"proposals\" will be\n    modified.\n    Args:\n        crop_bbox(np.ndarray | None): The bbox used to crop the original image.\n    \"\"\"\n    def __init__(self, crop_bbox):\n        self.crop_bbox = crop_bbox\n    def __call__(self, results):\n        proposals = results['proposals']\n        gt_bboxes = results['gt_bboxes']\n        if self.crop_bbox is None:\n            return results\n        x1, y1, x2, y2 = self.crop_bbox\n        img_w, img_h = x2 - x1, y2 - y1\n        assert gt_bboxes.shape[-1] == 4\n        gt_bboxes_ = gt_bboxes.copy()\n        gt_bboxes_[..., 0::2] = np.clip(gt_bboxes[..., 0::2] - x1, 0, img_w - 1)\n        gt_bboxes_[..., 1::2] = np.clip(gt_bboxes[..., 1::2] - y1, 0, img_h - 1)\n        results['gt_bboxes'] = gt_bboxes_\n        if proposals is not None:\n            assert proposals.shape[-1] == 4"
        },
        {
            "comment": "This code defines two classes, \"EntityBoxFlip\" and a nameless class. The nameless class performs cropping operations on proposals based on given coordinates (x1, y1). It also updates the results['proposals'] with the modified proposals. The EntityBoxFlip class flips the entity boxes and proposals horizontally with a certain probability. It adds or modifies keys \"gt_bboxes\" in the results dictionary. If \"proposals\" is not None, it will also modify them. The img_shape tuple represents the image shape.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":224-248",
            "content": "            proposals_ = proposals.copy()\n            proposals_[..., 0::2] = np.clip(proposals[..., 0::2] - x1, 0,\n                                            img_w - 1)\n            proposals_[..., 1::2] = np.clip(proposals[..., 1::2] - y1, 0,\n                                            img_h - 1)\n            results['proposals'] = proposals_\n        return results\n    def __repr__(self):\n        return f'{self.__class__.__name__}(crop_bbox={self.crop_bbox})'\n@PIPELINES.register()\nclass EntityBoxFlip:\n    \"\"\"Flip the entity boxes and proposals with a probability.\n    Reverse the order of elements in the given bounding boxes and proposals\n    with a specific direction. The shape of them are preserved, but the\n    elements are reordered. Only the horizontal flip is supported (seems\n    vertical flipping makes no sense). Required keys are \"proposals\",\n    \"gt_bboxes\", added or modified keys are \"gt_bboxes\". If \"proposals\"\n    is not None, it will also be modified.\n    Args:\n        img_shape (tuple[int]): The img shape."
        },
        {
            "comment": "This code defines a pipeline for resizing images to a specific size. It first initializes the pipeline with an image shape and then, in the __call__ method, it adjusts the ground truth bounding boxes and proposal bounding boxes by subtracting their width values from the total image width minus 1. If there are no proposals, it sets proposals_ to None. The __repr__ method provides a string representation of the pipeline.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":249-283",
            "content": "    \"\"\"\n    def __init__(self, img_shape):\n        self.img_shape = img_shape\n    def __call__(self, results):\n        proposals = results['proposals']\n        gt_bboxes = results['gt_bboxes']\n        img_h, img_w = self.img_shape\n        assert gt_bboxes.shape[-1] == 4\n        gt_bboxes_ = gt_bboxes.copy()\n        gt_bboxes_[..., 0::4] = img_w - gt_bboxes[..., 2::4] - 1\n        gt_bboxes_[..., 2::4] = img_w - gt_bboxes[..., 0::4] - 1\n        if proposals is not None:\n            assert proposals.shape[-1] == 4\n            proposals_ = proposals.copy()\n            proposals_[..., 0::4] = img_w - proposals[..., 2::4] - 1\n            proposals_[..., 2::4] = img_w - proposals[..., 0::4] - 1\n        else:\n            proposals_ = None\n        results['proposals'] = proposals_\n        results['gt_bboxes'] = gt_bboxes_\n        return results\n    def __repr__(self):\n        repr_str = f'{self.__class__.__name__}(img_shape={self.img_shape})'\n        return repr_str\n@PIPELINES.register()\nclass Resize:\n    \"\"\"Resize images to a specific size."
        },
        {
            "comment": "This code defines a function for image augmentation in PaddleVideo. The function takes arguments like scale, keep_ratio, interpolation, and lazy. If keep_ratio is True, it scales the image by the given factor or resizes to the maximum size specified by the tuple. It uses bilinear interpolation by default. Lazy operation can be determined if lazy argument is set to True.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":285-302",
            "content": "    Required keys are \"imgs\", \"img_shape\", \"modality\", added or modified\n    keys are \"imgs\", \"img_shape\", \"keep_ratio\", \"scale_factor\", \"lazy\",\n    \"resize_size\". Required keys in \"lazy\" is None, added or modified key is\n    \"interpolation\".\n    Args:\n        scale (float | Tuple[int]): If keep_ratio is True, it serves as scaling\n            factor or maximum size:\n            If it is a float number, the image will be rescaled by this\n            factor, else if it is a tuple of 2 integers, the image will\n            be rescaled as large as possible within the scale.\n            Otherwise, it serves as (w, h) of output size.\n        keep_ratio (bool): If set to True, Images will be resized without\n            changing the aspect ratio. Otherwise, it will resize images to a\n            given size. Default: True.\n        interpolation (str): Algorithm used for interpolation:\n            \"nearest\" | \"bilinear\". Default: \"bilinear\".\n        lazy (bool): Determine whether to apply lazy operation. Default: False."
        },
        {
            "comment": "Initializes a resize augmentation object with scale, keeps ratio (True or False), interpolation method ('bilinear' default), and lazy flag (False).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":303-333",
            "content": "    \"\"\"\n    def __init__(self,\n                 scale,\n                 keep_ratio=True,\n                 interpolation='bilinear',\n                 lazy=False):\n        if isinstance(scale, str):\n            scale = eval(scale)\n        if isinstance(scale, float):\n            if scale <= 0:\n                raise ValueError(f'Invalid scale {scale}, must be positive.')\n        elif isinstance(scale, tuple):\n            max_long_edge = max(scale)\n            max_short_edge = min(scale)\n            if max_short_edge == -1:\n                # assign np.inf to long edge for rescaling short edge later.\n                scale = (np.inf, max_long_edge)\n        else:\n            raise TypeError(\n                f'Scale must be float or tuple of int, but got {type(scale)}')\n        self.scale = scale\n        self.keep_ratio = keep_ratio\n        self.interpolation = interpolation\n        self.lazy = lazy\n    def __call__(self, results):\n        \"\"\"Performs the Resize augmentation.\n        Args:\n            results (dict): The resulting dict to be modified and passed"
        },
        {
            "comment": "This code resizes images and keypoints based on the 'scale_factor' or scale provided. If 'scale_factor' is not already in the results, it initializes it with a default value of [1, 1]. The code then calculates new image width (new_w) and height (new_h) based on the scale or keep_ratio setting. It updates 'img_shape', 'keep_ratio', and 'scale_factor' in the results dictionary, and if not lazy, it resizes images and keypoints accordingly using the imresize function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":334-362",
            "content": "                to the next transform in pipeline.\n        \"\"\"\n        _init_lazy_if_proper(results, self.lazy)\n        if 'scale_factor' not in results:\n            results['scale_factor'] = np.array([1, 1], dtype=np.float32)\n        img_h, img_w = results['img_shape']\n        if self.keep_ratio:\n            new_w, new_h = rescale_size((img_w, img_h), self.scale)\n        else:\n            new_w, new_h = self.scale\n        self.scale_factor = np.array([new_w / img_w, new_h / img_h],\n                                     dtype=np.float32)\n        results['img_shape'] = (new_h, new_w)\n        results['keep_ratio'] = self.keep_ratio\n        results['scale_factor'] = results['scale_factor'] * self.scale_factor\n        if not self.lazy:\n            if 'imgs' in results:\n                results['imgs'] = [\n                    imresize(\n                        img, (new_w, new_h), interpolation=self.interpolation)\n                    for img in results['imgs']\n                ]\n            if 'keypoint' in results:\n                results['keypoint'] = results['keypoint'] * self.scale_factor"
        },
        {
            "comment": "This code defines a class RandomRescale that performs random rescaling on images, maintaining the aspect ratio. It takes in a range for the short edge size, and an optional interpolation method. The class also has a lazy attribute to control whether the transformation is applied lazily or not. The class also includes an EntityBoxRescale function to rescale bounding boxes. The code ends with registering RandomRescale as a pipeline module.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":363-392",
            "content": "        else:\n            lazyop = results['lazy']\n            if lazyop['flip']:\n                raise NotImplementedError('Put Flip at last for now')\n            lazyop['interpolation'] = self.interpolation\n        #if 'gt_bboxes' in results:\n        assert not self.lazy\n        entity_box_rescale = EntityBoxRescale(self.scale_factor)\n        results = entity_box_rescale(results)\n        return results\n    def __repr__(self):\n        repr_str = (f'{self.__class__.__name__}('\n                    f'scale={self.scale}, keep_ratio={self.keep_ratio}, '\n                    f'interpolation={self.interpolation}, '\n                    f'lazy={self.lazy})')\n        return repr_str\n@PIPELINES.register()\nclass RandomRescale:\n    \"\"\"Randomly resize images so that the short_edge is resized to a specific\n    size in a given range. The scale ratio is unchanged after resizing.\n    \"\"\"\n    def __init__(self, scale_range, interpolation='bilinear'):\n        scale_range = eval(scale_range)\n        self.scale_range = scale_range"
        },
        {
            "comment": "This code defines a Resize augmentation transform with random scaling range, keeps aspect ratio and applies specified interpolation. It also includes a __repr__ method to provide class name, scale range and short edge value for debugging purposes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":394-422",
            "content": "        assert len(scale_range) == 2\n        assert scale_range[0] < scale_range[1]\n        assert np.all([x > 0 for x in scale_range])\n        self.keep_ratio = True\n        self.interpolation = interpolation\n    def __call__(self, results):\n        \"\"\"Performs the Resize augmentation.\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"\n        short_edge = np.random.randint(self.scale_range[0],\n                                       self.scale_range[1] + 1)\n        resize = Resize((-1, short_edge),\n                        keep_ratio=True,\n                        interpolation=self.interpolation,\n                        lazy=False)\n        results = resize(results)\n        results['short_edge'] = short_edge\n        return results\n    def __repr__(self):\n        scale_range = self.scale_range\n        repr_str = (f'{self.__class__.__name__}('\n                    f'scale_range=({scale_range[0]}, {scale_range[1]}), '"
        },
        {
            "comment": "This code defines a Rescale augmentation class for image processing in the PaddleVideo framework. It resizes images so that the short edge length is within a specified range, while maintaining the aspect ratio. The interpolation method can be set to 'nearest' or 'bilinear'. This augmentation modifies the 'imgs', 'img_shape', 'keep_ratio', 'scale_factor', 'resize_size', and 'short_edge' keys in the results dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":423-454",
            "content": "                    f'interpolation={self.interpolation})')\n        return repr_str\n@PIPELINES.register()\nclass Rescale:\n    \"\"\"resize images so that the short_edge is resized to a specific\n    size in a given range. The scale ratio is unchanged after resizing.\n    Required keys are \"imgs\", \"img_shape\", \"modality\", added or modified\n    keys are \"imgs\", \"img_shape\", \"keep_ratio\", \"scale_factor\", \"resize_size\",\n    \"short_edge\".\n    Args:\n        scale_range (tuple[int]): The range of short edge length. A closed\n            interval.\n        interpolation (str): Algorithm used for interpolation:\n            \"nearest\" | \"bilinear\". Default: \"bilinear\".\n    \"\"\"\n    def __init__(self, scale_range, interpolation='bilinear'):\n        scale_range = eval(scale_range)\n        self.scale_range = scale_range\n        self.keep_ratio = True\n        self.interpolation = interpolation\n    def __call__(self, results):\n        \"\"\"Performs the Resize augmentation.\n        Args:\n            results (dict): The resulting dict to be modified and passed"
        },
        {
            "comment": "This code defines a Resize transform and a RandomCrop_v2 class for image processing pipelines in PaddleVideo. The Resize transform scales images within a specified range and with optional interpolation, while the RandomCrop_v2 performs square random cropping on images to a specific output size.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":455-486",
            "content": "                to the next transform in pipeline.\n        \"\"\"\n        resize = Resize(\n            self.scale_range,\n            keep_ratio=True,\n            interpolation=self.interpolation,\n            lazy=False)\n        results = resize(results)\n        return results\n    def __repr__(self):\n        scale_range = self.scale_range\n        repr_str = (f'{self.__class__.__name__}('\n                    f'scale_range=({scale_range[0]}, {scale_range[1]}), '\n                    f'interpolation={self.interpolation})')\n        return repr_str\n@PIPELINES.register()\nclass RandomCrop_v2:\n    \"\"\"Vanilla square random crop that specifics the output size.\n    Required keys in results are \"imgs\" and \"img_shape\", added or\n    modified keys are \"imgs\", \"lazy\"; Required keys in \"lazy\" are \"flip\",\n    \"crop_bbox\", added or modified key is \"crop_bbox\".\n    Args:\n        size (int): The output size of the images.\n        lazy (bool): Determine whether to apply lazy operation. Default: False.\n    \"\"\"\n    def __init__(self, size, lazy=False):"
        },
        {
            "comment": "This code defines a class with an __init__ method that checks if the input 'size' is an integer, and a __call__ method to perform random cropping. The __call__ method takes a dictionary of results and performs random cropping based on the size attribute of the class instance. It asserts that the size is less than or equal to the image height and width, then randomly selects y and x offsets for cropping. If 'crop_quadruple' is not in the results dictionary, it adds a new entry with initial values. Finally, it calculates ratios for cropping based on the input size and image dimensions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":487-516",
            "content": "        if not isinstance(size, int):\n            raise TypeError(f'Size must be an int, but got {type(size)}')\n        self.size = size\n        self.lazy = lazy\n    def __call__(self, results):\n        \"\"\"Performs the RandomCrop augmentation.\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"\n        _init_lazy_if_proper(results, self.lazy)\n        img_h, img_w = results['img_shape']\n        assert self.size <= img_h and self.size <= img_w\n        y_offset = 0\n        x_offset = 0\n        if img_h > self.size:\n            y_offset = int(np.random.randint(0, img_h - self.size))\n        if img_w > self.size:\n            x_offset = int(np.random.randint(0, img_w - self.size))\n        if 'crop_quadruple' not in results:\n            results['crop_quadruple'] = np.array(\n                [0, 0, 1, 1],  # x, y, w, h\n                dtype=np.float32)\n        x_ratio, y_ratio = x_offset / img_w, y_offset / img_h\n        w_ratio, h_ratio = self.size / img_w, self.size / img_h"
        },
        {
            "comment": "This code segment is adjusting the crop quadruple, calculating a new crop bounding box, and updating the image shape based on provided offsets. It also handles lazy loading if enabled.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":518-543",
            "content": "        old_crop_quadruple = results['crop_quadruple']\n        old_x_ratio, old_y_ratio = old_crop_quadruple[0], old_crop_quadruple[1]\n        old_w_ratio, old_h_ratio = old_crop_quadruple[2], old_crop_quadruple[3]\n        new_crop_quadruple = [\n            old_x_ratio + x_ratio * old_w_ratio,\n            old_y_ratio + y_ratio * old_h_ratio, w_ratio * old_w_ratio,\n            h_ratio * old_x_ratio\n        ]\n        results['crop_quadruple'] = np.array(\n            new_crop_quadruple, dtype=np.float32)\n        new_h, new_w = self.size, self.size\n        results['crop_bbox'] = np.array(\n            [x_offset, y_offset, x_offset + new_w, y_offset + new_h])\n        results['img_shape'] = (new_h, new_w)\n        if not self.lazy:\n            results['imgs'] = [\n                img[y_offset:y_offset + new_h, x_offset:x_offset + new_w]\n                for img in results['imgs']\n            ]\n        else:\n            lazyop = results['lazy']\n            if lazyop['flip']:\n                raise NotImplementedError('Put Flip at last for now')"
        },
        {
            "comment": "This code section is responsible for applying augmentations to video frames, specifically crop and flip operations. It takes input parameters such as image size, whether it should be applied lazily or not, and the direction of flipping (if applicable). The code adjusts the crop region based on the specified offset values and stores them in the 'crop_bbox' field of the lazy operation dictionary. Additionally, if there are entity boxes present, they will also be processed according to the applied crop and flip operations.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":545-570",
            "content": "            # record crop_bbox in lazyop dict to ensure only crop once in Fuse\n            lazy_left, lazy_top, lazy_right, lazy_bottom = lazyop['crop_bbox']\n            left = x_offset * (lazy_right - lazy_left) / img_w\n            right = (x_offset + new_w) * (lazy_right - lazy_left) / img_w\n            top = y_offset * (lazy_bottom - lazy_top) / img_h\n            bottom = (y_offset + new_h) * (lazy_bottom - lazy_top) / img_h\n            lazyop['crop_bbox'] = np.array(\n                [(lazy_left + left), (lazy_top + top), (lazy_left + right),\n                 (lazy_top + bottom)],\n                dtype=np.float32)\n        # Process entity boxes\n        if 'gt_bboxes' in results:\n            assert not self.lazy\n            entity_box_crop = EntityBoxCrop(results['crop_bbox'])\n            results = entity_box_crop(results)\n        return results\n    def __repr__(self):\n        repr_str = (f'{self.__class__.__name__}(size={self.size}, '\n                    f'lazy={self.lazy})')\n        return repr_str\ndef imflip_(img, direction='horizontal'):"
        },
        {
            "comment": "The provided code contains three functions: `inplace_flip`, `iminvert`, and a pipeline class called `Flip`. \n\n`inplace_flip` takes an image (`ndarray`) and the direction for flipping (horizontal, vertical or diagonal), asserts that the direction is valid, and returns the flipped image in-place. If the direction is horizontal, it uses `cv2.flip()` with parameter 1 to flip horizontally; if the direction is vertical, it uses `cv2.flip()` with parameter 0 to flip vertically; if the direction is diagonal, it uses `cv2.flip()` with parameter -1 for diagonal flipping.\n\n`iminvert` takes an image (`ndarray`) and returns its negative (inverted) version by subtracting the original image from a numpy array of full value 255 (the maximum possible value for an 8-bit image). This effectively reverses all pixel intensities in the image.\n\nThe `Flip` class is a pipeline module that flips the input images with a certain probability. It requires keys \"imgs\", \"img_shape\", and \"modality\" (although it does not modify them) and adds no new keys.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":571-608",
            "content": "    \"\"\"Inplace flip an image horizontally or vertically.\n    Args:\n        img (ndarray): Image to be flipped.\n        direction (str): The flip direction, either \"horizontal\" or\n            \"vertical\" or \"diagonal\".\n    Returns:\n        ndarray: The flipped image (inplace).\n    \"\"\"\n    assert direction in ['horizontal', 'vertical', 'diagonal']\n    if direction == 'horizontal':\n        return cv2.flip(img, 1, img)\n    elif direction == 'vertical':\n        return cv2.flip(img, 0, img)\n    else:\n        return cv2.flip(img, -1, img)\ndef iminvert(img):\n    \"\"\"Invert (negate) an image.\n    Args:\n        img (ndarray): Image to be inverted.\n    Returns:\n        ndarray: The inverted image.\n    \"\"\"\n    return np.full_like(img, 255) - img\n@PIPELINES.register()\nclass Flip:\n    \"\"\"Flip the input images with a probability.\n    Reverse the order of elements in the given imgs with a specific direction.\n    The shape of the imgs is preserved, but the elements are reordered.\n    Required keys are \"imgs\", \"img_shape\", \"modality\", added or modified"
        },
        {
            "comment": "This code defines a Flip augmentation class for image processing in PaddleVideo. It takes flip ratio, direction (horizontal or vertical), and lazy operation as parameters. The flip_ratio determines the probability of applying the flip transformation, while direction specifies whether to flip horizontally or vertically. If the 'lazy' parameter is True, the transformation will be applied lazily. This augmentation should be placed after cropping/reshaping transformations for proper crop_quadruple calculation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":609-630",
            "content": "    keys are \"imgs\", \"lazy\" and \"flip_direction\". Required keys in \"lazy\" is\n    None, added or modified key are \"flip\" and \"flip_direction\". The Flip\n    augmentation should be placed after any cropping / reshaping augmentations,\n    to make sure crop_quadruple is calculated properly.\n    Args:\n        flip_ratio (float): Probability of implementing flip. Default: 0.5.\n        direction (str): Flip imgs horizontally or vertically. Options are\n            \"horizontal\" | \"vertical\". Default: \"horizontal\".\n        lazy (bool): Determine whether to apply lazy operation. Default: False.\n    \"\"\"\n    _directions = ['horizontal', 'vertical']\n    def __init__(self, flip_ratio=0.5, direction='horizontal', lazy=False):\n        if direction not in self._directions:\n            raise ValueError(f'Direction {direction} is not supported. '\n                             f'Currently support ones are {self._directions}')\n        self.flip_ratio = flip_ratio\n        self.direction = direction\n        self.lazy = lazy\n    def __call__(self, results):"
        },
        {
            "comment": "The code snippet performs a Flip augmentation on images, randomly flipping them horizontally based on a given flip ratio. It also sets the 'flip' and 'flip_direction' keys in the results dictionary. If the 'lazy' option is not used (self.lazy), it iterates through the images, applying the flip transformation if necessary. It also handles 'gt_bboxes' if they exist in the results dictionary, ensuring horizontal flips are applied correctly without any issues.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":631-659",
            "content": "        \"\"\"Performs the Flip augmentation.\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"\n        _init_lazy_if_proper(results, self.lazy)\n        flip = np.random.rand() < self.flip_ratio\n        results['flip'] = flip\n        results['flip_direction'] = self.direction\n        if not self.lazy:\n            if flip:\n                for i, img in enumerate(results['imgs']):\n                    imflip_(img, self.direction)\n                lt = len(results['imgs'])\n            else:\n                results['imgs'] = list(results['imgs'])\n        else:\n            lazyop = results['lazy']\n            if lazyop['flip']:\n                raise NotImplementedError('Use one Flip please')\n            lazyop['flip'] = flip\n            lazyop['flip_direction'] = self.direction\n        if 'gt_bboxes' in results and flip:\n            assert not self.lazy and self.direction == 'horizontal'\n            entity_box_flip = EntityBoxFlip(results['img_shape'])"
        },
        {
            "comment": "This code contains a class for image augmentation, including flip ratio and direction, with a method to normalize an image using mean and std values. It also includes an inplace normalization function that converts BGR to RGB if necessary. The `__repr__` method returns a string representation of the class attributes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":660-692",
            "content": "            results = entity_box_flip(results)\n        return results\n    def __repr__(self):\n        repr_str = (\n            f'{self.__class__.__name__}('\n            f'flip_ratio={self.flip_ratio}, direction={self.direction}, '\n            f'lazy={self.lazy})')\n        return repr_str\ndef imnormalize_(img, mean, std, to_rgb=True):\n    \"\"\"Inplace normalize an image with mean and std.\n    Args:\n        img (ndarray): Image to be normalized.\n        mean (ndarray): The mean to be used for normalize.\n        std (ndarray): The std to be used for normalize.\n        to_rgb (bool): Whether to convert to rgb.\n    Returns:\n        ndarray: The normalized image.\n    \"\"\"\n    # cv2 inplace normalization does not accept uint8\n    assert img.dtype != np.uint8\n    mean = np.float64(mean.reshape(1, -1))\n    stdinv = 1 / np.float64(std.reshape(1, -1))\n    if to_rgb:\n        cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)  # inplace\n    cv2.subtract(img, mean, img)  # inplace\n    cv2.multiply(img, stdinv, img)  # inplace\n    return img"
        },
        {
            "comment": "This code defines a class called \"Normalize\" that normalizes images based on given mean and std values. It can also convert channels from RGB to BGR if necessary. Additionally, it adjusts flow magnitude when modality is 'Flow' with an optional adjust_magnitude parameter. The class requires keys \"imgs\", \"img_shape\", \"modality\" with additional keys \"imgs\" and \"img_norm_cfg\" being added or modified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":695-719",
            "content": "@PIPELINES.register()\nclass Normalize:\n    \"\"\"Normalize images with the given mean and std value.\n    Required keys are \"imgs\", \"img_shape\", \"modality\", added or modified\n    keys are \"imgs\" and \"img_norm_cfg\". If modality is 'Flow', additional\n    keys \"scale_factor\" is required\n    Args:\n        mean (Sequence[float]): Mean values of different channels.\n        std (Sequence[float]): Std values of different channels.\n        to_bgr (bool): Whether to convert channels from RGB to BGR.\n            Default: False.\n        adjust_magnitude (bool): Indicate whether to adjust the flow magnitude\n            on 'scale_factor' when modality is 'Flow'. Default: False.\n    \"\"\"\n    def __init__(self, mean, std, to_bgr=False, adjust_magnitude=False):\n        if not isinstance(mean, Sequence):\n            raise TypeError(\n                f'Mean must be list, tuple or np.ndarray, but got {type(mean)}')\n        if not isinstance(std, Sequence):\n            raise TypeError(\n                f'Std must be list, tuple or np.ndarray, but got {type(std)}')"
        },
        {
            "comment": "This code defines an augmentation pipeline for image normalization in AVA. It initializes mean, std, and to_bgr values, and then applies the normalization transformation to each input image. The normalized images are stored in 'imgs' and the configuration is saved in 'img_norm_cfg'. The __repr__ method provides a string representation of the object's state.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/augmentations_ava.py\":721-748",
            "content": "        self.mean = np.array(mean, dtype=np.float32)\n        self.std = np.array(std, dtype=np.float32)\n        self.to_bgr = to_bgr\n        self.adjust_magnitude = adjust_magnitude\n    def __call__(self, results):\n        n = len(results['imgs'])\n        h, w, c = results['imgs'][0].shape\n        imgs = np.empty((n, h, w, c), dtype=np.float32)\n        for i, img in enumerate(results['imgs']):\n            imgs[i] = img\n        for img in imgs:\n            imnormalize_(img, self.mean, self.std, self.to_bgr)\n        results['imgs'] = imgs\n        results['img_norm_cfg'] = dict(\n            mean=self.mean, std=self.std, to_bgr=self.to_bgr)\n        return results\n    def __repr__(self):\n        repr_str = (f'{self.__class__.__name__}('\n                    f'mean={self.mean}, '\n                    f'std={self.std}, '\n                    f'to_bgr={self.to_bgr}, '\n                    f'adjust_magnitude={self.adjust_magnitude})')\n        return repr_str"
        }
    ]
}