{
    "summary": "This guide details fine-tuning the VideoTag model using custom data, covering AttentionLSTM and TSN models, feature extraction, and multi/single GPU support. The code trains, evaluates, predicts with TSN, requires specific weight files, allows save directories, and preprocesses videos into images.",
    "details": [
        {
            "comment": "This is a guide for fine-tuning the VideoTag pre-trained model with custom training data, covering AttentionLSTM and TSN models, principle explanations, and reference papers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/FineTune.md\":0-31",
            "content": "# \u6a21\u578b\u5fae\u8c03\u6307\u5357\n---\n## \u5185\u5bb9\n\u53c2\u8003\u672c\u6587\u6863\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u81ea\u5df1\u7684\u8bad\u7ec3\u6570\u636e\u5728VideoTag\u9884\u8bad\u7ec3\u6a21\u578b\u4e0a\u8fdb\u884cfine-tune\uff0c\u8bad\u7ec3\u51fa\u81ea\u5df1\u7684\u6a21\u578b\u3002\n\u6587\u6863\u5185\u5bb9\u5305\u62ec:\n- [\u539f\u7406\u89e3\u6790](#\u539f\u7406\u89e3\u6790)\n- [\u5bf9AttentionLSTM\u6a21\u578b\u8fdb\u884c\u5fae\u8c03](#\u5bf9AttentionLSTM\u6a21\u578b\u8fdb\u884c\u5fae\u8c03)\n- [\u5bf9TSN\u6a21\u578b\u8fdb\u884c\u5fae\u8c03](#\u5bf9TSN\u6a21\u578b\u8fdb\u884c\u5fae\u8c03)\n- [\u6269\u5c55\u5185\u5bb9](#\u6269\u5c55\u5185\u5bb9)\n- [\u53c2\u8003\u8bba\u6587](#\u53c2\u8003\u8bba\u6587)\n## \u539f\u7406\u89e3\u6790\nVideoTag\u91c7\u7528\u4e24\u9636\u6bb5\u5efa\u6a21\u65b9\u5f0f\uff0c\u7531\u4e24\u4e2a\u6a21\u578b\u7ec4\u6210: TSN + AttentionLSTM\u3002\nTemporal Segment Network (TSN) \u662f\u7ecf\u5178\u7684\u57fa\u4e8e2D-CNN\u7684\u89c6\u9891\u5206\u7c7b\u6a21\u578b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u7a00\u758f\u91c7\u6837\u89c6\u9891\u5e27\u7684\u65b9\u5f0f\uff0c\u5728\u6355\u83b7\u89c6\u9891\u65f6\u5e8f\u4fe1\u606f\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u91cf\u3002\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003\u8bba\u6587[Temporal Segment Networks: Towards Good Practices for Deep Action Recognition](https://arxiv.org/abs/1608.00859)\nAttentionLSTM\u4ee5\u89c6\u9891\u7684\u7279\u5f81\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u91c7\u7528\u53cc\u5411\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u5bf9\u6240\u6709\u5e27\u7279\u5f81\u8fdb\u884c\u7f16\u7801\uff0c\u5e76\u589e\u52a0Attention\u5c42\uff0c\u5c06\u6bcf\u4e2a\u65f6\u523b\u7684\u9690\u72b6\u6001\u8f93\u51fa\u4e0e\u81ea\u9002\u5e94\u6743\u91cd\u7ebf\u6027\u52a0\u6743\u5f97\u5230\u6700\u7ec8\u5206\u7c7b\u5411\u91cf\u3002\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003\u8bba\u6587[AttentionCluster](https://arxiv.org/abs/1711.09550)\nVideoTag\u8bad\u7ec3\u65f6\u5206\u4e24\u4e2a\u9636\u6bb5: \u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5c11\u91cf\u89c6\u9891\u6837\u672c\uff08\u5341\u4e07\u7ea7\u522b\uff09\u8bad\u7ec3\u5927\u89c4\u6a21\u89c6\u9891\u7279\u5f81\u63d0\u53d6\u6a21\u578b(TSN)\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u5343\u4e07\u7ea7\u6570\u636e\u8bad\u7ec3\u9884\u6d4b\u5668(AttentionLSTM)\u3002\nVideoTag\u9884\u6d4b\u65f6\u4e5f\u5206\u4e24\u4e2a\u9636\u6bb5: \u7b2c\u4e00\u9636\u6bb5\u4ee5\u89c6\u9891\u6587\u4ef6\u4f5c\u4e3a\u8f93\u5165\uff0c\u7ecf\u8fc7\u53bb\u9664\u4e86\u5168\u8fde\u63a5\u5c42\u4ee5\u53ca\u635f\u5931\u51fd\u6570\u5c42\u7684TSN\u7f51\u7edc\u540e\u5f97\u5230\u8f93\u51fa\u7279\u5f81\u5411\u91cf\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4ee5TSN\u7f51\u7edc\u8f93\u51fa\u7684\u7279\u5f81\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u7ecf\u8fc7AttentionLSTM\u540e\u5f97\u5230\u6700\u7ec8\u7684\u5206\u7c7b\u7ed3\u679c\u3002\n\u57fa\u4e8e\u6211\u4eec\u7684\u9884\u6a21\u578b\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u81ea\u5df1\u7684\u8bad\u7ec3\u6570\u636e\u8fdb\u884cfine-tune:\n- [\u5bf9AttentionLSTM\u6a21\u578b\u8fdb\u884c\u5fae\u8c03](#\u5bf9AttentionLSTM\u6a21\u578b\u8fdb\u884c\u5fae\u8c03)\n- [\u5bf9TSN\u6a21\u578b\u8fdb\u884c\u5fae\u8c03](#\u5bf9TSN\u6a21\u578b\u8fdb\u884c\u5fae\u8c03)\n## \u5bf9AttentionLSTM\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\nAttentionLSTM\u4ee5\u89c6\u9891\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u663e\u5b58\u5360\u7528\u5c11\uff0c\u8bad\u7ec3\u901f\u5ea6\u8f83TSN\u66f4\u5feb\uff0c\u56e0\u6b64\u63a8\u8350\u4f18\u5148\u5bf9AttentionLSTM\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u8f93\u5165\u89c6\u9891\u9996\u5148\u7ecf\u8fc7TSN\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u53d6\u7279\u5f81\u5411\u91cf\uff0c\u7136\u540e\u5c06\u7279\u5f81\u5411\u91cf\u4f5c\u4e3a\u8bad\u7ec3\u8f93\u5165\u6570\u636e\uff0c\u5fae\u8c03AttentionLSTM\u6a21\u578b\u3002"
        },
        {
            "comment": "Extract features from TSN pre-trained model, save the extracted features in specified directory. AttentionLSTM model fine-tuning requires TSN extracted features with corresponding labels in the train.list file. Label indices are defined in a separate text file, e.g., label_3396.txt.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/FineTune.md\":33-80",
            "content": "### TSN\u9884\u6a21\u578b\u63d0\u53d6\u7279\u5f81\u5411\u91cf\n#### \u6570\u636e\u51c6\u5907\n- \u9884\u8bad\u7ec3\u6743\u91cd\u4e0b\u8f7d: \u53c2\u8003[\u6837\u4f8b\u4ee3\u7801\u8fd0\u884c\u6307\u5357-\u6570\u636e\u51c6\u5907-\u9884\u8bad\u7ec3\u6743\u91cd\u4e0b\u8f7d](./Run.md)\n- \u51c6\u5907\u8bad\u7ec3\u6570\u636e: \u51c6\u5907\u597d\u5f85\u8bad\u7ec3\u7684\u89c6\u9891\u6570\u636e\uff0c\u5e76\u5728video\\_tag/data/TsnExtractor.list\u6587\u4ef6\u4e2d\u6307\u5b9a\u5f85\u8bad\u7ec3\u7684\u6587\u4ef6\u8def\u5f84\uff0c\u5185\u5bb9\u683c\u5f0f\u5982\u4e0b:\n```\nmy_video_path/my_video_file1.mp4\nmy_video_path/my_video_file2.mp4\n...\n```\n#### \u7279\u5f81\u63d0\u53d6\n\u7279\u5f81\u63d0\u53d6\u811a\u672c\u5982\u4e0b:\n```\npython tsn_extractor.py --model_name=TSN --config=./configs/tsn.yaml --weights=./weights/tsn.pdparams\n```\n- \u901a\u8fc7--weights\u53ef\u6307\u5b9aTSN\u6743\u91cd\u53c2\u6570\u7684\u5b58\u50a8\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3avideo\\_tag/weights/tsn.pdparams\n- \u901a\u8fc7--save\\_dir\u53ef\u6307\u5b9a\u7279\u5f81\u5411\u91cf\u4fdd\u5b58\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3avideo\\_tag/data/tsn\\_features\uff0c\u4e0d\u540c\u8f93\u5165\u89c6\u9891\u7684\u7279\u5f81\u5411\u91cf\u63d0\u53d6\u7ed3\u679c\u5206\u6587\u4ef6\u4fdd\u5b58\u5728\u4e0d\u540c\u7684npy\u6587\u4ef6\u4e2d\uff0c\u76ee\u5f55\u5f62\u5f0f\u4e3a:\n```\nvideo_tag\n  \u251c\u2500\u2500data\n    \u251c\u2500\u2500tsn_features\n      \u251c\u2500\u2500 my_feature_file1.npy\n      \u251c\u2500\u2500 my_feature_file2.npy\n      ...\n```\n- tsn\u63d0\u53d6\u7684\u7279\u5f81\u5411\u91cf\u7ef4\u5ea6\u4e3a```\u5e27\u6570*\u7279\u5f81\u7ef4\u5ea6```\uff0c\u9ed8\u8ba4\u4e3a300 * 2048\u3002\n### AttentionLSTM\u6a21\u578bFine-tune\n#### \u6570\u636e\u51c6\u5907\nVideoTag\u4e2d\u7684AttentionLSTM\u4ee5TSN\u6a21\u578b\u63d0\u53d6\u7684\u7279\u5f81\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\u3002\u5728video\\_tag/data/dataset/attention\\_lstm/train.list\u6587\u4ef6\u4e2d\u6307\u5b9a\u5f85\u8bad\u7ec3\u7684\u6587\u4ef6\u8def\u5f84\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u5185\u5bb9\u683c\u5f0f\u5982\u4e0b:\n```\nmy_feature_path/my_feature_file1.npy label1 label2\nmy_feature_path/my_feature_file2.npy label1\n...\n```\n- \u4e00\u4e2a\u8f93\u5165\u89c6\u9891\u53ef\u4ee5\u6709\u591a\u4e2a\u6807\u7b7e\uff0c\u6807\u7b7e\u7d22\u5f15\u4e3a\u6574\u578b\u6570\u636e\uff0c\u6587\u4ef6\u540d\u4e0e\u6807\u7b7e\u4e4b\u95f4\u3001\u591a\u4e2a\u6807\u7b7e\u4e4b\u95f4\u4ee5\u4e00\u4e2a\u7a7a\u683c\u5206\u9694\uff1b\n- \u6807\u7b7e\u7d22\u5f15\u4e0e\u6807\u7b7e\u540d\u79f0\u7684\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u4ee5list\u6587\u4ef6\u6307\u5b9a\uff0c\u53ef\u53c2\u8003VideoTag\u7528\u5230\u7684label_3396.txt\u6587\u4ef6\u6784\u9020\uff0c\u884c\u7d22\u5f15\u5bf9\u5e94\u6807\u7b7e\u7d22\u5f15;"
        },
        {
            "comment": "This code chunk is for fine-tuning the AttentionLSTM model in PaddleVideo's VideoTag application. It provides instructions for training the model with multiple GPUs or a single GPU, and specifies the configuration file and pretrained weights required. The code also demonstrates how to evaluate the trained model using eval.py script. The precision metrics printed include GAP and Hit@1.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/FineTune.md\":82-112",
            "content": "- \u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u4ee5\u53ca\u9884\u6d4b\u6570\u636e\u96c6\u7684\u6784\u9020\u65b9\u5f0f\u540c\u8bad\u7ec3\u96c6\u7c7b\u4f3c\uff0c\u4ec5\u9700\u8981\u5728video\\_tag/data/attention\\_lstm/\u76ee\u5f55\u4e0b\u5bf9\u5e94\u7684list\u6587\u4ef6\u4e2d\u6307\u5b9a\u76f8\u5173\u6587\u4ef6\u8def\u5f84/\u6807\u7b7e\u5373\u53ef\u3002\n#### \u6a21\u578b\u8bad\u7ec3\n\u4f7f\u7528VideoTag\u4e2d\u7684AttentionLSTM\u9884\u6a21\u578b\u8fdb\u884cfine-tune\u8bad\u7ec3\u811a\u672c\u5982\u4e0b:\n```\nexport CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\npython train.py --model_name=AttentionLSTM --config=./configs/attention_lstm.yaml --pretrain=./weights/attention_lstm\n```\n- AttentionLSTM\u6a21\u578b\u9ed8\u8ba4\u4f7f\u75288\u5361\u8bad\u7ec3\uff0c\u603b\u7684batch size\u6570\u662f1024\u3002\u82e5\u4f7f\u7528\u5355\u5361\u8bad\u7ec3\uff0c\u8bf7\u4fee\u6539\u73af\u5883\u53d8\u91cf\uff0c\u811a\u672c\u5982\u4e0b:\n```\nexport CUDA_VISIBLE_DEVICES=0\npython train.py --model_name=AttentionLSTM --config=./configs/attention_lstm-single.yaml --pretrain=./weights/attention_lstm\n```\n- \u8bf7\u786e\u4fdd\u8bad\u7ec3\u6837\u672c\u6570\u5927\u4e8ebatch_size\u6570\n- \u901a\u8fc7--pretrain\u53c2\u6570\u53ef\u6307\u5b9aAttentionLSTM\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a./weights/attention\\_lstm\uff1b\n- \u6a21\u578b\u76f8\u5173\u914d\u7f6e\u5199\u5728video_tag/configs/attention\\_lstm.yaml\u6587\u4ef6\u4e2d\uff0c\u53ef\u4ee5\u65b9\u4fbf\u7684\u8c03\u8282\u5404\u9879\u8d85\u53c2\u6570\uff1b\n- \u901a\u8fc7--save_dir\u53c2\u6570\u53ef\u6307\u5b9a\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u7684\u4fdd\u5b58\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a./data/checkpoints\uff1b\n#### \u6a21\u578b\u8bc4\u4f30\n\u53ef\u7528\u5982\u4e0b\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u8bc4\u4f30:\n```\npython eval.py --model_name=AttentionLSTM --config=./configs/attention_lstm.yaml --weights=./data/checkpoints/AttentionLSTM_epoch9.pdparams\n```\n- \u901a\u8fc7--weights\u53c2\u6570\u53ef\u6307\u5b9a\u8bc4\u4f30\u9700\u8981\u7684\u6743\u91cd\uff0c\u9ed8\u8ba4\u4e3a./data/checkpoints/AttentionLSTM_epoch9.pdparams\uff1b\n- \u8bc4\u4f30\u7ed3\u679c\u4ee5log\u7684\u5f62\u5f0f\u76f4\u63a5\u6253\u5370\u8f93\u51faGAP\u3001Hit@1\u7b49\u7cbe\u5ea6\u6307\u6807\u3002"
        },
        {
            "comment": "This code provides instructions for model inference and fine-tuning using the PaddleVideo framework's VideoTag application. It explains how to specify the model, configuration file, weights, label files, and save directory for prediction results. Additionally, it outlines the steps for preparing data, training, and executing a pre-trained TSN model in the VideoTag application.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/FineTune.md\":114-151",
            "content": "#### \u6a21\u578b\u63a8\u65ad\n\u53ef\u7528\u5982\u4e0b\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u63a8\u65ad:\n```\npython predict.py --model_name=AttentionLSTM --config=./configs/attention_lstm.yaml --weights=./data/checkpoints/AttentionLSTM_epoch9.pdparams\n```\n- \u901a\u8fc7--weights\u53c2\u6570\u53ef\u6307\u5b9a\u63a8\u65ad\u9700\u8981\u7684\u6743\u91cd\uff0c\u9ed8\u8ba4\u4e3a./data/checkpoints/AttentionLSTM_epoch9.pdparams\uff1b\n- \u901a\u8fc7--label_file\u53c2\u6570\u6307\u5b9a\u6807\u7b7e\u6587\u4ef6\uff0c\u8bf7\u6839\u636e\u81ea\u5df1\u7684\u6570\u636e\u4fee\u6539\uff0c\u9ed8\u8ba4\u4e3a./label_3396.txt;\n- \u9884\u6d4b\u7ed3\u679c\u4f1a\u4ee5\u65e5\u5fd7\u5f62\u5f0f\u6253\u5370\u51fa\u6765\uff0c\u540c\u65f6\u4e5f\u4fdd\u5b58\u5728json\u6587\u4ef6\u4e2d\uff0c\u901a\u8fc7--save_dir\u53c2\u6570\u53ef\u6307\u5b9a\u9884\u6d4b\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a./data/predict_results/attention_lstm\u3002\n## \u5bf9TSN\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\nVideoTag\u4e2d\u4f7f\u7528\u7684TSN\u6a21\u578b\u4ee5mp4\u6587\u4ef6\u4e3a\u8f93\u5165\uff0cbackbone\u4e3aResNet101\u3002\n### \u6570\u636e\u51c6\u5907\n\u51c6\u5907\u597d\u8bad\u7ec3\u89c6\u9891\u6587\u4ef6\u540e\uff0c\u5728video\\_tag/data/dataset/tsn/train.list\u6587\u4ef6\u4e2d\u6307\u5b9a\u5f85\u8bad\u7ec3\u7684\u6587\u4ef6\u8def\u5f84\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\u5373\u53ef\uff0c\u5185\u5bb9\u683c\u5f0f\u5982\u4e0b:\n```\nmy_video_path/my_video_file1.mp4 label1\nmy_video_path/my_video_file2.mp4 label2\n...\n```\n- \u4e00\u4e2a\u8f93\u5165\u89c6\u9891\u53ea\u80fd\u6709\u4e00\u4e2a\u6807\u7b7e\uff0c\u6807\u7b7e\u7d22\u5f15\u4e3a\u6574\u578b\u6570\u636e\uff0c\u6807\u7b7e\u7d22\u5f15\u4e0e\u6587\u4ef6\u540d\u4e4b\u95f4\u4ee5\u4e00\u4e2a\u7a7a\u683c\u5206\u9694\uff1b\n- \u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u4ee5\u53ca\u9884\u6d4b\u6570\u636e\u96c6\u7684\u6784\u9020\u65b9\u5f0f\u540c\u8bad\u7ec3\u96c6\u7c7b\u4f3c\uff0c\u4ec5\u9700\u8981\u5728video\\_tag/data/dataset/tsn\u76ee\u5f55\u4e0b\u5bf9\u5e94\u7684list\u6587\u4ef6\u4e2d\u6307\u5b9a\u76f8\u5173\u6587\u4ef6\u8def\u5f84/\u6807\u7b7e\u5373\u53ef\u3002\n#### \u6a21\u578b\u8bad\u7ec3\n\u4f7f\u7528VideoTag\u4e2d\u7684TSN\u9884\u6a21\u578b\u8fdb\u884cfine-tune\u8bad\u7ec3\u811a\u672c\u5982\u4e0b:\n```\nexport CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\npython train.py --model_name=TSN --config=./configs/tsn.yaml --pretrain=./weights/tsn\n```\n- TSN\u6a21\u578b\u9ed8\u8ba4\u4f7f\u75288\u5361\u8bad\u7ec3\uff0c\u603b\u7684batch size\u6570\u662f256\u3002\u82e5\u4f7f\u7528\u5355\u5361\u8bad\u7ec3\uff0c\u8bf7\u4fee\u6539\u73af\u5883\u53d8\u91cf\uff0c\u811a\u672c\u5982\u4e0b:\n```"
        },
        {
            "comment": "This code is for training, evaluating and predicting with the TSN model. It uses different Python scripts (train.py, eval.py, and predict.py) along with a configuration file (tsn.yaml). The TSN model requires specific weight files saved at certain locations. It also has options to specify save directories for checkpoints, evaluation results, and prediction outputs. To speed up the training process, videos can be preprocessed into images before training.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/FineTune.md\":152-187",
            "content": "export CUDA_VISIBLE_DEVICES=0\npython train.py --model_name=TSN --config=./configs/tsn-single.yaml --pretrain=./weights/tsn\n```\n- \u901a\u8fc7--pretrain\u53c2\u6570\u53ef\u6307\u5b9aTSN\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8def\u5f84\uff0c\u793a\u4f8b\u4e3a./weights/tsn\uff1b\n- \u6a21\u578b\u76f8\u5173\u914d\u7f6e\u5199\u5728video_tag/configs/tsn.yaml\u6587\u4ef6\u4e2d\uff0c\u53ef\u4ee5\u65b9\u4fbf\u7684\u8c03\u8282\u5404\u9879\u8d85\u53c2\u6570\uff1b\n- \u901a\u8fc7--save_dir\u53c2\u6570\u53ef\u6307\u5b9a\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u7684\u4fdd\u5b58\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a./data/checkpoints\uff1b\n#### \u6a21\u578b\u8bc4\u4f30\n\u53ef\u7528\u5982\u4e0b\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u8bc4\u4f30:\n```\npython eval.py --model_name=TSN --config=./configs/tsn.yaml --weights=./data/checkpoints/TSN_epoch44.pdparams\n```\n- \u901a\u8fc7--weights\u53c2\u6570\u53ef\u6307\u5b9a\u8bc4\u4f30\u9700\u8981\u7684\u6743\u91cd\uff0c\u793a\u4f8b\u4e3a./data/checkpoints/TSN_epoch44.pdparams\uff1b\n- \u8bc4\u4f30\u7ed3\u679c\u4ee5log\u7684\u5f62\u5f0f\u76f4\u63a5\u6253\u5370\u8f93\u51faTOP1_ACC\u3001TOP5_ACC\u7b49\u7cbe\u5ea6\u6307\u6807\u3002\n#### \u6a21\u578b\u63a8\u65ad\n\u53ef\u7528\u5982\u4e0b\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u63a8\u65ad:\n```\npython predict.py --model_name=TSN --config=./configs/tsn.yaml --weights=./data/checkpoints/TSN_epoch44.pdparams --save_dir=./data/predict_results/tsn/\n```\n- \u901a\u8fc7--weights\u53c2\u6570\u53ef\u6307\u5b9a\u63a8\u65ad\u9700\u8981\u7684\u6743\u91cd\uff0c\u793a\u4f8b\u4e3a./data/checkpoints/TSN_epoch44.pdparams\uff1b\n- \u901a\u8fc7--label_file\u53c2\u6570\u6307\u5b9a\u6807\u7b7e\u6587\u4ef6\uff0c\u8bf7\u6839\u636e\u81ea\u5df1\u7684\u6570\u636e\u4fee\u6539\uff0c\u9ed8\u8ba4\u4e3a./label_3396.txt;\n- \u9884\u6d4b\u7ed3\u679c\u4f1a\u4ee5\u65e5\u5fd7\u5f62\u5f0f\u6253\u5370\u51fa\u6765\uff0c\u540c\u65f6\u4e5f\u4fdd\u5b58\u5728json\u6587\u4ef6\u4e2d\uff0c\u901a\u8fc7--save_dir\u53c2\u6570\u53ef\u6307\u5b9a\u9884\u6d4b\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84\uff0c\u793a\u4f8b\u4e3a./data/predict_results/tsn\u3002\n### \u8bad\u7ec3\u52a0\u901f\nTSN\u6a21\u578b\u9ed8\u8ba4\u4ee5mp4\u7684\u89c6\u9891\u6587\u4ef6\u4f5c\u4e3a\u8f93\u5165\uff0c\u8bad\u7ec3\u65f6\u9700\u8981\u5148\u5bf9\u89c6\u9891\u6587\u4ef6\u89e3\u7801\uff0c\u518d\u5c06\u89e3\u7801\u540e\u7684\u6570\u636e\u9001\u5165\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\uff0c\u5982\u679c\u89c6\u9891\u6587\u4ef6\u5f88\u5927\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5c06\u4f1a\u5f88\u8017\u65f6\u3002\n\u4e3a\u52a0\u901f\u8bad\u7ec3\uff0c\u53ef\u4ee5\u5148\u5c06\u89c6\u9891\u89e3\u7801\u6210\u56fe\u7247\uff0c\u7136\u540e\u4fdd\u5b58\u4e0b\u6765\uff0c\u8bad\u7ec3\u65f6\u76f4\u63a5\u6839\u636e\u7d22\u5f15\u8bfb\u53d6\u5e27\u56fe\u7247\u4f5c\u4e3a\u8f93\u5165\uff0c\u52a0\u5feb\u8bad\u7ec3\u8fc7\u7a0b\u3002"
        },
        {
            "comment": "The code is preparing the data by decoding videos into frames and generating a file path list for these frames. It modifies the configuration file, changing the model format to \"frames\" and updating the filelist accordingly. Additional information about TSN and AttentionLSTM models can be found in their respective PaddleCV repositories, with references provided to the original papers as well.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/FineTune.md\":189-205",
            "content": "- \u6570\u636e\u51c6\u5907: \u9996\u5148\u5c06\u89c6\u9891\u89e3\u7801\uff0c\u5b58\u6210\u5e27\u56fe\u7247\uff1b\u7136\u540e\u751f\u6210\u5e27\u56fe\u7247\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868\u3002\u5b9e\u73b0\u8fc7\u7a0b\u53ef\u53c2\u8003[ucf-101\u6570\u636e\u51c6\u5907](../../../../dygraph/tsn/data/dataset/ucf101/README.md)\n- \u4fee\u6539\u914d\u7f6e\u6587\u4ef6: \u4fee\u6539\u914d\u7f6e\u6587\u4ef6./config/tsn.yaml\uff0c\u5176\u4e2dMODEL.format\u503c\u6539\u4e3a\"frames\"\uff0c\u4e0d\u540c\u6a21\u5f0f\u4e0b\u7684filelist\u503c\u6539\u4e3a\u5bf9\u5e94\u7684\u5e27\u56fe\u7247\u6587\u4ef6list\u3002\n## \u6269\u5c55\u5185\u5bb9\n- \u66f4\u591a\u5173\u4e8eTSN\u6a21\u578b\u7684\u5185\u5bb9\u53ef\u53c2\u8003PaddleCV\u89c6\u9891\u5e93[TSN\u89c6\u9891\u5206\u7c7b\u6a21\u578b](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/models/tsn/README.md)\u3002\n- \u66f4\u591a\u5173\u4e8eAttentionLSTM\u6a21\u578b\u7684\u5185\u5bb9\u53ef\u53c2\u8003PaddleCV\u89c6\u9891\u5e93[AttentionLSTM\u89c6\u9891\u5206\u7c7b\u6a21\u578b](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/video/models/attention_lstm)\u3002\n## \u53c2\u8003\u8bba\u6587\n- [Temporal Segment Networks: Towards Good Practices for Deep Action Recognition](https://arxiv.org/abs/1608.00859), Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, Luc Van Gool\n- [Beyond Short Snippets: Deep Networks for Video Classification](https://arxiv.org/abs/1503.08909) Joe Yue-Hei Ng, Matthew Hausknecht, Sudheendra Vijayanarasimhan, Oriol Vinyals, Rajat Monga, George Toderici"
        }
    ]
}