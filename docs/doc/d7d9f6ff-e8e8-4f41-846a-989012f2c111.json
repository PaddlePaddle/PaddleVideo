{
    "summary": "The code defines a function for loading annotations and includes helper functions, iterates through label ranges and thresholds to find the best combination of IOU and score threshold for evaluating basketball actions, calculates evaluation results, updates best scores, and prints these best scores along with the evaluation results.",
    "details": [
        {
            "comment": "This code defines a function called `load_gts()` which loads ground truth annotations (gts) for video evaluation. It imports necessary modules, sets up global variables like fps and mode, and utilizes a JSON file to map labels to their indices. The gts data is stored in a dictionary with 'fps' and 'gts' keys, where 'fps' stores the frame rate and 'gts' stores individual annotations for each video. Each annotation has a 'mode' key indicating whether it's from training or validation set.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":0-35",
            "content": "\"\"\"\nget instance for lstm\n\u6839\u636egts\u8ba1\u7b97\u6bcf\u4e2aproposal_bmn\u7684iou\u3001ioa\u3001label\u7b49\u4fe1\u606f\n\"\"\"\nimport os\nimport sys\nimport json\nimport random\nimport pickle\nimport numpy as np\nimport io\nsys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding = 'utf-8')\ndataset = \"datasets/\"\nlabel_index_file = './configs_basketball/index_label_basketball_6.json'\neval_datasets = ['EuroCup2016']\nlabel_files = {'train': 'label_cls6_train.json',\n               'validation': 'label_cls6_val.json'}\nglobal fps, mode\nlabel_index = json.load(open(label_index_file, 'rb'))\ndef load_gts():\n    global fps\n    gts_data = {'fps': 0, 'gts': {}}\n    for eval_data in eval_datasets:\n        for item, value in label_files.items():\n            label_file = '{}/{}/{}'.format(dataset, eval_data, value)\n            gts = json.load(open(label_file, 'rb'))\n            gts_data['fps'] = gts['fps']\n            fps = gts['fps']\n            for gt in gts['gts']:\n                gt['mode'] = item\n                basename = '{}/{}/mp4/{}'.format(dataset, eval_data, os.path.basename(gt['url']))"
        },
        {
            "comment": "This code snippet defines three functions: \"get_gt\", \"computeIoU\", and \"convert_proposal\". The \"get_gt\" function takes a baseline name and returns the ground truth (GT) for that specific baseline. The \"computeIoU\" function calculates the intersection over union (IoU) between two events. Lastly, the \"convert_proposal\" function converts event proposals into ground truths based on their scores, threshold, and frame rates.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":36-66",
            "content": "                gts_data['gts'][basename] = gt\n    return gts_data['gts']\ndef computeIoU(e1, e2):\n    \"\"\"\n    clc iou and ioa\n    \"\"\"\n    if not (e1['label'] == e2['label'] and e1['basename'] == e2['basename']):\n        return 0.\n    area1 = e1[\"end\"] - e1[\"start\"]\n    area2 = e2[\"end\"] - e2[\"start\"]\n    x1 = np.maximum(e1[\"start\"], e2[\"start\"])\n    x2 = np.minimum(e1[\"end\"], e2[\"end\"])\n    inter = np.maximum(0.0, x2 - x1)\n    iou = 0.0 if (area1 + area2 - inter) == 0 else inter * 1.0 / (area1 + area2 - inter)\n    if not mode == 'proposal':\n        iou = 0.0 if area2 == 0 else inter * 1.0 / area2\n    return iou\ndef convert_proposal(boxes, basename, score_threshold=0.01):\n    boxes = sorted(boxes, key=lambda x:float(x['score']), reverse=True)\n    res = []\n    for box in boxes:\n        if not float(box['score']) >= score_threshold:\n            continue\n        res.append({'basename': basename,\n                    'start': int(float(box['start']) / fps),\n                    'end': int(float(box['end']) / fps),\n                    'label': 0})"
        },
        {
            "comment": "The code defines a function `convert_classify` that takes in boxes, base name, iou threshold, and score threshold. It sorts the boxes based on their classify score and iou score in descending order. The function then loops over each box, checks if the box meets the iou and score thresholds, and appends to a list named 'res' with necessary details such as basename, start time converted to frame number, end time converted to frame number, and label id. The code also has another function `convert_groundtruth` which takes in boxes, base name, and phase (optional). It iterates over the label ids of each box and appends a dictionary to the list 'res' with necessary details such as basename, start id, and label.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":67-92",
            "content": "    return res\ndef convert_classify(boxes, basename, iou_threshold, score_threshold):\n    boxes = sorted(boxes, key=lambda x:(float(x['classify_score']), float(x['iou_score'])), reverse=True)\n    def convert_time_to_frame(time_type):\n        return int(time_type)\n        h, m, s = time_type.split(':')\n        return int(h) * 3600 + int(m) * 60 + int(s)\n    res = []\n    for box in boxes:\n        if not (box['iou_score'] >= iou_threshold and\n                box['classify_score'] >= score_threshold):\n            continue\n        res.append({'basename': basename,\n                    'start': convert_time_to_frame(box['start_time']),\n                    'end': convert_time_to_frame(box['end_time']),\n                    'label': box['label_id']})\n    return res\ndef convert_groundtruth(boxes, basename, phase=None):\n    res = []\n    for box in boxes:\n        for item in box['label_ids']:\n            label = 0 if phase == 'proposal' else item\n            res.append({'basename': basename,\n                        'start': box['start_id'],"
        },
        {
            "comment": "This code contains four functions: `evaluation`, `print_result`, `print_head`, and `print_head`. These functions calculate and print the evaluation results for a set of detected boxes (res_boxes) against the ground truth boxes (gts_boxes). The code also calculates various metrics such as precision, recall, hit properties, and number of instances. It uses label ranges, IoU thresholds, and can show intermediate IoU values if specified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":93-119",
            "content": "                        'end': box['end_id'],\n                        'label': label})\n    return res\ndef print_head(iou):\n    print(\"\\nioa = {:.1f}\".format(iou))\n    res_str = ''\n    for item in ['label_name']:\n        res_str += '{:<12s}'.format(item)\n    for item in ['label_id', 'precision', 'recall', 'hit_prop', 'num_prop', 'hit_gts', 'num_gts']:\n        res_str += '{:<10s}'.format(item)\n    print(res_str)\ndef print_result(res_dict, label='avg'):\n    if label == 'avg':\n        res_str = '{:<22s}'.format(str(label))\n    else:\n        res_str = '{0:{2}<6s}{1:<10s}'.format(label_index[str(label)], str(label), chr(12288))\n    for item in ['prec', 'recall']:\n        res_str += '{:<10.4f}'.format(res_dict[item])\n    for item in ['hit_prop', 'num_prop', 'hit_gts', 'num_gts']:\n        res_str += '{:<10d}'.format(res_dict[item])\n    print(res_str)\ndef evaluation(res_boxes, gts_boxes, label_range, iou_range, show_sub = False):\n    iou_map = [computeIoU(resId, gtsId) for resId in res_boxes \\\n                                        for gtsId in gts_boxes]"
        },
        {
            "comment": "This code calculates evaluation metrics for detected objects based on their Intersection over Union (IoU) with ground truth objects. It iterates through different IoU thresholds and label ranges to compute hit proportion, number of propositions, hit GTs, and number of ground truth objects for each threshold and label. The results are stored in a dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":120-143",
            "content": "    iou_map = np.array(iou_map).reshape((len(res_boxes), len(gts_boxes)))\n    hit_map_prop_total = np.max(iou_map, axis=1)\n    hit_map_index_total = np.argmax(iou_map, axis=1)\n    res_dict = ['hit_prop', 'num_prop', 'hit_gts', 'num_gts']\n    for iou_threshold in iou_range:\n        if show_sub:\n            print_head(iou_threshold)\n        iou_prop = np.array([k >= iou_threshold for k in hit_map_prop_total])\n        average_results = {}\n        for label_id in label_range:\n            sub_results = {}\n            label_prop = np.array([k['label'] == label_id for k in res_boxes])\n            label_gts = np.array([k['label'] == label_id for k in gts_boxes])\n            sub_results['num_prop'] = sum(label_prop)\n            sub_results['num_gts'] = sum(label_gts)\n            if sub_results['num_prop'] == 0:\n                hit_prop_index = []\n            else:\n                hit_prop_index = label_prop & iou_prop\n            sub_results['hit_prop'] = sum(hit_prop_index)\n            sub_results['hit_gts'] = len(set(hit_map_index_total[hit_prop_index]))"
        },
        {
            "comment": "This code calculates precision and recall values for sub-results and average results in a classification task. It handles cases where the number of true positives, true negatives, false positives or false negatives is zero by assigning precision and recall as 0. The code outputs average values only for labels with a range greater than one.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":145-160",
            "content": "            sub_results['prec'] = 0.0 if sub_results['num_prop'] == 0 \\\n                                      else sub_results['hit_prop'] * 1.0 / sub_results['num_prop']\n            sub_results['recall'] = 0.0 if sub_results['num_gts'] == 0 \\\n                                        else sub_results['hit_gts'] * 1.0 / sub_results['num_gts']\n            if show_sub:\n                print_result(sub_results, label=label_id)\n            for item in res_dict:\n                if not item in average_results:\n                    average_results[item] = 0\n                average_results[item] += sub_results[item]\n        if len(label_range) == 1:   # proposal \u4e0d\u9700\u8981\u8f93\u51faaverage\u503c\n            continue\n        average_results['prec'] = 0.0 if average_results['num_prop'] == 0 \\\n                                      else average_results['hit_prop'] * 1.0 / average_results['num_prop']\n        average_results['recall'] = 0.0 if average_results['num_gts'] == 0 \\\n                                        else average_results['hit_gts'] * 1.0 / average_results['num_gts']"
        },
        {
            "comment": "This code calculates the F1 score for a set of predictions and ground truth data. If 'show_sub' is True, it prints the average results. It then calculates the F1 score based on precision and recall values. The function returns the average results containing precision, recall, and F1 score.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":161-188",
            "content": "        if show_sub:\n            print_result(average_results)\n        average_results['F1'] = 0.0 if (average_results['prec'] + average_results['recall'] == 0) \\\n                                    else 2 * average_results['prec'] * average_results['recall'] / \\\n                                            (average_results['prec'] + average_results['recall'])\n        return average_results\ndef get_eval_results(predicts, gts_data, phase, iou_threshold = 0.3, score_threshold = 0.3, show_sub = False):\n    global mode\n    mode = phase\n    res_boxes = []\n    gts_boxes = []\n    for ped_data in predicts:\n        basename = ped_data['video_name']\n        # eval sub data\n        such_eval = False\n        for eval_name in eval_datasets:\n            if eval_name in basename:\n                such_eval = True\n                break\n        if not such_eval:\n            continue\n        gts = gts_data[basename]['actions']\n        if phase == 'proposal':\n            res_boxes.extend(convert_proposal(ped_data['bmn_results'], basename, score_threshold))"
        },
        {
            "comment": "The code is evaluating the performance of a video action detection model. It extends the ground truth boxes for proposals and classifies them based on IOU and score thresholds. It then performs evaluation using these results and displays the best F1 score.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":189-217",
            "content": "            gts_boxes.extend(convert_groundtruth(gts, basename, phase='proposal'))\n            label_range = [0]\n            iou_range = np.arange(0.1, 1, 0.1)\n        else:\n            res_boxes.extend(convert_classify(ped_data['action_results'], basename, iou_threshold, score_threshold))\n            gts_boxes.extend(convert_groundtruth(gts, basename))\n            label_range = range(1, len(label_index))\n            iou_range = np.arange(0.5, 0.6, 0.1)\n    eval_results = evaluation(res_boxes, gts_boxes, label_range, iou_range, show_sub = show_sub)\n    return eval_results\nif __name__ == \"__main__\":\n    result_file = sys.argv[1]\n    predicts = json.load(open(result_file, 'r', encoding='utf-8'))\n    gts_data = load_gts()\n    get_eval_results(predicts, gts_data, 'proposal', \n                     score_threshold = 0.03,\n                     show_sub = True)\n    #get_eval_results(predicts, gts_data, 'actions')\n    best_F1 = -0.1\n    best_res = {}\n    best_iou_threshold = 0.\n    best_score_threshold = 0.\n    for iou_threshold in np.arange(0.1, 0.9, 0.1):"
        },
        {
            "comment": "This code is iterating through different score thresholds to find the best combination of IOU and score threshold for evaluating basketball actions. It calculates evaluation results for each threshold, updating the best scores accordingly. Finally, it prints these best scores and displays the evaluation results using a function called print_result().",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/BasketballAction/predict/eval.py\":218-236",
            "content": "        for score_threshold in np.arange(0.1, 1, 0.1):\n            avg_res = get_eval_results(predicts, gts_data, 'actions', \n                                       iou_threshold = iou_threshold,\n                                       score_threshold = score_threshold,\n                                       show_sub = False)\n            if best_F1 < avg_res['F1']:\n                best_F1 = avg_res['F1']\n                best_res = avg_res\n                best_iou_threshold = iou_threshold\n                best_score_threshold = score_threshold\n    print(\"best iou threshold = {:.1f}\".format(best_iou_threshold))\n    print(\"best score threshold = {:.1f}\".format(best_score_threshold))\n    print('best F1 score = {:.4f}'.format(best_F1))\n    print_head(0.5)\n    print_result(best_res)\n    get_eval_results(predicts, gts_data, 'actions', iou_threshold = best_iou_threshold,\n                                                    score_threshold = best_score_threshold,\n                                                    show_sub = True)"
        }
    ]
}