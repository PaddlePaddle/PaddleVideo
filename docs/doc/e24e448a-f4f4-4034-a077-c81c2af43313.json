{
    "summary": "This code compares PaddleVideo's speed with popular frameworks, highlighting Slowfast's 2x faster speed and evaluates action segmentation model performance on Breakfast dataset. Tested on V100 GPU with batch size 2.",
    "details": [
        {
            "comment": "This code provides a benchmark comparison of PaddleVideo with other popular frameworks and official releases in terms of speed. It specifies the environment, hardware, and software used for the experiments. The statistics include average training time and training speed measured in instances per second (ips). The dataset is prepared according to a specific method to ensure fairness in the comparison.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/benchmark.md\":0-26",
            "content": "[\u7b80\u4f53\u4e2d\u6587](../zh-CN/benchmark.md) | English\n# Benchmark\nWe compare our results with some popular frameworks and official releases in terms of speed.\n## Environment\n### Hardware\n- 8 NVIDIA Tesla V100 (16G) GPUs\n- Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz\n### Software\n- Python 3.7\n- PaddlePaddle2.0\n- CUDA 10.1\n- CUDNN 7.6.3\n- NCCL 2.1.15\n- GCC 8.2.0\n## Experiments and Statistics\nThe statistic is the average training time, including data processing and model training time, and the training speed is measured with ips(instance per second). Note that we skip the first 50 iters as they may contain the device warmup time.\nHere we compare PaddleVideo with the other video understanding toolkits in the same data and model settings.\nTo ensure the fairness of the comparison, the comparison experiments were conducted under the same hardware environment and using the same dataset. The dataset we used is generated by the [data preparation](dataset/k400.md), and in each model setting, the same data preprocessing methods are applied to make sure the same feature input."
        },
        {
            "comment": "This table compares the inference performance (ips) of various video understanding models using PaddleVideo. It shows the batch size, number of GPUs used, and ips for each model. Slowfast model stands out for its 2x faster speed compared to counterparts. TSM and TSN have higher ips than others, but the reference implementation is not available.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/benchmark.md\":28-44",
            "content": "Significant improvement can be observed when comparing with other video understanding framework as shown in the table below, Especially the [Slowfast](../../configs/recognition/slowfast/slowfast.yaml) model is nearly 2x faster than the counterparts.\n## Results\n### Recognizers\n| Model | batch size <sub>x</sub> gpus | PaddleVideo(ips) | Reference(ips) | MMAction2 (ips)  | PySlowFast (ips)|\n| :------: | :-------------------:|:---------------:|:---------------: | :---------------:  |:---------------: |\n| [TSM](../../configs/recognition/tsm/tsm.yaml) | 16x8 | 58.1 | 46.04(temporal-shift-module) | To do | X |\n| [PPTSM](../../configs/recognition/tsm/pptsm.yaml) | 16x8 |  57.6 | X |    X   | X |\n| [TSN](../../configs/recognition/tsn/tsn.yaml) | 16x8 |  841.1 |  To do (tsn-pytorch) | To do | X |\n| [Slowfast](../../configs/recognition/slowfast/slowfast.yaml)| 16x8 | 99.5 | X | To do | 43.2 |\n| [Attention_LSTM](../../configs/recognition/attention_lstm/attention_lstm.yaml) |  128x8  | 112.6  | X | X | X |\n### Localizers"
        },
        {
            "comment": "This code provides a comparison of performance and accuracy between classical and popular sequential action segmentation models, with metrics such as F1@0.5, model names, Flops(M), Params(M), and test/inference times for different batch sizes. It is part of a repository that aims to compare these models using the Breakfast dataset.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/benchmark.md\":46-63",
            "content": "| Model | PaddleVideo(ips) |MMAction2 (ips) |BMN(boundary matching network) (ips)|\n| :--- | :---------------: | :-------------------------------------: | :-------------------------------------: |\n| [BMN](../../configs/localization/bmn.yaml)  | 43.84 | x | x |\n### Segmenters\nThis repo provides performance and accuracy comparison between classical and popular sequential action segmentation models\n| Model | Metrics | Value | Flops(M) |Params(M) | test time(ms) bs=1 | test time(ms) bs=2 | inference time(ms) bs=1 | inference time(ms) bs=2 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| MS-TCN | F1@0.5 | 38.8% | 791.360 | 0.8 | 170 | - | 10.68 | - |\n| ASRF | F1@0.5 | 55.7% | 1,283.328 | 1.3 | 190 | - | 16.34 | - |\n* Model: model name, for example: PP-TSM\n* Metrics: Fill in the indicators used in the model test, and the data set used is **breakfast**\n* Value: Fill in the value corresponding to the metrics index, and generally keep two decimal places\n* Flops(M): The floating-"
        },
        {
            "comment": "This code is describing the performance measurements for a PaddleVideo model. It calculates the model parameters (M), test time, and inference time with specific batch sizes and input tensor shapes. The test data used is \"breakfast\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/benchmark.md\":63-67",
            "content": "point computation required for one forward operation of the model can be called `paddlevideo/tools/summary.py`script calculation (different models may need to be modified slightly), keep one decimal place, and measure it with data **input tensor with shape of (1, 2048, 1000)**\n* Params(M): The model parameter quantity, together with flops, will be calculated by the script, and one decimal place will be reserved\n* test time(ms) bs=1: When the python script starts the batchsize = 1 test, the time required for a sample is kept to two decimal places. The data set used in the test is **breakfast**.\n* test time(ms) bs=2: When the python script starts the batchsize = 2 test, the time required for a sample is kept to two decimal places. The sequential action segmentation model is generally a full convolution network, so the batch of training, testing and reasoning_ Size is 1. The data set used in the test is **breakfast**.\n* inference time(ms) bs=1: When the reasoning model is tested with GPU (def"
        },
        {
            "comment": "The code states that the reasoning model is tested on a GPU (default V100) with batch size 2. The time required for a sample is reserved to two decimal places, and the dataset used for this particular reasoning process is \"breakfast\". Additionally, it mentions that the sequential action segmentation model is generally a full convolution network, which typically has a batch size of 1 during training, testing, and reasoning.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/benchmark.md\":67-68",
            "content": "ault V100) with batchsize = 1, the time required for a sample is reserved to two decimal places. The dataset used for reasoning is **breakfast**.\n* inference time(ms) bs=2: When the reasoning model is tested with GPU (default V100) with batchsize = 1, the time required for a sample is reserved to two decimal places. The sequential action segmentation model is generally a full convolution network, so the batch of training, testing and reasoning_ Size is 1. The dataset used for reasoning is **breakfast**."
        }
    ]
}