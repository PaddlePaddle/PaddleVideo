{
    "summary": "This script trains multiple deep learning models for various computer vision tasks with PaddlePaddle framework and demonstrates running BMN test, exporting models, inference using PaddleVideo toolkit, and provides training time calculation.",
    "details": [
        {
            "comment": "This script sets the CUDA visible devices, launches distributed training for multiple models (pp-tsm, pp-tsm_v2, ava), and specifies log directories and configurations. It runs all at once using 8 GPUs and Python3.7.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/run.sh\":0-17",
            "content": "export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n#export FLAGS_conv_workspace_size_limit=800 #MB\n#export FLAGS_cudnn_exhaustive_search=1\n#export FLAGS_cudnn_batchnorm_spatial_persistent=1\nstart_time=$(date +%s)\n# run pp-tsm training\n#python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsm  main.py --validate -c configs/recognition/pptsm/pptsm_k400_frames_uniform.yaml\n# run pp-tsm_v2 distillation training\npython3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsm_v2  main.py --validate -c configs/recognition/pptsm/v2/pptsm_lcnet_k400_16frames_uniform_dml_distillation.yaml\n# run ava training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3\" --log_dir=logdir.ava_part main.py --validate -w paddle.init_param.pdparams -c configs/detection/ava/ava_part.yaml\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=logdir.ava_all.1203 main.py --validate -w paddle.init_param.pdparams -c configs/detection/ava/ava_all.yaml"
        },
        {
            "comment": "This code contains various command lines to run different video recognition training processes using PaddlePaddle framework on multiple GPUs. Each line specifies the model architecture, the configuration file, and the options like validation, amp (automatic mixed precision), and GPU allocation for each specific task.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/run.sh\":19-35",
            "content": "# run adds training\n# python3.7 main.py --validate -c configs/estimation/adds/adds.yaml --seed 20\n# run tsm training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_tsm main.py  --validate -c configs/recognition/tsm/tsm_k400_frames.yaml\n# run tsm amp training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_tsm main.py  --amp --validate -c configs/recognition/tsm/tsm_k400_frames.yaml\n# run tsm amp training, nhwc\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_tsm main.py  --amp --validate -c configs/recognition/tsm/tsm_k400_frames_nhwc.yaml\n# run tsn training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_tsn main.py  --validate -c configs/recognition/tsn/tsn_k400_frames.yaml\n# run video-swin-transformer training\n# python3.7 -u -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_videoswin main.py --amp --validate -c configs/recognition/videoswin/videoswin_k400_videos.yaml"
        },
        {
            "comment": "This code executes multiple deep learning model training scripts for various computer vision tasks such as recognition, localization, and more using PaddlePaddle framework. The training runs in distributed mode with GPU utilization to speed up the process.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/run.sh\":37-53",
            "content": "# run slowfast training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_slowfast  main.py --validate -c configs/recognition/slowfast/slowfast.yaml\n# run slowfast multi-grid training\n# python3.7 -B -m paddle.distributed.launch --selected_gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log-slowfast main.py --validate --multigrid -c configs/recognition/slowfast/slowfast_multigrid.yaml\n# run bmn training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3\"  --log_dir=log_bmn main.py  --validate -c configs/localization/bmn.yaml\n# run attention_lstm training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_attetion_lstm  main.py  --validate -c configs/recognition/attention_lstm/attention_lstm_youtube-8m.yaml\n# run pp-tsn training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsn  main.py  --validate -c configs/recognition/pptsn/pptsn_k400_frames.yaml\n# run timesformer training\n# python3.7 -B -m paddle."
        },
        {
            "comment": "This code executes multiple deep learning model training and testing scripts for various tasks. It launches distributed training with specific GPU configurations, sets log directories, and uses different configuration files depending on the task. The tasks include pp-timesformer, st-gcn, agcn, actbert, tsn dali training, and example test.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/run.sh\":53-73",
            "content": "distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_timesformer  main.py  --validate -c configs/recognition/timesformer/timesformer_k400_videos.yaml\n# run pp-timesformer training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptimesformer  main.py  --validate -c configs/recognition/pptimesformer/pptimesformer_k400_videos.yaml\n# run st-gcn training\n# python3.7 main.py -c configs/recognition/stgcn/stgcn_fsd.yaml\n# run agcn training\n# python3.7 main.py -c configs/recognition/agcn/agcn_fsd.yaml\n# run actbert training\n# python3.7 main.py  --validate -c configs/multimodal/actbert/actbert.yaml\n# run tsn dali training\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3\" --log_dir=log_tsn main.py --train_dali -c configs/recognition/tsn/tsn_dali.yaml\n# test.sh\n# just use `example` as example, please replace to real name.\n# python3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_test main.py --test -c configs/example.yaml -w \"output/example/example_best.pdparams\""
        },
        {
            "comment": "This script demonstrates the process of running BMN test, exporting models, and performing inference using the PaddleVideo toolkit. It highlights the commands required for each step, including the necessary configuration files and output directories. The script also calculates and outputs the training time in minutes and seconds.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/run.sh\":75-88",
            "content": "# NOTE: run bmn test, only support single card, bs=1\n# python3.7 main.py --test -c configs/localization/bmn.yaml -w output/BMN/BMN_epoch_00010.pdparams -o DATASET.batch_size=1\n# export_models script\n# just use `example` as example, please replace to real name.\n# python3.7 tools/export_model.py -c configs/example.yaml -p output/example/example_best.pdparams -o ./inference\n# predict script\n# just use `example` as example, please replace to real name.\n# python3.7 tools/predict.py -v example.avi --model_file \"./inference/example.pdmodel\" --params_file \"./inference/example.pdiparams\" --enable_benchmark=False --model=\"example\" --num_seg=8\nend_time=$(date +%s)\ncost_time=$[ $end_time-$start_time ]\necho \"Time to train is $(($cost_time/60))min $(($cost_time%60))s\""
        }
    ]
}