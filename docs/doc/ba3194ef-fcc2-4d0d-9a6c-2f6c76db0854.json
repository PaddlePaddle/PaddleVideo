{
    "summary": "The code introduces a PaddleVideo class in Python for loading and processing video datasets, reading index files, applying transforms, handles corrupted files with retries, and provides error logging during training/validation.",
    "details": [
        {
            "comment": "This code is a Python class defining a video dataset for action recognition. It loads raw videos and applies specified transforms on them using an index file with multiple lines, each indicating the properties of a video. The code is part of the PaddleVideo library.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py\":0-31",
            "content": "\"\"\"\n# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"\nimport os.path as osp\nimport copy\nimport random\nimport numpy as np\nfrom ..registry import DATASETS\nfrom .base import BaseDataset\nfrom ...utils import get_logger\nlogger = get_logger(\"paddlevideo\")\n@DATASETS.register()\nclass VideoDataset(BaseDataset):\n    \"\"\"Video dataset for action recognition\n       The dataset loads raw videos and apply specified transforms on them.\n       The index file is a file with multiple lines, and each line indicates"
        },
        {
            "comment": "This code initializes a dataset class, which reads an index file containing paths to video files and their labels. It loads the index file line by line and processes each line to append video information into a list called \"info\". The filename is assumed to have .avi suffix in this case. If there is a data_prefix assigned, it will be added to the filename.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py\":32-57",
            "content": "       a sample video with the filepath and label, which are split with a whitesapce.\n       Example of a inde file:\n       .. code-block:: txt\n           path/000.mp4 1\n           path/001.mp4 1\n           path/002.mp4 2\n           path/003.mp4 2\n       Args:\n           file_path(str): Path to the index file.\n           pipeline(XXX): A sequence of data transforms.\n           **kwargs: Keyword arguments for ```BaseDataset```.\n    \"\"\"\n    def __init__(self, file_path, pipeline, num_retries=5, **kwargs):\n        self.num_retries = num_retries\n        super().__init__(file_path, pipeline, **kwargs)\n    def load_file(self):\n        \"\"\"Load index file to get video information.\"\"\"\n        info = []\n        with open(self.file_path, 'r') as fin:\n            for line in fin:\n                line_split = line.strip().split()\n                filename, labels = line_split\n                #TODO(hj): Required suffix format: may mp4/avi/wmv\n                filename = filename + '.avi'\n                if self.data_prefix is not None:"
        },
        {
            "comment": "The code is a part of a video dataset loader. It handles preparing data for training, validation, and testing in a dataset with potential corrupted files. It joins filenames to the prefix, stores them along with labels in a list (info). For training/validation, it tries a set number of times to read each file due to possible corruption, applies a pipeline to the data, logs exceptions if they occur, and tries again with a random index if needed. In testing, it simply returns the prepared data without retries or error handling.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py\":58-80",
            "content": "                    filename = osp.join(self.data_prefix, filename)\n                info.append(dict(filename=filename, labels=int(labels)))\n        return info\n    def prepare_train(self, idx):\n        \"\"\"TRAIN & VALID. Prepare the data for training/valid given the index.\"\"\"\n        #Try to catch Exception caused by reading corrupted video file\n        for ir in range(self.num_retries):\n            try:\n                results = copy.deepcopy(self.info[idx])\n                results = self.pipeline(results)\n            except Exception as e:\n                logger.info(e)\n                if ir < self.num_retries - 1:\n                    logger.info(\n                        \"Error when loading {}, have {} trys, will try again\".\n                        format(results['filename'], ir))\n                idx = random.randint(0, len(self.info) - 1)\n                continue\n            return results['imgs'], np.array([results['labels']])\n    def prepare_test(self, idx):\n        \"\"\"TEST. Prepare the data for test given the index.\"\"\""
        },
        {
            "comment": "This code attempts to read a video file and catch any exceptions caused by reading corrupted files. It uses a retry mechanism with a maximum number of retries (self.num_retries) to handle potential errors. If an exception occurs, the error is logged, and if there are more retries left, it tries again with a different random index from self.info. Once successful, it returns the images and labels as numpy arrays.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py\":81-94",
            "content": "        #Try to catch Exception caused by reading corrupted video file\n        for ir in range(self.num_retries):\n            try:\n                results = copy.deepcopy(self.info[idx])\n                results = self.pipeline(results)\n            except Exception as e:\n                logger.info(e)\n                if ir < self.num_retries - 1:\n                    logger.info(\n                        \"Error when loading {}, have {} trys, will try again\".\n                        format(results['filename'], ir))\n                idx = random.randint(0, len(self.info) - 1)\n                continue\n            return results['imgs'], np.array([results['labels']])"
        }
    ]
}