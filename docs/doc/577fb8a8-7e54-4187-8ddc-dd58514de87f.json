{
    "summary": "This code deploys a PaddlePaddle model for serving using PaddleServing in PaddleVideo, supporting GPU and CPU installations on Linux platforms. Input/output variables are set for Python serving, and the RPC method is used for prediction. Results are displayed in cmd window.",
    "details": [
        {
            "comment": "This code provides instructions on how to deploy a model service using PaddleServing in the PaddleVideo platform. It starts by explaining that this deployment example uses an HTTP prediction server and is currently only supported on Linux platforms. The instructions then cover how to install Serving, specifying steps for both GPU-accelerated docker installation and CPU-only docker installation, as well as installing the necessary Python packages.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/readme.md\":0-31",
            "content": "\u7b80\u4f53\u4e2d\u6587 | [English](./readme_en.md)\n# \u6a21\u578b\u670d\u52a1\u5316\u90e8\u7f72\n## \u7b80\u4ecb\n[Paddle Serving](https://github.com/PaddlePaddle/Serving) \u65e8\u5728\u5e2e\u52a9\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u8005\u8f7b\u677e\u90e8\u7f72\u5728\u7ebf\u9884\u6d4b\u670d\u52a1\uff0c\u652f\u6301\u4e00\u952e\u90e8\u7f72\u5de5\u4e1a\u7ea7\u7684\u670d\u52a1\u80fd\u529b\u3001\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u7aef\u4e4b\u95f4\u9ad8\u5e76\u53d1\u548c\u9ad8\u6548\u901a\u4fe1\u3001\u5e76\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u5f00\u53d1\u5ba2\u6237\u7aef\u3002\n\u8be5\u90e8\u5206\u4ee5 HTTP \u9884\u6d4b\u670d\u52a1\u90e8\u7f72\u4e3a\u4f8b\uff0c\u4ecb\u7ecd\u600e\u6837\u5728 PaddleVideo \u4e2d\u4f7f\u7528 PaddleServing \u90e8\u7f72\u6a21\u578b\u670d\u52a1\u3002\u76ee\u524d\u53ea\u652f\u6301 Linux \u5e73\u53f0\u90e8\u7f72\uff0c\u6682\u4e0d\u652f\u6301 Windows \u5e73\u53f0\u3002\n## Serving \u5b89\u88c5\nServing \u5b98\u7f51\u63a8\u8350\u4f7f\u7528 docker \u5b89\u88c5\u5e76\u90e8\u7f72 Serving \u73af\u5883\u3002\u9996\u5148\u9700\u8981\u62c9\u53d6 docker \u73af\u5883\u5e76\u521b\u5efa\u57fa\u4e8e Serving \u7684 docker\u3002\n```bash\n# \u542f\u52a8GPU docker\ndocker pull paddlepaddle/serving:0.7.0-cuda10.2-cudnn7-devel\nnvidia-docker run -p 9292:9292 --name test -dit paddlepaddle/serving:0.7.0-cuda10.2-cudnn7-devel bash\nnvidia-docker exec -it test bash\n# \u542f\u52a8CPU docker\ndocker pull paddlepaddle/serving:0.7.0-devel\ndocker run -p 9292:9292 --name test -dit paddlepaddle/serving:0.7.0-devel bash\ndocker exec -it test bash\n```\n\u8fdb\u5165 docker \u540e\uff0c\u9700\u8981\u5b89\u88c5 Serving \u76f8\u5173\u7684 python \u5305\u3002\n```bash\npython3.7 -m pip install paddle-serving-client==0.7.0\npython3.7 -m pip install paddle-serving-app==0.7.0\npython3.7 -m pip install faiss-cpu==1.7.1post2\n#\u82e5\u4e3aCPU\u90e8\u7f72\u73af\u5883:\npython3.7 -m pip install paddle-serving-server==0.7.0  # CPU"
        },
        {
            "comment": "Install PaddlePaddle for CPU and GPU environments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/readme.md\":32-57",
            "content": "python3.7 -m pip install paddlepaddle==2.2.0           # CPU\n#\u82e5\u4e3aGPU\u90e8\u7f72\u73af\u5883\npython3.7 -m pip install paddle-serving-server-gpu==0.7.0.post102  # GPU with CUDA10.2 + TensorRT6\npython3.7 -m pip install paddlepaddle-gpu==2.2.0                   # GPU with CUDA10.2\n#\u5176\u4ed6GPU\u73af\u5883\u9700\u8981\u786e\u8ba4\u73af\u5883\u518d\u9009\u62e9\u6267\u884c\u54ea\u4e00\u6761\npython3.7 -m pip install paddle-serving-server-gpu==0.7.0.post101  # GPU with CUDA10.1 + TensorRT6\npython3.7 -m pip install paddle-serving-server-gpu==0.7.0.post112  # GPU with CUDA11.2 + TensorRT8\n```\n* \u5982\u679c\u5b89\u88c5\u901f\u5ea6\u592a\u6162\uff0c\u53ef\u4ee5\u901a\u8fc7 `-i https://pypi.tuna.tsinghua.edu.cn/simple` \u66f4\u6362\u6e90\uff0c\u52a0\u901f\u5b89\u88c5\u8fc7\u7a0b\n* \u66f4\u591a\u73af\u5883\u548c\u5bf9\u5e94\u7684\u5b89\u88c5\u5305\u8be6\u89c1\uff1ahttps://github.com/PaddlePaddle/Serving/blob/v0.9.0/doc/Install_Linux_Env_CN.md\n## \u884c\u4e3a\u8bc6\u522b\u670d\u52a1\u90e8\u7f72\n### \u6a21\u578b\u8f6c\u6362\n\u4f7f\u7528 PaddleServing \u505a\u670d\u52a1\u5316\u90e8\u7f72\u65f6\uff0c\u9700\u8981\u5c06\u4fdd\u5b58\u7684 inference \u6a21\u578b\u8f6c\u6362\u4e3a Serving \u6a21\u578b\u3002\u4e0b\u9762\u4ee5 PP-TSM \u6a21\u578b\u4e3a\u4f8b\uff0c\u4ecb\u7ecd\u5982\u4f55\u90e8\u7f72\u884c\u4e3a\u8bc6\u522b\u670d\u52a1\u3002\n- \u4e0b\u8f7d\u8bad\u7ec3\u597d\u7684 PP-TSM \u7684\u6a21\u578b\uff0c\u5e76\u8f6c\u5316\u4e3a\u63a8\u7406\u6a21\u578b\uff1a\n  ```bash\n  # \u8fdb\u5165PaddleVideo\u76ee\u5f55\n  cd PaddleVideo\n  wget -P data/ https://videotag.bj.bcebos.com/PaddleVideo-release2.1/PPTSM/ppTSM_k400_uniform.pdparams\n  python3.7 tools/export_model.py \\\n  -c configs/recognition/pptsm/pptsm_k400_frames_uniform.yaml \\"
        },
        {
            "comment": "This code is converting a pre-trained PaddlePaddle model to a format suitable for serving on the server. It downloads and unzips the pre-trained model, then uses paddle_serving_client to convert it into the correct format for deployment with specified directories for serving server and client. The `dirname` specifies where the pre-trained model files are stored, while `model_filename` names the Inference Program structure file, defaulting to \"__model__\" if not specified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/readme.md\":58-82",
            "content": "  -p data/ppTSM_k400_uniform.pdparams \\\n  -o inference/ppTSM\n  ```\n- \u6211\u4eec\u4e5f\u63d0\u4f9b\u4e86\u8f6c\u6362\u597d\u7684\u63a8\u7406\u6a21\u578b\uff0c\u6309\u4ee5\u4e0b\u547d\u4ee4\u4e0b\u8f7d\u5e76\u89e3\u538b\n  ```bash\n  mkdir ./inference\n  wget -nc -P ./inference https://videotag.bj.bcebos.com/PaddleVideo-release2.3/ppTSM.zip --no-check-certificate\n  pushd ./inference\n  unzip ppTSM.zip\n  popd\n  ```\n- \u7528 paddle_serving_client \u628a\u8f6c\u6362\u597d\u7684\u63a8\u7406\u6a21\u578b\u518d\u8f6c\u6362\u6210\u6613\u4e8e Server \u90e8\u7f72\u7684\u6a21\u578b\u683c\u5f0f\uff1a\n  ```bash\n  python3.7 -m paddle_serving_client.convert \\\n  --dirname inference/ppTSM \\\n  --model_filename ppTSM.pdmodel \\\n  --params_filename ppTSM.pdiparams \\\n  --serving_server ./deploy/python_serving/ppTSM_serving_server/ \\\n  --serving_client ./deploy/python_serving/ppTSM_serving_client/\n  ```\n  | \u53c2\u6570              | \u7c7b\u578b | \u9ed8\u8ba4\u503c             | \u63cf\u8ff0                                                         |\n  | ----------------- | ---- | ------------------ | ------------------------------------------------------------ |\n  | `dirname`         | str  | -                  | \u9700\u8981\u8f6c\u6362\u7684\u6a21\u578b\u6587\u4ef6\u5b58\u50a8\u8def\u5f84\uff0cProgram\u7ed3\u6784\u6587\u4ef6\u548c\u53c2\u6570\u6587\u4ef6\u5747\u4fdd\u5b58\u5728\u6b64\u76ee\u5f55\u3002 |\n  | `model_filename`  | str  | None               | \u5b58\u50a8\u9700\u8981\u8f6c\u6362\u7684\u6a21\u578bInference Program\u7ed3\u6784\u7684\u6587\u4ef6\u540d\u79f0\u3002\u5982\u679c\u8bbe\u7f6e\u4e3aNone\uff0c\u5219\u4f7f\u7528 `__model__` \u4f5c\u4e3a\u9ed8\u8ba4\u7684\u6587\u4ef6\u540d |"
        },
        {
            "comment": "The code provides parameters for the PP-TSM model transformation, including a parameter file name (params_filename), and paths to store the converted model files (serving_server) and client configuration files (serving_client). The resulting files will be organized in separate folders (ppTSM_serving_server and ppTSM_serving_client), with specific formats. The alias names 'outputs' must be set for both fetch_var in serving_server_conf.prototxt to ensure compatibility and easy deployment of different models without modifying the code.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/readme.md\":83-102",
            "content": "  | `params_filename` | str  | None               | \u5b58\u50a8\u9700\u8981\u8f6c\u6362\u7684\u6a21\u578b\u6240\u6709\u53c2\u6570\u7684\u6587\u4ef6\u540d\u79f0\u3002\u5f53\u4e14\u4ec5\u5f53\u6240\u6709\u6a21\u578b\u53c2\u6570\u88ab\u4fdd>\u5b58\u5728\u4e00\u4e2a\u5355\u72ec\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e2d\uff0c\u5b83\u624d\u9700\u8981\u88ab\u6307\u5b9a\u3002\u5982\u679c\u6a21\u578b\u53c2\u6570\u662f\u5b58\u50a8\u5728\u5404\u81ea\u5206\u79bb\u7684\u6587\u4ef6\u4e2d\uff0c\u8bbe\u7f6e\u5b83\u7684\u503c\u4e3aNone |\n  | `serving_server`  | str  | `\"serving_server\"` | \u8f6c\u6362\u540e\u7684\u6a21\u578b\u6587\u4ef6\u548c\u914d\u7f6e\u6587\u4ef6\u7684\u5b58\u50a8\u8def\u5f84\u3002\u9ed8\u8ba4\u503c\u4e3aserving_server |\n  | `serving_client`  | str  | `\"serving_client\"` | \u8f6c\u6362\u540e\u7684\u5ba2\u6237\u7aef\u914d\u7f6e\u6587\u4ef6\u5b58\u50a8\u8def\u5f84\u3002\u9ed8\u8ba4\u503c\u4e3aserving_client       |\nPP-TSM \u63a8\u7406\u6a21\u578b\u8f6c\u6362\u5b8c\u6210\u540e\uff0c\u4f1a\u5728\u5f53\u524d\u6587\u4ef6\u5939\u591a\u51fa `ppTSM_serving_server` \u548c `ppTSM_serving_client` \u7684\u6587\u4ef6\u5939\uff0c\u5177\u5907\u5982\u4e0b\u683c\u5f0f\uff1a\n  ```bash\n  PaddleVideo/deploy/python_serving\n  \u251c\u2500\u2500 ppTSM_serving_server\n      \u251c\u2500\u2500 ppTSM.pdiparams\n      \u251c\u2500\u2500 ppTSM.pdmodel\n      \u251c\u2500\u2500 serving_server_conf.prototxt\n      \u2514\u2500\u2500 serving_server_conf.stream.prototxt\n  \u251c\u2500\u2500 ppTSM_serving_client\n      \u251c\u2500\u2500 serving_client_conf.prototxt\n      \u2514\u2500\u2500 serving_client_conf.stream.prototxt\n  ```\n\u5f97\u5230\u6a21\u578b\u6587\u4ef6\u4e4b\u540e\uff0c\u9700\u8981\u5206\u522b\u4fee\u6539 `ppTSM_serving_server` \u548c `ppTSM_serving_client` \u4e0b\u7684\u6587\u4ef6 `serving_server_conf.prototxt`\uff0c\u5c06 \u4e24\u4efd\u6587\u4ef6\u4e2d`fetch_var` \u4e0b\u7684 `alias_name` \u5747\u6539\u4e3a `outputs`\n**\u5907\u6ce8**:  Serving \u4e3a\u4e86\u517c\u5bb9\u4e0d\u540c\u6a21\u578b\u7684\u90e8\u7f72\uff0c\u63d0\u4f9b\u4e86\u8f93\u5165\u8f93\u51fa\u91cd\u547d\u540d\u7684\u529f\u80fd\u3002\u8fd9\u6837\uff0c\u4e0d\u540c\u7684\u6a21\u578b\u5728\u63a8\u7406\u90e8\u7f72\u65f6\uff0c\u53ea\u9700\u8981\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u7684`alias_name`\u5373\u53ef\uff0c\u65e0\u9700\u4fee\u6539\u4ee3\u7801\u5373\u53ef\u5b8c\u6210\u63a8\u7406\u90e8\u7f72\u3002\n\u4fee\u6539\u540e\u7684`serving_server_conf.prototxt`\u5982\u4e0b\u6240\u793a:"
        },
        {
            "comment": "The code represents the configuration for input (\"feed_var\") and output (\"fetch_var\") variables in the PaddleVideo deployment's Python serving. The input variable has a shape of 8,3,224,224 and the output variable has a shape of 400. This code is part of the setup process for sending prediction requests to the PaddleVideo pipeline service using either HTTP or RPC methods.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/readme.md\":104-151",
            "content": "```yaml\nfeed_var {\n  name: \"data_batch_0\"\n  alias_name: \"data_batch_0\"\n  is_lod_tensor: false\n  feed_type: 1\n  shape: 8\n  shape: 3\n  shape: 224\n  shape: 224\n}\nfetch_var {\n  name: \"linear_2.tmp_1\"\n  alias_name: \"outputs\"\n  is_lod_tensor: false\n  fetch_type: 1\n  shape: 400\n}\n```\n### \u670d\u52a1\u90e8\u7f72\u548c\u8bf7\u6c42\n`python_serving` \u76ee\u5f55\u5305\u542b\u4e86\u542f\u52a8 pipeline \u670d\u52a1\u3001C++ serving\u670d\u52a1(TODO)\u548c\u53d1\u9001\u9884\u6d4b\u8bf7\u6c42\u7684\u4ee3\u7801\uff0c\u5177\u4f53\u5305\u62ec\uff1a\n```bash\n__init__.py\nconfigs/xxx.yaml            # \u542f\u52a8pipeline\u670d\u52a1\u7684\u914d\u7f6e\u6587\u4ef6\npipeline_http_client.py     # http\u65b9\u5f0f\u53d1\u9001pipeline\u9884\u6d4b\u8bf7\u6c42\u7684python\u811a\u672c\npipeline_rpc_client.py      # rpc\u65b9\u5f0f\u53d1\u9001pipeline\u9884\u6d4b\u8bf7\u6c42\u7684python\u811a\u672c\nrecognition_web_service.py  # \u542f\u52a8pipeline\u670d\u52a1\u7aef\u7684python\u811a\u672c\nutils.py                    # \u50a8\u5b58\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u5e38\u7528\u7684\u51fd\u6570\uff0c\u5982parse_file_paths, numpy_to_base64, video_to_numpy\n```\n#### Python Serving\n- \u8fdb\u5165\u5de5\u4f5c\u76ee\u5f55\uff1a\n```bash\ncd deploy/python_serving\n```\n- \u542f\u52a8\u670d\u52a1\uff1a\n```bash\n# \u5728\u5f53\u524d\u547d\u4ee4\u884c\u7a97\u53e3\u542f\u52a8\u5e76\u4fdd\u6301\u5728\u524d\u7aef\npython3.7 recognition_web_service.py -n PPTSM -c configs/PP-TSM.yaml\n# \u5728\u540e\u53f0\u542f\u52a8\uff0c\u8fc7\u7a0b\u4e2d\u6253\u5370\u8f93\u51fa\u7684\u65e5\u5fd7\u4f1a\u91cd\u5b9a\u5411\u4fdd\u5b58\u5230log.txt\u4e2d\npython3.7 recognition_web_service.py -n PPTSM -c configs/PP-TSM.yaml &>log.txt &\n```\n- \u53d1\u9001\u8bf7\u6c42\uff1a\n```bash\n# \u4ee5http\u65b9\u5f0f\u7684\u53d1\u9001\u9884\u6d4b\u8bf7\u6c42\u5e76\u63a5\u53d7\u7ed3\u679c\npython3.7 pipeline_http_client.py -i ../../data/example.avi"
        },
        {
            "comment": "This code demonstrates running the PaddleVideo model for prediction using the RPC (Remote Procedure Call) method. The command \"python3.7 pipeline_rpc_client.py -i ../../data/example.avi\" is used to execute the prediction, and the results are printed in the cmd window.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/readme.md\":153-184",
            "content": "# \u4ee5rpc\u65b9\u5f0f\u7684\u53d1\u9001\u9884\u6d4b\u8bf7\u6c42\u5e76\u63a5\u53d7\u7ed3\u679c\npython3.7 pipeline_rpc_client.py -i ../../data/example.avi\n```\n\u6210\u529f\u8fd0\u884c\u540e\uff0c\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c\u4f1a\u6253\u5370\u5728 cmd \u7a97\u53e3\u4e2d\uff0c\u7ed3\u679c\u5982\u4e0b\uff1a\n```bash\n# http\u65b9\u5f0f\u6253\u5370\u7684\u7ed3\u679c\n{'err_no': 0, 'err_msg': '', 'key': ['label', 'prob'], 'value': [\"['archery']\", '[0.9907388687133789]'], 'tensors': []}\n# rpc\u65b9\u5f0f\u6253\u5370\u7684\u7ed3\u679c\nPipelineClient::predict pack_data time:1645631086.764019\nPipelineClient::predict before time:1645631086.8485317\nkey: \"label\"\nkey: \"prob\"\nvalue: \"[\\'archery\\']\"\nvalue: \"[0.9907388687133789]\"\n```\n## FAQ\n**Q1**\uff1a \u53d1\u9001\u8bf7\u6c42\u540e\u6ca1\u6709\u7ed3\u679c\u8fd4\u56de\u6216\u8005\u63d0\u793a\u8f93\u51fa\u89e3\u7801\u62a5\u9519\n**A1**\uff1a \u542f\u52a8\u670d\u52a1\u548c\u53d1\u9001\u8bf7\u6c42\u65f6\u4e0d\u8981\u8bbe\u7f6e\u4ee3\u7406\uff0c\u53ef\u4ee5\u5728\u542f\u52a8\u670d\u52a1\u524d\u548c\u53d1\u9001\u8bf7\u6c42\u524d\u5173\u95ed\u4ee3\u7406\uff0c\u5173\u95ed\u4ee3\u7406\u7684\u547d\u4ee4\u662f\uff1a\n```\nunset https_proxy\nunset http_proxy\n```\n**Q2**\uff1a \u670d\u52a1\u7aef\u542f\u52a8\u540e\u6ca1\u6709\u53cd\u5e94\uff0c\u4e00\u76f4\u505c\u5728`start proxy service`\u4e0d\u52a8\n**A2**\uff1a \u5f88\u53ef\u80fd\u662f\u542f\u52a8\u8fc7\u7a0b\u4e2d\u9047\u5230\u4e86\u95ee\u9898\uff0c\u53ef\u4ee5\u5728`./deploy/python_serving/PipelineServingLogs/pipeline.log`\u65e5\u5fd7\u6587\u4ef6\u4e2d\u67e5\u770b\u8be6\u7ec6\u62a5\u9519\u4fe1\u606f\n\u66f4\u591a\u7684\u670d\u52a1\u90e8\u7f72\u7c7b\u578b\uff0c\u5982 `RPC \u9884\u6d4b\u670d\u52a1` \u7b49\uff0c\u53ef\u4ee5\u53c2\u8003 Serving \u7684[github \u5b98\u7f51](https://github.com/PaddlePaddle/Serving/tree/v0.7.0/examples)"
        }
    ]
}