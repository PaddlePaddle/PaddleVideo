{
    "summary": "FocalLoss optimizes hard examples in object detection, while YowoLoss and RegionLoss use softmax encoding. Code prepares input with reshaping, sigmoid activation, and anchor parameters. The code calculates YOLOv3-style losses for bounding box location, confidence, and classification on GPU.",
    "details": [
        {
            "comment": "This code snippet defines a FocalLoss class that implements the Focal Loss criterion. It is used for dense object detection and aims to reduce the classification loss for well-classified samples, focusing more on hard examples. The formula for the loss is given as -\u03b1(1-softmax(x)[class])^\u03b3 * log(softmax(x)[class]).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":0-30",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport numpy\nimport paddle\nimport paddle.nn.functional as F\nimport paddle.nn as nn\nfrom paddle.static import Variable\nfrom ..registry import LOSSES\nfrom .base import BaseWeightedLoss\nfrom ..framework.localizers.yowo_utils import build_targets\nclass FocalLoss(nn.Layer):\n    \"\"\"\n        This criterion is a implemenation of Focal Loss, which is proposed in\n        Focal Loss for Dense Object Detection.\n            Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])"
        },
        {
            "comment": "FocalLoss is a criterion that takes in alpha, gamma, and size_average as arguments. It averages losses across observations for each minibatch by default but can sum the losses if size_average is set to False. Alpha is either a tensor or variable, and gamma should be greater than 0, reducing relative loss for well-classified examples.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":32-54",
            "content": "        The losses are averaged across observations for each minibatch.\n        Args:\n            alpha(1D Tensor, Variable) : the scalar factor for this criterion\n            gamma(float, double) : gamma > 0; reduces the relative loss for well-classi\ufb01ed examples (p > .5),\n                                   putting more focus on hard, misclassi\ufb01ed examples\n            size_average(bool): size_average(bool): By default, the losses are averaged over observations for each minibatch.\n                                However, if the field size_average is set to False, the losses are\n                                instead summed for each minibatch.\n    \"\"\"\n    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n        super(FocalLoss, self).__init__()\n        if alpha is None:\n            self.alpha = paddle.ones(\n                [class_num, 1])\n            self.alpha.stop_gradient = False\n        else:\n            if isinstance(alpha, Variable):\n                self.alpha = alpha\n            else:"
        },
        {
            "comment": "This code defines a class for the Yowo loss function. The constructor sets various attributes like alpha, gamma, class_num, size_average, and stop_gradient. The forward method calculates the loss using softmax, one-hot encoding, and other operations. If inputs or self.alpha are not in GPU, it transfers them to the GPU. It then computes the batch_loss and finally returns either average or sum depending on size_average attribute.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":55-86",
            "content": "                self.alpha = (alpha)\n                self.alpha.stop_gradient = False\n        self.gamma = gamma\n        self.class_num = class_num\n        self.size_average = size_average\n    def forward(self, inputs, targets):\n        N = inputs.shape[0]\n        C = inputs.shape[1]\n        P = F.softmax(inputs, axis=1)\n        tmp = numpy.zeros((N, C))\n        class_mask = paddle.to_tensor(tmp, place=inputs.place)\n        class_mask.stop_gradient = False\n        ids = paddle.reshape(targets, [-1, 1])\n        class_mask = F.one_hot(ids.squeeze(-1), class_mask.shape[1])\n        if \"Place\" not in str(inputs.place) and \"Place\" not in str(self.alpha.place):\n            self.alpha = self.alpha.cuda()\n        alpha = self.alpha[paddle.reshape(ids.detach(), [-1])]\n        probs = paddle.reshape((P * class_mask).sum(1), [-1, 1])\n        log_p = probs.log()\n        batch_loss = -alpha * (paddle.pow((1 - probs), self.gamma)) * log_p\n        if self.size_average:\n            loss = batch_loss.mean()\n        else:\n            loss = batch_loss.sum()"
        },
        {
            "comment": "This code defines a RegionLoss class that inherits from BaseWeightedLoss. It takes parameters such as num_classes, anchors, num_anchors, object_scale, noobject_scale, class_scale, and coord_scale. The class initializes an instance of FocalLoss and sets a threshold. The forward method computes the loss between output and target tensors.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":87-111",
            "content": "        return loss\n@LOSSES.register()\nclass RegionLoss(BaseWeightedLoss):\n    # for our model anchors has 10 values and number of anchors is 5\n    # parameters: 24, 10 float values, 24, 5\n    def __init__(self, num_classes, anchors, num_anchors, object_scale, noobject_scale, class_scale, coord_scale):\n        super().__init__()\n        self.num_classes = num_classes\n        self.anchors = [float(x) for x in anchors]\n        self.num_anchors = num_anchors\n        self.anchor_step = len(self.anchors) // self.num_anchors  # each anchor has 2 parameters\n        self.object_scale = object_scale\n        self.noobject_scale = noobject_scale\n        self.class_scale = class_scale\n        self.coord_scale = coord_scale\n        self.focalloss = FocalLoss(class_num=self.num_classes, gamma=2, size_average=False)\n        self.thresh = 0.6\n    def convert2cpu(self, gpu_matrix):\n        # return paddle.to_tensor((gpu_matrix.shape), dtype=\"float32\").copy_(gpu_matrix)\n        return gpu_matrix.cpu()\n    def forward(self, output, target):"
        },
        {
            "comment": "This code reshapes the output tensor for each anchor's parameters and applies sigmoid activation to the transformed tensor. The output tensor is of shape B*A*(4+1+num_classes)*H*W, which represents the coordinates (tx, ty), width, height, confidence score, and class probabilities for each anchor box in the image grid. By applying sigmoid activation functions to tx and ty, the code scales the anchor's parameter values between 0 and 1, preparing them for the subsequent operations in the YOLOv4 model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":112-136",
            "content": "        # output : B*A*(4+1+num_classes)*H*W            8*5*29*24*24\n        # B: number of batches\n        # A: number of anchors\n        # 4: 4 parameters for each bounding box\n        # 1: confidence score\n        # num_classes\n        # H: height of the image (in grids)\n        # W: width of the image (in grids)\n        # for each grid cell, there are A*(4+1+num_classes) parameters\n        nB = output.detach().shape[0]  # batch\n        nA = self.num_anchors  # anchor_num\n        nC = self.num_classes\n        nH = output.detach().shape[2]\n        nW = output.detach().shape[3]\n        # resize the output (all parameters for each anchor can be reached)\n        output = paddle.reshape(output, [nB, nA, (5 + nC), nH, nW])\n        # anchor's parameter tx\n        x = F.sigmoid(\n            paddle.reshape(paddle.index_select(output, paddle.to_tensor([0], dtype='int64').cuda(), axis=2),\n                           [nB, nA, nH, nW]))\n        x.stop_gradient = False\n        # anchor's parameter ty\n        y = F.sigmoid("
        },
        {
            "comment": "The code reshapes and assigns stop_gradient to output slices of the tensor \"output\" corresponding to anchor parameters (paddle, w, h) and a confidence score (conf), as well as class labels (cls). All are assigned stop_gradient=False.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":137-154",
            "content": "            paddle.reshape(paddle.index_select(output, paddle.to_tensor([1], dtype='int64').cuda(), axis=2),\n                           [nB, nA, nH, nW]))\n        y.stop_gradient = False\n        # anchor's parameter tw\n        w = paddle.reshape(paddle.index_select(output, paddle.to_tensor([2], dtype='int64').cuda(), axis=2),\n                           [nB, nA, nH, nW])\n        w.stop_gradient = False\n        # anchor's parameter th\n        h = paddle.reshape(paddle.index_select(output, paddle.to_tensor([3], dtype='int64').cuda(), axis=2),\n                           [nB, nA, nH, nW])\n        h.stop_gradient = False\n        # confidence score for each anchor\n        conf = F.sigmoid(\n            paddle.reshape(paddle.index_select(output, paddle.to_tensor([4], dtype='int64').cuda(), axis=2),\n                           [nB, nA, nH, nW]))\n        conf.stop_gradient = False\n        # anchor's parameter class label\n        cls = paddle.index_select(output, paddle.linspace(5, 5 + nC - 1, nC, 'int64').cuda(), axis=2)"
        },
        {
            "comment": "This code resizes the data structure to have a class label for each anchor, initializes prediction boxes, and creates grid coordinates for localization. It uses PaddlePaddle's linear algebra functions like paddle.reshape, paddle.transpose, and paddle.linspace. The code aims to prepare the input data for object detection model training.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":155-168",
            "content": "        cls.stop_gradient = False\n        # resize the data structure so that for every anchor there is a class label in the last dimension\n        cls = paddle.reshape(paddle.transpose(paddle.reshape(cls, [nB * nA, nC, nH * nW]), [0, 2, 1]),\n                             [nB * nA * nH * nW, nC])\n        # for the prediction of localization of each bounding box, there exist 4 parameters (tx, ty, tw, th)\n        # pred_boxes = torch.cuda.FloatTensor(4, nB*nA*nH*nW)\n        pred_boxes = paddle.zeros([4, nB * nA * nH * nW], dtype='float32').cuda()\n        # tx and ty\n        grid_x = paddle.reshape(paddle.tile(paddle.tile(paddle.linspace(0, nW - 1, nW), [nH, 1]), [nB * nA, 1, 1]),\n                                [nB * nA * nH * nW]).cuda()\n        grid_y = paddle.reshape(paddle.tile(paddle.tile(paddle.linspace(0, nH - 1, nH), [nW, 1]).t(), [nB * nA, 1, 1]),\n                                [nB * nA * nH * nW]).cuda()\n        # for each anchor there are anchor_step variables (with the structure num_anchor*anchor_step)"
        },
        {
            "comment": "This code is preparing anchor width and height values for the YOWO loss function. It reshapes the anchors, index selects the width and height values, tiles them to match grid dimensions, and assigns the prediction of bounding box localization for each grid cell.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":169-180",
            "content": "        # for each row(anchor), the first variable is anchor's width, second is anchor's height\n        # pw and ph\n        anchor_w = paddle.index_select(paddle.reshape(paddle.to_tensor(self.anchors), [nA, self.anchor_step]),\n                                       paddle.to_tensor([0], dtype='int64'), axis=1).cuda()\n        anchor_h = paddle.index_select(paddle.reshape(paddle.to_tensor(self.anchors), [nA, self.anchor_step]),\n                                       paddle.to_tensor([1], dtype='int64'), axis=1).cuda()\n        # for each pixel (grid) repeat the above process (obtain width and height of each grid)\n        anchor_w = paddle.reshape(paddle.tile(paddle.tile(anchor_w, [nB, 1]), [1, 1, nH * nW]), [nB * nA * nH * nW])\n        anchor_h = paddle.reshape(paddle.tile(paddle.tile(anchor_h, [nB, 1]), [1, 1, nH * nW]), [nB * nA * nH * nW])\n        # prediction of bounding box localization\n        # x.data and y.data: top left corner of the anchor\n        # grid_x, grid_y: tx and ty predictions made by yowo"
        },
        {
            "comment": "This code reshapes and casts input tensors, calculates predicted bounding box coordinates based on input features, and calls a function to build targets for the model. It then reshapes and transposes the predicted boxes tensor before passing it to the build_targets function. The function is part of the YOLOv3-style loss calculation in PaddleVideo.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":182-198",
            "content": "        x_data = paddle.reshape(x.detach(), [-1])\n        y_data = paddle.reshape(y.detach(), [-1])\n        w_data = paddle.reshape(w.detach(), [-1])\n        h_data = paddle.reshape(h.detach(), [-1])\n        pred_boxes[0] = paddle.cast(x_data, dtype='float32') + paddle.cast(grid_x, dtype='float32')  # bx\n        pred_boxes[1] = paddle.cast(y_data, dtype='float32') + paddle.cast(grid_y, dtype='float32')  # by\n        pred_boxes[2] = paddle.exp(paddle.cast(w_data, dtype='float32')) * paddle.cast(anchor_w, dtype='float32')  # bw\n        pred_boxes[3] = paddle.exp(paddle.cast(h_data, dtype='float32')) * paddle.cast(anchor_h, dtype='float32')  # bh\n        # the size -1 is inferred from other dimensions\n        # pred_boxes (nB*nA*nH*nW, 4)\n        pred_boxes = self.convert2cpu(\n            paddle.cast(paddle.reshape(paddle.transpose(pred_boxes, (1, 0)), [-1, 4]), dtype='float32'))\n        nGT, nCorrect, coord_mask, conf_mask, cls_mask, tx, ty, tw, th, tconf, tcls = build_targets(pred_boxes,\n           "
        },
        {
            "comment": "This code is setting up a loss function for object detection. It takes in target values, anchors, number of anchors (nA), number of classes (nC), and the image dimensions (nH, nW). The noobject_scale and object_scale variables control how the loss is applied depending on whether an object is present or not. The cls_mask variable filters out proposals with low box confidence scores. The final predictions are kept if their confidence score is greater than 0.25. The tensor tx is moved to the GPU (cuda).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":198-209",
            "content": "                                                                                         target.detach(),\n                                                                                                    self.anchors, nA,\n                                                                                                    nC, \\\n                                                                                                    nH, nW,\n                                                                                                    self.noobject_scale,\n                                                                                                    self.object_scale,\n                                                                                                    self.thresh)\n        cls_mask = (cls_mask == 1)\n        #  keep those with high box confidence scores (greater than 0.25) as our final predictions\n        nProposals = int((conf > 0.25).sum().detach().item())\n        tx = (tx).cuda()"
        },
        {
            "comment": "This code is moving variables to the GPU and setting their gradient flags to False. Then, it calculates losses for bounding box location, prediction confidence, and classification separately using SmoothL1Loss.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":210-236",
            "content": "        tx.stop_gradient = False\n        ty = ty.cuda()\n        ty.stop_gradient = False\n        tw = tw.cuda()\n        tw.stop_gradient = False\n        th = th.cuda()\n        th.stop_gradient = False\n        tconf = tconf.cuda()\n        tconf.stop_gradient = False\n        tcls = paddle.reshape(tcls, [-1]).astype('int64')[paddle.reshape(cls_mask, [-1])].cuda()\n        tcls.stop_gradient = False\n        coord_mask = coord_mask.cuda()\n        coord_mask.stop_gradient = False\n        conf_mask = conf_mask.cuda().sqrt()\n        coord_mask.stop_gradient = False\n        cls_mask = paddle.tile(paddle.reshape(cls_mask, [-1, 1]), [1, nC]).cuda()\n        cls_mask.stop_gradient = False\n        cls = paddle.reshape(cls[cls_mask], [-1, nC])\n        # losses between predictions and targets (ground truth)\n        # In total 6 aspects are considered as losses:\n        # 4 for bounding box location, 2 for prediction confidence and classification seperately\n        L1_loss = nn.SmoothL1Loss(reduction='sum')\n        loss_x = self.coord_scale * L1_loss(paddle.cast(x, dtype=\"float32\") * coord_mask, tx * coord_mask) / 2.0"
        },
        {
            "comment": "This code calculates the loss for an object detection model, consisting of L1_loss for coordinates (x, y, w, h) and MSELoss for confidence. It applies focal loss for classification with a gamma value of 2, sums all losses together, and returns the total loss and count of correct predictions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/yowo_loss.py\":237-248",
            "content": "        loss_y = self.coord_scale * L1_loss(paddle.cast(y, dtype=\"float32\") * coord_mask, ty * coord_mask) / 2.0\n        loss_w = self.coord_scale * L1_loss(paddle.cast(w * coord_mask, dtype=\"float32\"), tw * coord_mask) / 2.0\n        loss_h = self.coord_scale * L1_loss(paddle.cast(h * coord_mask, dtype=\"float32\"), th * coord_mask) / 2.0\n        loss_conf = nn.MSELoss(reduction='sum')(paddle.cast(conf, dtype=\"float32\") * conf_mask, tconf * conf_mask) / 2.0\n        # try focal loss with gamma = 2\n        loss_cls = self.class_scale * self.focalloss(cls, tcls)\n        # sum of loss\n        loss = loss_x + loss_y + loss_w + loss_h + loss_conf + loss_cls\n        return loss, nCorrect"
        }
    ]
}