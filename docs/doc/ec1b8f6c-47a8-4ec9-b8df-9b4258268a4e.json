{
    "summary": "The code defines a PaddlePaddle GCN class with convolutional blocks for temporal sequences, utilizing layers such as batch normalization and residual connections. It also presents a custom AGCN backbone model for graph convolution tasks using adaptive graph convolutions.",
    "details": [
        {
            "comment": "The code is defining a GCN (Graph Convolutional Network) class within the PaddlePaddle framework. It takes in channel dimensions, output channel dimensions, vertex numbers and stride as parameters for its constructor. The class has one convolution layer with kernel size of 1 and stride of 1.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/agcn.py\":0-26",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as F\nfrom ..registry import BACKBONES\nclass GCN(nn.Layer):\n    def __init__(self, in_channels, out_channels, vertex_nums=25, stride=1):\n        super(GCN, self).__init__()\n        self.conv1 = nn.Conv2D(in_channels=in_channels,\n                               out_channels=3 * out_channels,\n                               kernel_size=1,\n                               stride=1)"
        },
        {
            "comment": "The code defines a convolutional block for processing temporal sequences with 3D spatial-temporal convolutions. The block applies multiple convolution layers, batch normalization, and transposes the dimensions to perform feature extraction from the input sequence. It is parameterized by the number of channels, output channels, vertex numbers, temporal size, and a flag for residual connections.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/agcn.py\":27-56",
            "content": "        self.conv2 = nn.Conv2D(in_channels=vertex_nums * 3,\n                               out_channels=vertex_nums,\n                               kernel_size=1)\n    def forward(self, x):\n        # x --- N,C,T,V\n        x = self.conv1(x)  # N,3C,T,V\n        N, C, T, V = x.shape\n        x = paddle.reshape(x, [N, C // 3, 3, T, V])  # N,C,3,T,V\n        x = paddle.transpose(x, perm=[0, 1, 2, 4, 3])  # N,C,3,V,T\n        x = paddle.reshape(x, [N, C // 3, 3 * V, T])  # N,C,3V,T\n        x = paddle.transpose(x, perm=[0, 2, 1, 3])  # N,3V,C,T\n        x = self.conv2(x)  # N,V,C,T\n        x = paddle.transpose(x, perm=[0, 2, 3, 1])  # N,C,T,V\n        return x\nclass Block(paddle.nn.Layer):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 vertex_nums=25,\n                 temporal_size=9,\n                 stride=1,\n                 residual=True):\n        super(Block, self).__init__()\n        self.residual = residual\n        self.out_channels = out_channels\n        self.bn_res = nn.BatchNorm2D(out_channels)"
        },
        {
            "comment": "This code initializes a convolutional residual block with a Graph Convolutional Network (GCN) and Temporal Convolutional Network (TCN). The conv_res is a 1x1 convolution, gcn is a GCN layer, and tcn is a TCN layer. In the forward pass, if residual is True, the input goes through the conv_res layer before being passed to the gcn layer, then the tcn layer. The output is either the sum of the input and the residual (if residual is True) or just the output of the GCN layer, which is then passed through a ReLU activation function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/agcn.py\":57-83",
            "content": "        self.conv_res = nn.Conv2D(in_channels=in_channels,\n                                  out_channels=out_channels,\n                                  kernel_size=1,\n                                  stride=(stride, 1))\n        self.gcn = GCN(in_channels=in_channels,\n                       out_channels=out_channels,\n                       vertex_nums=vertex_nums)\n        self.tcn = nn.Sequential(\n            nn.BatchNorm2D(out_channels),\n            nn.ReLU(),\n            nn.Conv2D(in_channels=out_channels,\n                      out_channels=out_channels,\n                      kernel_size=(temporal_size, 1),\n                      padding=((temporal_size - 1) // 2, 0),\n                      stride=(stride, 1)),\n            nn.BatchNorm2D(out_channels),\n        )\n    def forward(self, x):\n        if self.residual:\n            y = self.conv_res(x)\n            y = self.bn_res(y)\n        x = self.gcn(x)\n        x = self.tcn(x)\n        out = x + y if self.residual else x\n        out = F.relu(out)\n        return out"
        },
        {
            "comment": "The code defines a class AGCN (Adaptive Graph Convolutional Network) as a subclass of nn.Layer, which is an improved version of ST-GCN for graph convolution tasks using adaptive graph convolutions. The model architecture consists of several Block layers with varying in_channels and out_channels, and downsampling is performed with stride=2.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/agcn.py\":86-109",
            "content": "@BACKBONES.register()\nclass AGCN(nn.Layer):\n    \"\"\"\n    AGCN model improves the performance of ST-GCN using\n    Adaptive Graph Convolutional Networks.\n    Args:\n        in_channels: int, channels of vertex coordinate. 2 for (x,y), 3 for (x,y,z). Default 2.\n    \"\"\"\n    def __init__(self, in_channels=2, **kwargs):\n        super(AGCN, self).__init__()\n        self.data_bn = nn.BatchNorm1D(25 * 2)\n        self.agcn = nn.Sequential(\n            Block(in_channels=in_channels,\n                  out_channels=64,\n                  residual=False,\n                  **kwargs), Block(in_channels=64, out_channels=64, **kwargs),\n            Block(in_channels=64, out_channels=64, **kwargs),\n            Block(in_channels=64, out_channels=64, **kwargs),\n            Block(in_channels=64, out_channels=128, stride=2, **kwargs),\n            Block(in_channels=128, out_channels=128, **kwargs),\n            Block(in_channels=128, out_channels=128, **kwargs),\n            Block(in_channels=128, out_channels=256, stride=2, **kwargs),\n            Block(in_channels=256, out_channels=256, **kwargs),"
        },
        {
            "comment": "This code defines a custom backbone for AGCN model with a block of 256 in_channels and out_channels, followed by an adaptive average pooling layer. The forward function performs data normalization, transposes the shape, reshapes it, applies the AGCN layer, pools it to size (1,1), and finally reshapes and averages along one axis before returning the result.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/agcn.py\":110-127",
            "content": "            Block(in_channels=256, out_channels=256, **kwargs))\n        self.pool = nn.AdaptiveAvgPool2D(output_size=(1, 1))\n    def forward(self, x):\n        # data normalization\n        N, C, T, V, M = x.shape\n        x = x.transpose((0, 4, 1, 2, 3))  # N, M, C, T, V\n        x = x.reshape((N * M, C, T, V))\n        x = self.agcn(x)\n        x = self.pool(x)  # NM,C,T,V --> NM,C,1,1\n        C = x.shape[1]\n        x = paddle.reshape(x, (N, M, C, 1, 1)).mean(axis=1)  # N,C,1,1\n        return x"
        }
    ]
}