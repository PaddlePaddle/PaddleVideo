{
    "summary": "The code extracts audio features for Table Tennis prediction, using spectrogram and Mel scale transformation, and reads WAV files with VGG-16 model for MFCC and STFT feature extraction.",
    "details": [
        {
            "comment": "This code is for audio feature extraction in TableTennis application. It defines functions `frame`, `periodic_hann` and `stft_magnitude`. The `frame` function resizes the data array into frames with specified window length and hop length. The `periodic_hann` function generates a periodic Hann window for the STFT operation. Finally, `stft_magnitude` calculates the magnitude of the Short-Time Fourier Transform (STFT) of an audio signal.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py\":0-38",
            "content": "\"\"\"\naudio feature extract\n\"\"\"\n# coding: utf-8\nimport os\nimport numpy as np\nimport pickle\nimport mfcc.vgg_params as vgg_params\nimport sys\ndef frame(data, window_length, hop_length):\n    \"\"\"\n    frame\n    \"\"\"\n    num_samples = data.shape[0]\n    #print(\"window_length , hop_length\", window_length, hop_length)\n    #print(\"num_sample = \", num_samples)\n    num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))\n    #print(\" num_frames = \", num_frames)\n    shape = (num_frames, window_length) + data.shape[1:]\n    #print(\" shape = \", shape)\n    strides = (data.strides[0] * hop_length, ) + data.strides\n    #print(\"data.strides = \", data.strides)\n    #print(\"strides = \", strides)\n    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\ndef periodic_hann(window_length):\n    \"\"\"\n    periodic_hann\n    \"\"\"\n    return 0.5 - (0.5 *\n                  np.cos(2 * np.pi / window_length * np.arange(window_length)))\ndef stft_magnitude(signal, fft_length, hop_length=None, window_length=None):\n    \"\"\"\n    stft_magnitude"
        },
        {
            "comment": "The code defines functions for feature extraction and conversion of audio signals. The \"hertz_to_mel\" function converts frequencies from Hertz to Mel scale, which is used in psychoacoustics. The \"spectrogram_to_mel_matrix\" function creates a mel-frequency cepstral coefficients (MFCC) matrix for audio spectrograms. It checks for lower and upper frequency edge validity and calculates Mel frequencies based on the provided parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py\":39-69",
            "content": "    \"\"\"\n    frames = frame(signal, window_length, hop_length)\n    window = periodic_hann(window_length)\n    windowed_frames = frames * window\n    return np.abs(np.fft.rfft(windowed_frames, int(fft_length)))\n_MEL_BREAK_FREQUENCY_HERTZ = 700.0\n_MEL_HIGH_FREQUENCY_Q = 1127.0\ndef hertz_to_mel(frequencies_hertz):\n    \"\"\"\n    hertz_to_mel\n    \"\"\"\n    return _MEL_HIGH_FREQUENCY_Q * np.log(1.0 + (frequencies_hertz /\n                                                 _MEL_BREAK_FREQUENCY_HERTZ))\ndef spectrogram_to_mel_matrix(num_mel_bins=20,\n                              num_spectrogram_bins=129,\n                              audio_sample_rate=8000,\n                              lower_edge_hertz=125.0,\n                              upper_edge_hertz=3800.0):\n    \"\"\"\n    spectrogram_to_mel_matrix\n    \"\"\"\n    nyquist_hertz = audio_sample_rate / 2.\n    if lower_edge_hertz >= upper_edge_hertz:\n        raise ValueError(\"lower_edge_hertz %.1f >= upper_edge_hertz %.1f\" %\n                         (lower_edge_hertz, upper_edge_hertz))"
        },
        {
            "comment": "This code is performing Mel frequency cepstral coefficients (MFCC) feature extraction on audio data. It creates spectrogram bins in Hz, converts them to the mel scale, defines mel band edges, and computes the corresponding mel weights matrix. The function returns this matrix after setting the first row to zero. This process is commonly used for speech processing and analysis.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py\":70-90",
            "content": "    spectrogram_bins_hertz = np.linspace(0.0, nyquist_hertz,\n                                         num_spectrogram_bins)\n    spectrogram_bins_mel = hertz_to_mel(spectrogram_bins_hertz)\n    band_edges_mel = np.linspace(hertz_to_mel(lower_edge_hertz),\n                                 hertz_to_mel(upper_edge_hertz),\n                                 num_mel_bins + 2)\n    mel_weights_matrix = np.empty((num_spectrogram_bins, num_mel_bins))\n    for i in range(num_mel_bins):\n        lower_edge_mel, center_mel, upper_edge_mel = band_edges_mel[i:i + 3]\n        lower_slope = ((spectrogram_bins_mel - lower_edge_mel) /\n                       (center_mel - lower_edge_mel))\n        upper_slope = ((upper_edge_mel - spectrogram_bins_mel) /\n                       (upper_edge_mel - center_mel))\n        mel_weights_matrix[:,\n                           i] = np.maximum(0.0,\n                                           np.minimum(lower_slope, upper_slope))\n    mel_weights_matrix[0, :] = 0.0\n    return mel_weights_matrix\ndef log_mel_spectrogram(data,"
        },
        {
            "comment": "This code defines a function called `log_mel_spectrogram` which takes audio data, sample rate, and optional keyword arguments. It calculates window length in samples, hop length in samples, FFT length, and then uses the Short-Time Fourier Transform (STFT) to generate a spectrogram from the input audio data. The resulting spectrogram is stored in the `spectrogram` variable and its shape is printed for debugging or reference purposes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py\":91-111",
            "content": "                        audio_sample_rate=8000,\n                        log_offset=0.0,\n                        window_length_secs=0.025,\n                        hop_length_secs=0.010,\n                        **kwargs):\n    \"\"\"\n    log_mel_spectrogram\n    \"\"\"\n    window_length_samples = int(round(audio_sample_rate * window_length_secs))\n    #print(\"audio_sample_rate = \", audio_sample_rate)\n    #print(\"window_length_secs = \", window_length_secs)\n    #print(\"window_length_sample \", window_length_samples)\n    hop_length_samples = int(round(audio_sample_rate * hop_length_secs))\n    #print(\"hop_length_samples \", hop_length_samples)\n    fft_length = 2**int(np.ceil(np.log(window_length_samples) / np.log(2.0)))\n    #print(\" fft_lengt = \", fft_length)\n    spectrogram = stft_magnitude(data,\n                                 fft_length=fft_length,\n                                 hop_length=hop_length_samples,\n                                 window_length=window_length_samples)\n    #print(\" spectrogram.shape = \", spectrogram.shape)"
        },
        {
            "comment": "Function `spectrogram_to_mel_matrix` converts the spectrogram to Mel scale. Code calculates Mel spectrogram by taking dot product of spectrogram with `spectrogram_to_mel_matrix`. The result is then log transformed to avoid numerical underflow and returned.\nThe function `wav_to_example` takes wav file data, validates sample type, pads zeros to achieve desired window length, scales the wav data to range -1 to 1 by dividing by 32768.0. It is used for audio feature extraction in TableTennis application of PaddleVideo.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py\":112-136",
            "content": "    mel_spectrogram = np.dot(\n        spectrogram,\n        spectrogram_to_mel_matrix(num_spectrogram_bins=spectrogram.shape[1],\n                                  audio_sample_rate=audio_sample_rate,\n                                  **kwargs))\n    return np.log(mel_spectrogram + log_offset)\ndef wav_to_example(wav_data, sample_rate):\n    \"\"\"\n    wav_to_example\n    \"\"\"\n    #sample_rate, wav_data = wavfile.read(wav_file)\n    assert wav_data.dtype == np.int16, 'Bad sample type: %r' % wav_data.dtype\n    #wav_data = wav_data[:16000*30]\n    #print(\" wav_data \", wav_data.shape)\n    #print(\" wav_data \", wav_data.shape)\n    pad_zero_num = int(sample_rate * (vgg_params.STFT_WINDOW_LENGTH_SECONDS -\n                                      vgg_params.STFT_HOP_LENGTH_SECONDS))\n    wav_data_extend = np.hstack((wav_data, np.zeros(pad_zero_num)))\n    wav_data = wav_data_extend\n    #print(\" wav_data \", wav_data.shape)\n    wav_data = wav_data / 32768.0  # Convert to [-1.0, +1.0]\n    #print(\" wav_data after convert to -1 1\", wav_data)"
        },
        {
            "comment": "This code extracts audio features for Table Tennis prediction. It first reshapes and resamples the input wav_data if necessary, then calculates log mel spectrogram from wav_data using given parameters. Finally, it frames these features into examples with a specific window length.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py\":137-157",
            "content": "    #if wav_data.shape[0] > max_second * sample_rate:\n    #    wav_data = wav_data[:max_second * sample_rate, :]\n    if len(wav_data.shape) > 1:\n        wav_data = np.mean(wav_data, axis=1)\n    #print(\" wav_data after mean\", wav_data.shape, len(wav_data.shape), wav_data)\n    # Resample to the rate assumed by vgg.\n    #if sample_rate != vgg_params.SAMPLE_RATE:\n    #    wav_data = resampy.resample(wav_data, sample_rate, vgg_params.SAMPLE_RATE)\n    log_mel = log_mel_spectrogram(\n        wav_data,\n        audio_sample_rate=vgg_params.SAMPLE_RATE,\n        log_offset=vgg_params.LOG_OFFSET,\n        window_length_secs=vgg_params.STFT_WINDOW_LENGTH_SECONDS,\n        hop_length_secs=vgg_params.STFT_HOP_LENGTH_SECONDS,\n        num_mel_bins=vgg_params.NUM_MEL_BINS,\n        lower_edge_hertz=vgg_params.MEL_MIN_HZ,\n        upper_edge_hertz=vgg_params.MEL_MAX_HZ)\n    # Frame features into examples.\n    features_sample_rate = 1.0 / vgg_params.STFT_HOP_LENGTH_SECONDS\n    example_window_length = int(\n        round(vgg_params.EXAMPLE_WINDOW_SECONDS * features_sample_rate))"
        },
        {
            "comment": "This code extracts audio features from a WAV file using the VGG-16 model, specifically focusing on MFCC (Mel Frequency Cepstral Coefficients) and STFT (Short-Time Fourier Transform). The code also defines a function to convert PCM data into examples and another to extract MFCC features. Lastly, it demonstrates how to use the code by reading a WAV file and printing its shape.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py\":159-182",
            "content": "    example_hop_length = int(\n        round(vgg_params.EXAMPLE_HOP_SECONDS * features_sample_rate))\n    log_mel_examples = frame(log_mel,\n                             window_length=example_window_length,\n                             hop_length=example_hop_length)\n    return log_mel_examples\ndef extract_pcm(pcm_file, sample_rate):\n    with open(pcm_file, \"rb\") as f:\n        pcm_data = f.read()\n    audio_data = np.fromstring(pcm_data, dtype=np.int16)\n    examples = wav_to_example(audio_data, sample_rate)\n    return examples\nif __name__ == \"__main__\":\n    wav_file = sys.argv[1]\n    print(\"wav_file = \", wav_file)\n    with open(wav_file, \"rb\") as f:\n        pcm_data = f.read()\n    audio_data = np.fromstring(pcm_data, dtype=np.int16)\n    examples_batch = wav_to_example(audio_data, 16000)\n    print(\"examples_batch.shape\", examples_batch.shape)"
        }
    ]
}