{
    "summary": "This code defines a class for evaluating metrics in video analysis tasks, handling inference mode and performing tagging/classification using a model with functions for metrics update, calculator reset, logging results, and saving/retrieving metrics.",
    "details": [
        {
            "comment": "This code is importing necessary libraries and initializing a class called Metrics. It appears to be part of a larger module for evaluating metrics, possibly in the context of video analysis or recognition tasks. The code defines an object-oriented structure with methods that will likely handle different types of evaluation tasks based on the input name, mode, and metrics_args parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":0-32",
            "content": "#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n#Licensed under the Apache License, Version 2.0 (the \"License\");\n#you may not use this file except in compliance with the License.\n#You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#Unless required by applicable law or agreed to in writing, software\n#distributed under the License is distributed on an \"AS IS\" BASIS,\n#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#See the License for the specific language governing permissions and\n#limitations under the License.\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nimport logging\nimport os\nimport io\nimport numpy as np\nimport json\nfrom metrics.youtube8m import eval_util as youtube8m_metrics\nfrom metrics.kinetics import accuracy_metrics as kinetics_metrics\nlogger = logging.getLogger(__name__)\nclass Metrics(object):\n    def __init__(self, name, mode, metrics_args):"
        },
        {
            "comment": "The code defines a class named Youtube8mMetrics that inherits from the Metrics base class. It has methods for calculating and logging metrics, accumulating results, finalizing and logging output, and resetting variables. The Youtube8mMetrics class is initialized with a name, mode, and metrics_args. The calculate_and_log_out method calculates loss, prediction, and ground truth labels, then calls the youtube8m_metrics.calculate_hit_at_one function to compute the hit at one metric.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":33-68",
            "content": "        \"\"\"Not implemented\"\"\"\n        pass\n    def calculate_and_log_out(self, fetch_list, info=''):\n        \"\"\"Not implemented\"\"\"\n        pass\n    def accumulate(self, fetch_list, info=''):\n        \"\"\"Not implemented\"\"\"\n        pass\n    def finalize_and_log_out(self, info='', savedir='./'):\n        \"\"\"Not implemented\"\"\"\n        pass\n    def reset(self):\n        \"\"\"Not implemented\"\"\"\n        pass\nclass Youtube8mMetrics(Metrics):\n    def __init__(self, name, mode, metrics_args):\n        self.name = name\n        self.mode = mode\n        self.num_classes = metrics_args['MODEL']['num_classes']\n        self.topk = metrics_args['MODEL']['topk']\n        self.calculator = youtube8m_metrics.EvaluationMetrics(\n            self.num_classes, self.topk)\n        if self.mode == 'infer':\n            self.infer_results = []\n    def calculate_and_log_out(self, fetch_list, info=''):\n        loss = np.mean(np.array(fetch_list[0]))\n        pred = np.array(fetch_list[1])\n        label = np.array(fetch_list[2])\n        hit_at_one = youtube8m_metrics.calculate_hit_at_one(pred, label)"
        },
        {
            "comment": "This function accumulates metrics for a video tagging application. It handles two modes: 'infer' and others. For the 'infer' mode, it gathers predictions for each video, calculates top-k indices, and appends them to a list. For other modes, it takes in loss, prediction, and label arrays, and accumulates metrics using the calculator object. It logs information including loss, Hit@1, precision at equal recall rate (PERR), and gap.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":69-89",
            "content": "        perr = youtube8m_metrics.calculate_precision_at_equal_recall_rate(\n            pred, label)\n        gap = youtube8m_metrics.calculate_gap(pred, label)\n        logger.info(info + ' , loss = {0}, Hit@1 = {1}, PERR = {2}, GAP = {3}'.format(\\\n                     '%.6f' % loss, '%.2f' % hit_at_one, '%.2f' % perr, '%.2f' % gap))\n    def accumulate(self, fetch_list, info=''):\n        if self.mode == 'infer':\n            predictions = np.array(fetch_list[0])\n            video_id = fetch_list[1]\n            for i in range(len(predictions)):\n                topk_inds = predictions[i].argsort()[0 - self.topk:]\n                topk_inds = topk_inds[::-1]\n                preds = predictions[i][topk_inds]\n                self.infer_results.append(\n                    (video_id[i], topk_inds.tolist(), preds.tolist()))\n        else:\n            loss = np.array(fetch_list[0])\n            pred = np.array(fetch_list[1])\n            label = np.array(fetch_list[2])\n            self.calculator.accumulate(loss, pred, label)"
        },
        {
            "comment": "This code snippet is part of the VideoTag application and it logs out the final results for each video. It reads a label file, iterates through each item's predictions, matches class ID to class name and probability, and then prints them out. The function can be called with optional parameters to specify the output directory (default: `./data/results`) and the label file path (default: `./label_3396.txt`). It is designed to run in 'infer' mode only.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":91-112",
            "content": "    def finalize_and_log_out(self,\n                             info='',\n                             savedir='./data/results',\n                             label_file='./label_3396.txt'):\n        if self.mode == 'infer':\n            for index, item in enumerate(self.infer_results):\n                video_id = item[0]\n                print('[========video_id [ {} ] , topk({}) preds: ========]\\n'.\n                      format(video_id, self.topk))\n                f = io.open(label_file, \"r\", encoding=\"utf-8\")\n                fl = f.readlines()\n                res_list = []\n                res_list.append(video_id)\n                for i in range(len(item[1])):\n                    class_id = item[1][i]\n                    class_prob = item[2][i]\n                    class_name = fl[class_id].split('\\n')[0]\n                    print('class_id: {},'.format(class_id), 'class_name:',\n                          class_name,\n                          ',  probability:  {} \\n'.format(class_prob))\n                    save_dict = {"
        },
        {
            "comment": "This code snippet appears to be part of a larger program that performs some sort of video tagging or classification. It includes functions to save the result of an inference operation and update metrics after each epoch, as well as a reset function for the calculator. The \"calculator\" object seems to keep track of average hit rate at one, perr, loss, aps, and gap for some type of learning algorithm or model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":113-134",
            "content": "                        \"'class_id\": class_id,\n                        \"class_name\": class_name,\n                        \"probability\": class_prob\n                    }\n                    res_list.append(save_dict)\n                # save infer result into output dir\n                with io.open(os.path.join(savedir,\n                                          'result' + str(index) + '.json'),\n                             'w',\n                             encoding='utf-8') as f:\n                    f.write(json.dumps(res_list, ensure_ascii=False))\n        else:\n            epoch_info_dict = self.calculator.get()\n            logger.info(info + '\\tavg_hit_at_one: {0},\\tavg_perr: {1},\\tavg_loss :{2},\\taps: {3},\\tgap:{4}'\\\n                     .format(epoch_info_dict['avg_hit_at_one'], epoch_info_dict['avg_perr'], \\\n                             epoch_info_dict['avg_loss'], epoch_info_dict['aps'], epoch_info_dict['gap']))\n    def reset(self):\n        self.calculator.clear()\n        if self.mode == 'infer':\n            self.infer_results = []"
        },
        {
            "comment": "Class Kinetics400Metrics is used for calculating and logging metrics, accepting a name, mode, and metrics_args. It stores the topk value from metrics_args, initializes a MetricsCalculator instance with the given name and mode, and maintains an infer_results list if in inference mode. The calculate_and_log_out method takes a fetch_list as input and calculates the mean loss, accuracy for top-1 and top-5 predictions, and logs the information. It can be used to accumulate results during inference.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":137-162",
            "content": "class Kinetics400Metrics(Metrics):\n    def __init__(self, name, mode, metrics_args):\n        self.name = name\n        self.mode = mode\n        self.topk = metrics_args['MODEL']['topk']\n        self.calculator = kinetics_metrics.MetricsCalculator(name, mode.lower())\n        if self.mode == 'infer':\n            self.infer_results = []\n    def calculate_and_log_out(self, fetch_list, info=''):\n        if len(fetch_list) == 3:\n            loss = fetch_list[0]\n            loss = np.mean(np.array(loss))\n            pred = np.array(fetch_list[1])\n            label = np.array(fetch_list[2])\n        else:\n            loss = 0.\n            pred = np.array(fetch_list[0])\n            label = np.array(fetch_list[1])\n        acc1, acc5 = self.calculator.calculate_metrics(loss, pred, label)\n        logger.info(info + '\\tLoss: {},\\ttop1_acc: {}, \\ttop5_acc: {}'.format('%.6f' % loss, \\\n                       '%.2f' % acc1, '%.2f' % acc5))\n        return loss\n    def accumulate(self, fetch_list, info=''):\n        if self.mode == 'infer':"
        },
        {
            "comment": "This code appears to be a part of a machine learning model's evaluation process. It calculates top predictions and loss values for each video, accumulates them, and then logs out the results. The method \"finalize_and_log_out\" likely concludes the evaluation process and saves or outputs the final results. The code seems to handle both cases where results are available for each video (predictions and losses) and when only predictions and labels are given.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":163-186",
            "content": "            predictions = np.array(fetch_list[0])\n            video_id = fetch_list[1]\n            for i in range(len(predictions)):\n                topk_inds = predictions[i].argsort()[0 - self.topk:]\n                topk_inds = topk_inds[::-1]\n                preds = predictions[i][topk_inds]\n                self.infer_results.append(\n                    (video_id[i], topk_inds.tolist(), preds.tolist()))\n        else:\n            if len(fetch_list) == 3:\n                loss = fetch_list[0]\n                loss = np.mean(np.array(loss))\n                pred = np.array(fetch_list[1])\n                label = np.array(fetch_list[2])\n            else:\n                loss = 0.\n                pred = np.array(fetch_list[0])\n                label = np.array(fetch_list[1])\n            self.calculator.accumulate(loss, pred, label)\n    def finalize_and_log_out(self,\n                             info='',\n                             savedir='./data/results',\n                             label_file='./label_3396.txt'):"
        },
        {
            "comment": "This code is part of a function that iterates over the 'infer_results' list and prints out the video ID, topk predictions for each class, along with their respective probabilities. It reads labels from the 'label_file', appends each prediction to a 'res_list' as a dictionary containing class_id, class_name, and probability, and then continues to the next iteration. The label file is read once per video.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":187-209",
            "content": "        if self.mode == 'infer':\n            for index, item in enumerate(self.infer_results):\n                video_id = item[0]\n                print('[========video_id [ {} ] , topk({}) preds: ========]\\n'.\n                      format(video_id, self.topk))\n                f = io.open(label_file, \"r\", encoding=\"utf-8\")\n                fl = f.readlines()\n                res_list = []\n                res_list.append(video_id)\n                for i in range(len(item[1])):\n                    class_id = item[1][i]\n                    class_prob = item[2][i]\n                    class_name = fl[class_id].split('\\n')[0]\n                    print('class_id: {},'.format(class_id), 'class_name:',\n                          class_name,\n                          ',  probability:  {} \\n'.format(class_prob))\n                    save_dict = {\n                        \"'class_id\": class_id,\n                        \"class_name\": class_name,\n                        \"probability\": class_prob\n                    }\n                    res_list.append(save_dict)"
        },
        {
            "comment": "The code saves the infer results into the specified output directory, finalizes and retrieves computed metrics from a calculator, logs the loss, top1_acc, and top5_acc if in 'train' mode, resets the calculator and list of infer results when resetting, and defines a MetricsNotFoundError exception for missing metrics.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":211-236",
            "content": "                # save infer result into output dir\n                with io.open(os.path.join(savedir,\n                                          'result' + str(index) + '.json'),\n                             'w',\n                             encoding='utf-8') as f:\n                    f.write(json.dumps(res_list, ensure_ascii=False))\n        else:\n            self.calculator.finalize_metrics()\n            metrics_dict = self.calculator.get_computed_metrics()\n            loss = metrics_dict['avg_loss']\n            acc1 = metrics_dict['avg_acc1']\n            acc5 = metrics_dict['avg_acc5']\n            logger.info(info + '\\tLoss: {},\\ttop1_acc: {}, \\ttop5_acc: {}'.format('%.6f' % loss, \\\n                       '%.2f' % acc1, '%.2f' % acc5))\n    def reset(self):\n        self.calculator.reset()\n        if self.mode == 'infer':\n            self.infer_results = []\nclass MetricsNotFoundError(Exception):\n    \"Error: metrics not found\"\n    def __init__(self, metrics_name, avail_metrics):\n        super(MetricsNotFoundError, self).__init__()"
        },
        {
            "comment": "This code defines a MetricsZoo class to manage and retrieve metrics. It provides regist() and get() methods for registering and retrieving metrics by name, respectively. The MetricsZoo instance is made singleton via global variable metrics_zoo. Youtube8mMetrics are registered under the name \"ATTENTIONLSTM\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":237-277",
            "content": "        self.metrics_name = metrics_name\n        self.avail_metrics = avail_metrics\n    def __str__(self):\n        msg = \"Metrics {} Not Found.\\nAvailiable metrics:\\n\".format(\n            self.metrics_name)\n        for metric in self.avail_metrics:\n            msg += \"  {}\\n\".format(metric)\n        return msg\nclass MetricsZoo(object):\n    def __init__(self):\n        self.metrics_zoo = {}\n    def regist(self, name, metrics):\n        assert metrics.__base__ == Metrics, \"Unknow model type {}\".format(\n            type(metrics))\n        self.metrics_zoo[name] = metrics\n    def get(self, name, mode, cfg):\n        for k, v in self.metrics_zoo.items():\n            if k == name:\n                return v(name, mode, cfg)\n        raise MetricsNotFoundError(name, self.metrics_zoo.keys())\n# singleton metrics_zoo\nmetrics_zoo = MetricsZoo()\ndef regist_metrics(name, metrics):\n    metrics_zoo.regist(name, metrics)\ndef get_metrics(name, mode, cfg):\n    return metrics_zoo.get(name, mode, cfg)\n# sort by alphabet\nregist_metrics(\"ATTENTIONLSTM\", Youtube8mMetrics)"
        },
        {
            "comment": "The code registers the \"TSN\" metric with the Kinetics400Metrics class.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/metrics_util.py\":278-278",
            "content": "regist_metrics(\"TSN\", Kinetics400Metrics)"
        }
    ]
}