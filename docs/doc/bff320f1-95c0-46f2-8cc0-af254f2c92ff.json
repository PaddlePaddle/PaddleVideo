{
    "summary": "The code introduces a spatial-temporal detection dataset class in PaddleVideo, initializes attributes and evaluation functions, loads records from paths, prepares training data by filtering proposals and annotations, pads elements to fixed lengths, and defines methods for padding 2D/1D features.",
    "details": [
        {
            "comment": "This code snippet is the AVA dataset class for spatial-temporal detection, which is part of PaddleVideo. It imports necessary modules and registers the dataset in the DATASETS registry. The class inherits from BaseDataset and includes a function ava_evaluate_results for evaluation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":0-31",
            "content": "# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport os.path as osp\nimport copy\nimport random\nimport numpy as np\nimport sys\nimport os\nimport pickle\nfrom datetime import datetime\nfrom ...metrics.ava_utils import ava_evaluate_results\nfrom ..registry import DATASETS\nfrom .base import BaseDataset\nfrom collections import defaultdict\n@DATASETS.register()\nclass AVADataset(BaseDataset):\n    \"\"\"AVA dataset for spatial temporal detection.\n    the dataset loads raw frames, bounding boxes, proposals and applies"
        },
        {
            "comment": "This code is initializing a class with various parameters for the AvaDataset. It sets default values and performs checks on input values, such as ensuring 'person_det_score_thr' falls within 0 to 1 range. The code also initializes instance variables, including custom classes, exclude file path, label file path, proposal file path, and more.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":32-61",
            "content": "    transformations to return the frame tensors and other information.\n    \"\"\"\n    _FPS = 30\n    def __init__(self,\n                 pipeline,\n                 file_path=None,\n                 exclude_file=None,\n                 label_file=None,\n                 suffix='{:05}.jpg',\n                 proposal_file=None,\n                 person_det_score_thr=0.9,\n                 num_classes=81,\n                 data_prefix=None,\n                 test_mode=False,\n                 num_max_proposals=1000,\n                 timestamp_start=900,\n                 timestamp_end=1800):\n        self.custom_classes = None\n        self.exclude_file = exclude_file\n        self.label_file = label_file\n        self.proposal_file = proposal_file\n        assert 0 <= person_det_score_thr <= 1, (\n            'The value of '\n            'person_det_score_thr should in [0, 1]. ')\n        self.person_det_score_thr = person_det_score_thr\n        self.num_classes = num_classes\n        self.suffix = suffix\n        self.num_max_proposals = num_max_proposals"
        },
        {
            "comment": "The code snippet initializes class attributes and checks for proposal file. If the proposal file exists, it loads the proposals; otherwise, it sets them as None. It then filters out invalid indexes if not in test mode. The code also includes a method to load data from a given path using pickle and close the file afterward. Another method parses img_records by extracting bounding boxes, labels, and entity IDs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":62-92",
            "content": "        self.timestamp_start = timestamp_start\n        self.timestamp_end = timestamp_end\n        super().__init__(\n            file_path,\n            pipeline,\n            data_prefix,\n            test_mode,\n        )\n        if self.proposal_file is not None:\n            self.proposals = self._load(self.proposal_file)\n        else:\n            self.proposals = None\n        if not test_mode:\n            valid_indexes = self.filter_exclude_file()\n            self.info = self.info = [self.info[i] for i in valid_indexes]\n    def _load(self, path):\n        f = open(path, 'rb')\n        res = pickle.load(f)\n        f.close()\n        return res\n    def parse_img_record(self, img_records):\n        bboxes, labels, entity_ids = [], [], []\n        while len(img_records) > 0:\n            img_record = img_records[0]\n            num_img_records = len(img_records)\n            selected_records = list(\n                filter(\n                    lambda x: np.array_equal(x['entity_box'], img_record[\n                        'entity_box']), img_records))"
        },
        {
            "comment": "This code is filtering out specific records from the dataset. It checks if the entity box of each record matches with a given img_record's entity box, excluding them if they do. If there are no exclude file information, it includes all the records in valid_indexes. Finally, it stacks and returns bboxes, labels, and entity_ids for further processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":93-121",
            "content": "            num_selected_records = len(selected_records)\n            img_records = list(\n                filter(\n                    lambda x: not np.array_equal(x['entity_box'], img_record[\n                        'entity_box']), img_records))\n            assert len(img_records) + num_selected_records == num_img_records\n            bboxes.append(img_record['entity_box'])\n            valid_labels = np.array([\n                selected_record['label'] for selected_record in selected_records\n            ])\n            label = np.zeros(self.num_classes, dtype=np.float32)\n            label[valid_labels] = 1.\n            labels.append(label)\n            entity_ids.append(img_record['entity_id'])\n        bboxes = np.stack(bboxes)\n        labels = np.stack(labels)\n        entity_ids = np.stack(entity_ids)\n        return bboxes, labels, entity_ids\n    def filter_exclude_file(self):\n        valid_indexes = []\n        if self.exclude_file is None:\n            valid_indexes = list(range(len(self.info)))\n        else:\n            exclude_video_infos = ["
        },
        {
            "comment": "The code reads a file, splits each line into video ID, timestamp, and other data. It then checks for any exclusion videos based on the ID and timestamp. If found, it removes that index from the valid_indexes list. Finally, it returns the updated valid_indexes list. The load_file method reads the file, extracts information including video ID, timestamp, entity box, label, and entity ID for each line.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":122-147",
            "content": "                x.strip().split(',') for x in open(self.exclude_file)\n            ]\n            for i, video_info in enumerate(self.info):\n                valid_indexes.append(i)\n                for video_id, timestamp in exclude_video_infos:\n                    if (video_info['video_id'] == video_id\n                            and video_info['timestamp'] == int(timestamp)):\n                        valid_indexes.pop()\n                        break\n        return valid_indexes\n    def load_file(self):\n        \"\"\"Load index file to get video information.\"\"\"\n        info = []\n        records_dict_by_img = defaultdict(list)\n        with open(self.file_path, 'r') as fin:\n            for line in fin:\n                line_split = line.strip().split(',')\n                video_id = line_split[0]\n                timestamp = int(line_split[1])\n                img_key = f'{video_id},{timestamp:04d}'\n                entity_box = np.array(list(map(float, line_split[2:6])))\n                label = int(line_split[6])\n                entity_id = int(line_split[7])"
        },
        {
            "comment": "The code initializes `shot_info` based on the timestamp range and FPS, then creates a `video_info` dictionary containing various video details. It appends this information to the `records_dict_by_img` for each `img_key`. Next, it extracts video ID and timestamp from `img_key`, calls `parse_img_record()`, and stores the resulting bounding boxes, labels, and entity IDs in an `ann` dictionary. Finally, it sets the frame directory path and adds a new `video_info` dictionary for each video.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":148-169",
            "content": "                shot_info = (0, (self.timestamp_end - self.timestamp_start) *\n                             self._FPS)\n                video_info = dict(video_id=video_id,\n                                  timestamp=timestamp,\n                                  entity_box=entity_box,\n                                  label=label,\n                                  entity_id=entity_id,\n                                  shot_info=shot_info)\n                records_dict_by_img[img_key].append(video_info)\n        for img_key in records_dict_by_img:\n            video_id, timestamp = img_key.split(',')\n            bboxes, labels, entity_ids = self.parse_img_record(\n                records_dict_by_img[img_key])\n            ann = dict(gt_bboxes=bboxes,\n                       gt_labels=labels,\n                       entity_ids=entity_ids)\n            frame_dir = video_id\n            if self.data_prefix is not None:\n                frame_dir = osp.join(self.data_prefix, frame_dir)\n            video_info = dict(frame_dir=frame_dir,"
        },
        {
            "comment": "The code initializes a video information object with the provided parameters, including the video ID, timestamp, image key, shot info, FPS, and annotations. It then appends this object to a list of video information. The prepare_train method takes an index, creates a copy of the corresponding video information from the list, adds suffix and timestamp information if applicable, and populates proposals with default values if not present in self.proposals.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":170-196",
            "content": "                              video_id=video_id,\n                              timestamp=int(timestamp),\n                              img_key=img_key,\n                              shot_info=shot_info,\n                              fps=self._FPS,\n                              ann=ann)\n            info.append(video_info)\n        return info\n    def prepare_train(self, idx):\n        results = copy.deepcopy(self.info[idx])\n        img_key = results['img_key']\n        results['suffix'] = self.suffix\n        results['timestamp_start'] = self.timestamp_start\n        results['timestamp_end'] = self.timestamp_end\n        if self.proposals is not None:\n            if img_key not in self.proposals:\n                results['proposals'] = np.array([[0, 0, 1, 1]])\n                results['scores'] = np.array([1])\n            else:\n                proposals = self.proposals[img_key]\n                assert proposals.shape[-1] in [4, 5]\n                if proposals.shape[-1] == 5:\n                    thr = min(self.person_det_score_thr, max(proposals[:, 4]))"
        },
        {
            "comment": "This code is filtering and padding proposals and annotations for a dataset. It selects positive proposals based on a threshold, limits the number of proposals to the maximum allowed, and assigns the results to different categories. If there are no positive proposals, it simply limits the number and assigns them. After that, it retrieves ground truth bounding boxes, labels, and entity IDs from the 'ann' dictionary. Finally, the code pads the proposals, scores, and other elements with zeros to reach a fixed length of 128 using a custom padding function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":197-220",
            "content": "                    positive_inds = (proposals[:, 4] >= thr)\n                    proposals = proposals[positive_inds]\n                    proposals = proposals[:self.num_max_proposals]\n                    results['proposals'] = proposals[:, :4]\n                    results['scores'] = proposals[:, 4]\n                else:\n                    proposals = proposals[:self.num_max_proposals]\n                    results['proposals'] = proposals\n        ann = results.pop('ann')\n        results['gt_bboxes'] = ann['gt_bboxes']\n        results['gt_labels'] = ann['gt_labels']\n        results['entity_ids'] = ann['entity_ids']\n        #ret = self.pipeline(results, \"\")\n        ret = self.pipeline(results)\n        #padding for dataloader\n        len_proposals = ret['proposals'].shape[0]\n        len_gt_bboxes = ret['gt_bboxes'].shape[0]\n        len_gt_labels = ret['gt_labels'].shape[0]\n        len_scores = ret['scores'].shape[0]\n        len_entity_ids = ret['entity_ids'].shape[0]\n        padding_len = 128\n        ret['proposals'] = self.my_padding_2d(ret['proposals'], padding_len)"
        },
        {
            "comment": "This code snippet defines a class with methods for padding 2D and 1D features. The 'my_padding_2d' method takes a feature matrix and pads it with zeros to the maximum length specified, while the 'my_padding_1d' method does the same but for 1D features. These methods are then called in another function to pad various feature matrices before returning them along with other variables.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":221-239",
            "content": "        ret['gt_bboxes'] = self.my_padding_2d(ret['gt_bboxes'], padding_len)\n        ret['gt_labels'] = self.my_padding_2d(ret['gt_labels'], padding_len)\n        ret['scores'] = self.my_padding_1d(ret['scores'], padding_len)\n        ret['entity_ids'] = self.my_padding_1d(ret['entity_ids'], padding_len)\n        return ret['imgs'][0], ret['imgs'][1], ret['proposals'], ret[\n            'gt_bboxes'], ret['gt_labels'], ret['scores'], ret[\n                'entity_ids'], np.array(\n                    ret['img_shape'], dtype=int\n                ), idx, len_proposals, len_gt_bboxes, len_gt_labels, len_scores, len_entity_ids\n    def my_padding_2d(self, feat, max_len):\n        feat_add = np.zeros((max_len - feat.shape[0], feat.shape[1]),\n                            dtype=np.float32)\n        feat_pad = np.concatenate((feat, feat_add), axis=0)\n        return feat_pad\n    def my_padding_1d(self, feat, max_len):\n        feat_add = np.zeros((max_len - feat.shape[0]), dtype=np.float32)\n        feat_pad = np.concatenate((feat, feat_add), axis=0)"
        },
        {
            "comment": "The code defines three functions: 'prepare_train', 'prepare_test', and 'evaluate'. The 'prepare_train' function is used to prepare training data given an index, while the 'prepare_test' function returns the same as 'prepare_train'. The 'evaluate' function evaluates the results using 'ava_evaluate_results' by passing various arguments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dataset/ava_dataset.py\":240-248",
            "content": "        return feat_pad\n    def prepare_test(self, idx):\n        return self.prepare_train(idx)\n    def evaluate(self, results):\n        return ava_evaluate_results(self.info, len(self), results,\n                                    self.custom_classes, self.label_file,\n                                    self.file_path, self.exclude_file)"
        }
    ]
}