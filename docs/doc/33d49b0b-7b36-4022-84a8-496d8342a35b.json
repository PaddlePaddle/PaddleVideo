{
    "summary": "The code configures logging, imports libraries, initializes a video tagging model using PaddlePaddle and PaddleVideo. It sets up input data with efficient execution on GPU/CPU resources, measures predictor model's execution time for performance analysis or optimization within the main script function.",
    "details": [
        {
            "comment": "Code sets the logging configuration for INFO level, defines the log format, and redirects the logs to stdout. It also imports necessary libraries and modules, and configures logging handlers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":0-33",
            "content": "#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n#Licensed under the Apache License, Version 2.0 (the \"License\");\n#you may not use this file except in compliance with the License.\n#You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#Unless required by applicable law or agreed to in writing, software\n#distributed under the License is distributed on an \"AS IS\" BASIS,\n#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#See the License for the specific language governing permissions and\n#limitations under the License.\nimport os\nimport sys\nimport time\nimport logging\nimport argparse\nimport ast\nimport numpy as np\nimport paddle\nimport paddle.static as static\nfrom utils.config_utils import *\nimport models\nfrom reader import get_reader\nfrom metrics import get_metrics\nfrom utils.utility import check_cuda\nfrom utils.utility import check_version\nlogging.root.handlers = []\nFORMAT = '[%(levelname)s: %(filename)s: %(lineno)4d]: %(message)s'\nlogging.basicConfig(level=logging.INFO, format=FORMAT, stream=sys.stdout)"
        },
        {
            "comment": "This code snippet defines a function \"parse_args()\" which uses the argparse module to parse command-line arguments. It sets default values for extractor and predictor model configurations, names, and enables GPU usage by default.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":34-61",
            "content": "logger = logging.getLogger(__name__)\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--extractor_config',\n                        type=str,\n                        default='configs/tsn.yaml',\n                        help='path to config file of model')\n    parser.add_argument('--extractor_name',\n                        type=str,\n                        default='TSN',\n                        help='extractor model name, default TSN')\n    parser.add_argument('--predictor_config',\n                        '--pconfig',\n                        type=str,\n                        default='configs/attention_lstm.yaml',\n                        help='path to config file of model')\n    parser.add_argument(\n        '--predictor_name',\n        '--pname',\n        type=str,\n        default='AttentionLSTM',\n        help='predictor model name, as AttentionLSTM, AttentionCluster, NEXTVLAD'\n    )\n    parser.add_argument('--use_gpu',\n                        type=ast.literal_eval,\n                        default=True,"
        },
        {
            "comment": "This code snippet uses the argparse module to define command-line arguments for a video tagging application. These arguments include GPU usage, extractor and predictor weight paths, input file list, output directory, and Chinese label file path. The function `parser.parse_args()` is called at the end to return these arguments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":62-85",
            "content": "                        help='default use gpu.')\n    parser.add_argument('--extractor_weights',\n                        type=str,\n                        default='weights/tsn',\n                        help='extractor weight path')\n    parser.add_argument('--predictor_weights',\n                        '--pweights',\n                        type=str,\n                        default='weights/attention_lstm',\n                        help='predictor weight path')\n    parser.add_argument('--filelist',\n                        type=str,\n                        default='./data/VideoTag_test.list',\n                        help='path of video data, multiple video')\n    parser.add_argument('--save_dir',\n                        type=str,\n                        default='data/VideoTag_results',\n                        help='output file path')\n    parser.add_argument('--label_file',\n                        type=str,\n                        default='label_3396.txt',\n                        help='chinese label file path')\n    args = parser.parse_args()"
        },
        {
            "comment": "This code defines a video classification model with two stages: extracting features from the input video using an extractor and predicting the classification results based on those extracted features. It uses PaddlePaddle's static graph mode for performance improvement and organizes the code within name scopes \"extractor_scope\" and \"predictor_scope\". The code also checks if the save directory exists, creates it if not, and measures time taken by the extractor stage.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":86-110",
            "content": "    return args\ndef main():\n    \"\"\"\n    Video classification model of 3000 Chinese tags.\n    videotag_extractor_prdictor (as videotag_TSN_AttentionLSTM)\n    two stages in our model:\n        1. extract feature from input video(mp4 format) using extractor\n        2. predict classification results from extracted feature  using predictor\n    we implement this using two name scopes, ie. extractor_scope and predictor_scope.\n    \"\"\"\n    if not os.path.isdir(args.save_dir):\n        os.makedirs(args.save_dir)\n    extractor_config = parse_config(args.extractor_config)\n    extractor_infer_config = merge_configs(extractor_config, 'infer',\n                                           vars(args))\n    extractor_start_time = time.time()\n    extractor_scope = paddle.static.Scope()\n    with static.scope_guard(extractor_scope):\n        extractor_startup_prog = static.Program()\n        extractor_main_prog = static.Program()\n        with static.program_guard(extractor_main_prog, extractor_startup_prog):\n            paddle.disable_static()"
        },
        {
            "comment": "This code builds a model, sets up the necessary parameters for execution, and loads pre-trained weights from a specified location. The model is built in inferencing mode for video tagging tasks, and it utilizes GPU or CPU resources based on the provided arguments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":111-133",
            "content": "                # build model\n            extractor_model = models.get_model(args.extractor_name,\n                                               extractor_infer_config,\n                                               mode='infer',\n                                               is_videotag=True)\n            extractor_model.build_input(use_dataloader=False)\n            extractor_model.build_model()\n            extractor_feeds = extractor_model.feeds()\n            extractor_fetch_list = extractor_model.fetches()\n            place = paddle.CUDAPlace(0) if args.use_gpu else paddle.CPUPlace()\n            exe = static.Executor(place)\n            exe.run(extractor_startup_prog)\n            logger.info('load extractor weights from {}'.format(\n                args.extractor_weights))\n            extractor_model.load_pretrain_params(exe,\n                                                 args.extractor_weights,\n                                                 extractor_main_prog)\n                # get reader and metrics"
        },
        {
            "comment": "The code is setting up a reader and feeder for an extractor in PaddleVideo, iterating through data from the reader, running the extractor using static mode, and logging progress. It also measures and prints the time taken for extraction.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":134-153",
            "content": "            extractor_reader = get_reader(args.extractor_name, 'infer',\n                                          extractor_infer_config)\n            extractor_feeder = paddle.fluid.DataFeeder(place=place,\n                                                feed_list=extractor_feeds)\n            feature_list = []\n            file_list = []\n            for idx, data in enumerate(extractor_reader()):\n                file_id = [item[-1] for item in data]\n                feed_data = [item[:-1] for item in data]\n                feature_out = exe.run(fetch_list=extractor_fetch_list,\n                                      feed=extractor_feeder.feed(feed_data))\n                feature_list.append(feature_out[0])  #get out from list\n                file_list.append(file_id)\n                logger.info(\n                    '========[Stage 1 Sample {} ] Extractor finished======'.\n                    format(idx))\n            paddle.enable_static()\n        extractor_end_time = time.time()\n        print('extractor_time', extractor_end_time - extractor_start_time)"
        },
        {
            "comment": "This code configures and prepares input data for a predictor model. It first parses the predictor configuration file, then merges it with command line arguments to create an inferencing configuration. Depending on the specified predictor model, it either extracts relevant segments from feature lists or uses the entire feature list. The resulting data is added to a list of inputs for the predictor model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":155-176",
            "content": "    predictor_config = parse_config(args.predictor_config)\n    predictor_infer_config = merge_configs(predictor_config, 'infer',\n                                           vars(args))\n    # get Predictor input from Extractor output\n    predictor_feed_list = []\n    for i in range(len(feature_list)):\n        feature_out = feature_list[i]\n        if args.predictor_name == \"AttentionCluster\":\n            extractor_seg_num = extractor_infer_config.INFER.seg_num\n            predictor_seg_num = predictor_infer_config.MODEL.seg_num\n            idxs = []\n            stride = float(extractor_seg_num) / predictor_seg_num\n            for j in range(predictor_seg_num):\n                pos = (j + np.random.random()) * stride\n                idxs.append(min(extractor_seg_num - 1, int(pos)))\n            extractor_feature = feature_out[:, idxs, :].astype(\n                float)  # get from bs dim\n        else:\n            extractor_feature = feature_out.astype(float)\n        predictor_feed_data = [extractor_feature]\n        predictor_feed_list.append((predictor_feed_data, file_list[i]))"
        },
        {
            "comment": "This code sets up a predictor model, builds its inputs, builds the model itself, initializes feeds, runs a startup program, loads test weights from a specified location, and performs these actions within scopes and programs for efficient execution.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":178-198",
            "content": "    predictor_start_time = time.time()\n    predictor_scope = paddle.static.Scope()\n    with static.scope_guard(predictor_scope):\n        predictor_startup_prog = static.Program()\n        predictor_main_prog = static.Program()\n        with static.program_guard(predictor_main_prog, predictor_startup_prog):\n            paddle.disable_static()\n                # parse config\n            predictor_model = models.get_model(args.predictor_name,\n                                               predictor_infer_config,\n                                               mode='infer')\n            predictor_model.build_input(use_dataloader=False)\n            predictor_model.build_model()\n            predictor_feeds = predictor_model.feeds()\n            exe.run(predictor_startup_prog)\n            logger.info('load predictor weights from {}'.format(\n                args.predictor_weights))\n            predictor_model.load_test_weights(exe, args.predictor_weights,\n                                              predictor_main_prog)"
        },
        {
            "comment": "This code snippet is initializing a DataFeeder for predictor model, fetching the list of metrics for predictor model and resetting them. It then iterates over the feed data, runs the model with each data instance, accumulates the final results in the metrics object, and finally logs the output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":200-220",
            "content": "            predictor_feeder = paddle.fluid.DataFeeder(place=place,\n                                                feed_list=predictor_feeds)\n            predictor_fetch_list = predictor_model.fetches()\n            predictor_metrics = get_metrics(args.predictor_name.upper(),\n                                            'infer', predictor_infer_config)\n            predictor_metrics.reset()\n            for idx, data in enumerate(predictor_feed_list):\n                file_id = data[1]\n                predictor_feed_data = data[0]\n                final_outs = exe.run(\n                    fetch_list=predictor_fetch_list,\n                    feed=predictor_feeder.feed(predictor_feed_data))\n                logger.info(\n                    '=======[Stage 2 Sample {} ] Predictor finished========'\n                    .format(idx))\n                final_result_list = [item\n                                     for item in final_outs] + [file_id]\n                predictor_metrics.accumulate(final_result_list)\n            predictor_metrics.finalize_and_log_out("
        },
        {
            "comment": "The code measures the time taken for a predictor to run and outputs it. It also records the total time taken for inferencing and displays the result, indicating when the inference is finished. This code snippet appears within the main function of the script, suggesting that this timing information is used for performance analysis or optimization purposes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/videotag_test.py\":221-237",
            "content": "                savedir=args.save_dir, label_file=args.label_file)\n            paddle.enable_static()\n    predictor_end_time = time.time()\n    print('predictor_time', predictor_end_time - predictor_start_time)\nif __name__ == '__main__':\n    start_time = time.time()\n    args = parse_args()\n    print(args)\n    check_cuda(args.use_gpu)\n    check_version()\n    logger.info(args)\n    main()\n    end_time = time.time()\n    period = end_time - start_time\n    print('[INFER] infer finished. cost time: {}'.format(period))"
        }
    ]
}