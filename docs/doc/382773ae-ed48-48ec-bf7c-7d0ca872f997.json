{
    "summary": "This Python script loads Baidu Cloud models for video classification, extracts audio and pcm features, logs details, saves features in a pickle file, creates \"features\" directory if necessary, and classifies videos from a specified dataset directory.",
    "details": [
        {
            "comment": "This Python script is for the Baidu Cloud action, loading and initializing image and audio models according to a given configuration file. It also provides a function to classify videos. The script logs information about model loading time and the progress of video classification.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/extractor/extract_feat.py\":0-49",
            "content": "#!./python27-gcc482/bin/python\n# coding: utf-8\n\"\"\"\nBAIDU CLOUD action\n\"\"\"\nimport os\nimport sys\nimport pickle\nimport json\nimport time\nimport shutil\nimport numpy as np\nsys.path.append(\"../predict/action_detect\")\nimport models.pptsm_infer as image_model\nimport models.audio_infer as audio_model\nfrom utils.preprocess import get_images\nfrom utils.config_utils import parse_config, print_configs\nimport utils.config_utils as config_utils\nimport logger\nlogger = logger.Logger()\ndef load_model(cfg_file=\"configs/configs.yaml\"):\n    \"\"\"\n    load_model\n    \"\"\"\n    logger.info(\"load model ... \")\n    global infer_configs\n    infer_configs = parse_config(cfg_file)\n    print_configs(infer_configs, \"Infer\")\n    t0 = time.time()\n    global image_model, audio_model\n    image_model = image_model.InferModel(infer_configs)\n    audio_model = audio_model.InferModel(infer_configs)\n    t1 = time.time()\n    logger.info(\"step0: load model time: {} min\\n\".format((t1 - t0) * 1.0 / 60))\ndef video_classify(video_name):\n    \"\"\"\n    extract_feature\n    \"\"\"\n    logger.info('predict ... ')"
        },
        {
            "comment": "Extracting video features, specifically images and audio. Converting extracted features to numpy arrays. Logging shapes of the arrays and time taken for feature extraction.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/extractor/extract_feat.py\":50-73",
            "content": "    logger.info(video_name)\n    imgs_path = video_name.replace(\".mp4\", \"\").replace(\"mp4\", \"frames\")\n    pcm_path = video_name.replace(\".mp4\", \".pcm\").replace(\"mp4\", \"pcm\")\n    # step 1: extract feature\n    t0 = time.time()\n    image_path_list = get_images(imgs_path)\n    infer_configs['PPTSM']['frame_list'] = image_path_list\n    infer_configs['AUDIO']['pcm_file'] = pcm_path\n    image_features = image_model.predict(infer_configs)\n    audio_features, pcm_features = audio_model.predict(infer_configs)\n    np_image_features = np.array(image_features, dtype=np.float32)\n    np_audio_features = np.array(audio_features, dtype=np.float32)\n    np_pcm_features = np.array(pcm_features, dtype=np.float32)\n    t1 = time.time()\n    logger.info('{} {} {}'.format(np_image_features.shape,\n                                  np_audio_features.shape,\n                                  np_pcm_features.shape))\n    logger.info(\"step1: feature extract time: {} min\".format(\n        (t1 - t0) * 1.0 / 60))\n    video_features = {\n        'image_feature': np_image_features,"
        },
        {
            "comment": "The code extracts audio and pcm features from video files, saves them in a pickle file named after the original video, creates a \"features\" directory if it doesn't exist, then classifies each video based on its location in a specified dataset directory.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/extractor/extract_feat.py\":74-99",
            "content": "        'audio_feature': np_audio_features,\n        'pcm_feature': np_pcm_features\n    }\n    # save feature\n    feature_path = video_name.replace(\".mp4\", \".pkl\").replace(\"mp4\", \"features\")\n    feat_pkl_str = pickle.dumps(video_features,\n                                protocol=pickle.HIGHEST_PROTOCOL)\n    with open(feature_path, 'wb') as fout:\n        fout.write(feat_pkl_str)\nif __name__ == '__main__':\n    dataset_dir = \"../datasets/EuroCup2016\"\n    if not os.path.exists(dataset_dir + '/features'):\n        os.mkdir(dataset_dir + '/features')\n    load_model()\n    video_url = os.path.join(dataset_dir, 'url.list')\n    with open(video_url, 'r') as f:\n        lines = f.readlines()\n    lines = [os.path.join(dataset_dir, k.strip()) for k in lines]\n    for line in lines:\n        video_classify(line)"
        }
    ]
}