{
    "summary": "This code uses OpenCV and other libraries, processes video frames in batches with PaddleVideo's Recognition class, enables benchmarking if set, and handles main function execution and program termination.",
    "details": [
        {
            "comment": "This code file contains copyright information, license details, and includes necessary header files for OpenCV, Google Logging, GFlags, and other utilities. It also includes the header file for video_rec and utility functions. This seems to be part of a larger codebase related to video processing or analysis.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/main.cpp\":0-34",
            "content": "// Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n#include \"glog/logging.h\"\n#include \"omp.h\"\n#include \"opencv2/core.hpp\"\n#include \"opencv2/imgcodecs.hpp\"\n#include \"opencv2/imgproc.hpp\"\n#include <chrono>\n#include <iomanip>\n#include <iostream>\n#include <ostream>\n#include <vector>\n#include <cstring>\n#include <fstream>\n#include <numeric>\n#include <include/video_rec.h>\n#include <include/utility.h>\n#include <sys/stat.h>\n#include <gflags/gflags.h>\n#include \"auto_log/autolog.h\""
        },
        {
            "comment": "This code defines various parameters for an inference process. The use_gpu flag determines if GPU or CPU is used, gpu_id specifies the device id of the GPU, gpu_mem sets the GPU id for inferencing with GPU, cpu_threads indicates the number of threads for CPU usage, enable_mkldnn enables MKL-DNN for CPU operations, use_tensorrt utilizes TensorRT, precision selects the desired precision format (fp32/fp16/int8), benchmark tracks inference timings, and video recognition parameters include the input video directory, model path, model name, number of frames per segment, and batch number.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/main.cpp\":36-53",
            "content": "// general parameters\nDEFINE_bool(use_gpu, false, \"Infering with GPU or CPU.\");\nDEFINE_int32(gpu_id, 0, \"Device id of GPU to execute.\");\nDEFINE_int32(gpu_mem, 4000, \"GPU id when infering with GPU.\");\nDEFINE_int32(cpu_threads, 10, \"Num of threads with CPU.\");\nDEFINE_bool(enable_mkldnn, false, \"Whether use mkldnn with CPU.\");\nDEFINE_bool(use_tensorrt, false, \"Whether use tensorrt.\");\nDEFINE_string(precision, \"fp32\", \"Precision be one of fp32/fp16/int8.\");\nDEFINE_bool(benchmark, true, \"Whether to log and report benchmark information during inference.\");\n// video recognition related\nDEFINE_string(video_dir, \"\", \"Dir of input video(s).\");\nDEFINE_string(rec_model_dir, \"../example_video_dir\", \"Path of video rec inference model.\");\nDEFINE_string(inference_model_name, \"ppTSM\", \"The name of the model used in the prediction.\");\nDEFINE_int32(num_seg, 8, \"number of frames input to model, which are extracted from a video.\");\nDEFINE_int32(seg_len, 1, \"number of frames from a segment.\");\nDEFINE_int32(rec_batch_num, 1, \"rec_batch_num.\");"
        },
        {
            "comment": "Initializing a video recognition object and processing each video in batches.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/main.cpp\":54-84",
            "content": "DEFINE_string(char_list_file, \"../../data/k400/Kinetics-400_label_list.txt\", \"Path of dictionary.\");\nusing namespace std;\nusing namespace cv;\nusing namespace PaddleVideo;\nstatic bool PathExists(const std::string& path)\n{\n#ifdef _WIN32\n    struct _stat buffer;\n    return (_stat(path.c_str(), &buffer) == 0);\n#else\n    struct stat buffer;\n    return (stat(path.c_str(), &buffer) == 0);\n#endif  // !_WIN32\n}\nint main_rec(std::vector<cv::String> &cv_all_video_names)\n{\n    std::vector<double> time_info = {0, 0, 0}; // Statement time statistics vector\n    VideoRecognizer rec(FLAGS_rec_model_dir, FLAGS_inference_model_name, FLAGS_use_gpu, FLAGS_num_seg,\n                        FLAGS_rec_batch_num, FLAGS_gpu_id,\n                        FLAGS_gpu_mem, FLAGS_cpu_threads,\n                        FLAGS_enable_mkldnn, FLAGS_char_list_file,\n                        FLAGS_use_tensorrt, FLAGS_precision); // Instantiate a video recognition object\n    int batch_num = FLAGS_rec_batch_num;\n    for (int i = 0, n = cv_all_video_names.size(); i < n; i += batch_num) // Process each video"
        },
        {
            "comment": "This code is processing a batch of video frames using PaddleVideo's Recognition class. It initializes time consumption statistics, then runs the recognition method on each frame within the specified batch and stores the results in `time_info`. Additionally, it enables benchmarking if FLAGS_benchmark flag is set.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/main.cpp\":85-108",
            "content": "    {\n        int start_idx = i;\n        int end_idx = min(i + batch_num, n);\n        std::vector<std::vector<cv::Mat> > frames_batch;\n        for (int j = start_idx; j < end_idx; ++j)\n        {\n            std::vector<cv::Mat> frames = Utility::SampleFramesFromVideo(cv_all_video_names[i], FLAGS_num_seg, FLAGS_seg_len);\n            frames_batch.emplace_back(frames);\n        }\n        std::vector<double> rec_times; // Initialization time consumption statistics\n        // Take the read several video frames and send them to the run method of the recognition class to predict\n        rec.Run(std::vector<string>(cv_all_video_names.begin() + start_idx, cv_all_video_names.begin() + end_idx), frames_batch, &rec_times);\n        time_info[0] += rec_times[0];\n        time_info[1] += rec_times[1];\n        time_info[2] += rec_times[2];\n    }\n    if (FLAGS_benchmark)\n    {\n        AutoLogger autolog(\"rec\",\n                           FLAGS_use_gpu,\n                           FLAGS_use_tensorrt,\n                           FLAGS_enable_mkldnn,"
        },
        {
            "comment": "This code segment is checking the parameters for running the video inference. If it's in recording mode, it ensures that both rec_model_dir and video_dir are not empty. It also checks if the precision specified (fp32, fp16, or int8) is valid. If any error is found, it displays an appropriate usage message and exits with an error code.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/main.cpp\":109-137",
            "content": "                           FLAGS_cpu_threads,\n                           FLAGS_rec_batch_num,\n                           \"dynamic\",\n                           FLAGS_precision,\n                           time_info,\n                           cv_all_video_names.size()); // Generate detailed information on the run\n        autolog.report(); // Print running details\n    }\n    return 0;\n}\nvoid check_params(char* mode)\n{\n    if (strcmp(mode, \"rec\") == 0)\n    {\n        std::cout << \"[\" << FLAGS_rec_model_dir << \"]\" << std::endl;\n        std::cout << \"[\" << FLAGS_video_dir << \"]\" << std::endl;\n        if (FLAGS_rec_model_dir.empty() || FLAGS_video_dir.empty())\n        {\n            std::cout << \"Usage[rec]: ./ppvideo --rec_model_dir=/PATH/TO/REC_INFERENCE_MODEL/ \"\n                      << \"--video_dir=/PATH/TO/INPUT/VIDEO/\" << std::endl;\n            exit(1);\n        }\n    }\n    if (FLAGS_precision != \"fp32\" && FLAGS_precision != \"fp16\" && FLAGS_precision != \"int8\")\n    {\n        cout << \"precison should be 'fp32'(default), 'fp16' or 'int8'. \" << endl;"
        },
        {
            "comment": "The code checks the user input and ensures the correct mode (\"rec\") is chosen. If not, it outputs an error message and returns -1. It also validates if the video directory exists and displays the total number of videos found. Finally, it calls the main_rec function for recording mode.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/main.cpp\":138-169",
            "content": "        exit(1);\n    }\n}\nint main(int argc, char **argv)\n{\n    if (argc <= 1 || (strcmp(argv[1], \"rec\") != 0)) //Get user input and check\n    {\n        std::cout << \"Please choose one mode of [rec] !\" << std::endl;\n        return -1;\n    }\n    std::cout << \"mode: \" << argv[1] << endl; // Type of inference task required for output\n    // Parsing command-line\n    google::ParseCommandLineFlags(&argc, &argv, true);\n    check_params(argv[1]);\n    if (!PathExists(FLAGS_video_dir)) // Determine whether the directory where the video exists\n    {\n        std::cerr << \"[ERROR] video path not exist! video_dir: \" << FLAGS_video_dir << endl;\n        exit(1);\n    }\n    std::vector<cv::String> cv_all_video_names; // Store all video paths\n    cv::glob(FLAGS_video_dir, cv_all_video_names); // Search all videos under FLAGS_video_dir, save in cv_all_video_names\n    std::cout << \"total videos num: \" << cv_all_video_names.size() << endl; // \u8f93\u51fa\u641c\u7d22\u5230\u7684\u89c6\u9891\u4e2a\u6570\n    if (strcmp(argv[1], \"rec\") == 0)\n    {\n        return main_rec(cv_all_video_names); // Output the number of videos searched"
        },
        {
            "comment": "The code snippet represents the end of the main function where a closing curly brace is followed by a return statement, indicating successful execution and termination of the program.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/main.cpp\":170-172",
            "content": "    }\n    return 0;\n}"
        }
    ]
}