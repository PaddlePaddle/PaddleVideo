{
    "summary": "This code defines ActBertLoss and actBertLoss classes as loss functions for ActBert model, using CrossEntropyLoss and nn.KLDivLoss. The total loss is calculated by summing masked text, masked image, masked action, and next sentence losses, based on predictions and labels from various sources.",
    "details": [
        {
            "comment": "This code defines the ActBertLoss class, which is a loss function for the ActBert model. It uses the CrossEntropyLoss from PaddlePaddle's nn library and takes two arguments: vocab_size and a_target_size. The class inherits from BaseWeightedLoss.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/actbert_loss.py\":0-31",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport numpy as np\nimport paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as F\nfrom ..registry import LOSSES\nfrom .base import BaseWeightedLoss\n@LOSSES.register()\nclass ActBertLoss(BaseWeightedLoss):\n    \"\"\"Loss for ActBert model\n    \"\"\"\n    def __init__(self, vocab_size=30522, a_target_size=700):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.a_target_size = a_target_size\n        self.loss_fct = nn.CrossEntropyLoss(ignore_index=-1)"
        },
        {
            "comment": "This code defines a class for an actBert loss function. It uses the nn.KLDivLoss function as a criterion and takes in prediction scores, sequence labels, image labels, image targets, action labels, and next sentence labels as input to compute the visual loss (img_loss). The prediction_scores_v variable is modified by removing the first element from each sequence, likely for consistency purposes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/actbert_loss.py\":32-49",
            "content": "        self.vis_criterion = nn.KLDivLoss(reduction=\"none\")\n    def forward(self, prediction_scores_t, prediction_scores_v, prediction_scores_a, seq_relationship_score, \\\n                text_labels, image_label, image_target, action_label, next_sentence_label):\n        \"\"\"\n        Args:\n            text_label: text label(with mask). Shape: [batch_size, seqence_length]\n            image_label: image label(with mask). Shape: [batch_size, region_length]\n            image_target: label of image feature distribution,\n                            Shape: [batch_size, region_length-1, num_image_class](minus 1 for xxx).\n            action label: action label(with mask), Shape: [batch_size, action_length]\n            next_sentence_label: is next sentence or not. Shape: [batch_size]\n        \"\"\"\n        prediction_scores_v = prediction_scores_v[:,\n                                                  1:]  #8,37,1601 --> 8,36,1601\n        img_loss = self.vis_criterion(\n            F.log_softmax(prediction_scores_v, axis=2),"
        },
        {
            "comment": "This code calculates a total loss by summing the masked text loss, masked image loss, masked action loss, and next sentence loss. The losses are calculated based on predictions and labels from various sources. The `loss_fct` function is used to compute these losses, and they are reshaped before being added together for the final total loss.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/losses/actbert_loss.py\":50-74",
            "content": "            image_target  #8,36,1601\n        )\n        masked_img_loss = paddle.sum(\n            img_loss * (image_label == 1).unsqueeze(2).astype('float32')) / max(\n                paddle.sum((image_label == 1).astype('float32')), 1e-6)\n        masked_text_loss = self.loss_fct(\n            prediction_scores_t.reshape([-1, self.vocab_size]),  #8,36,30522\n            text_labels.reshape([-1]),  #8,36   # label -1 will be ignored\n        )\n        masked_action_loss = self.loss_fct(\n            prediction_scores_a.reshape([-1, self.a_target_size]),  #8,5,700\n            action_label.reshape([-1]),  #8,5\n        )\n        next_sentence_loss = self.loss_fct(\n            seq_relationship_score.reshape([-1, 2]),\n            next_sentence_label.reshape([-1])  #8,2\n        )\n        total_loss = masked_text_loss.unsqueeze(0) + masked_img_loss.unsqueeze(\n            0) + masked_action_loss.unsqueeze(0) + next_sentence_loss.unsqueeze(\n                0)\n        return total_loss"
        }
    ]
}