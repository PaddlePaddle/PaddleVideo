{
    "summary": "This code employs machine learning and deep learning for Baidu Cloud's action detection system, including preprocessing, feature extraction, model application, and time-tracked execution. It configures PPTSM model, predicts features from data, creates a video feature dictionary, loads pre-existing features, checks shapes, and writes results to JSON file.",
    "details": [
        {
            "comment": "This code is for the Baidu Cloud action detection system, which uses machine learning and deep learning models to classify actions from both audio and image inputs. It includes utilities for preprocessing data, extracting features, and applying various models including image, audio, and propensity models. The code also has a logger module to log processing time information. A class ActionDetection is defined which likely handles the overall action detection process.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/action.py\":0-43",
            "content": "#!./python27-gcc482/bin/python\n# coding: utf-8\n\"\"\"\nBAIDU CLOUD action\n\"\"\"\nimport os\nimport sys\nimport pickle\nimport json\nimport time\nimport functools\nimport numpy as np\nfrom utils.preprocess import get_images\nfrom utils.config_utils import parse_config, print_configs\nimport mfcc.feature_extractor as mfcc_extractor\nimport models.pptsm_infer as image_model\nimport models.audio_infer as audio_model\nimport models.bmn_infer as prop_model\nimport models.lstm_infer as classify_model\nimport logger\nlogger = logger.Logger()\ndef record_time_info(func):\n    \"\"\"decorator func to log cost time for func\n    \"\"\"\n    @functools.wraps(func)\n    def timer(*args):\n        \"\"\"log cost time for func\n        \"\"\"\n        logger.info(\"function [{}] processing ...\".format(func.__name__))\n        start_time = time.time()\n        retval = func(*args)\n        cost_time = round(time.time() - start_time, 5)\n        logger.info(\"function [{}] run time: {:.2f} min\".format(func.__name__, cost_time / 60))\n        return retval\n    return timer\nclass ActionDetection(object):"
        },
        {
            "comment": "This code initializes a ModelPredict object with various configuration settings and properties. It reads configuration data from a specified file, prints relevant information for debugging, and sets attributes related to model components such as BMN_ONLY, LSTM_ONLY, and PCM_ONLY. If LSTM_ONLY is set to true, it populates a prop_dict with video names and their corresponding BMN results for later use in the load_model function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/action.py\":44-70",
            "content": "    \"\"\"ModelPredict\"\"\"\n    def __init__(self, cfg_file=\"configs/configs.yaml\"):\n        cfg = parse_config(cfg_file)\n        self.configs = cfg\n        print_configs(self.configs, \"Infer\")\n        name = 'COMMON'\n        self.DEBUG          = cfg[name]['DEBUG']\n        self.BMN_ONLY       = cfg[name]['BMN_ONLY']\n        self.LSTM_ONLY      = cfg[name]['LSTM_ONLY']\n        self.PCM_ONLY       = cfg[name]['PCM_ONLY']\n        if self.LSTM_ONLY:\n            self.prop_dict = {}\n            for dataset in ['EuroCup2016']:\n                prop_json = '/home/work/datasets/{}/feature_bmn/prop.json'.format(dataset)\n                json_data = json.load(open(prop_json, 'r'))\n                for item in json_data:\n                    basename = prop_json.replace('feature_bmn/prop.json', 'mp4')\n                    basename = basename + '/' + item['video_name'] + '.mp4'\n                    self.prop_dict[basename] = item['bmn_results']\n    @record_time_info\n    def load_model(self):\n        \"\"\"\n        load_model\n        \"\"\""
        },
        {
            "comment": "This code initializes models for image, audio, property prediction, and action classification. If DEBUG is not set, it creates InferModel instances for each model type. It then extracts features from input video, gets proposals using BMN (Bidirectional Mixture of Experts Network), and classifies the actions based on these features and proposals.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/action.py\":71-102",
            "content": "        if not self.DEBUG:\n            self.image_model = image_model.InferModel(self.configs)\n            if not self.PCM_ONLY:\n                self.audio_model = audio_model.InferModel(self.configs)\n        if not self.LSTM_ONLY:\n            self.prop_model = prop_model.InferModel(self.configs)\n        if not self.BMN_ONLY:\n            self.classify_model = classify_model.InferModel(self.configs)\n        logger.info(\"==> Action Detection prepared.\")\n    @record_time_info\n    def infer(self, imgs_path, pcm_path, fps=5):\n        \"\"\"\n        extract_feature\n        \"\"\"\n        self.imgs_path = imgs_path\n        self.pcm_path = pcm_path\n        self.configs['COMMON']['fps'] = fps\n        logger.info(\"==> input video {}\".format(os.path.basename(self.imgs_path)))\n        # step 1: extract feature\n        video_features = self.extract_feature()\n        # step2: get proposal\n        bmn_results = self.extract_proposal(video_features)\n        # step3: classify \n        material = {'feature': video_features, 'proposal': bmn_results}"
        },
        {
            "comment": "The code contains multiple methods: `video_classify`, `extract_proposal`, and `extract_feature`. The `video_classify` method predicts actions using a classification model, while the `extract_proposal` method extracts proposals (BMN results) for an input video. Both methods are decorated with the `@record_time_info` decorator to track execution time. The `extract_feature` method extracts features from images in the given path and is only executed if `DEBUG` flag is not set.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/action.py\":103-131",
            "content": "        action_results = self.video_classify(material)\n        return bmn_results, action_results\n    @record_time_info\n    def video_classify(self, material):\n        \"\"\"video classify\"\"\"\n        if self.BMN_ONLY:\n            return []\n        action_results = self.classify_model.predict(self.configs, material=material) \n        logger.info('action shape {}'.format(np.array(action_results).shape))\n        return action_results\n    @record_time_info\n    def extract_proposal(self, video_features):\n        \"\"\"extract proposal\"\"\"\n        if self.LSTM_ONLY:\n            basename = self.imgs_path.replace('frames', 'mp4') + '.mp4'\n            bmn_results = self.prop_dict[basename]\n            return bmn_results\n        bmn_results = self.prop_model.predict(self.configs, material=video_features)\n        logger.info('proposal shape {}'.format(np.array(bmn_results).shape))\n        return bmn_results\n    @record_time_info\n    def extract_feature(self):\n        \"\"\"extract feature\"\"\"\n        if not self.DEBUG:\n            image_path_list = get_images(self.imgs_path)"
        },
        {
            "comment": "This code configures the PPTSM model with image and audio data, then predicts features for both. If PCM_ONLY is True, it extracts MFCC from pcm file. It creates a video feature dictionary containing the predicted image, audio, and (if applicable) pcm features. If no input images are given, it loads the corresponding features from the specified feature path.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/action.py\":132-150",
            "content": "            self.configs['PPTSM']['frame_list'] = image_path_list\n            self.configs['AUDIO']['pcm_file'] = self.pcm_path\n            image_features = self.image_model.predict(self.configs)\n            if self.PCM_ONLY:\n                sample_rate = self.configs['AUDIO']['sample_rate']\n                pcm_features = mfcc_extractor.extract_pcm(self.pcm_path, sample_rate)\n                audio_features = []\n            else:\n                audio_features, pcm_features = self.audio_model.predict(self.configs)\n            np_image_features = np.array(image_features, dtype=np.float32)\n            np_audio_features = np.array(audio_features, dtype=np.float32)\n            np_pcm_features = np.array(pcm_features, dtype=np.float32)\n            video_features = {'image_feature': np_image_features,\n                              'audio_feature': np_audio_features,\n                              'pcm_feature': np_pcm_features}\n        else:\n            feature_path = self.imgs_path.replace(\"frames\", \"features\") + '.pkl'"
        },
        {
            "comment": "Code loads pre-existing video features from a file, checks their shapes and returns them for further processing. It then creates an instance of the ActionDetection model, loads the model, and calls infer function with image and audio paths. Finally, it writes results to a JSON file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/action.py\":151-172",
            "content": "            video_features = pickle.load(open(feature_path, 'rb'))\n        logger.info(\"feature shape {} {} {}\".format(video_features['image_feature'].shape,\n                                                    video_features['audio_feature'].shape,\n                                                    video_features['pcm_feature'].shape))\n        return video_features\nif __name__ == '__main__':\n    model_predict = ActionDetection(cfg_file=\"../configs/configs.yaml\")\n    model_predict.load_model()\n    imgs_path = \"/home/work/datasets/EuroCup2016/frames/1be705a8f67648da8ec4b4296fa80895\"\n    pcm_path = \"/home/work/datasets/EuroCup2016/pcm/1be705a8f67648da8ec4b4296fa80895.pcm\"\n    bmn_results, action_results = model_predict.infer(imgs_path, pcm_path)\n    results = {'bmn_results': bmn_results, 'action_results': action_results}\n    with open('results.json', 'w', encoding='utf-8') as f:\n       data = json.dumps(results, indent=4, ensure_ascii=False)\n       f.write(data)"
        }
    ]
}