{
    "summary": "The CAM_Module and YOWO backbone model are for image processing and video classification respectively, using attention mechanism and convolutional layers. The code loads pretrain weights correctly and returns a Paddle Video YOWO model after processing input clips through backbones, CFAM, and convolutional layers.",
    "details": [
        {
            "comment": "This code is a part of the PaddleVideo library and defines a custom layer called CAM_Module. It takes an input dimension as a parameter, initializes a gamma parameter, and inherits from nn.Layer. The class constructor creates a zero-dimensional tensor as the initial value for gamma using paddle.create_parameter function. This module is used in backbone architectures to enable Channel Attention Mechanism for image processing tasks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/yowo.py\":0-27",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom ..registry import BACKBONES\nfrom .darknet import Darknet\nfrom .resnext101 import ResNext101\nimport paddle.nn as nn\nimport paddle\nclass CAM_Module(nn.Layer):\n    def __init__(self, in_dim):\n        super(CAM_Module, self).__init__()\n        self.chanel_in = in_dim\n        temp = paddle.zeros([1], dtype='float32')\n        self.gamma = paddle.create_parameter(shape=temp.shape, dtype=str(temp.numpy().dtype),\n                                             default_initializer=paddle.nn.initializer.Assign(temp))"
        },
        {
            "comment": "The code defines a CFAMPBlock layer with a Channel-wise Attention Mechanism. It contains a convolution, batch normalization, and ReLU layers for the attention mechanism, followed by a gamma scaling and channel-wise attention calculation. The forward function performs the attention operation and scales the input using the attention map.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/yowo.py\":28-52",
            "content": "        self.softmax = nn.Softmax(axis=-1)\n    def forward(self, x):\n        m_batchsize, C, height, width = x.shape\n        proj_query = paddle.reshape(x, [m_batchsize, C, -1])\n        proj_key = paddle.transpose(paddle.reshape(\n            x, [m_batchsize, C, -1]), perm=[0, 2, 1])\n        energy = paddle.bmm(proj_query, proj_key)\n        energy_new = paddle.expand_as(paddle.max(\n            energy, axis=-1, keepdim=True), energy) - energy\n        attention = self.softmax(energy_new)\n        proj_value = paddle.reshape(x, [m_batchsize, C, -1])\n        out = paddle.bmm(attention, proj_value)\n        out = out.reshape([m_batchsize, C, height, width])\n        out = self.gamma * out + x\n        return out\nclass CFAMBlock(nn.Layer):\n    def __init__(self, in_channels, out_channels):\n        super(CFAMBlock, self).__init__()\n        inter_channels = 1024\n        self.conv_bn_relu1 = nn.Sequential(nn.Conv2D(in_channels, inter_channels, kernel_size=1, bias_attr=False),\n                                           nn.BatchNorm2D(inter_channels),"
        },
        {
            "comment": "This code defines a YOWO backbone model, which is a neural network architecture for video classification tasks. It consists of several convolutional layers followed by batch normalization and ReLU activations. The CAM_Module is also included, which might be a custom attention mechanism. The output channels are adjusted based on the input size. Dropout regularization is applied to prevent overfitting.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/yowo.py\":53-78",
            "content": "                                           nn.ReLU())\n        self.conv_bn_relu2 = nn.Sequential(nn.Conv2D(inter_channels, inter_channels, 3, padding=1, bias_attr=False),\n                                           nn.BatchNorm2D(inter_channels),\n                                           nn.ReLU())\n        self.sc = CAM_Module(inter_channels)\n        self.conv_bn_relu3 = nn.Sequential(nn.Conv2D(inter_channels, inter_channels, 3, padding=1, bias_attr=False),\n                                           nn.BatchNorm2D(inter_channels),\n                                           nn.ReLU())\n        self.conv_out = nn.Sequential(nn.Dropout2D(0.1), nn.Conv2D(\n            inter_channels, out_channels, 1, bias_attr=True))\n    def forward(self, x):\n        x = self.conv_bn_relu1(x)\n        x = self.conv_bn_relu2(x)\n        x = self.sc(x)\n        x = self.conv_bn_relu3(x)\n        output = self.conv_out(x)\n        return output\n@BACKBONES.register()\nclass YOWO(nn.Layer):\n    def __init__(self, num_class, pretrained_2d=None, pretrained_3d=None):"
        },
        {
            "comment": "The code initializes a YOWO model with pre-trained 2D and 3D backbones, loads pre-trained weights if provided for both backbones, and has a method to initialize weights.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/yowo.py\":79-107",
            "content": "        super(YOWO, self).__init__()\n        self.pretrained_2d = pretrained_2d\n        self.pretrained_3d = pretrained_3d\n        self.backbone_2d = Darknet()\n        self.backbone_3d = ResNext101()\n        self.num_ch_2d = 425\n        self.num_ch_3d = 2048\n        self.num_class = num_class\n        self.cfam = CFAMBlock(self.num_ch_2d + self.num_ch_3d, 1024)\n        self.conv_final = nn.Conv2D(\n            1024, 5 * (self.num_class + 4 + 1), kernel_size=1, bias_attr=False)\n        self.seen = 0\n    def init_weights(self):\n        if self.pretrained_2d is not None:\n            self.backbone_2d = self.load_pretrain_weight(\n                self.backbone_2d, self.pretrained_2d)\n        if self.pretrained_3d is not None:\n            self.backbone_3d = self.load_pretrain_weight(\n                self.backbone_3d, self.pretrained_3d)\n    def load_pretrain_weight(self, model, weights_path):\n        model_dict = model.state_dict()\n        param_state_dict = paddle.load(weights_path)\n        ignore_weights = set()\n        # hack: fit for faster rcnn. Pretrain weights contain prefix of 'backbone'"
        },
        {
            "comment": "This code is replacing the prefix of 'res5' with 'bbox_head.head' in param_state_dict to load pretrain weights correctly. It then checks if the weight shapes match and adds redundant or unmatched weights to ignore_weights.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/yowo.py\":108-128",
            "content": "        # while res5 module is located in bbox_head.head. Replace the prefix of\n        # res5 with 'bbox_head.head' to load pretrain weights correctly.\n        for k in list(param_state_dict.keys()):\n            if 'backbone.res5' in k:\n                new_k = k.replace('backbone', 'bbox_head.head')\n                if new_k in model_dict.keys():\n                    value = param_state_dict.pop(k)\n                    param_state_dict[new_k] = value\n        for name, weight in param_state_dict.items():\n            if name in model_dict.keys():\n                if list(weight.shape) != list(model_dict[name].shape):\n                    print(\n                        '{} not used, shape {} unmatched with {} in model.'.format(\n                            name, weight.shape, list(model_dict[name].shape)))\n                    ignore_weights.add(name)\n            else:\n                print('Redundant weight {} and ignore it.'.format(name))\n                ignore_weights.add(name)\n        for weight in ignore_weights:"
        },
        {
            "comment": "This function loads model weights from the specified path and returns a Paddle Video YOWO model. The model's `forward` method takes an input clip, separates it into 3D and 2D representations, passes them through their respective backbones, concatenates them together, and finally feeds it to CFAM and a convolutional layer for processing before returning the output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/yowo.py\":129-149",
            "content": "            param_state_dict.pop(weight, None)\n        model.set_dict(param_state_dict)\n        print('Finish loading model weights: {}'.format(weights_path))\n        return model\n    def forward(self, input):\n        x_3d = input  # Input clip\n        x_2d = input[:, :, -1, :, :]  # Last frame of the clip that is read\n        x_2d = self.backbone_2d(x_2d)\n        x_3d = self.backbone_3d(x_3d)\n        x_3d = paddle.squeeze(x_3d, axis=2)\n        x = paddle.concat([x_3d, x_2d], axis=1)\n        x = self.cfam(x)\n        out = self.conv_final(x)\n        return out"
        }
    ]
}