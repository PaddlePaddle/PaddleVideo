{
    "summary": "This PyTorch code uses OpenCV for image processing, offers conversion functions and error handling with PaddleVideo. It initializes tensors using Xavier/Glorot or Kaiming normal distribution, favoring Torch.nn.init methods over older ones.",
    "details": [
        {
            "comment": "Imports various modules and defines a type hint for paddle tensor or iterable of tensors.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":0-27",
            "content": "from __future__ import absolute_import\nimport json\nimport math\nimport os\nimport pickle\nimport warnings\nimport numpy\nimport numpy as np\nfrom numpy import inf\nfrom paddle import Tensor, concat, reshape, nn\nimport paddle\nfrom typing import Union, Iterable\n# from reprod_log.compare import compute_diff\n# from reprod_log.utils import check_print_diff, np2torch, np2paddle, torch2np, paddle2np\n_tensor_or_tensors = Union[paddle.Tensor, Iterable[paddle.Tensor]]\n_palette = [\n    0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 128, 0, 0, 0, 128, 128, 0, 128, 0, 128,\n    128, 128, 128, 128, 64, 0, 0, 191, 0, 0, 64, 128, 0, 191, 128, 0, 64, 0,\n    128, 191, 0, 128, 64, 128, 128, 191, 128, 128, 0, 64, 0, 128, 64, 0, 0, 191,\n    0, 128, 191, 0, 0, 64, 128, 128, 64, 128, 22, 22, 22, 23, 23, 23, 24, 24,\n    24, 25, 25, 25, 26, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30, 30,\n    31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36, 36, 37,\n    37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40, 41, 41, 41, 42, 42, 42, 43, 43,"
        },
        {
            "comment": "This code consists of a long sequence of integers with no apparent functionality or structure. It may represent an array, list, or range of values used in various parts of the codebase, but without further context, it is impossible to determine the specific purpose or usage for these numbers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":28-40",
            "content": "    43, 44, 44, 44, 45, 45, 45, 46, 46, 46, 47, 47, 47, 48, 48, 48, 49, 49, 49,\n    50, 50, 50, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54, 55, 55, 55, 56,\n    56, 56, 57, 57, 57, 58, 58, 58, 59, 59, 59, 60, 60, 60, 61, 61, 61, 62, 62,\n    62, 63, 63, 63, 64, 64, 64, 65, 65, 65, 66, 66, 66, 67, 67, 67, 68, 68, 68,\n    69, 69, 69, 70, 70, 70, 71, 71, 71, 72, 72, 72, 73, 73, 73, 74, 74, 74, 75,\n    75, 75, 76, 76, 76, 77, 77, 77, 78, 78, 78, 79, 79, 79, 80, 80, 80, 81, 81,\n    81, 82, 82, 82, 83, 83, 83, 84, 84, 84, 85, 85, 85, 86, 86, 86, 87, 87, 87,\n    88, 88, 88, 89, 89, 89, 90, 90, 90, 91, 91, 91, 92, 92, 92, 93, 93, 93, 94,\n    94, 94, 95, 95, 95, 96, 96, 96, 97, 97, 97, 98, 98, 98, 99, 99, 99, 100,\n    100, 100, 101, 101, 101, 102, 102, 102, 103, 103, 103, 104, 104, 104, 105,\n    105, 105, 106, 106, 106, 107, 107, 107, 108, 108, 108, 109, 109, 109, 110,\n    110, 110, 111, 111, 111, 112, 112, 112, 113, 113, 113, 114, 114, 114, 115,\n    115, 115, 116, 116, 116, 117, 117, 117, 118, 118, 118, 119, 119, 119, 120,"
        },
        {
            "comment": "This code likely contains a list of integer values, potentially representing coordinates or other numerical data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":41-53",
            "content": "    120, 120, 121, 121, 121, 122, 122, 122, 123, 123, 123, 124, 124, 124, 125,\n    125, 125, 126, 126, 126, 127, 127, 127, 128, 128, 128, 129, 129, 129, 130,\n    130, 130, 131, 131, 131, 132, 132, 132, 133, 133, 133, 134, 134, 134, 135,\n    135, 135, 136, 136, 136, 137, 137, 137, 138, 138, 138, 139, 139, 139, 140,\n    140, 140, 141, 141, 141, 142, 142, 142, 143, 143, 143, 144, 144, 144, 145,\n    145, 145, 146, 146, 146, 147, 147, 147, 148, 148, 148, 149, 149, 149, 150,\n    150, 150, 151, 151, 151, 152, 152, 152, 153, 153, 153, 154, 154, 154, 155,\n    155, 155, 156, 156, 156, 157, 157, 157, 158, 158, 158, 159, 159, 159, 160,\n    160, 160, 161, 161, 161, 162, 162, 162, 163, 163, 163, 164, 164, 164, 165,\n    165, 165, 166, 166, 166, 167, 167, 167, 168, 168, 168, 169, 169, 169, 170,\n    170, 170, 171, 171, 171, 172, 172, 172, 173, 173, 173, 174, 174, 174, 175,\n    175, 175, 176, 176, 176, 177, 177, 177, 178, 178, 178, 179, 179, 179, 180,\n    180, 180, 181, 181, 181, 182, 182, 182, 183, 183, 183, 184, 184, 184, 185,"
        },
        {
            "comment": "This code appears to be a list of integers. It is difficult to provide a brief comment as there seems to be no clear context or purpose for these numbers in this specific location.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":54-66",
            "content": "    185, 185, 186, 186, 186, 187, 187, 187, 188, 188, 188, 189, 189, 189, 190,\n    190, 190, 191, 191, 191, 192, 192, 192, 193, 193, 193, 194, 194, 194, 195,\n    195, 195, 196, 196, 196, 197, 197, 197, 198, 198, 198, 199, 199, 199, 200,\n    200, 200, 201, 201, 201, 202, 202, 202, 203, 203, 203, 204, 204, 204, 205,\n    205, 205, 206, 206, 206, 207, 207, 207, 208, 208, 208, 209, 209, 209, 210,\n    210, 210, 211, 211, 211, 212, 212, 212, 213, 213, 213, 214, 214, 214, 215,\n    215, 215, 216, 216, 216, 217, 217, 217, 218, 218, 218, 219, 219, 219, 220,\n    220, 220, 221, 221, 221, 222, 222, 222, 223, 223, 223, 224, 224, 224, 225,\n    225, 225, 226, 226, 226, 227, 227, 227, 228, 228, 228, 229, 229, 229, 230,\n    230, 230, 231, 231, 231, 232, 232, 232, 233, 233, 233, 234, 234, 234, 235,\n    235, 235, 236, 236, 236, 237, 237, 237, 238, 238, 238, 239, 239, 239, 240,\n    240, 240, 241, 241, 241, 242, 242, 242, 243, 243, 243, 244, 244, 244, 245,\n    245, 245, 246, 246, 246, 247, 247, 247, 248, 248, 248, 249, 249, 249, 250,"
        },
        {
            "comment": "This code defines a function called \"mask\\_damager\" which takes in labels and a probability of blacking out as input. It randomly scales the image using a scale range of (0.8, 1.0, 1.2), generates a random kernel size between 10 to 15, and applies random rotation to the image. If a random number is less than the given probability, it sets the final label as black; otherwise, it performs random rotations and scaling on the input labels.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":67-104",
            "content": "    250, 250, 251, 251, 251, 252, 252, 252, 253, 253, 253, 254, 254, 254, 255,\n    255, 255\n]\n# paddle.set_device('gpu') if paddle.is_compiled_with_cuda() else paddle.set_device('cpu')\nimport paddle\nimport PIL\nimport numbers\nimport numpy as np\nfrom PIL import Image\nfrom paddle.vision.transforms import BaseTransform\nfrom paddle.vision.transforms import functional as F\nimport numpy as np\nfrom scipy.ndimage import interpolation, binary_dilation\ntry:\n    from skimage import morphology, transform\nexcept ImportError as e:\n    print(\n        f\"{e}, [scikit-image] package and it's dependencies is required for EIVideo.\"\n    )\nimport paddle\nimport cv2\nimport random\n####\ndef mask_damager(labels=None, p_black=0.2):\n    scales = (0.8, 1.0, 1.2)\n    kernel_size = random.randint(10, 15)\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    if random.random() < p_black:\n        final_label = paddle.zeros_like(labels)\n        final_label = final_label.squeeze().numpy()\n    else:\n        prot = random.randint(5, 15)\n        nrot = random.randint(-15, -5)"
        },
        {
            "comment": "The code performs morphological operations on an image using OpenCV and then applies a rotation transformation to overlay the segmentation mask onto the RGB image. It uses different colors for different classes in the segmentation mask.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":105-145",
            "content": "        rots = [prot, nrot, 0]\n        rot = rots[random.randint(0, 2)]\n        sc = scales[random.randint(0, 2)]\n        _, _, h, w = labels.shape\n        tmp = labels.squeeze()\n        tmp = tmp.unsqueeze(-1)\n        tmp = tmp.numpy().astype(np.uint8)\n        morph_p = random.random()\n        if morph_p < 0.5:\n            tmp = cv2.morphologyEx(tmp, cv2.MORPH_OPEN, kernel)\n        else:\n            tmp = cv2.morphologyEx(tmp, cv2.MORPH_CLOSE, kernel)\n        tmp = tmp.astype(np.uint8)\n        center = (w / 2, h / 2)\n        M = cv2.getRotationMatrix2D(center, rot, sc)\n        final_label = cv2.warpAffine(tmp, M, (w, h), cv2.INTER_NEAREST)\n    return final_label\ncolor_map = [\n    [0, 0, 0],\n    [255, 127, 0],\n    [30, 144, 255],\n    [186, 85, 211],\n    [255, 105, 180],\n    [192, 255, 62],\n    [255, 105, 180],\n    [50, 255, 255],\n]\ncolor_map_np = np.array(color_map)\ndef overlay_davis(image, mask, alpha=0.5):\n    \"\"\" Overlay segmentation on top of RGB image. from davis official\"\"\"\n    im_overlay = image.copy()\n    mask = mask.astype('uint8')"
        },
        {
            "comment": "This function takes a list of masks and images, and for each pair, it applies an overlay function to generate an overlay image. It saves these overlay images in the specified directory with filenames corresponding to their original image names. Additionally, it stores the list of overlays as JSON in a file named \"masks.json\". The comments suggest that there might be another function to store masks as a list instead of overlays.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":146-171",
            "content": "    colored_mask = color_map_np[mask]\n    foreground = image * alpha + (1 - alpha) * colored_mask\n    binary_mask = (mask > 0)\n    # Compose image\n    im_overlay[binary_mask] = foreground[binary_mask]\n    countours = binary_dilation(binary_mask) ^ binary_mask\n    im_overlay[countours, :] = 0\n    return im_overlay.astype(image.dtype)\n# TODO\ndef submit_masks(masks, images, inter_file_path):\n    overlays = []\n    save_result_path = os.path.join(inter_file_path, 'result')\n    os.makedirs(save_result_path, exist_ok=True)\n    for imgname, (mask, image) in enumerate(zip(masks, images)):\n        overlay = overlay_davis(image, mask)\n        overlays.append(overlay.tolist())\n        overlay = Image.fromarray(overlay)\n        imgname = str(imgname)\n        while len(imgname) < 5:\n            imgname = '0' + imgname\n        overlay.save(os.path.join(save_result_path, imgname + '.png'))\n    result = {'overlays': overlays}\n    # result = {'masks': masks.tolist()}\n    with open(os.path.join(save_result_path, 'masks.json'), 'w') as f:"
        },
        {
            "comment": "load_video function reads frames from a video file and optionally resizes the frame to match a minimum side length, appending each frame to a list. The function then stacks the frames in the list into a single numpy array and returns it. get_scribbles generates scribble data for 8 labels by iterating through corresponding JSON files and yields the data along with a flag indicating if it is the first label or not. get_images retrieves video images from a specified sequence directory.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":172-205",
            "content": "        json.dump(result, f)\ndef load_video(path, min_side=None):\n    frame_list = []\n    cap = cv2.VideoCapture(path)\n    while (cap.isOpened()):\n        _, frame = cap.read()\n        if frame is None:\n            break\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        if min_side:\n            h, w = frame.shape[:2]\n            new_w = (w * min_side // min(w, h))\n            new_h = (h * min_side // min(w, h))\n            frame = cv2.resize(frame, (new_w, new_h),\n                               interpolation=cv2.INTER_CUBIC)\n            # .transpose([2, 0, 1])\n        frame_list.append(frame)\n    frames = np.stack(frame_list, axis=0)\n    return frames\ndef get_scribbles():\n    for i in range(8):\n        with open(f'/home/lc/paddlevideo/data/bike-packing/lable/{i + 1}.json'\n                  ) as f:\n            scribbles = json.load(f)\n            first_scribble = not i\n            yield scribbles, first_scribble\ndef get_images(sequence='bike-packing'):\n    img_path = os.path.join('/home/lc/paddlevideo/data', sequence.strip(),"
        },
        {
            "comment": "The code defines two functions: \"load_image\" and \"rough_ROI\". The \"load_image\" function loads an image from a specified directory, sorts the images by file name, reads each image using PIL library, and returns the images as a numpy array. The \"rough_ROI\" function receives scribble labels as input, determines the bounding box around each scribble in the batch, applies this bounding box to another mask, and returns the final scribble labels after filtering.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":206-235",
            "content": "                            'frame')\n    img_files = os.listdir(img_path)\n    img_files.sort()\n    files = []\n    for img in img_files:\n        img_file = np.array(Image.open(os.path.join(img_path, img)))\n        files.append(img_file)\n    return np.array(files)\ndef rough_ROI(ref_scribble_labels):\n    #### b*1*h*w\n    dist = 20\n    b, _, h, w = ref_scribble_labels.shape\n    filter_ = paddle.zeros_like(ref_scribble_labels)\n    to_fill = paddle.zeros_like(ref_scribble_labels)\n    for i in range(b):\n        no_background = (ref_scribble_labels[i] != -1)\n        no_background = no_background.squeeze(0)\n        no_b = no_background.nonzero()\n        (h_min, w_min) = paddle.min(no_b, 0)\n        (h_max, w_max) = paddle.max(no_b, 0)\n        filter_[i, 0,\n                max(h_min - dist, 0):min(h_max + dist, h - 1),\n                max(w_min - dist, 0):min(w_max + dist, w - 1)] = 1\n    final_scribble_labels = paddle.where(byte_(filter_), ref_scribble_labels,\n                                         to_fill)\n    return final_scribble_labels"
        },
        {
            "comment": "This code defines a function `load` that loads a pretrained model from a file. It checks if the file exists, then loads either the 'state_dict' or the entire dictionary depending on compatibility with the model keys. The function also filters out 'num_batches_tracked' and 'head.' before assigning the correct values to state_dicts. Finally, it writes both the modified state_dicts and model to separate text files.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":238-271",
            "content": "import os.path as osp\ndef load(file_name, model, **cfg):\n    if not osp.isfile(file_name):\n        raise IOError(f'{file_name} not exist')\n    try:\n        state_dicts_ = paddle.load(file_name)['state_dict']\n    except:\n        state_dicts_ = paddle.load(file_name)\n    state_dicts = {}\n    for k in model.keys():\n        if 'num_batches_tracked' not in k:\n            if ('head.' + k) not in state_dicts_.keys():\n                if k not in state_dicts_.keys():\n                    print(f'model -----{k} -------is not in pretrained')\n                else:\n                    state_dicts[k] = state_dicts_[k]\n            else:\n                state_dicts[k] = state_dicts_['head.' + k]\n    write_dict(state_dicts, 'state_dicts.txt', **cfg)\n    write_dict(model, 'model.txt', **cfg)\n    return state_dicts\n#####\ndef write_dict(state_dict, file_name, **cfg):\n    lines = []\n    tot = 0\n    for k, v in state_dict.items():\n        # \u76ee\u524d\u53ea\u53d1\u73b0\u4e86torch\u548cpaddle\u6a21\u578b\u53c2\u6570\u547d\u540d\u7684\u8fd9\u4e09\u79cd\u4e0d\u4e00\u81f4\n        # \u4e0d\u4e00\u81f41\n        if 'num_batches_tracked' in k:\n            tot += 1"
        },
        {
            "comment": "The code defines two functions: `damage_masks` and `damage_masks_np`. Both functions take in a labels array, and apply damage to the masks by applying shift, scale, and rotate transformations. The output is returned as a tensor after being transposed. The functions are designed for PaddlePaddle and NumPy respectively, and the input must be of shape (batch_size * 1 * h * w).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":272-303",
            "content": "            continue\n        try:\n            line = str(k) + '\\t' + str(v.cpu().detach().numpy().shape) + '\\n'\n        except:\n            line = str(k) + '\\t' + str(v.shape) + '\\n'\n        lines.append(line)\n    # with open(cfg.get(\"output_dir\", f\"./output/{file_name}\"), 'w') as f:\n    #     f.writelines(lines)\n    # print('%d num_batches_tracked skipped' % tot)\ndef damage_masks(labels, shift=True, scale=True, rotate=True):\n    \"\"\"\n    Args:\n    labels: numpy array (batch_size * 1 * h * w)\n    \"\"\"\n    bs, _, h, w = labels.shape\n    labels = labels.transpose([0, 2, 3, 1])\n    labels = labels.numpy()\n    final_label = []\n    for i in range(bs):\n        label = labels[i]\n        damaged_label = damage_masks_np(label, shift, scale, rotate)\n        final_label.append(damaged_label)\n    final_label = np.array(final_label)\n    final_label = paddle.to_tensor(final_label)\n    final_label = final_label.transpose([0, 3, 1, 2])\n    return final_label\ndef damage_masks_np(labels, shift=True, scale=True, rotate=True):\n    \"\"\"Performs the actual mask damaging in numpy."
        },
        {
            "comment": "This function damages the input labels by randomly shifting, scaling, rotating, and dilating the object masks. It first extracts unique labels, then shuffles them before iterating through each unique label to generate a damaged version of the labels. The `_damage_single_object_mask` function is used internally for performing mask damage on a single object.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":304-329",
            "content": "    Args:\n    labels: Int32 numpy array of shape (height, width, 1).\n    shift: Boolean, whether to damage the masks by shifting.\n    scale: Boolean, whether to damage the masks by scaling.\n    rotate: Boolean, whether to damage the masks by rotation.\n    dilate: Boolean, whether to damage the masks by dilation.\n    Returns:\n    The damaged version of labels.\n    \"\"\"\n    unique_labels = np.unique(labels)\n    unique_labels = np.setdiff1d(unique_labels, [0])\n    # Shuffle to get random depth ordering when combining together.\n    np.random.shuffle(unique_labels)\n    damaged_labels = np.zeros_like(labels)\n    for l in unique_labels:\n        obj_mask = (labels == l)\n        damaged_obj_mask = _damage_single_object_mask(obj_mask, shift, scale,\n                                                      rotate)\n        damaged_labels[damaged_obj_mask] = l\n    return damaged_labels\ndef _damage_single_object_mask(mask, shift, scale, rotate):\n    \"\"\"Performs mask damaging in numpy for a single object.\n    Args:\n    mask: Boolean numpy array of shape(height, width, 1)."
        },
        {
            "comment": "This code appears to be part of a function that damages a mask for a single object by randomly shifting it in numpy. The function takes a Boolean numpy array as input and returns the shifted version of the mask. It also includes parameters for scaling, rotation, and dilation, but these operations are not defined in this snippet.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":330-360",
            "content": "    shift: Boolean, whether to damage the masks by shifting.\n    scale: Boolean, whether to damage the masks by scaling.\n    rotate: Boolean, whether to damage the masks by rotation.\n    dilate: Boolean, whether to damage the masks by dilation.\n    Returns:\n    The damaged version of mask.\n    \"\"\"\n    if shift:\n        mask = _shift_mask(mask)\n    if scale:\n        mask = _scale_mask(mask)\n    if rotate:\n        mask = _rotate_mask(mask)\n    return mask\ndef _shift_mask(mask, max_shift_factor=0.05):\n    \"\"\"Damages a mask for a single object by randomly shifting it in numpy.\n    Args:\n    mask: Boolean numpy array of shape(height, width, 1).\n    max_shift_factor: Float scalar, the maximum factor for random shifting.\n    Returns:\n    The shifted version of mask.\n    \"\"\"\n    nzy, nzx, _ = mask.nonzero()\n    h = nzy.max() - nzy.min()\n    w = nzx.max() - nzx.min()\n    size = np.sqrt(h * w)\n    offset = np.random.uniform(-size * max_shift_factor,\n                               size * max_shift_factor, 2)\n    shifted_mask = interpolation.shift(np.squeeze(mask, axis=2),"
        },
        {
            "comment": "The code contains three functions: _shift_mask, _scale_mask, and _rotate_mask. These functions are used to randomly manipulate a binary mask by shifting, scaling, or rotating it for a single object. The purpose is to damage the mask to enhance the robustness of the AI system against different poses or scales of the object.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":361-387",
            "content": "                                       offset,\n                                       order=0).astype('bool')[..., np.newaxis]\n    return shifted_mask\ndef _scale_mask(mask, scale_amount=0.025):\n    \"\"\"Damages a mask for a single object by randomly scaling it in numpy.\n    Args:\n    mask: Boolean numpy array of shape(height, width, 1).\n    scale_amount: Float scalar, the maximum factor for random scaling.\n    Returns:\n    The scaled version of mask.\n    \"\"\"\n    nzy, nzx, _ = mask.nonzero()\n    cy = 0.5 * (nzy.max() - nzy.min())\n    cx = 0.5 * (nzx.max() - nzx.min())\n    scale_factor = np.random.uniform(1.0 - scale_amount, 1.0 + scale_amount)\n    shift = transform.SimilarityTransform(translation=[-cx, -cy])\n    inv_shift = transform.SimilarityTransform(translation=[cx, cy])\n    s = transform.SimilarityTransform(scale=[scale_factor, scale_factor])\n    m = (shift + (s + inv_shift)).inverse\n    scaled_mask = transform.warp(mask, m) > 0.5\n    return scaled_mask\ndef _rotate_mask(mask, max_rot_degrees=3.0):\n    \"\"\"Damages a mask for a single object by randomly rotating it in numpy."
        },
        {
            "comment": "This code defines a function that rotates and scales a binary mask. It first calculates the center coordinates of the mask, then generates a random rotation angle within a specified range, applies the transformation, and inverses it to get the final scaling transformation matrix. The result is a warped version of the mask where pixels above 0.5 are considered as true values. Additionally, there's an AverageMeter class that computes and stores average and current value for continuous metrics calculation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":388-421",
            "content": "    Args:\n    mask: Boolean numpy array of shape(height, width, 1).\n    max_rot_degrees: Float scalar, the maximum number of degrees to rotate.\n    Returns:\n    The scaled version of mask.\n    \"\"\"\n    cy = 0.5 * mask.shape[0]\n    cx = 0.5 * mask.shape[1]\n    rot_degrees = np.random.uniform(-max_rot_degrees, max_rot_degrees)\n    shift = transform.SimilarityTransform(translation=[-cx, -cy])\n    inv_shift = transform.SimilarityTransform(translation=[cx, cy])\n    r = transform.SimilarityTransform(rotation=np.deg2rad(rot_degrees))\n    m = (shift + (r + inv_shift)).inverse\n    scaled_mask = transform.warp(mask, m) > 0.5\n    return scaled_mask\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n"
        },
        {
            "comment": "Code utilities for PaddleVideo: converts label to colormap, converts PyTorch data types to Paddle, fills tensor with a value, sets tensor value to zero, and casts tensor to float32 dtype.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":422-465",
            "content": "        self.count += n\n        self.avg = self.sum / self.count\nimport numpy as np\ndef label2colormap(label):\n    m = label.astype(np.uint8)\n    r, c = m.shape\n    cmap = np.zeros((r, c, 3), dtype=np.uint8)\n    cmap[:, :, 0] = (m & 1) << 7 | (m & 8) << 3 | (m & 64) >> 1\n    cmap[:, :, 1] = (m & 2) << 6 | (m & 16) << 2 | (m & 128) >> 2\n    cmap[:, :, 2] = (m & 4) << 5 | (m & 32) << 1\n    return cmap\ndef torch2paddle(data):\n    try:\n        import torch\n        if isinstance(data, dict):\n            np_data = {}\n            for k, v in data.items():\n                np_data[k] = paddle.to_tensor(v.detach().numpy())\n            return np_data\n        else:\n            return paddle.to_tensor(data.detach().numpy())\n    except:\n        pass\ndef fill_(tensor: Tensor, value):\n    return tensor.set_value(paddle.full_like(tensor, value))\ndef zero_(tensor: Tensor):\n    return tensor.set_value(paddle.zeros_like(tensor))\ndef float_(tensor: Tensor):\n    return paddle.to_tensor(tensor, dtype='float32')\ndef long_(tensor: Tensor):"
        },
        {
            "comment": "The code provides three functions for converting tensors to different data types: int64, int32, and bool. The class ToPILImage is used to convert images from Tensor or np.ndarray format to PIL Image. It checks the type of input pic and throws a TypeError if it's not a Tensor or ndarray. If pic has 2 or 3 dimensions, it adds a channel dimension for 2D images. If the number of dimensions is not 2 or 3, it raises a ValueError.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":466-499",
            "content": "    return paddle.to_tensor(tensor, dtype='int64')\ndef int_(tensor: Tensor):\n    return paddle.to_tensor(tensor, dtype='int32')\ndef byte_(tensor: Tensor):\n    return paddle.to_tensor(tensor, dtype='bool')\nclass ToPILImage(BaseTransform):\n    def __init__(self, mode=None, keys=None):\n        super(ToPILImage, self).__init__(keys)\n    def _apply_image(self, pic):\n        \"\"\"\n        Args:\n            pic (Tensor|np.ndarray): Image to be converted to PIL Image.\n        Returns:\n            PIL: Converted image.\n        \"\"\"\n        if not (isinstance(pic, paddle.Tensor) or isinstance(pic, np.ndarray)):\n            raise TypeError('pic should be Tensor or ndarray. Got {}.'.format(\n                type(pic)))\n        elif isinstance(pic, paddle.Tensor):\n            if pic.ndimension() not in {2, 3}:\n                raise ValueError(\n                    'pic should be 2/3 dimensional. Got {} dimensions.'.format(\n                        pic.ndimension()))\n            elif pic.ndimension() == 2:\n                # if 2D image, add channel dimension (CHW)"
        },
        {
            "comment": "This code is checking the input \"pic\" and adjusting its format to be compatible with the function. It first checks if it's a tensor or ndarray, then ensures that the image is 2D or 3D (adding channels if necessary) before converting it into NumPy ndarray format. Finally, it checks the data type and mode to further adjust the \"pic\" as needed. If any issue arises during this process, it raises an error with a descriptive message.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":500-528",
            "content": "                pic = pic.unsqueeze(0)\n        elif isinstance(pic, np.ndarray):\n            if pic.ndim not in {2, 3}:\n                raise ValueError(\n                    'pic should be 2/3 dimensional. Got {} dimensions.'.format(\n                        pic.ndim))\n            elif pic.ndim == 2:\n                # if 2D image, add channel dimension (HWC)\n                pic = np.expand_dims(pic, 2)\n        npimg = pic\n        if isinstance(pic, paddle.Tensor) and \"float\" in str(\n                pic.numpy().dtype) and self.mode != 'F':\n            pic = pic.mul(255).byte()\n        if isinstance(pic, paddle.Tensor):\n            npimg = np.transpose(pic.numpy(), (1, 2, 0))\n        if not isinstance(npimg, np.ndarray):\n            raise TypeError(\n                'Input pic must be a paddle.Tensor or NumPy ndarray, ' +\n                'not {}'.format(type(npimg)))\n        if npimg.shape[2] == 1:\n            expected_mode = None\n            npimg = npimg[:, :, 0]\n            if npimg.dtype == np.uint8:\n                expected_mode = 'L'"
        },
        {
            "comment": "This code is validating the input image's data type and dimensions to determine the appropriate mode for the image. It raises a ValueError if the supplied self.mode does not match the expected mode based on the input type, or if the number of channels in the image does not match permitted modes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":529-552",
            "content": "            elif npimg.dtype == np.int16:\n                expected_mode = 'I;16'\n            elif npimg.dtype == np.int32:\n                expected_mode = 'I'\n            elif npimg.dtype == np.float32:\n                expected_mode = 'F'\n            if self.mode is not None and self.mode != expected_mode:\n                raise ValueError(\n                    \"Incorrect self.mode ({}) supplied for input type {}. Should be {}\"\n                    .format(self.mode, np.dtype, expected_mode))\n            self.mode = expected_mode\n        elif npimg.shape[2] == 2:\n            permitted_2_channel_modes = ['LA']\n            if self.mode is not None and self.mode not in permitted_2_channel_modes:\n                raise ValueError(\n                    \"Only self.modes {} are supported for 2D inputs\".format(\n                        permitted_2_channel_modes))\n            if self.mode is None and npimg.dtype == np.uint8:\n                self.mode = 'LA'\n        elif npimg.shape[2] == 4:\n            permitted_4_channel_modes = ['RGBA', 'CMYK', 'RGBX']"
        },
        {
            "comment": "The code snippet is part of a class function that checks the input image mode and data type to determine if it's compatible with the operation. If not, it raises an error or sets the mode accordingly. It also defines a placeholder identity operator class.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":553-577",
            "content": "            if self.mode is not None and self.mode not in permitted_4_channel_modes:\n                raise ValueError(\n                    \"Only self.modes {} are supported for 4D inputs\".format(\n                        permitted_4_channel_modes))\n            if self.mode is None and npimg.dtype == np.uint8:\n                self.mode = 'RGBA'\n        else:\n            permitted_3_channel_modes = ['RGB', 'YCbCr', 'HSV']\n            if self.mode is not None and self.mode not in permitted_3_channel_modes:\n                raise ValueError(\n                    \"Only self.modes {} are supported for 3D inputs\".format(\n                        permitted_3_channel_modes))\n            if self.mode is None and npimg.dtype == np.uint8:\n                self.mode = 'RGB'\n        if self.mode is None:\n            raise TypeError('Input type {} is not supported'.format(\n                npimg.dtype))\n        return Image.fromarray(npimg, mode=self.mode)\nclass Identity(nn.Layer):\n    r\"\"\"A placeholder identity operator that is argument-insensitive."
        },
        {
            "comment": "This code defines a class \"Identity\" with an empty forward function and a convert function that converts dictionary data between Paddle and Torch formats. If 'paddle' is given as the to parameter, it converts numpy arrays in the input dictionary to Paddle tensors. If 'torch' is given, it tries to import torch and converts numpy arrays or leaves unchanged non-numpy elements in the input dictionary to Torch tensors. Dtype can be used to specify a specific data type for tensor conversion.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":579-614",
            "content": "    Args:\n        args: any argument (unused)\n        kwargs: any keyword argument (unused)\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(Identity, self).__init__()\n    def forward(self, input):\n        return input\ndef convert(data: dict, to, dtype=None):\n    assert isinstance(data, dict)\n    input = {}\n    for k, v in data.items():\n        if 'paddle' == to:\n            if isinstance(v, np.ndarray):\n                if dtype is not None:\n                    input[k] = paddle.to_tensor(v.astype(dtype))\n                else:\n                    input[k] = paddle.to_tensor(v)\n            else:\n                input[k] = v\n        elif 'torch' == to:\n            try:\n                import torch\n                if isinstance(v, np.ndarray):\n                    if dtype is not None:\n                        input[k] = torch.tensor(v.astype(dtype))\n                    else:\n                        input[k] = torch.tensor(v)\n                else:\n                    input[k] = v\n            except:\n                pass"
        },
        {
            "comment": "This function clips the gradient norm of an iterable of parameters. The norm is computed over all gradients together, as if they were concatenated into a single vector. Gradients are modified in-place. It takes arguments such as iterable of Tensors or a single Tensor that will have gradients normalized, max_norm (float or int) to set the maximum norm of the gradients, norm_type (float or int) for the type of used p-norm, and error_if_nonfinite (bool) to indicate whether an error should be thrown if total norm is nan.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":615-639",
            "content": "        else:\n            if isinstance(v, np.ndarray):\n                input[k] = v.astype(to)\n            else:\n                input[k] = v\n    return input\ndef clip_grad_norm_(parameters: _tensor_or_tensors,\n                    max_norm: float,\n                    norm_type: float = 2.0,\n                    error_if_nonfinite: bool = False) -> paddle.Tensor:\n    r\"\"\"Clips gradient norm of an iterable of parameters.\n    The norm is computed over all gradients together, as if they were\n    concatenated into a single vector. Gradients are modified in-place.\n    Args:\n        parameters (Iterable[Tensor] or Tensor): an iterable of Tensors or a\n            single Tensor that will have gradients normalized\n        max_norm (float or int): max norm of the gradients\n        norm_type (float or int): type of the used p-norm. Can be ``'inf'`` for\n            infinity norm.\n        error_if_nonfinite (bool): if True, an error is thrown if the total\n            norm of the gradients from :attr:``parameters`` is ``nan``,"
        },
        {
            "comment": "This function calculates the total norm of parameters (viewed as a single vector) and handles cases where parameters are tensors. It first checks if the parameter is a tensor, then selects only those with non-null gradients, detaches their gradients, and applies different norm types based on the input. If the norm type is infinity, it calculates maximum absolute values for each parameter; otherwise, it calculates the p-norm using provided parameters and detached gradients.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":640-665",
            "content": "            ``inf``, or ``-inf``. Default: False (will switch to True in the future)\n    Returns:\n        Total norm of the parameters (viewed as a single vector).\n    \"\"\"\n    import time\n    if isinstance(parameters, paddle.Tensor):\n        parameters = [parameters]\n    parameters = [p for p in parameters if p.grad is not None]\n    detached_grads = [p.grad.detach() for p in parameters]\n    max_norm = float(max_norm)\n    norm_type = float(norm_type)\n    if len(parameters) == 0:\n        return paddle.to_tensor(0.)\n    # device = paddle.get_device()  # parameters[0].grad.device\n    if norm_type == inf:\n        norms = [p.abs().max() for p in parameters]\n        total_norm = norms[0] if len(norms) == 1 else paddle.max(\n            paddle.stack(norms))\n    else:\n        #         tik = time.time()\n        total_norm = paddle.norm(\n            paddle.stack([paddle.norm(g, norm_type) for g in detached_grads]),\n            norm_type)\n    #         total_norm = paddle.norm(paddle.stack([paddle.sqrt(paddle.sum(g*g)) for g in detached_grads]), norm_type)  # fixed."
        },
        {
            "comment": "This code checks if the total norm of gradients from `parameters` is non-finite. If it is, it raises a RuntimeError and suggests setting `error_if_nonfinite=False`. Then it calculates the clipping coefficient, performs a clip operation to ensure it's within the range (0, 1], and finally multiplies the gradients with this coefficient to scale them.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":666-681",
            "content": "    #         print(time.time() - tik)\n    if error_if_nonfinite and paddle.logical_or(total_norm.isnan(),\n                                                total_norm.isinf()):\n        raise RuntimeError(\n            f'The total norm of order {norm_type} for gradients from '\n            '`parameters` is non-finite, so it cannot be clipped. To disable '\n            'this error and scale the gradients by the non-finite norm anyway, '\n            'set `error_if_nonfinite=False`')\n    clip_coef = max_norm / (total_norm + 1e-6)\n    # Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so\n    # avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\n    # when the gradients do not reside in CPU memory.\n    clip_coef_clamped = paddle.clip(clip_coef, max=1.0)\n    for i, p in enumerate(parameters):\n        #         p.set_value(paddle.multiply(p, clip_coef_clamped))\n        p.grad.set_value(detached_grads[i] * clip_coef_clamped)  # fixed"
        },
        {
            "comment": "This code defines a function `max()` that finds the maximum values in a tensor and their corresponding indices. It also includes a `gather()` function that performs tensor gathering based on provided indices. The functions use PaddlePaddle library for Tensor operations.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":682-715",
            "content": "    #         p.grad.detach().mul_(clip_coef_clamped\n    return total_norm\n# def max(a: paddle.Tensor, axis=0, keepdim=True):\n#     \"\"\"ndarray=numpy.array([[1, 2, 3, 4],\n#            [4, 3, 2, 1],\n#            [5, 6, 7, 8],\n#            [8, 7, 6, 5]])\n#     np.where(ndarray == np.max(ndarray))\n#     (array([2, 3]), array([3, 0]))\n#     ndarray[np.where(ndarray == np.max(ndarray))]\n#     array([8, 8])\n#     \"\"\"\n#     max_ = a.max(axis).unsqueeze(-1)\n#     index = paddle.argmax(a, axis=axis, keepdim=keepdim)\n#     max_ = max_.numpy()\n#     index = index.numpy()\n#     # index = paddle.argmax(a, axis=axis, keepdim=keepdim)[-1].flatten()\n#     return max_, index\ndef gather(tmp: paddle.Tensor, ind: paddle.Tensor):\n    shape = tmp.shape\n    tmp = paddle.to_tensor(tmp)\n    ind = paddle.to_tensor(ind)\n    if len(shape) == 2:\n        b = shape[0]\n        return concat([\n            reshape(paddle.gather(tmp[i, :], ind[i, :]), [1, -1])\n            for i in range(b)\n        ],\n                      axis=0)\n    elif len(shape) == 3:"
        },
        {
            "comment": "This function performs sampling and reshaping operations on tensors with different shapes. It handles cases where the tensor shape has 0, 1, or 4 dimensions. In case of a 4-dimensional tensor, it uses gather and concat functions to rearrange data according to the given indices. The no_grad_* functions are used as wrappers for parts that require `torch.no_grad()` context manager due to JIT's inability to handle context managers directly.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":716-744",
            "content": "        out = []\n        for i in range(tmp.shape[0]):\n            _ = paddle.index_sample(tmp[i], ind[i])\n            out.append(_)\n        return paddle.to_tensor(out)\n    elif len(shape) == 4:\n        b, c, d = shape[:3]\n        return concat([\n            reshape(\n                concat([\n                    reshape(\n                        concat([\n                            reshape(\n                                paddle.gather(tmp[i, j, k, :], ind[i, j, k, :]),\n                                [1, -1]) for k in range(d)\n                        ],\n                               axis=0), [1, d, -1]) for j in range(c)\n                ],\n                       axis=0), [1, c, d, -1]) for i in range(b)\n        ],\n                      axis=0)\n    else:\n        pass\n# These no_grad_* functions are necessary as wrappers around the parts of these\n# functions that use `with torch.no_grad()`. The JIT doesn't support context\n# managers, so these need to be implemented as builtins. Using these wrappers\n# lets us keep those builtins small and re-usable."
        },
        {
            "comment": "This code defines three functions: `_no_grad_uniform_`, `_no_grad_normal_`, and `_no_grad_trunc_normal_`. These functions generate tensors with specific distributions while using gradient calculation, which helps in tensor initialization or randomization tasks. The first function generates uniformly distributed values within a defined range. The second function generates normally distributed values with specified mean and standard deviation. The third function generates truncated normal distribution values by combining uniform and normal distribution functions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":745-773",
            "content": "def _no_grad_uniform_(tensor, a, b):\n    with paddle.no_grad():\n        tensor.set_value(paddle.uniform(tensor.shape, min=a, max=b))\n        return tensor\ndef _no_grad_normal_(tensor, mean, std):\n    with paddle.no_grad():\n        tensor.set_value(paddle.normal(shape=tensor.shape, mean=mean, std=std))\n        return tensor\ndef _no_grad_trunc_normal_(tensor, mean, std, a, b):\n    from scipy import special\n    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n    def norm_cdf(x):\n        # Computes standard normal cumulative distribution function\n        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n    if (mean < a - 2 * std) or (mean > b + 2 * std):\n        warnings.warn(\n            \"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n            \"The distribution of values may be incorrect.\",\n            stacklevel=2)\n    with paddle.no_grad():\n        # Values are generated by using a truncated uniform distribution and\n        # then using the inverse CDF for the normal distribution."
        },
        {
            "comment": "This code snippet is used to generate random values within a specified range and then apply inverse cumulative distribution function (CDF) transforms to normalize the tensor. It uses PyTorch's `paddle` library for its operations. The result is then clamped between a minimum and maximum value, which are defined by the variables 'a' and 'b', respectively. This process ensures that the generated tensor falls within the desired range.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":774-805",
            "content": "        # Get upper and lower cdf values\n        l = norm_cdf((a - mean) / std)\n        u = norm_cdf((b - mean) / std)\n        # Uniformly fill tensor with values from [l, u], then translate to\n        # [2l-1, 2u-1].\n        tensor.set_value(\n            paddle.uniform(tensor.shape, min=2 * l - 1, max=2 * u - 1))\n        # tensor.uniform_(2 * l - 1, 2 * u - 1)\n        # Use inverse cdf transform for normal distribution to get truncated\n        # standard normal\n        # tensor.erfinv_()  # paddle \u65e0\n        tensor.set_value(special.erfinv(tensor))\n        # Transform to proper mean, std\n        # tensor.mul_(std * math.sqrt(2.))\n        tensor.set_value(tensor.multiply(paddle.to_tensor(std * math.sqrt(2.))))\n        tensor.add_(mean)\n        # Clamp to ensure it's in the proper range\n        tensor.clip_(min=a, max=b)\n        return tensor\ndef _no_grad_fill_(tensor, val):\n    with paddle.no_grad():\n        tensor.set_value(paddle.full_like(tensor, fill_value=val))\n        return tensor\ndef _no_grad_zero_(tensor):"
        },
        {
            "comment": "This function calculates the recommended gain value for a given nonlinearity function. The gain values depend on the function used, with different values assigned to functions like Linear/Identity (1), Sigmoid (1), Tanh (5/3), ReLU (sqrt(2)), Leaky Relu (sqrt((2/(1 + negative_slope^2))), SELU (3/4). The function takes nonlinearity and optional param as arguments, and returns the gain value.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":806-832",
            "content": "    with paddle.no_grad():\n        tensor.set_value(paddle.zeros_like(tensor))\n        return tensor\ndef calculate_gain(nonlinearity, param=None):\n    r\"\"\"Return the recommended gain value for the given nonlinearity function.\n    The values are as follows:\n    ================= ====================================================\n    nonlinearity      gain\n    ================= ====================================================\n    Linear / Identity :math:`1`\n    Conv{1,2,3}D      :math:`1`\n    Sigmoid           :math:`1`\n    Tanh              :math:`\\frac{5}{3}`\n    ReLU              :math:`\\sqrt{2}`\n    Leaky Relu        :math:`\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}`\n    SELU              :math:`\\frac{3}{4}`\n    ================= ====================================================\n    Args:\n        nonlinearity: the non-linear function (`nn.functional` name)\n        param: optional parameter for the non-linear function\n    Examples:\n        >>> gain = nn.init.calculate_gain('leaky_relu', 0.2)  # leaky_relu with negative_slope=0.2"
        },
        {
            "comment": "This code defines a function to map different nonlinearities (e.g., linear, sigmoid, tanh) to corresponding numerical values or exceptions when an unsupported nonlinearity is provided. It handles cases like linear, sigmoid, tanh, relu, leaky_relu, and selu, providing the appropriate values for each.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":833-858",
            "content": "    \"\"\"\n    linear_fns = [\n        'linear', 'conv1d', 'conv2d', 'conv3d', 'conv_transpose1d',\n        'conv_transpose2d', 'conv_transpose3d'\n    ]\n    if nonlinearity in linear_fns or nonlinearity == 'sigmoid':\n        return 1\n    elif nonlinearity == 'tanh':\n        return 5.0 / 3\n    elif nonlinearity == 'relu':\n        return math.sqrt(2.0)\n    elif nonlinearity == 'leaky_relu':\n        if param is None:\n            negative_slope = 0.01\n        elif not isinstance(param, bool) and isinstance(\n                param, int) or isinstance(param, float):\n            # True/False are instances of int, hence check above\n            negative_slope = param\n        else:\n            raise ValueError(\n                \"negative_slope {} not a valid number\".format(param))\n        return math.sqrt(2.0 / (1 + negative_slope**2))\n    elif nonlinearity == 'selu':\n        return 3.0 / 4  # Value found empirically (https://github.com/pytorch/pytorch/pull/50664)\n    else:\n        raise ValueError(\"Unsupported nonlinearity {}\".format(nonlinearity))"
        },
        {
            "comment": "These code snippets define functions to initialize a tensor with values drawn from a uniform or normal distribution. The `uniform_` function fills the input tensor with values from a uniform distribution, while `normal_` initializes it with values from a normal distribution. These functions can be used for various tasks such as initializing weights in a neural network.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":861-894",
            "content": "def uniform_(tensor: Tensor, a: float = 0., b: float = 1.) -> Tensor:\n    r\"\"\"Fills the input Tensor with values drawn from the uniform\n    distribution :math:`\\mathcal{U}(a, b)`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        a: the lower bound of the uniform distribution\n        b: the upper bound of the uniform distribution\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.uniform_(w)\n    \"\"\"\n    return _no_grad_uniform_(tensor, a, b)\ndef normal_(tensor: Tensor, mean: float = 0., std: float = 1.) -> Tensor:\n    r\"\"\"Fills the input Tensor with values drawn from the normal\n    distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        mean: the mean of the normal distribution\n        std: the standard deviation of the normal distribution\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.normal_(w)\n    \"\"\"\n    return _no_grad_normal_(tensor, mean, std)\ndef trunc_normal_(tensor: Tensor,\n                  mean: float = 0.,"
        },
        {
            "comment": "This code snippet defines a function `trunc_normal_` that fills the input Tensor with values drawn from a truncated normal distribution. The values are within the range [a, b] and the method works best when a <= mean <= b. Additionally, it includes a separate function `constant_` which fills the input Tensor with a constant value val.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":895-922",
            "content": "                  std: float = 1.,\n                  a: float = -2.,\n                  b: float = 2.) -> Tensor:\n    r\"\"\"Fills the input Tensor with values drawn from a truncated\n    normal distribution. The values are effectively drawn from the\n    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n    with values outside :math:`[a, b]` redrawn until they are within\n    the bounds. The method used for generating the random values works\n    best when :math:`a \\leq \\text{mean} \\leq b`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        mean: the mean of the normal distribution\n        std: the standard deviation of the normal distribution\n        a: the minimum cutoff value\n        b: the maximum cutoff value\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.trunc_normal_(w)\n    \"\"\"\n    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\ndef constant_(tensor: Tensor, val: float) -> Tensor:\n    r\"\"\"Fills the input Tensor with the value :math:`\\text{val}`.\n    Args:"
        },
        {
            "comment": "These methods fill a tensor with specific values or an identity matrix for Linear layers. The `constant_()`, `ones_()`, and `zeros_()` functions fill the input tensor with constant, ones, or zeros respectively. The `eye_()` function fills a 2-dimensional tensor with an identity matrix while preserving the identities of inputs in Linear layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":923-965",
            "content": "        tensor: an n-dimensional `torch.Tensor`\n        val: the value to fill the tensor with\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.constant_(w, 0.3)\n    \"\"\"\n    return _no_grad_fill_(tensor, val)\ndef ones_(tensor: Tensor) -> Tensor:\n    r\"\"\"Fills the input Tensor with the scalar value `1`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.ones_(w)\n    \"\"\"\n    return _no_grad_fill_(tensor, 1.)\ndef zeros_(tensor: Tensor) -> Tensor:\n    r\"\"\"Fills the input Tensor with the scalar value `0`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.zeros_(w)\n    \"\"\"\n    return _no_grad_zero_(tensor)\ndef eye_(tensor):\n    r\"\"\"Fills the 2-dimensional input `Tensor` with the identity\n    matrix. Preserves the identity of the inputs in `Linear` layers, where as\n    many inputs are preserved as possible.\n    Args:\n        tensor: a 2-dimensional `torch.Tensor`"
        },
        {
            "comment": "The provided code defines two functions, `eye_` and `dirac_`, that initialize a tensor with specific values. The `eye_` function fills the 2D tensor with an identity matrix, while the `dirac_` function fills a 3D, 4D or 5D tensor with Dirac delta functions. It also takes an optional argument for groups in case of Convolutional layers. Both functions require the input tensor to have specific dimensions and raise a ValueError if not satisfied.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":967-997",
            "content": "    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.eye_(w)\n    \"\"\"\n    if tensor.ndimension() != 2:\n        raise ValueError(\"Only tensors with 2 dimensions are supported\")\n    with paddle.no_grad():\n        tensor.set_value(paddle.eye(*tensor.shape))\n    return tensor\ndef dirac_(tensor, groups=1):\n    r\"\"\"Fills the {3, 4, 5}-dimensional input `Tensor` with the Dirac\n    delta function. Preserves the identity of the inputs in `Convolutional`\n    layers, where as many input channels are preserved as possible. In case\n    of groups>1, each group of channels preserves identity\n    Args:\n        tensor: a {3, 4, 5}-dimensional `torch.Tensor`\n        groups (optional): number of groups in the conv layer (default: 1)\n    Examples:\n        >>> w = torch.empty(3, 16, 5, 5)\n        >>> nn.init.dirac_(w)\n        >>> w = torch.empty(3, 24, 5, 5)\n        >>> nn.init.dirac_(w, 3)\n    \"\"\"\n    dimensions = tensor.ndimension()\n    if dimensions not in [3, 4, 5]:\n        raise ValueError(\n            \"Only tensors with 3, 4, or 5 dimensions are supported\")"
        },
        {
            "comment": "This function initializes a tensor with ones in specific positions based on the provided dimensions (3 for temporal convolution, 4 for spatial convolution, and 5 for volumetric convolution). It checks if dim 0 is divisible by groups and raises an error if not. Then it calculates out_chans_per_grp and min_dim, and finally initializes the tensor using no_grad context manager.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":999-1027",
            "content": "    sizes = tensor.shape\n    if sizes[0] % groups != 0:\n        raise ValueError('dim 0 must be divisible by groups')\n    out_chans_per_grp = sizes[0] // groups\n    min_dim = min(out_chans_per_grp, sizes[1])\n    with paddle.no_grad():\n        tensor.zero_()\n        for g in range(groups):\n            for d in range(min_dim):\n                if dimensions == 3:  # Temporal convolution\n                    tensor[g * out_chans_per_grp + d, d,\n                           tensor.shape[2] // 2] = 1\n                elif dimensions == 4:  # Spatial convolution\n                    tensor[g * out_chans_per_grp + d, d, tensor.shape[2] // 2,\n                           tensor.shape[3] // 2] = 1\n                else:  # Volumetric convolution\n                    tensor[g * out_chans_per_grp + d, d, tensor.shape[2] // 2,\n                           tensor.shape[3] // 2, tensor.shape[4] // 2] = 1\n    return tensor\ndef _calculate_fan_in_and_fan_out(tensor):\n    dimensions = tensor.dim()\n    if dimensions < 2:\n        raise ValueError("
        },
        {
            "comment": "Function to calculate fan_in and fan_out for tensor with dimensions greater than 2, compute the gain factor for Xavier uniform initialization, fill the input Tensor with values from a uniform distribution according to Glorot & Bengio (2010) method.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1028-1059",
            "content": "            \"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\"\n        )\n    num_input_fmaps = tensor.shape[1]  # .size(1)\n    num_output_fmaps = tensor.shape[0]  # .size(0)\n    receptive_field_size = 1\n    if tensor.dim() > 2:\n        for s in tensor.shape[2:]:\n            receptive_field_size *= s  # fixed\n    fan_in = num_input_fmaps * receptive_field_size\n    fan_out = num_output_fmaps * receptive_field_size\n    return fan_in, fan_out\ndef LongTensor(x):\n    return paddle.to_tensor(x, dtype='int64')\ndef IntTensor(x):\n    return paddle.to_tensor(x, dtype='int32')\ndef xavier_uniform_(tensor: Tensor, gain: float = 1.) -> Tensor:\n    r\"\"\"Fills the input `Tensor` with values according to the method\n    described in `Understanding the difficulty of training deep feedforward\n    neural networks` - Glorot, X. & Bengio, Y. (2010), using a uniform\n    distribution. The resulting tensor will have values sampled from\n    :math:`\\mathcal{U}(-a, a)` where\n    .. math::\n        a = \\text{gain} \\times \\sqrt{\\frac{6}{\\text{fan\\_in} + \\text{fan\\_out}}}"
        },
        {
            "comment": "This code snippet is for initializing a Tensor with values from a normal distribution, using the Xavier/Glorot initialization method. It calculates the standard deviation based on the fan-in and fan-out of the tensor and applies it to uniformly fill the tensor within specified bounds.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1061-1088",
            "content": "    Also known as Glorot initialization.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        gain: an optional scaling factor\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))\n    \"\"\"\n    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))\n    a = math.sqrt(3.0) * std  # Calculate uniform bounds from standard deviation\n    return _no_grad_uniform_(tensor, -a, a)\ndef xavier_normal_(tensor: Tensor, gain: float = 1.) -> Tensor:\n    r\"\"\"Fills the input `Tensor` with values according to the method\n    described in `Understanding the difficulty of training deep feedforward\n    neural networks` - Glorot, X. & Bengio, Y. (2010), using a normal\n    distribution. The resulting tensor will have values sampled from\n    :math:`\\mathcal{N}(0, \\text{std}^2)` where\n    .. math::\n        \\text{std} = \\text{gain} \\times \\sqrt{\\frac{2}{\\text{fan\\_in} + \\text{fan\\_out}}}\n    Also known as Glorot initialization."
        },
        {
            "comment": "This code snippet is from the PyTorch library and provides functions for initializing tensors with Xavier normal distribution. It includes the `kaiming_uniform_` function that takes a tensor, gain factor, and optional parameters for fan-in/fan-out calculation or nonlinearity. The `_calculate_fan_in_and_fan_out` and `_calculate_correct_fan` functions help calculate the appropriate fan values based on input arguments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1090-1119",
            "content": "    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        gain: an optional scaling factor\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.xavier_normal_(w)\n    \"\"\"\n    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))\n    return _no_grad_normal_(tensor, 0., std)\ndef _calculate_correct_fan(tensor, mode):\n    mode = mode.lower()\n    valid_modes = ['fan_in', 'fan_out']\n    if mode not in valid_modes:\n        raise ValueError(\"Mode {} not supported, please use one of {}\".format(\n            mode, valid_modes))\n    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n    return fan_in if mode == 'fan_in' else fan_out\ndef kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu'):\n    r\"\"\"Fills the input `Tensor` with values according to the method\n    described in `Delving deep into rectifiers: Surpassing human-level\n    performance on ImageNet classification` - He, K. et al. (2015), using a\n    uniform distribution. The resulting tensor will have values sampled from"
        },
        {
            "comment": "This function initializes a tensor with Kaiming uniform initialization, setting the standard deviation of the normal distribution to be equal to gain multiplied by the square root of 3 divided by fan mode. It's used for He initialization and applies nonlinearity based on the specified parameter.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1120-1144",
            "content": "    :math:`\\mathcal{U}(-\\text{bound}, \\text{bound})` where\n    .. math::\n        \\text{bound} = \\text{gain} \\times \\sqrt{\\frac{3}{\\text{fan\\_mode}}}\n    Also known as He initialization.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        a: the negative slope of the rectifier used after this layer (only\n            used with ``'leaky_relu'``)\n        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\n            preserves the magnitude of the variance of the weights in the\n            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\n            backwards pass.\n        nonlinearity: the non-linear function (`nn.functional` name),\n            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n    \"\"\"\n    fan = _calculate_correct_fan(tensor, mode)\n    gain = calculate_gain(nonlinearity, a)\n    std = gain / math.sqrt(fan)"
        },
        {
            "comment": "This code initializes a tensor using the Kaiming normal method. It fills the input tensor with values sampled from a normal distribution, where std is calculated based on gain and fan_mode (fan_in by default). This initialization method is often used in neural networks to improve performance.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1145-1169",
            "content": "    bound = math.sqrt(\n        3.0) * std  # Calculate uniform bounds from standard deviation\n    with paddle.no_grad():\n        tensor.set_value(paddle.uniform(tensor.shape, min=-bound, max=bound))\n        return tensor\ndef kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu'):\n    r\"\"\"Fills the input `Tensor` with values according to the method\n    described in `Delving deep into rectifiers: Surpassing human-level\n    performance on ImageNet classification` - He, K. et al. (2015), using a\n    normal distribution. The resulting tensor will have values sampled from\n    :math:`\\mathcal{N}(0, \\text{std}^2)` where\n    .. math::\n        \\text{std} = \\frac{\\text{gain}}{\\sqrt{\\text{fan\\_mode}}}\n    Also known as He initialization.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        a: the negative slope of the rectifier used after this layer (only\n            used with ``'leaky_relu'``)\n        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\n            preserves the magnitude of the variance of the weights in the"
        },
        {
            "comment": "These functions fill a tensor with either a (semi) orthogonal matrix or initialize weights using Kaiming normal distribution. The 'fan_out' and 'nonlinearity' parameters are used for the initialization process. These functions are inspired by research papers, one focusing on orthogonal matrices in deep linear neural networks and another on Kaiming normal distribution for weight initialization.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1170-1195",
            "content": "            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\n            backwards pass.\n        nonlinearity: the non-linear function (`nn.functional` name),\n            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> kaiming_normal_(w, mode='fan_out', nonlinearity='relu')\n    \"\"\"\n    fan = _calculate_correct_fan(tensor, mode)\n    gain = calculate_gain(nonlinearity, a)\n    std = gain / math.sqrt(fan)\n    with paddle.no_grad():\n        tensor.set_value(paddle.normal(shape=tensor.shape, mean=0, std=std))\n        return tensor\ndef orthogonal_(tensor, gain=1):\n    r\"\"\"Fills the input `Tensor` with a (semi) orthogonal matrix, as\n    described in `Exact solutions to the nonlinear dynamics of learning in deep\n    linear neural networks` - Saxe, A. et al. (2013). The input tensor must have\n    at least 2 dimensions, and for tensors with more than 2 dimensions the\n    trailing dimensions are flattened.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`, where :math:`n \\geq 2`"
        },
        {
            "comment": "This function initializes a 2D tensor with values drawn from the standard normal distribution, ensuring that at least a certain sparsity level is maintained. It uses QR factorization and scales the result by a given gain factor if specified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1196-1232",
            "content": "        gain: optional scaling factor\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.orthogonal_(w)\n    \"\"\"\n    if tensor.ndimension() < 2:\n        raise ValueError(\"Only tensors with 2 or more dimensions are supported\")\n    rows = tensor.shape[0]  # .size(0)\n    cols = tensor.numel() // rows\n    flattened = tensor.new(rows, cols).normal_(0, 1)\n    if rows < cols:\n        flattened.t_()\n    # Compute the qr factorization\n    q, r = paddle.to_tensor(np.linalg.qr(flattened.numpy()))\n    # q, r = torch.qr(flattened)\n    # Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\n    d = paddle.diag(r, 0)\n    ph = d.sign()\n    q *= ph\n    if rows < cols:\n        q.t_()\n    with paddle.no_grad():\n        tensor.view_as(q).copy_(q)\n        tensor.mul_(gain)\n    return tensor\ndef sparse_(tensor, sparsity, std=0.01):\n    r\"\"\"Fills the 2D input `Tensor` as a sparse matrix, where the\n    non-zero elements will be drawn from the normal distribution\n    :math:`\\mathcal{N}(0, 0.01)`, as described in `Deep learning via"
        },
        {
            "comment": "This code initializes a 2D torch.Tensor with a specified sparsity and standard deviation by setting some elements to zero while keeping others non-zero. It checks for tensor dimensions, normalizes values, assigns zeroes based on the input sparsity, and is compatible with both PyTorch and PaddlePaddle.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1233-1267",
            "content": "    Hessian-free optimization` - Martens, J. (2010).\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        sparsity: The fraction of elements in each column to be set to zero\n        std: the standard deviation of the normal distribution used to generate\n            the non-zero values\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.sparse_(w, sparsity=0.1)\n    \"\"\"\n    if tensor.ndimension() != 2:\n        raise ValueError(\"Only tensors with 2 dimensions are supported\")\n    rows, cols = tensor.shape\n    num_zeros = int(math.ceil(sparsity * rows))\n    with paddle.no_grad():\n        tensor.normal_(0, std)\n        for col_idx in range(cols):\n            row_indices = paddle.randperm(rows)\n            zero_indices = row_indices[:num_zeros]\n            tensor[zero_indices, col_idx] = 0\n    return tensor\n# for backward compatibility\ndef _make_deprecate(meth):\n    new_name = meth.__name__\n    old_name = new_name[:-1]\n    def deprecated_init(*args, **kwargs):\n        warnings.warn(\n            \"nn.init.{} is now deprecated in favor of nn.init.{}.\".format("
        },
        {
            "comment": "This code defines several deprecated initialization methods and creates their corresponding non-deprecated alternatives. The _make_deprecate function wraps the old functions with a warning that they are deprecated in favor of new Torch.nn.init functions, redirecting users to the new functions for more information.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py\":1268-1294",
            "content": "                old_name, new_name),\n            stacklevel=2)\n        return meth(*args, **kwargs)\n    deprecated_init.__doc__ = r\"\"\"\n    {old_name}(...)\n    .. warning::\n        This method is now deprecated in favor of :func:`torch.nn.init.{new_name}`.\n    See :func:`~torch.nn.init.{new_name}` for details.\"\"\".format(\n        old_name=old_name, new_name=new_name)\n    deprecated_init.__name__ = old_name\n    return deprecated_init\n# uniform = _make_deprecate(uniform_)\n# normal = _make_deprecate(normal_)\n# constant = _make_deprecate(constant_)\n# eye = _make_deprecate(eye_)\n# dirac = _make_deprecate(dirac_)\n# xavier_uniform = _make_deprecate(xavier_uniform_)\n# xavier_normal = _make_deprecate(xavier_normal_)\n# kaiming_uniform = _make_deprecate(kaiming_uniform_)\n# kaiming_normal = _make_deprecate(kaiming_normal_)\n# orthogonal = _make_deprecate(orthogonal_)\n# sparse = _make_deprecate(sparse_)"
        }
    ]
}