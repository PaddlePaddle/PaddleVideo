{
    "summary": "The code imports necessary libraries, registers object detection backbones, performs vector transformations, defines network creation functions, computes depth prediction, initializes PaddleVideo backbone, includes Project3D layer, calculates SSIM loss, and creates a deep learning model for image processing with ResNet V1.5, DepthDecoder, and PoseDecoder classes. The pose estimation model supports diverse inputs, handles day/night scenarios, computes parameters, generates warped images, and selects data based on conditions.",
    "details": [
        {
            "comment": "This code imports necessary libraries, defines constants, and registers backbones in a PaddlePaddle's object detection model library. It also includes comments for licensing and copyright information as well as function definitions for weight initialization and calculating fan-in and fan-out of layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":0-29",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport math\nfrom collections import OrderedDict\nimport numpy as np\nimport paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as F\nfrom paddle.nn import BatchNorm2D, Conv2D\nfrom paddle.nn.initializer import Constant, Normal\nfrom paddle.vision.models import ResNet\nfrom ...utils import load_ckpt\nfrom ..registry import BACKBONES\nfrom ..weight_init import kaiming_normal_, _calculate_fan_in_and_fan_out\nzeros_ = Constant(value=0.)"
        },
        {
            "comment": "Code snippet defines three functions - \"disp_to_depth\" for converting network's sigmoid output into depth prediction, \"gram_matrix\" for computing the Gram matrix of feature maps and \"convt_bn_relu\" for creating a convolution layer with batch normalization and ReLU activation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":30-66",
            "content": "ones_ = Constant(value=1.)\nnormal_ = Normal(mean=0, std=1e-3)\ndef disp_to_depth(disp, min_depth, max_depth):\n    \"\"\"Convert network's sigmoid output into depth prediction\n    The formula for this conversion is given in the 'additional considerations'\n    section of the paper.\n    \"\"\"\n    min_disp = 1 / max_depth\n    max_disp = 1 / min_depth\n    scaled_disp = min_disp + (max_disp - min_disp) * disp\n    depth = 1 / scaled_disp\n    return scaled_disp, depth\ndef gram_matrix(y):\n    (b, ch, h, w) = y.shape\n    features = y.reshape([b, ch, w * h])\n    features_t = paddle.transpose(features, [0, 2, 1])\n    gram = features.bmm(features_t) / (ch * h * w)\n    return gram\ndef convt_bn_relu(in_channels,\n                  out_channels,\n                  kernel_size,\n                  stride=1,\n                  padding=0,\n                  output_padding=0,\n                  bn=True,\n                  relu=True):\n    bias = not bn\n    layers = []\n    layers.append(\n        nn.Conv2DTranspose(in_channels,\n                           out_channels,"
        },
        {
            "comment": "The code defines a function for creating a convolutional transpose layer, adding batch normalization and Leaky ReLU activation if specified. It also includes weight initialization for the created layers. The second function converts network's (axisangle, translation) output into a 4x4 matrix based on parameters and an optional invert flag.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":67-103",
            "content": "                           kernel_size,\n                           stride,\n                           padding,\n                           output_padding,\n                           bias_attr=bias))\n    if bn:\n        layers.append(nn.BatchNorm2D(out_channels))\n    if relu:\n        layers.append(nn.LeakyReLU(0.2))\n    layers = nn.Sequential(*layers)\n    # initialize the weights\n    for m in layers.sublayers(include_self=True):\n        if isinstance(m, nn.Conv2DTranspose):\n            normal_(m.weight)\n            if m.bias is not None:\n                zeros_(m.bias)\n        elif isinstance(m, nn.BatchNorm2D):\n            ones_(m.weight)\n            zeros_(m.bias)\n    return layers\ndef transformation_from_parameters(axisangle, translation, invert=False):\n    \"\"\"Convert the network's (axisangle, translation) output into a 4x4 matrix\n    \"\"\"\n    R = rot_from_axisangle(axisangle)\n    t = translation.clone()\n    if invert:\n        R = R.transpose([0, 2, 1])\n        t *= -1\n    T = get_translation_matrix(t)\n    if invert:"
        },
        {
            "comment": "get_translation_matrix: Converts translation vector to a 4x4 transformation matrix.\nrot_from_axisangle: Converts axis-angle rotation into a 4x4 transformation matrix.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":104-150",
            "content": "        M = paddle.matmul(R, T)\n    else:\n        M = paddle.matmul(T, R)\n    return M\ndef get_translation_matrix(translation_vector):\n    \"\"\"Convert a translation vector into a 4x4 transformation matrix\n    \"\"\"\n    t = translation_vector.reshape([-1, 3, 1])\n    gather_object = paddle.stack([\n        paddle.zeros([\n            translation_vector.shape[0],\n        ], paddle.float32),\n        paddle.ones([\n            translation_vector.shape[0],\n        ], paddle.float32),\n        paddle.squeeze(t[:, 0], axis=-1),\n        paddle.squeeze(t[:, 1], axis=-1),\n        paddle.squeeze(t[:, 2], axis=-1),\n    ])\n    gather_index = paddle.to_tensor([\n        [1],\n        [0],\n        [0],\n        [2],\n        [0],\n        [1],\n        [0],\n        [3],\n        [0],\n        [0],\n        [1],\n        [4],\n        [0],\n        [0],\n        [0],\n        [1],\n    ])\n    T = paddle.gather_nd(gather_object, gather_index)\n    T = T.reshape([4, 4, -1]).transpose((2, 0, 1))\n    return T\ndef rot_from_axisangle(vec):\n    \"\"\"Convert an axisangle rotation into a 4x4 transformation matrix"
        },
        {
            "comment": "This code performs rotation operations on a 3D vector 'vec'. It calculates the angle and axis of rotation, then applies trigonometry to compute rotation matrices. Finally, it gathers transformed vectors using stacked tensor operations.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":151-187",
            "content": "    (adapted from https://github.com/Wallacoloo/printipi)\n    Input 'vec' has to be Bx1x3\n    \"\"\"\n    angle = paddle.norm(vec, 2, 2, True)\n    axis = vec / (angle + 1e-7)\n    ca = paddle.cos(angle)\n    sa = paddle.sin(angle)\n    C = 1 - ca\n    x = axis[..., 0].unsqueeze(1)\n    y = axis[..., 1].unsqueeze(1)\n    z = axis[..., 2].unsqueeze(1)\n    xs = x * sa\n    ys = y * sa\n    zs = z * sa\n    xC = x * C\n    yC = y * C\n    zC = z * C\n    xyC = x * yC\n    yzC = y * zC\n    zxC = z * xC\n    gather_object = paddle.stack([\n        paddle.squeeze(x * xC + ca, axis=(-1, -2)),\n        paddle.squeeze(xyC - zs, axis=(-1, -2)),\n        paddle.squeeze(zxC + ys, axis=(-1, -2)),\n        paddle.squeeze(xyC + zs, axis=(-1, -2)),\n        paddle.squeeze(y * yC + ca, axis=(-1, -2)),\n        paddle.squeeze(yzC - xs, axis=(-1, -2)),\n        paddle.squeeze(zxC - ys, axis=(-1, -2)),\n        paddle.squeeze(yzC + xs, axis=(-1, -2)),\n        paddle.squeeze(z * zC + ca, axis=(-1, -2)),\n        paddle.ones([\n            vec.shape[0],\n        ], dtype=paddle.float32),"
        },
        {
            "comment": "Code defines three functions: \"get_rot\", \"upsample\", and \"get_smooth_loss\". get_rot performs a gather operation on a tensor, reshapes the result, then transposes it. upsample interpolates an input tensor by doubling its size. get_smooth_loss computes the smoothness loss for disparity images using gradients of disparities and color image edges.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":188-230",
            "content": "        paddle.zeros([\n            vec.shape[0],\n        ], dtype=paddle.float32)\n    ])\n    gather_index = paddle.to_tensor([\n        [0],\n        [1],\n        [2],\n        [10],\n        [3],\n        [4],\n        [5],\n        [10],\n        [6],\n        [7],\n        [8],\n        [10],\n        [10],\n        [10],\n        [10],\n        [9],\n    ])\n    rot = paddle.gather_nd(gather_object, gather_index)\n    rot = rot.reshape([4, 4, -1]).transpose((2, 0, 1))\n    return rot\ndef upsample(x):\n    \"\"\"Upsample input tensor by a factor of 2\n    \"\"\"\n    return F.interpolate(x, scale_factor=2, mode=\"nearest\")\ndef get_smooth_loss(disp, img):\n    \"\"\"Computes the smoothness loss for a disparity image\n    The color image is used for edge-aware smoothness\n    \"\"\"\n    grad_disp_x = paddle.abs(disp[:, :, :, :-1] - disp[:, :, :, 1:])\n    grad_disp_y = paddle.abs(disp[:, :, :-1, :] - disp[:, :, 1:, :])\n    grad_img_x = paddle.mean(paddle.abs(img[:, :, :, :-1] - img[:, :, :, 1:]),\n                             1,\n                             keepdim=True)"
        },
        {
            "comment": "This code defines functions for creating convolutional layers and a ResNet model with multiple input images. The functions include 3x3 and 1x1 convolutions, along with a function that constructs the ResNet model itself. The ResNet model can handle multiple input images by combining gradients from each image channel.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":231-263",
            "content": "    grad_img_y = paddle.mean(paddle.abs(img[:, :, :-1, :] - img[:, :, 1:, :]),\n                             1,\n                             keepdim=True)\n    grad_disp_x *= paddle.exp(-grad_img_x)\n    grad_disp_y *= paddle.exp(-grad_img_y)\n    return grad_disp_x.mean() + grad_disp_y.mean()\ndef conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2D(in_planes,\n                     out_planes,\n                     kernel_size=3,\n                     stride=stride,\n                     padding=dilation,\n                     groups=groups,\n                     bias_attr=False,\n                     dilation=dilation)\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2D(in_planes,\n                     out_planes,\n                     kernel_size=1,\n                     stride=stride,\n                     bias_attr=False)\ndef resnet_multiimage_input(num_layers, num_input_images=1):\n    \"\"\"Constructs a ResNet model."
        },
        {
            "comment": "This code defines a function that creates a ResNet model with multiple image inputs. The model takes in the number of resnet layers (18 or 50), whether to use pretrained weights, and the number of input frames to stack. It then creates blocks based on the layer type and number of layers provided, and initializes the model's weights. The ConvBlock class performs a convolution followed by ELU activation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":264-293",
            "content": "    Args:\n        num_layers (int): Number of resnet layers. Must be 18 or 50\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        num_input_images (int): Number of frames stacked as input\n    \"\"\"\n    assert num_layers in [18, 50], \"Can only run with 18 or 50 layer resnet\"\n    blocks = {18: [2, 2, 2, 2], 50: [3, 4, 6, 3]}[num_layers]\n    block_type = {18: BasicBlock, 50: Bottleneck}[num_layers]\n    model = ResNetMultiImageInput(block_type,\n                                  num_layers,\n                                  blocks,\n                                  num_input_images=num_input_images)\n    model.init_weights()\n    return model\nclass ConvBlock(nn.Layer):\n    \"\"\"Layer to perform a convolution followed by ELU\n    \"\"\"\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.conv = Conv3x3(in_channels, out_channels)\n        self.nonlin = nn.ELU()\n    def forward(self, x):\n        out = self.conv(x)\n        out = self.nonlin(out)"
        },
        {
            "comment": "Conv3x3 is a layer that pads and convolves the input.\nBackprojectDepth transforms a depth image into a point cloud.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":294-329",
            "content": "        return out\nclass Conv3x3(nn.Layer):\n    \"\"\"Layer to pad and convolve input\n    \"\"\"\n    def __init__(self, in_channels, out_channels, use_refl=True):\n        super(Conv3x3, self).__init__()\n        if use_refl:\n            self.pad = nn.Pad2D(1, mode='reflect')\n        else:\n            self.pad = nn.Pad2D(1)\n        self.conv = nn.Conv2D(int(in_channels), int(out_channels), 3)\n    def forward(self, x):\n        out = self.pad(x)\n        out = self.conv(out)\n        return out\nclass BackprojectDepth(nn.Layer):\n    \"\"\"Layer to transform a depth image into a point cloud\n    \"\"\"\n    def __init__(self, batch_size, height, width):\n        super(BackprojectDepth, self).__init__()\n        self.batch_size = batch_size\n        self.height = height\n        self.width = width\n        meshgrid = np.meshgrid(range(self.width),\n                               range(self.height),\n                               indexing='xy')\n        id_coords = np.stack(meshgrid, axis=0).astype(np.float32)\n        self.id_coords = self.create_parameter(shape=list(id_coords.shape),"
        },
        {
            "comment": "This code creates and initializes parameters for a backbone in PaddleVideo, specifically for the ID and pixel coordinates. It sets the gradients to stop, meaning they won't be updated during backpropagation. The code uses paddling operations like unsqueeze, stack, tile, and concat for parameter creation and manipulation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":330-354",
            "content": "                                               dtype=paddle.float32)\n        self.id_coords.set_value(id_coords)\n        self.add_parameter(\"id_coords\", self.id_coords)\n        self.id_coords.stop_gradient = True\n        self.ones = self.create_parameter(\n            shape=[self.batch_size, 1, self.height * self.width],\n            default_initializer=ones_)\n        self.add_parameter(\"ones\", self.ones)\n        self.ones.stop_gradient = True\n        pix_coords = paddle.unsqueeze(\n            paddle.stack([\n                self.id_coords[0].reshape([\n                    -1,\n                ]), self.id_coords[1].reshape([\n                    -1,\n                ])\n            ], 0), 0)\n        pix_coords = pix_coords.tile([batch_size, 1, 1])\n        pix_coords = paddle.concat([pix_coords, self.ones], 1)\n        self.pix_coords = self.create_parameter(shape=list(pix_coords.shape), )\n        self.pix_coords.set_value(pix_coords)\n        self.add_parameter(\"pix_coords\", self.pix_coords)\n        self.pix_coords.stop_gradient = True"
        },
        {
            "comment": "The code defines a Project3D layer that projects 3D points into a camera with intrinsics K and at position T. It includes the forward pass, initialization, and required parameters such as batch_size, height, and width. The forward function calculates camera projection points by multiplying the intrinsic matrix K with the translation matrix T, then projects the points to pixels coordinates.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":356-384",
            "content": "    def forward(self, depth, inv_K):\n        cam_points = paddle.matmul(inv_K[:, :3, :3], self.pix_coords)\n        cam_points = depth.reshape([self.batch_size, 1, -1]) * cam_points\n        cam_points = paddle.concat([cam_points, self.ones], 1)\n        return cam_points\nclass Project3D(nn.Layer):\n    \"\"\"Layer which projects 3D points into a camera with intrinsics K and at position T\n    \"\"\"\n    def __init__(self, batch_size, height, width, eps=1e-7):\n        super(Project3D, self).__init__()\n        self.batch_size = batch_size\n        self.height = height\n        self.width = width\n        self.eps = eps\n    def forward(self, points, K, T):\n        P = paddle.matmul(K, T)[:, :3, :]\n        cam_points = paddle.matmul(P, points)\n        pix_coords = cam_points[:, :2, :] / (cam_points[:, 2, :].unsqueeze(1) +\n                                             self.eps)\n        pix_coords = pix_coords.reshape(\n            [self.batch_size, 2, self.height, self.width])\n        pix_coords = pix_coords.transpose([0, 2, 3, 1])"
        },
        {
            "comment": "The code defines a function `pix_coords` that normalizes pixel coordinates and a class `SSIM` for computing the Structural Similarity Index (SSIM) loss between two images. It initializes variables for mean, variance pooling, and applies padding to input images before calculating SSIM loss using provided formulas.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":385-416",
            "content": "        pix_coords[..., 0] /= self.width - 1\n        pix_coords[..., 1] /= self.height - 1\n        pix_coords = (pix_coords - 0.5) * 2\n        return pix_coords\nclass SSIM(nn.Layer):\n    \"\"\"Layer to compute the SSIM loss between a pair of images\n    \"\"\"\n    def __init__(self):\n        super(SSIM, self).__init__()\n        self.mu_x_pool = nn.AvgPool2D(3, 1, exclusive=False)\n        self.mu_y_pool = nn.AvgPool2D(3, 1, exclusive=False)\n        self.sig_x_pool = nn.AvgPool2D(3, 1, exclusive=False)\n        self.sig_y_pool = nn.AvgPool2D(3, 1, exclusive=False)\n        self.sig_xy_pool = nn.AvgPool2D(3, 1, exclusive=False)\n        self.refl = nn.Pad2D(1, mode='reflect')\n        self.C1 = 0.01**2\n        self.C2 = 0.03**2\n    def forward(self, x, y):\n        x = self.refl(x)\n        y = self.refl(y)\n        mu_x = self.mu_x_pool(x)\n        mu_y = self.mu_y_pool(y)\n        sigma_x = self.sig_x_pool(x**2) - mu_x**2\n        sigma_y = self.sig_y_pool(y**2) - mu_y**2\n        sigma_xy = self.sig_xy_pool(x * y) - mu_x * mu_y"
        },
        {
            "comment": "The code defines a ResNet model with multiple input images. It includes a convolution layer, batch normalization, ReLU activation, and max pooling for initial processing. The class \"ResNetMultiImageInput\" inherits from the base \"ResNet\" class and can handle different numbers of input images.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":418-440",
            "content": "        SSIM_n = (2 * mu_x * mu_y + self.C1) * (2 * sigma_xy + self.C2)\n        SSIM_d = (mu_x**2 + mu_y**2 + self.C1) * (sigma_x + sigma_y + self.C2)\n        return paddle.clip((1 - SSIM_n / SSIM_d) / 2, 0, 1)\nclass ResNetMultiImageInput(ResNet):\n    \"\"\"Constructs a resnet model with varying number of input images.\n    Adapted from https://github.com/pypaddle/vision/blob/master/paddlevision/models/resnet.py\n    \"\"\"\n    def __init__(self, block, depth, layers, num_input_images=1):\n        super(ResNetMultiImageInput, self).__init__(block, depth)\n        self.inplanes = 64\n        self.conv1 = nn.Conv2D(num_input_images * 3,\n                               64,\n                               kernel_size=7,\n                               stride=2,\n                               padding=3,\n                               bias_attr=False)\n        self.bn1 = nn.BatchNorm2D(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])"
        },
        {
            "comment": "The code defines a model architecture with multiple layers, including ConvBNLayer. It initializes the weights of these layers using specific methods and constraints for convolutional and batch normalization layers. This is typically done to improve performance and stability in deep learning models.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":441-465",
            "content": "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n    def init_weights(self):\n        for layer in self.sublayers(include_self=True):\n            if isinstance(layer, nn.Conv2D):\n                kaiming_normal_(layer.weight,\n                                mode='fan_out',\n                                nonlinearity='relu')\n            elif isinstance(layer, nn.BatchNorm2D):\n                ones_(layer.weight)\n                zeros_(layer.bias)\nclass ConvBNLayer(nn.Layer):\n    \"\"\"Conv2D and BatchNorm2D layer.\n    Args:\n        in_channels (int): Number of channels for the input.\n        out_channels (int): Number of channels for the output.\n        kernel_size (int): Kernel size.\n        stride (int): Stride in the Conv2D layer. Default: 1.\n        groups (int): Groups in the Conv2D, Default: 1.\n        act (str): Indicate activation after BatchNorm2D layer."
        },
        {
            "comment": "The `ConvBNLayer` class is a custom layer that consists of a convolution operation and batch normalization. It initializes the Conv2D layer and BatchNorm2D layer with specified parameters, and applies them sequentially in the forward pass.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":466-496",
            "content": "        name (str): the name of an instance of ConvBNLayer.\n    Note: weight and bias initialization include initialize values\n    and name the restored parameters, values initialization\n    are explicit declared in the ```init_weights``` method.\n    \"\"\"\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 kernel_size,\n                 stride=1,\n                 groups=1,\n                 act=None,\n                 name=None):\n        super(ConvBNLayer, self).__init__()\n        self._conv = Conv2D(in_channels=in_channels,\n                            out_channels=out_channels,\n                            kernel_size=kernel_size,\n                            stride=stride,\n                            padding=(kernel_size - 1) // 2,\n                            groups=groups,\n                            bias_attr=False)\n        self._act = act\n        self._batch_norm = BatchNorm2D(out_channels)\n    def forward(self, inputs):\n        y = self._conv(inputs)\n        y = self._batch_norm(y)"
        },
        {
            "comment": "The code defines a class called `BasicBlock` which is an instance of the `nn.Layer` class, and initializes it with parameters such as `inplanes`, `planes`, `stride`, `downsample`, `groups`, `base_width`, `dilation`, and `norm_layer`. It also performs some checks to ensure that certain values match the block's requirements, and then initializes specific layers like `conv1`, `bn1`, and `relu` accordingly. The code also handles cases where `stride` is not equal to 1 by downsampling the input through both `self.conv1` and `self.downsample`.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":497-527",
            "content": "        if self._act:\n            y = getattr(paddle.nn.functional, self._act)(y)\n        return y\nclass BasicBlock(nn.Layer):\n    expansion = 1\n    def __init__(self,\n                 inplanes,\n                 planes,\n                 stride=1,\n                 downsample=None,\n                 groups=1,\n                 base_width=64,\n                 dilation=1,\n                 norm_layer=None):\n        super(BasicBlock, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2D\n        if groups != 1 or base_width != 64:\n            raise ValueError(\n                'BasicBlock only supports groups=1 and base_width=64')\n        if dilation > 1:\n            raise NotImplementedError(\n                \"Dilation > 1 not supported in BasicBlock\")\n        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = nn.ReLU()\n        self.conv2 = conv3x3(planes, planes)"
        },
        {
            "comment": "The code defines a Bottleneck layer with stride at the 3x3 convolution (self.conv2) for ResNet V1.5, improving accuracy according to sources like \"Deep residual learning for image recognition\" and \"NVIDIA: ResNet_50_v1_5_for_PyTorch\". The Bottleneck layer has an expansion of 4, and its class initializes inplanes, planes, and other parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":528-562",
            "content": "        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n    def forward(self, x):\n        identity = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample is not None:\n            identity = self.downsample(x)\n        out += identity\n        out = self.relu(out)\n        return out\nclass Bottleneck(nn.Layer):\n    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n    # This variant is also known as ResNet V1.5 and improves accuracy according to\n    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n    expansion = 4\n    def __init__(self,\n                 inplanes,\n                 planes,"
        },
        {
            "comment": "The code defines a Bottleneck class for a convolutional neural network. It has multiple layers of 1x1 and 3x3 convolutions, with batch normalization and ReLU activation functions. The class also supports downsampling and stride configuration options.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":563-596",
            "content": "                 stride=1,\n                 downsample=None,\n                 groups=1,\n                 base_width=64,\n                 dilation=1,\n                 norm_layer=None):\n        super(Bottleneck, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2D\n        width = int(planes * (base_width / 64.)) * groups\n        self.conv1 = conv1x1(inplanes, width)\n        self.bn1 = norm_layer(width)\n        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n        self.bn2 = norm_layer(width)\n        self.conv3 = conv1x1(width, planes * self.expansion)\n        self.bn3 = norm_layer(planes * self.expansion)\n        self.relu = nn.ReLU()\n        self.downsample = downsample\n        self.stride = stride\n    def forward(self, x):\n        identity = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n        out = self.bn3(out)"
        },
        {
            "comment": "The code defines a class called DepthDecoder. It takes in parameters such as number of channels, scales, output channel count, and use_skips. The class initializes various attributes like num_output_channels, use_skips, upsample_mode, and scale. It also creates an OrderedDict named 'convs' which stores ConvBlock instances based on the given parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":598-630",
            "content": "        if self.downsample is not None:\n            identity = self.downsample(x)\n        out += identity\n        out = self.relu(out)\n        return out\nclass DepthDecoder(nn.Layer):\n    def __init__(self,\n                 num_ch_enc,\n                 scales=range(4),\n                 num_output_channels=1,\n                 use_skips=True):\n        super(DepthDecoder, self).__init__()\n        self.num_output_channels = num_output_channels\n        self.use_skips = use_skips\n        self.upsample_mode = 'nearest'\n        self.scales = scales\n        self.num_ch_enc = num_ch_enc\n        self.num_ch_dec = np.array([16, 32, 64, 128, 256])\n        # decoder\n        self.convs = OrderedDict()\n        for i in range(4, -1, -1):\n            # upconv_0\n            num_ch_in = self.num_ch_enc[-1] if i == 4 else self.num_ch_dec[i +\n                                                                           1]\n            num_ch_out = self.num_ch_dec[i]\n            self.convs[(\"upconv\", i, 0)] = ConvBlock(num_ch_in, num_ch_out)"
        },
        {
            "comment": "Code defines a convolutional network architecture for image decoding. It uses ConvBlock layers and Conv3x3 layers in the decoder section. The input features are upsampled and combined with previous encoder outputs at each stage, and then passed through convolution layers. The results are stored in 'outputs' dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":632-659",
            "content": "            # upconv_1\n            num_ch_in = self.num_ch_dec[i]\n            if self.use_skips and i > 0:\n                num_ch_in += self.num_ch_enc[i - 1]\n            num_ch_out = self.num_ch_dec[i]\n            self.convs[(\"upconv\", i, 1)] = ConvBlock(num_ch_in, num_ch_out)\n        for s in self.scales:\n            self.convs[(\"dispconv\", s)] = Conv3x3(self.num_ch_dec[s],\n                                                  self.num_output_channels)\n        self.decoder = nn.LayerList(list(self.convs.values()))\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, input_features):\n        outputs = {}\n        # decoder\n        x = input_features[-1]\n        for i in range(4, -1, -1):\n            x = self.convs[(\"upconv\", i, 0)](x)\n            x = [upsample(x)]\n            if self.use_skips and i > 0:\n                x += [input_features[i - 1]]\n            x = paddle.concat(x, 1)\n            x = self.convs[(\"upconv\", i, 1)](x)\n            if i in self.scales:\n                outputs[(\"disp\", i)] = self.sigmoid(self.convs[(\"dispconv\","
        },
        {
            "comment": "The PoseDecoder class in this code is a neural network layer that uses convolutional layers to predict pose for a given number of frames. It takes in the number of input channels, the number of input features, and an optional parameter for the number of frames to predict. The layer contains three convolution layers with different parameters for each.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":660-685",
            "content": "                                                                i)](x))\n        return outputs\nclass PoseDecoder(nn.Layer):\n    def __init__(self,\n                 num_ch_enc,\n                 num_input_features,\n                 num_frames_to_predict_for=None,\n                 stride=1):\n        super(PoseDecoder, self).__init__()\n        self.num_ch_enc = num_ch_enc\n        self.num_input_features = num_input_features\n        if num_frames_to_predict_for is None:\n            num_frames_to_predict_for = num_input_features - 1\n        self.num_frames_to_predict_for = num_frames_to_predict_for\n        self.convs = OrderedDict()\n        self.convs[(\"squeeze\")] = nn.Conv2D(self.num_ch_enc[-1], 256, 1)\n        self.convs[(\"pose\", 0)] = nn.Conv2D(num_input_features * 256, 256, 3,\n                                            stride, 1)\n        self.convs[(\"pose\", 1)] = nn.Conv2D(256, 256, 3, stride, 1)\n        self.convs[(\"pose\", 2)] = nn.Conv2D(256, 6 * num_frames_to_predict_for,\n                                            1)"
        },
        {
            "comment": "The code defines a class \"Adds\" with a forward function that performs feature extraction and concatenation, followed by convolution and activation operations. The code also includes a class \"ResnetEncoder\" which is a Pypaddle implementation of a ResNet encoder.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":687-724",
            "content": "        self.relu = nn.ReLU()\n        self.net = nn.LayerList(list(self.convs.values()))\n    def forward(self, input_features):\n        last_features = [f[-1] for f in input_features]\n        cat_features = [\n            self.relu(self.convs[\"squeeze\"](f)) for f in last_features\n        ]\n        cat_features = paddle.concat(cat_features, 1)\n        out = cat_features\n        for i in range(3):\n            out = self.convs[(\"pose\", i)](out)\n            if i != 2:\n                out = self.relu(out)\n        out = out.mean(3).mean(2)\n        out = 0.01 * out.reshape([-1, self.num_frames_to_predict_for, 1, 6])\n        axisangle = out[..., :3]\n        translation = out[..., 3:]\n        return axisangle, translation\nclass ResnetEncoder(nn.Layer):\n    \"\"\"Pypaddle module for a resnet encoder\n    \"\"\"\n    def __init__(self, num_layers, pretrained=False, num_input_images=1):\n        super(ResnetEncoder, self).__init__()\n        self.num_ch_enc = np.array([64, 64, 128, 256, 512])\n        resnets = {\n            18: paddle.vision.models.resnet18,"
        },
        {
            "comment": "The code defines a function that creates a ResNet backbone model with specified layers and checks if the input has multiple images. It uses pretrained weights, adds a convolutional layer to the output of the ResNet, and scales certain channels based on the number of layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":725-752",
            "content": "            34: paddle.vision.models.resnet34,\n            50: paddle.vision.models.resnet50,\n            101: paddle.vision.models.resnet101,\n            152: paddle.vision.models.resnet152\n        }\n        if num_layers not in resnets:\n            raise ValueError(\n                \"{} is not a valid number of resnet layers\".format(num_layers))\n        if num_input_images > 1:\n            self.encoder = resnet_multiimage_input(num_layers, pretrained,\n                                                   num_input_images)\n        else:\n            self.encoder = resnets[num_layers](pretrained)\n        if num_layers > 34:\n            self.num_ch_enc[1:] *= 4\n        ######################################\n        # night public first conv\n        ######################################\n        self.conv1 = nn.Conv2D(3,\n                               64,\n                               kernel_size=7,\n                               stride=2,\n                               padding=3,\n                               bias_attr=False)"
        },
        {
            "comment": "This code initializes a network backbone with shared and private encoders for day and night, as well as a shared decoder. It uses BatchNorm2D, ReLU activation, Conv2D layers, and sets up convolutional blocks for the encoders and decoder.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":753-775",
            "content": "        self.bn1 = nn.BatchNorm2D(64)\n        self.relu = nn.ReLU()  # NOTE\n        self.conv_shared = nn.Conv2D(512, 64, kernel_size=1)\n        ##########################################\n        # private source encoder, day\n        ##########################################\n        self.encoder_day = resnets[num_layers](pretrained)\n        self.conv_diff_day = nn.Conv2D(\n            512, 64, kernel_size=1)  # no bn after conv, so bias=true\n        ##########################################\n        # private target encoder, night\n        ##########################################\n        self.encoder_night = resnets[num_layers](pretrained)\n        self.conv_diff_night = nn.Conv2D(512, 64, kernel_size=1)\n        ######################################\n        # shared decoder (small decoder), use a simple de-conv to upsample the features with no skip connection\n        ######################################\n        self.convt5 = convt_bn_relu(in_channels=512,\n                                    out_channels=256,"
        },
        {
            "comment": "This code defines a series of convolutional layers with batch normalization and ReLU activation functions. The layers have different numbers of input and output channels, as well as identical kernel sizes, strides, padding, and output padding values. These layers likely form part of a deep learning model for image processing or analysis tasks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":776-796",
            "content": "                                    kernel_size=3,\n                                    stride=2,\n                                    padding=1,\n                                    output_padding=1)\n        self.convt4 = convt_bn_relu(in_channels=256,\n                                    out_channels=128,\n                                    kernel_size=3,\n                                    stride=2,\n                                    padding=1,\n                                    output_padding=1)\n        self.convt3 = convt_bn_relu(in_channels=128,\n                                    out_channels=64,\n                                    kernel_size=3,\n                                    stride=2,\n                                    padding=1,\n                                    output_padding=1)\n        self.convt2 = convt_bn_relu(in_channels=64,\n                                    out_channels=64,\n                                    kernel_size=3,\n                                    stride=2,\n                                    padding=1,"
        },
        {
            "comment": "The code defines a class with an initializer for two ConvT blocks and a convolutional layer. The forward function is used for training, where it subtracts 0.45 and divides by 0.225 from the input image to normalize it, and if the 'is_night' parameter is 'day', it passes this normalized image through the day encoder blocks of the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":797-816",
            "content": "                                    output_padding=1)\n        self.convt1 = convt_bn_relu(in_channels=64,\n                                    out_channels=64,\n                                    kernel_size=3,\n                                    stride=2,\n                                    padding=1,\n                                    output_padding=1)\n        self.convtf = nn.Conv2D(64, 3, kernel_size=1, stride=1, padding=0)\n    def forward(self, input_image, is_night):\n        if self.training:\n            result = []\n            input_data = (input_image - 0.45) / 0.225\n            if is_night == 'day':\n                # source private encoder, day\n                private_feature = self.encoder_day.conv1(input_data)\n                private_feature = self.encoder_day.bn1(private_feature)\n                private_feature = self.encoder_day.relu(private_feature)\n                private_feature = self.encoder_day.maxpool(private_feature)\n                private_feature = self.encoder_day.layer1(private_feature)"
        },
        {
            "comment": "The code is processing the input data through a day or night specific encoder, applying convolutions, batch normalization, ReLU activation, and max pooling. It then appends the resulting private code and gram matrix to the 'result' list.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":817-833",
            "content": "                private_feature = self.encoder_day.layer2(private_feature)\n                private_feature = self.encoder_day.layer3(private_feature)\n                private_feature = self.encoder_day.layer4(private_feature)\n                private_code = self.conv_diff_day(private_feature)\n                private_gram = gram_matrix(private_feature)\n                result.append(private_code)\n                result.append(private_gram)\n            elif is_night == 'night':\n                # target private encoder, night\n                private_feature = self.encoder_night.conv1(input_data)\n                private_feature = self.encoder_night.bn1(private_feature)\n                private_feature = self.encoder_night.relu(private_feature)\n                private_feature = self.encoder_night.maxpool(private_feature)\n                private_feature = self.encoder_night.layer1(private_feature)\n                private_feature = self.encoder_night.layer2(private_feature)\n                private_feature = self.encoder_night.layer3(private_feature)"
        },
        {
            "comment": "This code defines a model with two branches: one for day and one for night. It extracts features from the input image, applies different layers depending on whether it's day or night, and appends them to a list of features. Finally, it calculates a shared code for training using the last feature extracted.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":834-860",
            "content": "                private_feature = self.encoder_night.layer4(private_feature)\n                private_code = self.conv_diff_night(private_feature)\n                private_gram = gram_matrix(private_feature)\n                result.append(private_code)\n                result.append(private_gram)\n        # shared encoder\n        self.features = []\n        x = (input_image - 0.45) / 0.225\n        if is_night == 'day':\n            x = self.encoder.conv1(x)\n            x = self.encoder.bn1(x)\n            self.features.append(self.encoder.relu(x))\n        else:\n            x = self.conv1(x)\n            x = self.bn1(x)\n            self.features.append(self.relu(x))\n        self.features.append(\n            self.encoder.layer1(self.encoder.maxpool(self.features[-1])))\n        self.features.append(self.encoder.layer2(self.features[-1]))\n        self.features.append(self.encoder.layer3(self.features[-1]))\n        self.features.append(self.encoder.layer4(self.features[-1]))\n        if self.training:\n            shared_code = self.conv_shared(self.features[-1])"
        },
        {
            "comment": "This code defines a ResnetEncoder_pose class, which is a Pypaddle module for a resnet encoder. It initializes the number of layers and whether pre-trained weights are used. The code then defines several convolutional layers (convt1 to convt5) for processing feature maps. If pretrained is set to True, the method returns the features. Otherwise, it appends the processed feature maps to a result list and returns the features and result.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":861-888",
            "content": "            shared_gram = gram_matrix(self.features[-1])\n            result.append(shared_code)  # use this to calculate loss of diff\n            result.append(shared_gram)\n            result.append(\n                self.features[-1])  # use this to calculate loss of similarity\n            union_code = private_feature + self.features[-1]\n            rec_code = self.convt5(union_code)\n            rec_code = self.convt4(rec_code)\n            rec_code = self.convt3(rec_code)\n            rec_code = self.convt2(rec_code)\n            rec_code = self.convt1(rec_code)\n            rec_code = self.convtf(rec_code)\n            result.append(rec_code)\n            return self.features, result\n        else:\n            return self.features\nclass ResnetEncoder_pose(nn.Layer):\n    \"\"\"Pypaddle module for a resnet encoder\n    \"\"\"\n    def __init__(self, num_layers, pretrained=False, num_input_images=1):\n        super(ResnetEncoder_pose, self).__init__()\n        self.num_ch_enc = np.array([64, 64, 128, 256, 512])\n        resnets = {"
        },
        {
            "comment": "This code defines a ResNet backbone model with different layers (18, 34, 50, 101, 152) and handles multi-image input cases. The encoder is initialized based on the specified number of layers, and adjusts the number of channels for layers larger than 34. The forward function extracts features from an input image through a series of ResNet layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":889-916",
            "content": "            18: paddle.vision.models.resnet18,\n            34: paddle.vision.models.resnet34,\n            50: paddle.vision.models.resnet50,\n            101: paddle.vision.models.resnet101,\n            152: paddle.vision.models.resnet152\n        }\n        if num_layers not in resnets:\n            raise ValueError(\n                \"{} is not a valid number of resnet layers\".format(num_layers))\n        if num_input_images > 1:\n            self.encoder = resnet_multiimage_input(num_layers, num_input_images)\n        else:\n            self.encoder = resnets[num_layers](pretrained)\n        if num_layers > 34:\n            self.num_ch_enc[1:] *= 4\n    def forward(self, input_image):\n        features = []\n        x = (input_image - 0.45) / 0.225\n        x = self.encoder.conv1(x)\n        x = self.encoder.bn1(x)\n        features.append(self.encoder.relu(x))\n        features.append(self.encoder.layer1(self.encoder.maxpool(features[-1])))\n        features.append(self.encoder.layer2(features[-1]))\n        features.append(self.encoder.layer3(features[-1]))"
        },
        {
            "comment": "This code defines the class `ADDS_DepthNet`, which is a depth estimation network, with parameters such as number of layers, frame IDs, input size, batch size, etc. It inherits from `nn.Layer` and has methods to encode poses and features. The class also registers itself at `BACKBONES`.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":917-948",
            "content": "        features.append(self.encoder.layer4(features[-1]))\n        return features\n@BACKBONES.register()\nclass ADDS_DepthNet(nn.Layer):\n    def __init__(self,\n                 num_layers=18,\n                 frame_ids=[0, -1, 1],\n                 height=256,\n                 width=512,\n                 batch_size=6,\n                 pose_model_input=\"pairs\",\n                 use_stereo=False,\n                 only_depth_encoder=False,\n                 pretrained=None,\n                 scales=[0, 1, 2, 3],\n                 min_depth=0.1,\n                 max_depth=100.0,\n                 pose_model_type='separate_resnet',\n                 v1_multiscale=False,\n                 predictive_mask=False,\n                 disable_automasking=False):\n        super(ADDS_DepthNet, self).__init__()\n        self.num_layers = num_layers\n        self.height = height\n        self.width = width\n        self.batch_size = batch_size\n        self.frame_ids = frame_ids\n        self.pose_model_input = pose_model_input\n        self.use_stereo = use_stereo"
        },
        {
            "comment": "The code initializes the model parameters and instances, including whether to only use the depth encoder (only_depth_encoder), if pre-trained weights are used (pretrained), and the scales for the depth decoding (scales). It also determines the number of input frames needed for both depth and pose prediction based on the provided inputs. The code creates instances of DepthDecoder, ResnetEncoder, and ResnetEncoder_pose depending on the model configuration.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":949-971",
            "content": "        self.only_depth_encoder = only_depth_encoder\n        self.pretrained = pretrained\n        self.scales = scales\n        self.pose_model_type = pose_model_type\n        self.predictive_mask = predictive_mask\n        self.disable_automasking = disable_automasking\n        self.v1_multiscale = v1_multiscale\n        self.min_depth = min_depth\n        self.max_depth = max_depth\n        self.num_input_frames = len(self.frame_ids)\n        self.num_pose_frames = 2 if self.pose_model_input == \"pairs\" else self.num_input_frames\n        assert self.frame_ids[0] == 0, \"frame_ids must start with 0\"\n        self.use_pose_net = not (self.use_stereo and self.frame_ids == [0])\n        self.encoder = ResnetEncoder(self.num_layers)\n        if not self.only_depth_encoder:\n            self.depth = DepthDecoder(self.encoder.num_ch_enc, self.scales)\n        if self.use_pose_net and not self.only_depth_encoder:\n            if self.pose_model_type == \"separate_resnet\":\n                self.pose_encoder = ResnetEncoder_pose("
        },
        {
            "comment": "The code initializes a backbone model by defining its layers and scales, then initializing the weights of convolutional layers using Kaiming normalization and uniform initialization for bias. This backbone model is designed for handling pose estimation tasks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":972-995",
            "content": "                    self.num_layers, num_input_images=self.num_pose_frames)\n                self.pose = PoseDecoder(self.pose_encoder.num_ch_enc,\n                                        num_input_features=1,\n                                        num_frames_to_predict_for=2)\n        self.backproject_depth = {}\n        self.project_3d = {}\n        for scale in self.scales:\n            h = self.height // (2**scale)\n            w = self.width // (2**scale)\n            self.backproject_depth[scale] = BackprojectDepth(\n                self.batch_size, h, w)\n            self.project_3d[scale] = Project3D(batch_size, h, w)\n    def init_weights(self):\n        \"\"\"First init model's weight\"\"\"\n        for m in self.sublayers(include_self=True):\n            if isinstance(m, nn.Conv2D):\n                kaiming_normal_(m.weight, a=math.sqrt(5))\n                if m.bias is not None:\n                    fan_in, _ = _calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / math.sqrt(fan_in)\n                    uniform_ = paddle.nn.initializer.Uniform(-bound, bound)"
        },
        {
            "comment": "This code defines a forward function for a backbone model. It applies the encoder to inputs and uses the depth module to extract features. If pose prediction is enabled, it adds poses to the output dictionary, generates images, and stores frame IDs and scales in the outputs dictionary. This function handles both day and night scenarios.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":996-1018",
            "content": "                    uniform_(m.bias)\n        \"\"\"Second, if provide pretrained ckpt, load it\"\"\"\n        if self.pretrained:  # load pretrained weights\n            load_ckpt(self, self.pretrained)\n    def forward(self, inputs, day_or_night='day'):\n        if self.training:\n            features, result = self.encoder(inputs[\"color_aug\", 0, 0], 'day')\n            features_night, result_night = self.encoder(\n                inputs[(\"color_n_aug\", 0, 0)], 'night')\n            outputs = self.depth(features)\n            outputs_night = self.depth(features_night)\n            if self.use_pose_net and not self.only_depth_encoder:\n                outputs.update(self.predict_poses(inputs, 'day'))\n                outputs_night.update(self.predict_poses(inputs, 'night'))\n                self.generate_images_pred(inputs, outputs, 'day')\n                self.generate_images_pred(inputs, outputs_night, 'night')\n            outputs['frame_ids'] = self.frame_ids\n            outputs['scales'] = self.scales\n            outputs['result'] = result"
        },
        {
            "comment": "This code handles both dictionary and non-dictionary inputs for a model. If the input is a dictionary, it selects the 'color' input and processes accordingly. It uses an encoder to extract features from the input, then passes those features through a depth function to get predictions. The predictions are converted to depth format, and the final outputs include pred_disp and gt (ground truth) for further processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":1019-1043",
            "content": "            outputs['result_night'] = result_night\n            outputs_night['frame_ids'] = self.frame_ids\n            outputs_night['scales'] = self.scales\n            outputs['outputs_night'] = outputs_night\n        else:\n            if isinstance(inputs, dict):\n                input_color = inputs[(\"color\", 0, 0)]\n                features = self.encoder(input_color, day_or_night[0])\n                outputs = self.depth(features)\n                pred_disp, _ = disp_to_depth(outputs[(\"disp\", 0)],\n                                             self.min_depth, self.max_depth)\n                pred_disp = pred_disp[:, 0].numpy()\n                outputs['pred_disp'] = np.squeeze(pred_disp)\n                outputs['gt'] = np.squeeze(inputs['depth_gt'].numpy())\n            else:\n                input_color = inputs\n                features = self.encoder(input_color, day_or_night)\n                outputs = self.depth(features)\n                pred_disp, _ = disp_to_depth(outputs[(\"disp\", 0)],\n                                             self.min_depth, self.max_depth)"
        },
        {
            "comment": "This code is defining a function to predict poses between input frames for monocular sequences. It takes inputs as parameters and checks if the number of pose frames is 2. If so, it applies different treatments based on whether it's night or day. For night, it uses color_n_aug; for day, it uses color_aug. Then, it iterates through the frame IDs, excluding 's', and prepares inputs accordingly. The pose model type is \"separate_resnet\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":1045-1073",
            "content": "                pred_disp = pred_disp[:, 0]\n                outputs = paddle.squeeze(pred_disp)\n        return outputs\n    def predict_poses(self, inputs, is_night):\n        \"\"\"Predict poses between input frames for monocular sequences.\n        \"\"\"\n        outputs = {}\n        if self.num_pose_frames == 2:\n            if is_night:\n                pose_feats = {\n                    f_i: inputs[\"color_n_aug\", f_i, 0]\n                    for f_i in self.frame_ids\n                }\n            else:\n                pose_feats = {\n                    f_i: inputs[\"color_aug\", f_i, 0]\n                    for f_i in self.frame_ids\n                }\n            for f_i in self.frame_ids[1:]:\n                if f_i != \"s\":\n                    if f_i < 0:\n                        pose_inputs = [pose_feats[f_i], pose_feats[0]]\n                    else:\n                        pose_inputs = [pose_feats[0], pose_feats[f_i]]\n                    if self.pose_model_type == \"separate_resnet\":\n                        pose_inputs = ["
        },
        {
            "comment": "This code segment defines a function that calculates pose, axisangle, translation, and camera transformation parameters for an image. It takes input from the \"pose_encoder\" function, combines them, and assigns the results to specific positions in the \"outputs\" dictionary. If the frame ID is negative, it inverts the calculated matrix. The code also initializes a nested loop over different scales and generates warped color images for a given batch of inputs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":1074-1095",
            "content": "                            self.pose_encoder(paddle.concat(pose_inputs,\n                                                            axis=1))\n                        ]\n                    axisangle, translation = self.pose(pose_inputs)\n                    outputs[(\"axisangle\", 0, f_i)] = axisangle\n                    outputs[(\"translation\", 0, f_i)] = translation\n                    # Invert the matrix if the frame id is negative\n                    outputs[(\"cam_T_cam\", 0,\n                             f_i)] = transformation_from_parameters(\n                                 axisangle[:, 0],\n                                 translation[:, 0],\n                                 invert=(f_i < 0))\n            return outputs\n    def generate_images_pred(self, inputs, outputs, is_night):\n        \"\"\"Generate the warped (reprojected) color images for a minibatch.\n        Generated images are saved into the `outputs` dictionary.\n        \"\"\"\n        _, _, height, width = inputs['color', 0, 0].shape\n        for scale in self.scales:"
        },
        {
            "comment": "The code interpolates the displacement output based on the scale, and if multiscale is not enabled, it performs bilinear interpolation to match the input size. It then converts the displacement into depth using disp_to_depth function. Depth and its corresponding scale are added to the outputs. For each frame ID in the list, it retrieves camera transformation matrix T, backprojects depth to 3D coordinates, projects them onto image plane using project_3d, and adds the resulting pixel coordinates to the outputs. If is_night is True, it modifies the color_n input's stop_gradient attribute.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":1096-1121",
            "content": "            disp = outputs[(\"disp\", scale)]\n            if self.v1_multiscale:\n                source_scale = scale\n            else:\n                disp = F.interpolate(disp, [height, width],\n                                     mode=\"bilinear\",\n                                     align_corners=False)\n                source_scale = 0\n            _, depth = disp_to_depth(disp, self.min_depth, self.max_depth)\n            outputs[(\"depth\", 0, scale)] = depth\n            for i, frame_id in enumerate(self.frame_ids[1:]):\n                T = outputs[(\"cam_T_cam\", 0, frame_id)]\n                cam_points = self.backproject_depth[source_scale](\n                    depth, inputs[(\"inv_K\", source_scale)])\n                pix_coords = self.project_3d[source_scale](\n                    cam_points, inputs[(\"K\", source_scale)], T)\n                outputs[(\"sample\", frame_id, scale)] = pix_coords\n                if is_night:\n                    inputs[(\"color_n\", frame_id,\n                            source_scale)].stop_gradient = False"
        },
        {
            "comment": "This code performs grid sampling on a tensor and assigns the result to a specific location in the outputs dictionary based on frame_id and scale. If disable_automasking is True, it also creates an identity mask for night scenes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":1122-1141",
            "content": "                    outputs[(\"color\", frame_id,\n                             scale)] = paddle.nn.functional.grid_sample(\n                                 inputs[(\"color_n\", frame_id, source_scale)],\n                                 outputs[(\"sample\", frame_id, scale)],\n                                 padding_mode=\"border\",\n                                 align_corners=False)\n                else:\n                    inputs[(\"color\", frame_id,\n                            source_scale)].stop_gradient = False\n                    outputs[(\"color\", frame_id,\n                             scale)] = paddle.nn.functional.grid_sample(\n                                 inputs[(\"color\", frame_id, source_scale)],\n                                 outputs[(\"sample\", frame_id, scale)],\n                                 padding_mode=\"border\",\n                                 align_corners=False)\n                if not self.disable_automasking:\n                    if is_night:\n                        outputs[(\"color_identity\", frame_id, scale)] = \\"
        },
        {
            "comment": "This code is selecting the input data from a dictionary based on specific conditions. If the frame_id and source_scale match, it assigns the value to \"color_n\". Otherwise, it assigns the value of \"color\" input to \"color_identity\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/adds.py\":1142-1145",
            "content": "                            inputs[(\"color_n\", frame_id, source_scale)]\n                    else:\n                        outputs[(\"color_identity\", frame_id, scale)] = \\\n                            inputs[(\"color\", frame_id, source_scale)]"
        }
    ]
}