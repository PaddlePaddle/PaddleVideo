{
    "summary": "The code introduces a \"Scale\" class for image scaling and a MultiScaleCrop pipeline in PaddleVideo. It supports random or multi-crop based on test mode, maintaining aspect ratio while resizing/cropping images. A slower pathway is created by selecting specific frames from the fast_pathway array, rearranging dimensions, and then combined with the original for a list of frames before adding to 'results' dictionary.",
    "details": [
        {
            "comment": "This code registers a new class \"Scale\" for image scaling in PaddleVideo's VideoQualityAssessment module. The Scale class takes a short_size parameter and scales the images accordingly. It is registered as part of the PIPELINES in the application.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":0-34",
            "content": "\"\"\"\n#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"\nimport random\nimport numpy as np\nimport math\nfrom PIL import Image\nfrom ..registry import PIPELINES\nfrom collections.abc import Sequence\n@PIPELINES.register()\nclass Scale(object):\n    \"\"\"\n    Scale images.\n    Args:\n        short_size(float | int): Short size of an image will be scaled to the short_size.\n    \"\"\"\n    def __init__(self, short_size):\n        self.short_size = short_size\n    def __call__(self, results):"
        },
        {
            "comment": "The code defines a function that resizes PIL.Image objects in a list according to their aspect ratios and the short_size provided. If an image's width is less than or equal to its height, it is appended to resized_imgs without any modification. Otherwise, if the width is greater than the height, the image is scaled to fit within a square with the given short_size, maintaining aspect ratio using bilinear interpolation. If the height is greater than the width, the image is also scaled to fit within a square with the given short_size, again maintaining aspect ratio using bilinear interpolation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":35-60",
            "content": "        \"\"\"\n        Performs resize operations.\n        Args:\n            imgs (Sequence[PIL.Image]): List where each item is a PIL.Image.\n            For example, [PIL.Image0, PIL.Image1, PIL.Image2, ...]\n        return:\n            resized_imgs: List where each item is a PIL.Image after scaling.\n        \"\"\"\n        imgs = results['imgs']\n        resized_imgs = []\n        for i in range(len(imgs)):\n            img = imgs[i]\n            w, h = img.size\n            if (w <= h and w == self.short_size) or (h <= w\n                                                     and h == self.short_size):\n                resized_imgs.append(img)\n                continue\n            if w < h:\n                ow = self.short_size\n                oh = int(self.short_size * 4.0 / 3.0)\n                resized_imgs.append(img.resize((ow, oh), Image.BILINEAR))\n            else:\n                oh = self.short_size\n                ow = int(self.short_size * 4.0 / 3.0)\n                resized_imgs.append(img.resize((ow, oh), Image.BILINEAR))"
        },
        {
            "comment": "The code registers a custom pipeline for random cropping of images in PaddleVideo. It takes a target size as an argument and initializes the class with that target size. The __call__ method is used to perform random crop operations on a list of images. It first retrieves the original image sizes, ensures they are larger than the target size, then randomly selects x1 and y1 coordinates for the crop region, and appends the cropped image to a new list which is returned at the end.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":61-94",
            "content": "        results['imgs'] = resized_imgs\n        return results\n@PIPELINES.register()\nclass RandomCrop(object):\n    \"\"\"\n    Random crop images.\n    Args:\n        target_size(int): Random crop a square with the target_size from an image.\n    \"\"\"\n    def __init__(self, target_size):\n        self.target_size = target_size\n    def __call__(self, results):\n        \"\"\"\n        Performs random crop operations.\n        Args:\n            imgs: List where each item is a PIL.Image.\n            For example, [PIL.Image0, PIL.Image1, PIL.Image2, ...]\n        return:\n            crop_imgs: List where each item is a PIL.Image after random crop.\n        \"\"\"\n        imgs = results['imgs']\n        w, h = imgs[0].size\n        th, tw = self.target_size, self.target_size\n        assert (w >= self.target_size) and (h >= self.target_size), \\\n            \"image width({}) and height({}) should be larger than crop size {}\".format(\n                w, h, self.target_size)\n        crop_images = []\n        x1 = random.randint(0, w - tw)\n        y1 = random.randint(0, h - th)"
        },
        {
            "comment": "This code performs center cropping of images to a specified target size. It iterates through the list of images, checks if they are already at the target size, and appends them to the crop_images list. If the image is not at the target size, it crops the image to the center square of the original image and adds it to the crop_images list. The final results dictionary contains the list of cropped images. The class CenterCrop initializes with a target_size parameter and defines a __call__ method for applying the center crop operation on input images.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":96-129",
            "content": "        for img in imgs:\n            if w == tw and h == th:\n                crop_images.append(img)\n            else:\n                crop_images.append(img.crop((x1, y1, x1 + tw, y1 + th)))\n        results['imgs'] = crop_images\n        return results\n@PIPELINES.register()\nclass CenterCrop(object):\n    \"\"\"\n    Center crop images.\n    Args:\n        target_size(int): Center crop a square with the target_size from an image.\n    \"\"\"\n    def __init__(self, target_size):\n        self.target_size = target_size\n    def __call__(self, results):\n        \"\"\"\n        Performs Center crop operations.\n        Args:\n            imgs: List where each item is a PIL.Image.\n            For example, [PIL.Image0, PIL.Image1, PIL.Image2, ...]\n        return:\n            ccrop_imgs: List where each item is a PIL.Image after Center crop.\n        \"\"\"\n        imgs = results['imgs']\n        ccrop_imgs = []\n        for img in imgs:\n            w, h = img.size\n            th, tw = self.target_size, self.target_size\n            assert (w >= self.target_size) and (h >= self.target_size), \\"
        },
        {
            "comment": "MultiScaleCrop applies image resizing and cropping to an input image. The target size, scales, max_distort, fix_crop, and more_fix_crop parameters are used for image manipulation. Images are cropped into smaller ones with varying sizes based on the defined scales.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":130-159",
            "content": "                \"image width({}) and height({}) should be larger than crop size {}\".format(\n                    w, h, self.target_size)\n            x1 = int(round((w - tw) / 2.))\n            y1 = int(round((h - th) / 2.))\n            ccrop_imgs.append(img.crop((x1, y1, x1 + tw, y1 + th)))\n        results['imgs'] = ccrop_imgs\n        return results\n@PIPELINES.register()\nclass MultiScaleCrop(object):\n    def __init__(\n            self,\n            target_size,  #NOTE: named target size now, but still pass short size in it!\n            scales=None,\n            max_distort=1,\n            fix_crop=True,\n            more_fix_crop=True):\n        self.target_size = target_size\n        self.scales = scales if scales else [1, .875, .75, .66]\n        self.max_distort = max_distort\n        self.fix_crop = fix_crop\n        self.more_fix_crop = more_fix_crop\n    def __call__(self, results):\n        \"\"\"\n        Performs MultiScaleCrop operations.\n        Args:\n            imgs: List where wach item is a PIL.Image.\n            XXX:"
        },
        {
            "comment": "This code defines a function to sample random crop sizes for image augmentation. It first calculates the possible crop sizes based on input size and scales, then filters pairs that have a difference within max_distort. Finally, it randomly chooses one of the filtered pairs for cropping and optionally adds a random offset if fix_crop is False.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":160-191",
            "content": "        results:\n        \"\"\"\n        imgs = results['imgs']\n        input_size = [self.target_size, self.target_size]\n        im_size = imgs[0].size\n        # get random crop offset\n        def _sample_crop_size(im_size):\n            image_w, image_h = im_size[0], im_size[1]\n            base_size = min(image_w, image_h)\n            crop_sizes = [int(base_size * x) for x in self.scales]\n            crop_h = [\n                input_size[1] if abs(x - input_size[1]) < 3 else x\n                for x in crop_sizes\n            ]\n            crop_w = [\n                input_size[0] if abs(x - input_size[0]) < 3 else x\n                for x in crop_sizes\n            ]\n            pairs = []\n            for i, h in enumerate(crop_h):\n                for j, w in enumerate(crop_w):\n                    if abs(i - j) <= self.max_distort:\n                        pairs.append((w, h))\n            crop_pair = random.choice(pairs)\n            if not self.fix_crop:\n                w_offset = random.randint(0, image_w - crop_pair[0])"
        },
        {
            "comment": "This code generates a list of crop positions for an image. If the image height is greater than the second value in the crop pair, it randomly selects a horizontal offset. Otherwise, it calculates step sizes for width and height, and creates a list of crop positions using these steps. Additional crop positions are added if self.more_fix_crop is True.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":192-214",
            "content": "                h_offset = random.randint(0, image_h - crop_pair[1])\n            else:\n                w_step = (image_w - crop_pair[0]) / 4\n                h_step = (image_h - crop_pair[1]) / 4\n                ret = list()\n                ret.append((0, 0))  # upper left\n                if w_step != 0:\n                    ret.append((4 * w_step, 0))  # upper right\n                if h_step != 0:\n                    ret.append((0, 4 * h_step))  # lower left\n                if h_step != 0 and w_step != 0:\n                    ret.append((4 * w_step, 4 * h_step))  # lower right\n                if h_step != 0 or w_step != 0:\n                    ret.append((2 * w_step, 2 * h_step))  # center\n                if self.more_fix_crop:\n                    ret.append((0, 2 * h_step))  # center left\n                    ret.append((4 * w_step, 2 * h_step))  # center right\n                    ret.append((2 * w_step, 4 * h_step))  # lower center\n                    ret.append((2 * w_step, 0 * h_step))  # upper center\n                    ret.append((1 * w_step, 1 * h_step))  # upper left quarter"
        },
        {
            "comment": "The code randomly samples crop sizes from a set of predefined ratios, crops the input images accordingly, resizes them to the desired input size, and adds the flipped or cropped images to the results dictionary. It also includes an optional RandomFlip pipeline that randomly flips the image with a given probability.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":215-246",
            "content": "                    ret.append((3 * w_step, 1 * h_step))  # upper right quarter\n                    ret.append((1 * w_step, 3 * h_step))  # lower left quarter\n                    ret.append((3 * w_step, 3 * h_step))  # lower righ quarter\n                w_offset, h_offset = random.choice(ret)\n            return crop_pair[0], crop_pair[1], w_offset, h_offset\n        crop_w, crop_h, offset_w, offset_h = _sample_crop_size(im_size)\n        crop_img_group = [\n            img.crop((offset_w, offset_h, offset_w + crop_w, offset_h + crop_h))\n            for img in imgs\n        ]\n        ret_img_group = [\n            img.resize((input_size[0], input_size[1]), Image.BILINEAR)\n            for img in crop_img_group\n        ]\n        results['imgs'] = ret_img_group\n        return results\n@PIPELINES.register()\nclass RandomFlip(object):\n    \"\"\"\n    Random Flip images.\n    Args:\n        p(float): Random flip images with the probability p.\n    \"\"\"\n    def __init__(self, p=0.5):\n        self.p = p\n    def __call__(self, results):"
        },
        {
            "comment": "This code defines two classes: \"RandomFlip\" and \"Image2Array\". RandomFlip performs random flips on a list of PIL images, while Image2Array converts a PIL image to a numpy array with optional transpose. Both are registered as pipelines using @PIPELINES.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":247-280",
            "content": "        \"\"\"\n        Performs random flip operations.\n        Args:\n            imgs: List where each item is a PIL.Image.\n            For example, [PIL.Image0, PIL.Image1, PIL.Image2, ...]\n        return:\n            flip_imgs: List where each item is a PIL.Image after random flip.\n        \"\"\"\n        imgs = results['imgs']\n        v = random.random()\n        if v < self.p:\n            results['imgs'] = [\n                img.transpose(Image.FLIP_LEFT_RIGHT) for img in imgs\n            ]\n        else:\n            results['imgs'] = imgs\n        return results\n@PIPELINES.register()\nclass Image2Array(object):\n    \"\"\"\n    transfer PIL.Image to Numpy array and transpose dimensions from 'dhwc' to 'dchw'.\n    Args:\n        transpose: whether to transpose or not, default True, False for slowfast.\n    \"\"\"\n    def __init__(self, transpose=True):\n        self.transpose = transpose\n    def __call__(self, results):\n        \"\"\"\n        Performs Image to NumpyArray operations.\n        Args:\n            imgs: List where each item is a PIL.Image."
        },
        {
            "comment": "This function converts a list of PIL images to a numpy array, optionally transposes it if needed, and stores the result in the 'imgs' key of the results dictionary. Additionally, the Normalization class initializes with mean and std values for normalization and reshapes them to fit the tensor shape.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":281-309",
            "content": "            For example, [PIL.Image0, PIL.Image1, PIL.Image2, ...]\n        return:\n            np_imgs: Numpy array.\n        \"\"\"\n        imgs = results['imgs']\n        np_imgs = (np.stack(imgs)).astype('float32')\n        if self.transpose:\n            np_imgs = np_imgs.transpose(0, 3, 1, 2)  #nchw\n        results['imgs'] = np_imgs\n        return results\n@PIPELINES.register()\nclass Normalization(object):\n    \"\"\"\n    Normalization.\n    Args:\n        mean(Sequence[float]): mean values of different channels.\n        std(Sequence[float]): std values of different channels.\n        tensor_shape(list): size of mean, default [3,1,1]. For slowfast, [1,1,1,3]\n    \"\"\"\n    def __init__(self, mean, std, tensor_shape=[3, 1, 1]):\n        if not isinstance(mean, Sequence):\n            raise TypeError(\n                'Mean must be list, tuple or np.ndarray, but got {type(mean)}')\n        if not isinstance(std, Sequence):\n            raise TypeError(\n                'Std must be list, tuple or np.ndarray, but got {type(std)}')\n        self.mean = np.array(mean).reshape(tensor_shape).astype(np.float32)"
        },
        {
            "comment": "The code is a part of the PaddleVideo library's VideoQualityAssessment module. It performs normalization operations on image arrays and registers a JitterScale class for image scaling with random short size selection between min_size and max_size, also including cycling factors for default minimum size functionality.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":310-343",
            "content": "        self.std = np.array(std).reshape(tensor_shape).astype(np.float32)\n    def __call__(self, results):\n        \"\"\"\n        Performs normalization operations.\n        Args:\n            imgs: Numpy array.\n        return:\n            np_imgs: Numpy array after normalization.\n        \"\"\"\n        imgs = results['imgs']\n        norm_imgs = imgs / 255.\n        norm_imgs -= self.mean\n        norm_imgs /= self.std\n        results['imgs'] = norm_imgs\n        return results\n@PIPELINES.register()\nclass JitterScale(object):\n    \"\"\"\n    Scale image, while the target short size is randomly select between min_size and max_size.\n    Args:\n        min_size: Lower bound for random sampler.\n        max_size: Higher bound for random sampler.\n    \"\"\"\n    def __init__(self,\n                 min_size,\n                 max_size,\n                 short_cycle_factors=[0.5, 0.7071],\n                 default_min_size=256):\n        self.default_min_size = default_min_size\n        self.orig_min_size = self.min_size = min_size\n        self.max_size = max_size"
        },
        {
            "comment": "This code performs jitter resize operations and applies random scaling. It takes a sequence of PIL.Image, scales each item based on min_size, max_size, and short_cycle_factors. If the number of images is less than 1, it throws an error. The size is determined by randomly selecting values between min_size and max_size.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":344-369",
            "content": "        self.short_cycle_factors = short_cycle_factors\n    def __call__(self, results):\n        \"\"\"\n        Performs jitter resize operations.\n        Args:\n            imgs (Sequence[PIL.Image]): List where each item is a PIL.Image.\n            For example, [PIL.Image0, PIL.Image1, PIL.Image2, ...]\n        return:\n            resized_imgs: List where each item is a PIL.Image after scaling.\n        \"\"\"\n        short_cycle_idx = results.get('short_cycle_idx')\n        if short_cycle_idx in [0, 1]:\n            self.min_size = int(\n                round(self.short_cycle_factors[short_cycle_idx] *\n                      self.default_min_size))\n        else:\n            self.min_size = self.orig_min_size\n        imgs = results['imgs']\n        size = int(round(np.random.uniform(self.min_size, self.max_size)))\n        assert (len(imgs) >= 1) , \\\n            \"len(imgs):{} should be larger than 1\".format(len(imgs))\n        width, height = imgs[0].size\n        if (width <= height and width == size) or (height <= width\n                                                   and height == size):"
        },
        {
            "comment": "This code resizes the input images to a specified size while maintaining aspect ratio, and then applies random crop for multi-clip testing in the MultiCrop class. The target_size parameter determines the output image's dimensions after resizing and cropping.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":370-402",
            "content": "            return results\n        new_width = size\n        new_height = size\n        if width < height:\n            new_height = int(math.floor((float(height) / width) * size))\n        else:\n            new_width = int(math.floor((float(width) / height) * size))\n        frames_resize = []\n        for j in range(len(imgs)):\n            img = imgs[j]\n            scale_img = img.resize((new_width, new_height), Image.BILINEAR)\n            frames_resize.append(scale_img)\n        results['imgs'] = frames_resize\n        return results\n@PIPELINES.register()\nclass MultiCrop(object):\n    \"\"\"\n    Random crop image.\n    This operation can perform multi-crop during multi-clip test, as in slowfast model.\n    Args:\n        target_size(int): Random crop a square with the target_size from an image.\n    \"\"\"\n    def __init__(self,\n                 target_size,\n                 default_crop_size=224,\n                 short_cycle_factors=[0.5, 0.7071],\n                 test_mode=False):\n        self.orig_target_size = self.target_size = target_size"
        },
        {
            "comment": "The function performs random crop operations on images. It takes a list of PIL Images as input and returns the cropped images. The code checks if the current short cycle index is 0 or 1, in which case it adjusts the target size based on the short_cycle_factors variable. If the image size matches the target size, it skips the crop operation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":403-429",
            "content": "        self.short_cycle_factors = short_cycle_factors\n        self.default_crop_size = default_crop_size\n        self.test_mode = test_mode\n    def __call__(self, results):\n        \"\"\"\n        Performs random crop operations.\n        Args:\n            imgs: List where each item is a PIL.Image.\n            For example, [PIL.Image0, PIL.Image1, PIL.Image2, ...]\n        return:\n            crop_imgs: List where each item is a PIL.Image after random crop.\n        \"\"\"\n        imgs = results['imgs']\n        spatial_sample_index = results['spatial_sample_index']\n        spatial_num_clips = results['spatial_num_clips']\n        short_cycle_idx = results.get('short_cycle_idx')\n        if short_cycle_idx in [0, 1]:\n            self.target_size = int(\n                round(self.short_cycle_factors[short_cycle_idx] *\n                      self.default_crop_size))\n        else:\n            self.target_size = self.orig_target_size  # use saved value before call\n        w, h = imgs[0].size\n        if w == self.target_size and h == self.target_size:"
        },
        {
            "comment": "This function performs image cropping with or without random cropping. If not in test mode, it randomly selects x and y offsets within the image boundaries to crop an area of size self.target_size. In test mode, it performs multi-crop by dividing the image into equal parts based on spatial_num_clips, ensuring each part has a minimum size of self.target_size.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":430-451",
            "content": "            return results\n        assert (w >= self.target_size) and (h >= self.target_size), \\\n            \"image width({}) and height({}) should be larger than crop size({},{})\".format(w, h, self.target_size, self.target_size)\n        frames_crop = []\n        if not self.test_mode:\n            x_offset = random.randint(0, w - self.target_size)\n            y_offset = random.randint(0, h - self.target_size)\n        else:  #multi-crop\n            x_gap = int(\n                math.ceil((w - self.target_size) / (spatial_num_clips - 1)))\n            y_gap = int(\n                math.ceil((h - self.target_size) / (spatial_num_clips - 1)))\n            if h > w:\n                x_offset = int(math.ceil((w - self.target_size) / 2))\n                if spatial_sample_index == 0:\n                    y_offset = 0\n                elif spatial_sample_index == spatial_num_clips - 1:\n                    y_offset = h - self.target_size\n                else:\n                    y_offset = y_gap * spatial_sample_index\n            else:"
        },
        {
            "comment": "The code takes a list of images and crops them based on specified offset values to create new images with the desired target size. It then appends these cropped images to a list, stores them in 'frames_crop', and returns a dictionary containing 'imgs'. The function PackOutput is used for getting the slow pathway from the fast pathway based on the alpha factor in the SlowFast model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":452-483",
            "content": "                y_offset = int(math.ceil((h - self.target_size) / 2))\n                if spatial_sample_index == 0:\n                    x_offset = 0\n                elif spatial_sample_index == spatial_num_clips - 1:\n                    x_offset = w - self.target_size\n                else:\n                    x_offset = x_gap * spatial_sample_index\n        for img in imgs:\n            nimg = img.crop((x_offset, y_offset, x_offset + self.target_size,\n                             y_offset + self.target_size))\n            frames_crop.append(nimg)\n        results['imgs'] = frames_crop\n        return results\n@PIPELINES.register()\nclass PackOutput(object):\n    \"\"\"\n    In slowfast model, we want to get slow pathway from fast pathway based on\n    alpha factor.\n    Args:\n        alpha(int): temporal length of fast/slow\n    \"\"\"\n    def __init__(self, alpha):\n        self.alpha = alpha\n    def __call__(self, results):\n        fast_pathway = results['imgs']\n        # sample num points between start and end\n        slow_idx_start = 0"
        },
        {
            "comment": "This code is creating a slower pathway by selecting specific frames from the fast_pathway array and rearranging the dimensions. The slower pathway is then combined with the original fast_pathway to create a list of frames, which is added to the 'results' dictionary before returning it.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py\":484-497",
            "content": "        slow_idx_end = fast_pathway.shape[0] - 1\n        slow_idx_num = fast_pathway.shape[0] // self.alpha\n        slow_idxs_select = np.linspace(slow_idx_start, slow_idx_end,\n                                       slow_idx_num).astype(\"int64\")\n        slow_pathway = fast_pathway[slow_idxs_select]\n        # T H W C -> C T H W.\n        slow_pathway = slow_pathway.transpose(3, 0, 1, 2)\n        fast_pathway = fast_pathway.transpose(3, 0, 1, 2)\n        # slow + fast\n        frames_list = [slow_pathway, fast_pathway]\n        results['imgs'] = frames_list\n        return results"
        }
    ]
}