{
    "summary": "The code utilizes PaddlePaddle library for video retrieval, trains a model, handles memory-efficient sample copies, calculates metrics, logs progress, and visualizes ranking if available. Mean Average Precision is computed, results stored, and single test caption checked during each epoch.",
    "details": [
        {
            "comment": "This code is part of a larger program using the PaddlePaddle library for video retrieval. It defines a verbose function to display training metrics and a context manager to handle temporary copies of retrieval samples.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":0-30",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nimport paddle\nimport numpy as np\nfrom base import BaseTrainer\nfrom utils import memory_summary\nfrom contextlib import contextmanager\ndef verbose(epoch, metrics, mode, name=\"TEST\"):\n    r1, r5, r10, r50 = metrics[\"R1\"], metrics[\"R5\"], metrics[\"R10\"], metrics[\"R50\"]\n    msg = f\"[{mode}]{name:s} epoch {epoch}, R@1: {r1:.1f}\"\n    msg += f\", R@5: {r5:.1f}, R@10 {r10:.1f}, R@50 {r50:.1f}\"\n    msg += f\"MedR: {metrics['MedR']:g}, MeanR: {metrics['MeanR']:.1f}\"\n    print(msg)\n@contextmanager\ndef ctxt_mgr(samples):\n    \"\"\"Provide a context for managing temporary, cloned copies of retrieval"
        },
        {
            "comment": "This function creates a copy of the \"experts\" tensor from the input samples and replaces it in the samples dictionary. It also includes other relevant tensors and allows for evaluation without modifying the original samples. The copied samples are yielded, and then deleted after use to avoid memory leaks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":31-65",
            "content": "    sample tensors.\n    The rationale here is that to use nan-checking in the model (to validate the\n    positions of missing experts), we need to modify the underlying tensors. This\n    function lets the evaluation code run (and modify) temporary copies, without\n    modifying the originals.\n    \"\"\"\n    exp_dict = samples[\"experts\"].items()\n    experts = {key: val.clone() for key, val in exp_dict}\n    samples_ = {\n        \"experts\": experts,\n        \"ind\": samples[\"ind\"],\n        \"text\": samples[\"text\"],\n        \"cap_id\": samples[\"cap_id\"],\n        \"att_mask\": samples[\"att_mask\"],\n    }\n    if \"text_token_mask\" in samples:\n        samples_[\"text_token_mask\"] = samples[\"text_token_mask\"]\n    try:\n        yield samples_\n    finally:\n        del samples_\nclass Trainer(BaseTrainer):\n    \"\"\"\n    Trainer class\n    Note:\n        Inherited from BaseTrainer.\n    \"\"\"\n    def __init__(self, model, loss, metrics, optimizer, config, data_loaders,\n                 lr_scheduler, visualizer, skip_first_n_saves,\n                 include_optim_in_save_model, force_cpu_val, cache_targets=set(),"
        },
        {
            "comment": "This code defines a class for training a model with specific configurations, data loaders, learning rate scheduler, and more. It initializes the necessary attributes and provides a method for performing training during an epoch. The `_train_epoch` method performs training logic for an epoch and returns a log containing all relevant information.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":66-88",
            "content": "                 num_keep_ckpts=3, mini_train=False, val_freq=1, skip_tboard=False):\n        super().__init__(model, loss, metrics, optimizer, config, mini_train=mini_train,\n                         skip_tboard=skip_tboard, num_keep_ckpts=num_keep_ckpts)\n        self.config = config\n        self.cache_targets = cache_targets\n        self.data_loaders = data_loaders\n        self.lr_scheduler = lr_scheduler\n        self.mini_train = mini_train\n        self.len_epoch = len(self.data_loaders[\"train\"])\n        self.log_step = int(np.sqrt(data_loaders[\"train\"].batch_size))\n        self.visualizer = visualizer\n        self.force_cpu_val = force_cpu_val\n        self.val_freq = val_freq\n        self.skip_first_n_saves = skip_first_n_saves\n        self.include_optim_in_save_model = include_optim_in_save_model\n        self.seen = {\"train\": 0, \"val\": 0}\n    def _train_epoch(self, epoch):\n        \"\"\"\n        Training logic for an epoch\n        :param epoch: Current training epoch.\n        :return: A log that contains all information you want to save."
        },
        {
            "comment": "This code trains a model and computes the loss for each batch of data in the train loader. The loss is then backpropagated, the optimizer steps, and gradients are cleared before moving on to the next batch. The batch size is also tracked as part of the seen data count.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":90-116",
            "content": "        Note:\n            If you have additional information to record, for example:\n                > additional_log = {\"x\": x, \"y\": y}\n            merge it with log before return. i.e.\n                > log = {**log, **additional_log}\n                > return log\n            The metrics in log must have the key 'metrics'.\n        \"\"\"\n        total_loss = 0\n        self.model.train()\n        memory_summary()\n        for batch_idx, minibatch in enumerate(self.data_loaders[\"train\"]):\n            output = self.model(**minibatch)\n            if \"retrieval\" in self.data_loaders.dataloaders:\n                loss = self.loss(output[\"cross_view_conf_matrix\"])\n            else:\n                loss = self.loss(x=output[\"class_preds\"], target=labels)\n            loss.backward()\n            self.optimizer.step()\n            self.optimizer.clear_grad()\n            sample_key = list(minibatch[\"experts\"].keys())[0]\n            batch_size = minibatch[\"experts\"][sample_key].shape[0]\n            self.seen[\"train\"] += batch_size"
        },
        {
            "comment": "Training loop for a machine learning model, logging progress and validating after certain epochs. Performs validation metrics calculation and updates learning rate with a scheduler.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":118-149",
            "content": "            total_loss += loss.item()\n            if batch_idx % self.log_step == 0:\n                prog = self._progress(batch_idx)\n                self.logger.info(f\"Train Epoch: {epoch} {prog} Loss: {loss.item():.6f}\")\n            if batch_idx == self.len_epoch or (self.mini_train and batch_idx > 3):\n                break\n        log = {'loss': total_loss / self.len_epoch}\n        if epoch % self.val_freq == 0:\n            nested_log, cached_preds = self._valid_epoch(epoch)\n            log.update(nested_log)\n        else:\n            nested_log, cached_preds = {}, None\n            self.logger.info(f\"skipping val for epoch: {epoch}\")\n        self.lr_scheduler.step()\n        self.logger.info(f\"LR {self.lr_scheduler.get_lr()}\")\n        return log, cached_preds\n    def _valid_epoch(self, epoch):\n        \"\"\"Validate model after an epoch of training and store results to disk.\n        Args:\n            epoch (int): the current epoch\n        Returns:\n            A log that contains information about validation\n        NOTE: The validation metrics in log must have the key 'val_metrics'."
        },
        {
            "comment": "This code is initializing the model in evaluation mode, creating a dictionary to store cached predictions, and retrieving data from dataloaders. It also checks if there are too many queries and adjusts batch size accordingly. The text_keys variable stores keys for text-related data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":150-170",
            "content": "        \"\"\"\n        self.model.eval()\n        cached_preds = {key: {\"vid_name\": [], \"preds\": [], \"labels\": []}\n                        for key in self.cache_targets}\n        with paddle.no_grad():\n            if \"retrieval\" in self.data_loaders.dataloaders:\n                samples, meta = self.data_loaders[\"retrieval\"]\n                sample_key = list(samples[\"experts\"].keys())[0]\n                batch_size = samples[\"experts\"][sample_key].shape[0]\n                self.seen[\"val\"] += batch_size\n                num_queries = samples[\"text\"].shape[0] * samples[\"text\"].shape[1]\n                safe_queries = 1\n                text_keys = ['text', 'cap_id', 'att_mask', 'text_token_mask']\n                if num_queries > safe_queries:\n                    chk = 50\n                    tck = 50\n                    if samples['text'].shape[0] % chk == 0:\n                        vid_batch = samples['text'].shape[0] // chk\n                    else:\n                        vid_batch = samples['text'].shape[0] // chk + 1"
        },
        {
            "comment": "This code segment calculates the number of batches for 'text' and iterates through each batch. It then creates sub-samples and subsub-sims for further processing. This seems to be part of a machine learning model training process, possibly using video data with experts and indicators as additional features. The progress is printed every 5 batches.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":171-189",
            "content": "                    if samples['text'].shape[0] % tck == 0:\n                        text_batch  =  samples['text'].shape[0] // tck\n                    else:\n                        text_batch  =  samples['text'].shape[0] // tck + 1\n                    sub_sims = []\n                    for idx in range(text_batch):\n                        if idx % 5 == 0:\n                            print(idx,'/',text_batch)\n                        sub_samples = {}\n                        for key in text_keys:\n                            sub_samples.update({key: samples[key][idx*tck:idx*tck+tck]})\n                        subsub_sims = []\n                        for vid in range(vid_batch):\n                            sub_samples['experts'] = {}\n                            sub_samples['ind'] = {} \n                            for expert in samples['experts'].keys():\n                                sub_samples['experts'][expert] = samples['experts'][expert][vid*chk:vid*chk+chk]\n                                sub_samples['ind'][expert] = samples['ind'][expert][vid*chk:vid*chk+chk]"
        },
        {
            "comment": "This code appears to be part of a machine learning model training process. It uses PaddlePaddle, a deep learning framework, to calculate similarity metrics (sims) between samples or sub-samples, then concatenates them based on the given condition (if sub_samples exists). If no sub_samples exist, it directly calculates sims from the samples. The code then samples the loss using only the first query for each video and reshapes the sims tensor accordingly before passing it to a loss function (self.loss). Finally, the dataset name is captured in the variable \"dataset\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":190-208",
            "content": "                            with ctxt_mgr(sub_samples) as xx:\n                                output = self.model(**xx)\n                            subsub_sims.append(output[\"cross_view_conf_matrix\"].cpu())\n                        subsub_sims = paddle.concat(subsub_sims, axis=1)\n                        sub_sims.append(subsub_sims)\n                    sims = paddle.concat(sub_sims, axis=0)\n                    sims = paddle.to_tensor(sims, dtype='float32').cpu().numpy()\n                else:\n                    with ctxt_mgr(samples) as xx:\n                        output = self.model(**xx)\n                    sims = paddle.to_tensor(output[\"cross_view_conf_matrix\"], dtype='float32').cpu().numpy()\n                # sample the loss (using only the first query for each video)\n                queries_per_vid = meta[\"query_masks\"].shape[1]\n                sims_ = paddle.to_tensor(sims).reshape([-1, queries_per_vid, sims.shape[-1]])\n                loss = self.loss(sims_[:, 0, :])\n                dataset = self.data_loaders.dataset_name"
        },
        {
            "comment": "The code is calculating metrics such as Mean Average Precision (mAP) for each epoch and storing the results in a dictionary named nested_metrics. If mAP is calculated, it prints the value. It also calls a verbose function that takes the current epoch, metrics values, dataset name, and metric name as parameters. The code checks if there is only one test caption available (num_test_captions == 1) and if raw_captions exist. If so, it visualizes the ranking by calling a visualizer function passing simulation scores (sims), meta data, current epoch, and nested_metrics as arguments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":209-227",
            "content": "                nested_metrics = {}\n                for metric in self.metrics:\n                    metric_name = metric.__name__\n                    res = metric(sims, query_masks=meta[\"query_masks\"])\n                    if metric_name == \"mean_average_precision\":\n                        print(f\"Epoch: {epoch}, mean AP: {res['mAP']}\")\n                    else:\n                        verbose(epoch=epoch, metrics=res, name=dataset, mode=metric_name)\n                    nested_metrics[metric_name] = res\n                # TODO(Samuel) disabled visualisation for now, simple to add in later\n                num_test_caps = self.data_loaders.num_test_captions\n                if num_test_caps == 1 and meta[\"raw_captions\"] is not None:\n                    if self.visualizer is not None:\n                        self.visualizer.visualize_ranking(\n                            sims=sims,\n                            meta=meta,\n                            epoch=epoch,\n                            nested_metrics=nested_metrics,"
        },
        {
            "comment": "Iterating over validation data, calculates metrics for each batch, logs progress during iteration. If cache_targets includes \"val\", stores predictions and labels in cached_preds dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":228-248",
            "content": "                        )\n                return {\"nested_val_metrics\": nested_metrics}, cached_preds\n            elif \"val\" in self.data_loaders.dataloaders:\n                metrics = [x() for x in self.metrics]\n                for batch_idx, minibatch in enumerate(self.data_loaders[\"val\"]):\n                    labels = minibatch.pop(\"labels\")\n                    vid_name = minibatch.pop(\"vid_name\")\n                    output = self.model(**minibatch)\n                    if \"val\" in self.cache_targets:\n                        cached_preds[\"val\"][\"vid_name\"].append(vid_name)\n                        cached_preds[\"val\"][\"preds\"].append(output[\"class_preds\"])\n                    for metric in metrics:\n                        metric.add(output=output[\"class_preds\"], target=labels)\n                    if batch_idx % self.log_step == 0:\n                        prog = self._progress(batch_idx)\n                        self.logger.info(f\"Val Epoch: {epoch} {prog}\")\n                nested_metrics = {}\n                for metric in metrics:"
        },
        {
            "comment": "This code checks if the metric has a \"topk\" attribute, then creates a dictionary of top-k values and assigns it to \"res\". If not supported, raises a ValueError. It adds the accuracy metric to nested_metrics. The code then creates a nested dictionary for cache targets other than \"val\", and iterates through each data loader in self.data_loaders[\"tiny\"]. For each batch, it checks if labels are present, appends them to cached_preds with corresponding vid name and model predictions. Finally, it aggregates all cached predictions for the specified target(s).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":249-266",
            "content": "                    if hasattr(metric, \"topk\"):\n                        res = {f\"top{key}\": val for key, val in\n                               zip(metric.topk, metric.value())}\n                        nested_metrics[\"accuracy\"] = res\n                    else:\n                        raise ValueError(f\"unsupported mettric: {type(metric)}\")\n                nested = {\"nested_val_metrics\": nested_metrics}\n                for target in self.cache_targets - {\"val\"}:\n                    for batch_idx, minibatch in enumerate(self.data_loaders[\"tiny\"]):\n                        if \"labels\" in minibatch:\n                            cached_preds[target][\"labels\"].append(minibatch.pop(\"labels\"))\n                        cached_preds[target][\"vid_name\"].append(minibatch.pop(\"vid_name\"))\n                        output = self.model(**minibatch)\n                        cached_preds[target][\"preds\"].append(output[\"class_preds\"])\n                # aggregate all cached predictions\n                for target in self.cache_targets:"
        },
        {
            "comment": "The code defines two functions: _compute_nested_preds and _progress. The first function computes nested predictions from cached predictions for a given target, while the second one returns a progress message based on the current batch index and total number of samples or epoch length.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/trainer/trainer.py\":267-279",
            "content": "                    for key, val in cached_preds[target].items():\n                        cached_preds[key] = paddle.concat(val).cpu().numpy()\n                return nested, cached_preds\n    def _progress(self, batch_idx):\n        base = '[{}/{} ({:.0f}%)]'\n        if hasattr(self.data_loaders, 'n_samples'):\n            current = batch_idx * self.data_loaders.batch_size\n            total = self.data_loaders.n_samples\n        else:\n            current = batch_idx\n            total = self.len_epoch\n        return base.format(current, total, 100.0 * current / total)"
        }
    ]
}