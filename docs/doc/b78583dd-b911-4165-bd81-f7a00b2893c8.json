{
    "summary": "The code initializes a metric class for PaddleVideo, handling batch updates and GPU data to mitigate resampling effects while managing output accumulation, concatenation, top-k accuracy, and logging.",
    "details": [
        {
            "comment": "This code registers a class called CenterCropMetric as a metric in the PaddleVideo library. It initializes the metric with data_size, batch_size, and log_interval parameters. The rest_data_size is also stored to keep track of remaining samples to be tested.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/center_crop_metric.py\":0-30",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nfrom typing import List\nimport paddle\nfrom paddlevideo.utils import get_logger\nfrom .base import BaseMetric\nfrom .registry import METRIC\nlogger = get_logger(\"paddlevideo\")\n@METRIC.register\nclass CenterCropMetric(BaseMetric):\n    def __init__(self, data_size, batch_size, log_interval=1, **kwargs):\n        \"\"\"prepare for metrics\n        \"\"\"\n        super().__init__(data_size, batch_size, log_interval, **kwargs)\n        self.rest_data_size = data_size  # Number of samples remaining to be tested\n        self.all_outputs = []"
        },
        {
            "comment": "This code is initializing a metric object, allowing for batch updates, and handling data from multiple GPUs to avoid resampling effects when testing with multiple cards.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/center_crop_metric.py\":31-54",
            "content": "        self.all_labels = []\n        self.topk = kwargs.get(\"topk\", [1, 5])\n    def update(self, batch_id: int, data: List, outputs: paddle.Tensor) -> None:\n        \"\"\"update metrics during each iter\n        Args:\n            batch_id (int): iter id of current batch.\n            data (List): list of batched data, such as [inputs, labels]\n            outputs (paddle.Tensor): batched outputs from model\n        \"\"\"\n        labels = data[1]\n        if self.world_size > 1:\n            labels_gathered = self.gather_from_gpu(labels, concat_axis=0)\n            outpus_gathered = self.gather_from_gpu(outputs, concat_axis=0)\n        else:\n            labels_gathered = labels\n            outpus_gathered = outputs\n        # Avoid resampling effects when testing with multiple cards\n        labels_gathered = labels_gathered[0:min(len(labels_gathered), self.\n                                                rest_data_size)]\n        outpus_gathered = outpus_gathered[0:min(len(outpus_gathered), self.\n                                                rest_data_size)]"
        },
        {
            "comment": "The code is part of a class that seems to be handling batch processing in a machine learning application. It accumulates and concatenates outputs and labels from multiple batches, performs top-k accuracy calculations, and logs the results. The log_interval variable controls when progress updates are displayed.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/center_crop_metric.py\":55-78",
            "content": "        self.all_labels.append(labels_gathered)\n        self.all_outputs.append(outpus_gathered)\n        self.rest_data_size -= outpus_gathered.shape[0]\n        # preds ensemble\n        if batch_id % self.log_interval == 0:\n            logger.info(\"[TEST] Processing batch {}/{} ...\".format(\n                batch_id,\n                self.data_size // (self.batch_size * self.world_size)))\n    def accumulate(self):\n        \"\"\"accumulate, compute, and show metrics when finished all iters.\n        \"\"\"\n        self.all_outputs = paddle.concat(self.all_outputs, axis=0)\n        self.all_labels = paddle.concat(self.all_labels, axis=0)\n        result_str = []\n        for _k in self.topk:\n            topk_val = paddle.metric.accuracy(input=self.all_outputs,\n                                              label=self.all_labels,\n                                              k=_k).item()\n            result_str.append(f\"avg_acc{_k}={topk_val}\")\n        result_str = \", \".join(result_str)\n        logger.info(f\"[TEST] finished, {result_str}\")"
        }
    ]
}