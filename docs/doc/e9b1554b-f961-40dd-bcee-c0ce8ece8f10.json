{
    "summary": "The PaddleVideo library's function compresses predictions based on query masks and similarity scores. The code initializes a Paddle model, prepares data loaders, sets evaluation mode, processes samples, calculates metrics, evaluates models, and runs the \"evaluation\" function.",
    "details": [
        {
            "comment": "This code is part of the PaddleVideo library and contains a function named `compress_predictions`. It imports necessary libraries, defines function parameters, and utilizes various modules from the PaddleVideo library. The function compresses predictions based on query masks and similarity scores (`sims`) with optional top k values. It is type checked for data integrity.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":0-32",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nimport copy\nimport random\nimport paddle\nimport logging\nimport argparse\nimport numpy as np\nimport model.model as module_arch\nimport model.metric as module_metric\nimport data_loader.data_loaders as module_data\nfrom typing import Tuple\nfrom pathlib import Path\nfrom typeguard import typechecked\nfrom mergedeep import Strategy, merge\nfrom parse_config import ConfigParser\nfrom trainer.trainer import verbose, ctxt_mgr\nfrom utils.util import compute_dims, compute_trn_config\n@typechecked\ndef compress_predictions(query_masks: np.ndarray, sims: np.ndarray, topk: int = 10):"
        },
        {
            "comment": "Code validates input shapes, ensuring that sims and query_masks represent the same number of videos and queries. It asserts the correct dimensions for sims and query_masks to ensure compatibility in further computations, preventing potential errors.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":33-50",
            "content": "    \"\"\"We store the indices of the top-k predictions, rather than the full similarity\n    matrix, to reduce storage requirements.\n    NOTE: The similarity matrix contains `num_queries x num_videos` elements, where\n    `num_queries = num_videos x max_num_queries_per_video`.  We first mask out\n    locations in the similarity matrix that correspond to invalid queries (these are\n    produced by videos with fewer than `max_num_queries_per_video` descriptions).\n    \"\"\"\n    # validate the input shapes\n    assert query_masks.ndim == 2, \"Expected query_masks to be a matrix\"\n    query_num_videos, query_max_per_video = query_masks.shape\n    sims_queries, sims_num_videos = sims.shape\n    msg = (f\"Expected sims and query masks to represent the same number of videos \"\n           f\"(found {sims_num_videos} v {query_num_videos}\")\n    assert query_num_videos == sims_num_videos, msg\n    msg = (f\"Expected sims and query masks to represent the same number of queries \"\n           f\"(found {sims_queries} v {query_num_videos * query_max_per_video}\")"
        },
        {
            "comment": "This code defines a function that takes a configuration, logger, and model path as input, returns a tuple containing a Paddle.js layer model and an ExpertDataLoader object for training data. The function first computes the expert dimensions and raw input dimensions based on the provided config, then initializes the train data loaders using the same config and returns the model and data loader tuple. The code also handles cases where some features might be missing by allowing the use of zeros to fill in such gaps.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":51-83",
            "content": "    assert query_max_per_video * query_num_videos == sims_queries, msg\n    valid_sims = sims[query_masks.flatten().astype(np.bool)]\n    ranks = np.argsort(-valid_sims, axis=1)\n    return ranks[:, :topk]\n@typechecked\ndef get_model_and_data_loaders(\n        config: ConfigParser,\n        logger: logging.Logger,\n        model_path: Path,\n) -> Tuple[paddle.nn.Layer, module_data.ExpertDataLoader]:\n    expert_dims, raw_input_dims = compute_dims(config)\n    trn_config = compute_trn_config(config)\n    data_loaders = config.init(\n        name='data_loader',\n        module=module_data,\n        logger=logger,\n        raw_input_dims=raw_input_dims,\n        text_feat=config[\"experts\"][\"text_feat\"],\n        text_dim=config[\"experts\"][\"text_dim\"],\n        text_agg=config[\"experts\"][\"text_agg\"],\n        use_zeros_for_missing=config[\"experts\"].get(\"use_zeros_for_missing\", False),\n        eval_only=True,\n    )\n    model = config.init(\n        name='arch',\n        module=module_arch,\n        expert_dims=expert_dims,\n        text_dim=config[\"experts\"][\"text_dim\"],"
        },
        {
            "comment": "This code is initializing a model and preparing it for evaluation. It loads a checkpoint from the specified model path, creates a data loader, and performs an evaluation with the given configuration. The random seed is set to ensure reproducibility of results.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":84-115",
            "content": "        ce_shared_dim=config[\"experts\"].get(\"ce_shared_dim\", None),\n        feat_aggregation=config[\"data_loader\"][\"args\"][\"feat_aggregation\"],\n    )\n    model_path = config._args.resume\n    logger.info(f\"Loading checkpoint: {model_path} ...\")\n    checkpoint = paddle.load(model_path)\n    state_dict = checkpoint\n    if config['n_gpu'] > 1:\n        model = paddle.DataParallel(model)\n    model.load_dict(state_dict)\n    return model, data_loaders\ndef evaluation(config, logger=None, trainer=None):\n    if logger is None:\n        logger = config.get_logger('test')\n    if getattr(config._args, \"eval_from_training_config\", False):\n        eval_conf = copy.deepcopy(config)\n        merge(eval_conf._config, config[\"eval_settings\"], strategy=Strategy.REPLACE)\n        config = eval_conf\n    logger.info(\"Running evaluation with configuration:\")\n    logger.info(config)\n    # Set the random initial seeds\n    seed = config[\"seed\"]\n    logger.info(f\"Setting experiment random seed to {seed}\")\n    random.seed(seed)\n    np.random.seed(seed)"
        },
        {
            "comment": "The code snippet initializes the Paddle model, data loaders, and sets the model to evaluation mode. It also prepares the retrieval dataset by checking for nan values and making temporary copies of relevant data elements based on their shape. The code then determines the number of video batches and text batches based on the dataset size.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":116-145",
            "content": "    paddle.seed(seed)\n    model, data_loaders = get_model_and_data_loaders(\n        config=config,\n        logger=logger,\n        model_path=Path(config._args.resume),\n    )\n    logger.info(model)\n    metrics = [getattr(module_metric, met) for met in config['metrics']]\n    # prepare model for testing.  Note that some datasets fail to fit the retrieval\n    # set on the GPU, so we run them on the CPU\n    model.eval()\n    with paddle.no_grad():\n        samples, meta = data_loaders[\"retrieval\"]\n        #import pdb; pdb.set_trace()\n        # To use the nan-checks safely, we need make temporary copies of the data\n        all_text_num = samples['text'].shape[0]\n        text_keys = ['text', 'cap_id', 'att_mask', 'text_token_mask']\n        chk = 100\n        tck = 100 \n        if samples['text'].shape[0] % chk == 0:\n            vid_batch = samples['text'].shape[0] // chk\n        else:\n            vid_batch = samples['text'].shape[0] // chk + 1\n        if samples['text'].shape[0] % tck == 0:\n            text_batch  =  samples['text'].shape[0] // tck"
        },
        {
            "comment": "This code slices samples into sub-samples and processes them for multiple videos. It then concatenates the processed results along axis 1, storing each result in the list \"sub_sims\". This process is repeated for a batch of text and video samples. The code also includes progress printing and utilizes context management to run model operations efficiently.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":146-166",
            "content": "        else: \n            text_batch  =  samples['text'].shape[0] // tck + 1\n        sub_sims = []\n        for idx in range(text_batch):\n            if idx % 5 == 0:\n                print(idx,'/',text_batch)\n            sub_samples = {}\n            for key in text_keys:\n                sub_samples.update({key: samples[key][idx*tck:idx*tck+tck]})\n            subsub_sims = []\n            for vid in range(vid_batch):\n                sub_samples['experts'] = {}\n                sub_samples['ind'] = {}\n                for expert in samples['experts'].keys():\n                    sub_samples['experts'][expert] = samples['experts'][expert][vid*chk:vid*chk+chk]\n                    sub_samples['ind'][expert] = samples['ind'][expert][vid*chk:vid*chk+chk]\n                with ctxt_mgr(sub_samples) as valid:\n                    output = model(**valid)\n                subsub_sims.append(output[\"cross_view_conf_matrix\"].cpu())\n            subsub_sims = paddle.concat(subsub_sims, axis=1)\n            sub_sims.append(subsub_sims)"
        },
        {
            "comment": "This code calculates metrics for a dataset, concatenates sub-similarities, converts to numpy array, iterates through metrics and computes results for each metric using sims and query_masks. The results are logged for further analysis and information display.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":167-189",
            "content": "        sub_sims = paddle.concat(sub_sims, axis=0)\n        sims = paddle.to_tensor(sub_sims, dtype='float32').numpy()\n        dataset = data_loaders.dataset_name\n        nested_metrics = {}\n        for metric in metrics:\n            metric_name = metric.__name__\n            res = metric(sims, query_masks=meta[\"query_masks\"])\n            verbose(epoch=0, metrics=res, name=dataset, mode=metric_name)\n            if trainer is not None:\n                if not trainer.mini_train:\n                    trainer.writer.set_step(step=0, mode=\"val\")\n                # avoid tensboard folding by prefixing\n                metric_name_ = f\"test_{metric_name}\"\n                trainer.log_metrics(res, metric_name=metric_name_, mode=\"val\")\n            nested_metrics[metric_name] = res\n    log = {}\n    for subkey, subval in nested_metrics.items():\n        for subsubkey, subsubval in subval.items():\n            log[f\"test_{subkey}_{subsubkey}\"] = subsubval\n    for key, value in log.items():\n        logger.info(\" {:15s}: {}\".format(str(key), value))"
        },
        {
            "comment": "This code sets up argument parsing and configuration loading for evaluation. It checks if a model checkpoint is specified via --resume flag, then merges the main config file with eval_settings (if provided), finally calling the \"evaluation\" function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/test.py\":192-205",
            "content": "if __name__ == '__main__':\n    args = argparse.ArgumentParser(description='PyTorch Template')\n    args.add_argument('--config', default=None, type=str, help=\"config file path\")\n    args.add_argument('--resume', default=None, help='path to checkpoint for evaluation')\n    args.add_argument('--eval_from_training_config', action=\"store_true\",\n                      help=\"if true, evaluate directly from a training config file.\")\n    args.add_argument(\"--custom_args\", help=\"qualified key,val pairs\")\n    eval_config = ConfigParser(args)\n    cfg_msg = \"For evaluation, a model checkpoint must be specified via the --resume flag\"\n    assert eval_config._args.resume, cfg_msg\n    if eval_config._config.get(\"eval_settings\", False):\n        merge(eval_config._config, eval_config[\"eval_settings\"], strategy=Strategy.REPLACE)\n        evaluation(eval_config)"
        }
    ]
}