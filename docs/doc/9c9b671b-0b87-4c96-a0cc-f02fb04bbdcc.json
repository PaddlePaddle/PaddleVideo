{
    "summary": "The PaddleVideo library's UCF101 dataset offers utility functions and the Ucf24Metrics class for metric manipulation, bounding box handling, and precision/recall calculations. It computes mAP for image classification tasks and stores results per class using utility methods to read bounding box text files.",
    "details": [
        {
            "comment": "This code snippet is from the UCF101 dataset utility functions in the PaddleVideo library. It contains an enum class representing average precision metrics and a copyright notice with license information, original source link, and developer contact details.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":0-32",
            "content": "# copyright (c) 2021 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Forked from: https://github.com/rafaelpadilla/Object-Detection-Metrics\n# Developed by: Rafael Padilla (rafael.padilla@smt.ufrj.br)\nimport glob\nimport os\nimport shutil\nimport sys\nfrom collections import Counter\nimport numpy as np\nfrom enum import Enum\nimport cv2\nclass MethodAveragePrecision(Enum):\n    \"\"\"\n    Class representing if the coordinates are relative to the\n    image size or are absolute values.\n        Developed by: Rafael Padilla"
        },
        {
            "comment": "This code defines three enumerations (CoordinatesType, BBType, and BBFormat) to represent different types of coordinates and bounding boxes. It also includes a function convertToRelativeValues that takes a size and a box as input and returns the box in relative values. The code was developed by Rafael Padilla with last modifications on April 28th for CoordinatesType, May 24th for BBType and format, and the function convertToRelativeValues is defined as well.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":33-80",
            "content": "        Last modification: Apr 28 2018\n    \"\"\"\n    EveryPointInterpolation = 1\n    ElevenPointInterpolation = 2\nclass CoordinatesType(Enum):\n    \"\"\"\n    Class representing if the coordinates are relative to the\n    image size or are absolute values.\n        Developed by: Rafael Padilla\n        Last modification: Apr 28 2018\n    \"\"\"\n    Relative = 1\n    Absolute = 2\nclass BBType(Enum):\n    \"\"\"\n    Class representing if the bounding box is groundtruth or not.\n        Developed by: Rafael Padilla\n        Last modification: May 24 2018\n    \"\"\"\n    GroundTruth = 1\n    Detected = 2\nclass BBFormat(Enum):\n    \"\"\"\n    Class representing the format of a bounding box.\n    It can be (X,Y,width,height) => XYWH\n    or (X1,Y1,X2,Y2) => XYX2Y2\n        Developed by: Rafael Padilla\n        Last modification: May 24 2018\n    \"\"\"\n    XYWH = 1\n    XYX2Y2 = 2\ndef convertToRelativeValues(size, box):\n    dw = 1. / (size[0])\n    dh = 1. / (size[1])\n    cx = (box[1] + box[0]) / 2.0\n    cy = (box[3] + box[2]) / 2.0\n    w = box[1] - box[0]\n    h = box[3] - box[2]"
        },
        {
            "comment": "Function `ucf24_utils.py:81-121` defines a function `convertToAbsoluteValues` which takes in the size and bounding box coordinates (x, y, w, h) as input and returns absolute values for xIn, yIn, xEnd, yEnd considering the image size. If any of these values fall outside the image boundaries, they are adjusted to the last valid pixel within the image.\nThis code also includes a function `add_bb_into_image` which adds a bounding box with given coordinates (x1, y1, x2, y2) and label on the image using OpenCV's rectangle() function and font() function for adding labels to the bounding boxes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":81-121",
            "content": "    x = cx * dw\n    y = cy * dh\n    w = w * dw\n    h = h * dh\n    return x, y, w, h\ndef convertToAbsoluteValues(size, box):\n    xIn = round(((2 * float(box[0]) - float(box[2])) * size[0] / 2))\n    yIn = round(((2 * float(box[1]) - float(box[3])) * size[1] / 2))\n    xEnd = xIn + round(float(box[2]) * size[0])\n    yEnd = yIn + round(float(box[3]) * size[1])\n    if xIn < 0:\n        xIn = 0\n    if yIn < 0:\n        yIn = 0\n    if xEnd >= size[0]:\n        xEnd = size[0] - 1\n    if yEnd >= size[1]:\n        yEnd = size[1] - 1\n    return xIn, yIn, xEnd, yEnd\ndef add_bb_into_image(image, bb, color=(255, 0, 0), thickness=2, label=None):\n    r = int(color[0])\n    g = int(color[1])\n    b = int(color[2])\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    fontScale = 0.5\n    fontThickness = 1\n    x1, y1, x2, y2 = bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n    x1 = int(x1)\n    y1 = int(y1)\n    x2 = int(x2)\n    y2 = int(y2)\n    cv2.rectangle(image, (x1, y1), (x2, y2), (b, g, r), thickness)\n    # Add label\n    if label is not None:\n        # Get size of the text box"
        },
        {
            "comment": "This function calculates the text box coordinates and draws a rectangle around it, then adds text within the rectangle. The text position is adjusted if it's outside the image area. It also initializes a class for bounding boxes with properties like image name, class ID, and coordinates.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":122-147",
            "content": "        (tw, th) = cv2.getTextSize(label, font, fontScale, fontThickness)[0]\n        # Top-left coord of the textbox\n        (xin_bb, yin_bb) = (x1 + thickness, y1 - th + int(12.5 * fontScale))\n        # Checking position of the text top-left (outside or inside the bb)\n        if yin_bb - th <= 0:  # if outside the image\n            yin_bb = y1 + th  # put it inside the bb\n        r_Xin = x1 - int(thickness / 2)\n        r_Yin = y1 - th - int(thickness / 2)\n        # Draw filled rectangle to put the text in it\n        cv2.rectangle(image, (r_Xin, r_Yin - thickness),\n                      (r_Xin + tw + thickness * 3, r_Yin + th + int(12.5 * fontScale)), (b, g, r),\n                      -1)\n        cv2.putText(image, label, (xin_bb, yin_bb), font, fontScale, (0, 0, 0), fontThickness,\n                    cv2.LINE_AA)\n    return image\nclass BoundingBox:\n    def __init__(self,\n                 imageName,\n                 classId,\n                 x,\n                 y,\n                 w,\n                 h,\n                 typeCoordinates=None,"
        },
        {
            "comment": "This code snippet defines a constructor for the class Ucf24Metrics, which takes parameters like image name, class id, bounding box coordinates (x, y, w, h), and type of bounding box coordinates. It also accepts optional arguments such as imgSize, bbType, classConfidence, and format. If typeCoordinates is 'Relative', then imgSize is required. The constructor initializes an object representing a metric for UCF101 dataset.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":148-164",
            "content": "                 imgSize=None,\n                 bbType=None,\n                 classConfidence=None,\n                 format=None):\n        \"\"\"Constructor.\n        Args:\n            imageName: String representing the image name.\n            classId: String value representing class id.\n            x: Float value representing the X upper-left coordinate of the bounding box.\n            y: Float value representing the Y upper-left coordinate of the bounding box.\n            w: Float value representing the width bounding box.\n            h: Float value representing the height bounding box.\n            typeCoordinates: (optional) Enum (Relative or Absolute) represents if the bounding box\n            coordinates (x,y,w,h) are absolute or relative to size of the image. Default:'Absolute'.\n            imgSize: (optional) 2D vector (width, height)=>(int, int) represents the size of the\n            image of the bounding box. If typeCoordinates is 'Relative', imgSize is required.\n            bbType: (optional) Enum (Groundtruth or Detection) identifies if the bounding box"
        },
        {
            "comment": "This code defines a class with properties: imageName, typeCoordinates (Relative or Absolute), imgSize (image size required if typeCoordinates is Relative), bbType (Ground Truth or Detection), and classConfidence (optional for Detection). It also includes error checks for mandatory parameters (imgSize for Relative typeCoordinates and classConfidence for Detection bbType).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":165-180",
            "content": "            represents a ground truth or a detection. If it is a detection, the classConfidence has\n            to be informed.\n            classConfidence: (optional) Float value representing the confidence of the detected\n            class. If detectionType is Detection, classConfidence needs to be informed.\n            format: (optional) Enum (BBFormat.XYWH or BBFormat.XYX2Y2) indicating the format of the\n            coordinates of the bounding boxes. BBFormat.XYWH: <left> <top> <width> <height>\n            BBFormat.XYX2Y2: <left> <top> <right> <bottom>.\n        \"\"\"\n        self._imageName = imageName\n        self._typeCoordinates = typeCoordinates\n        if typeCoordinates == CoordinatesType.Relative and imgSize is None:\n            raise IOError(\n                'Parameter \\'imgSize\\' is required. It is necessary to inform the image size.')\n        if bbType == BBType.Detected and classConfidence is None:\n            raise IOError(\n                'For bbType=\\'Detection\\', it is necessary to inform the classConfidence value.')"
        },
        {
            "comment": "This function converts relative bounding box coordinates to absolute values and assigns them to the object. If the given format is XYWH, it adjusts the width and height accordingly. For absolute coordinates, it directly assigns the provided values. If the format does not match XYWH for relative coordinates, an IOError is raised.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":182-206",
            "content": "        self._classConfidence = classConfidence\n        self._bbType = bbType\n        self._classId = classId\n        self._format = format\n        # If relative coordinates, convert to absolute values\n        # For relative coords: (x,y,w,h)=(X_center/img_width , Y_center/img_height)\n        if typeCoordinates == CoordinatesType.Relative:\n            (self._x, self._y, self._w, self._h) = convertToAbsoluteValues(imgSize, (x, y, w, h))\n            self._width_img = imgSize[0]\n            self._height_img = imgSize[1]\n            if format == BBFormat.XYWH:\n                self._x2 = self._w\n                self._y2 = self._h\n                self._w = self._x2 - self._x\n                self._h = self._y2 - self._y\n            else:\n                raise IOError(\n                    'For relative coordinates, the format must be XYWH (x,y,width,height)')\n        # For absolute coords: (x,y,w,h)=real bb coords\n        else:\n            self._x = x\n            self._y = y\n            if format == BBFormat.XYWH:\n                self._w = w"
        },
        {
            "comment": "The code defines a class with methods to handle bounding box formats. It supports two formats: XYWH and XYX2Y2. The constructor initializes the bounding box dimensions and image size if provided. The getAbsoluteBoundingBox method returns the bounding box coordinates based on the format specified. If no image size is available, getRelativeBoundingBox requires the imgSize parameter to determine the absolute position of the bounding box.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":207-231",
            "content": "                self._h = h\n                self._x2 = self._x + self._w\n                self._y2 = self._y + self._h\n            else:  # format == BBFormat.XYX2Y2: <left> <top> <right> <bottom>.\n                self._x2 = w\n                self._y2 = h\n                self._w = self._x2 - self._x\n                self._h = self._y2 - self._y\n        if imgSize is None:\n            self._width_img = None\n            self._height_img = None\n        else:\n            self._width_img = imgSize[0]\n            self._height_img = imgSize[1]\n    def getAbsoluteBoundingBox(self, format=None):\n        if format == BBFormat.XYWH:\n            return self._x, self._y, self._w, self._h\n        elif format == BBFormat.XYX2Y2:\n            return self._x, self._y, self._x2, self._y2\n    def getRelativeBoundingBox(self, imgSize=None):\n        if imgSize is None and self._width_img is None and self._height_img is None:\n            raise IOError(\n                'Parameter \\'imgSize\\' is required. It is necessary to inform the image size.')"
        },
        {
            "comment": "This code defines a class with various getter methods to access different attributes of the detection result. The class also contains a static method compare() that takes two detections as input and compares them using absolute bounding boxes and image sizes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":232-265",
            "content": "        if imgSize is None:\n            return convertToRelativeValues((imgSize[0], imgSize[1]),\n                                           (self._x, self._y, self._w, self._h))\n        else:\n            return convertToRelativeValues((self._width_img, self._height_img),\n                                           (self._x, self._y, self._w, self._h))\n    def getImageName(self):\n        return self._imageName\n    def getConfidence(self):\n        return self._classConfidence\n    def getFormat(self):\n        return self._format\n    def getClassId(self):\n        return self._classId\n    def getImageSize(self):\n        return self._width_img, self._height_img\n    def getCoordinatesType(self):\n        return self._typeCoordinates\n    def getBBType(self):\n        return self._bbType\n    @staticmethod\n    def compare(det1, det2):\n        det1BB = det1.getAbsoluteBoundingBox(format=BBFormat.XYWH)\n        det1ImgSize = det1.getImageSize()\n        det2BB = det2.getAbsoluteBoundingBox(format=BBFormat.XYWH)\n        det2ImgSize = det2.getImageSize()"
        },
        {
            "comment": "The code snippet compares two bounding boxes to check if they match by comparing their class IDs, coordinates, and image sizes. If the conditions are met, it returns True; otherwise, False. The static method `clone` creates a new bounding box with the same properties as an existing one, allowing for easy cloning of bounding boxes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":267-293",
            "content": "        if det1.getClassId() == det2.getClassId() and \\\n                det1.classConfidence == det2.classConfidenc() and \\\n                det1BB[0] == det2BB[0] and \\\n                det1BB[1] == det2BB[1] and \\\n                det1BB[2] == det2BB[2] and \\\n                det1BB[3] == det2BB[3] and \\\n                det1ImgSize[0] == det1ImgSize[0] and \\\n                det2ImgSize[1] == det2ImgSize[1]:\n            return True\n        return False\n    @staticmethod\n    def clone(boundingBox):\n        absBB = boundingBox.getAbsoluteBoundingBox(format=BBFormat.XYWH)\n        newBoundingBox = BoundingBox(\n            boundingBox.getImageName(),\n            boundingBox.getClassId(),\n            absBB[0],\n            absBB[1],\n            absBB[2],\n            absBB[3],\n            typeCoordinates=boundingBox.getCoordinatesType(),\n            imgSize=boundingBox.getImageSize(),\n            bbType=boundingBox.getBBType(),\n            classConfidence=boundingBox.getConfidence(),\n            format=BBFormat.XYWH)\n        return newBoundingBox"
        },
        {
            "comment": "This class represents a collection of bounding boxes with methods to add, remove, and retrieve bounding boxes based on their type or class. It also provides functionality to retrieve all classes present in the bounding boxes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":296-331",
            "content": "class BoundingBoxes:\n    def __init__(self):\n        self._boundingBoxes = []\n    def addBoundingBox(self, bb):\n        self._boundingBoxes.append(bb)\n    def removeBoundingBox(self, _boundingBox):\n        for d in self._boundingBoxes:\n            if BoundingBox.compare(d, _boundingBox):\n                del self._boundingBoxes[d]\n                return\n    def removeAllBoundingBoxes(self):\n        self._boundingBoxes = []\n    def getBoundingBoxes(self):\n        return self._boundingBoxes\n    def getBoundingBoxByClass(self, classId):\n        boundingBoxes = []\n        for d in self._boundingBoxes:\n            if d.getClassId() == classId:  # get only specified bounding box type\n                boundingBoxes.append(d)\n        return boundingBoxes\n    def getClasses(self):\n        classes = []\n        for d in self._boundingBoxes:\n            c = d.getClassId()\n            if c not in classes:\n                classes.append(c)\n        return classes\n    def getBoundingBoxesByType(self, bbType):\n        # get only specified bb type"
        },
        {
            "comment": "Function `getBoundingBoxesByBBType` returns a list of bounding boxes with the specified BB type.\nFunction `getBoundingBoxesByImageName` returns a list of bounding boxes for the given image name.\nMethod `count` counts and returns the number of bounding boxes with the specified BB type, or all bounding boxes if no type is provided.\nMethod `clone` creates a new instance of BoundingBoxes and adds clones of each bounding box from the original instance.\nFunction `drawAllBoundingBoxes` draws all bounding boxes for the given image name on the specified image, only ground truth bounding boxes are drawn in green color.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":332-358",
            "content": "        return [d for d in self._boundingBoxes if d.getBBType() == bbType]\n    def getBoundingBoxesByImageName(self, imageName):\n        # get only specified bb type\n        return [d for d in self._boundingBoxes if d.getImageName() == imageName]\n    def count(self, bbType=None):\n        if bbType is None:  # Return all bounding boxes\n            return len(self._boundingBoxes)\n        count = 0\n        for d in self._boundingBoxes:\n            if d.getBBType() == bbType:  # get only specified bb type\n                count += 1\n        return count\n    def clone(self):\n        newBoundingBoxes = BoundingBoxes()\n        for d in self._boundingBoxes:\n            det = BoundingBox.clone(d)\n            newBoundingBoxes.addBoundingBox(det)\n        return newBoundingBoxes\n    def drawAllBoundingBoxes(self, image, imageName):\n        bbxes = self.getBoundingBoxesByImageName(imageName)\n        for bb in bbxes:\n            if bb.getBBType() == BBType.GroundTruth:  # if ground truth\n                image = add_bb_into_image(image, bb, color=(0, 255, 0))  # green"
        },
        {
            "comment": "The code defines a function `GetPascalVOCMetrics` within the `Evaluator` class to calculate metrics for Pascal VOC Challenge. It takes `boundingboxes`, `IOUThreshold`, and `method` as input parameters. The method can be set as `EveryPointInterpolation` or `ElevenPointInterpolation`. This function calculates precision, recall, F1 score, and AP metric using the provided parameters for Pascal VOC Challenge evaluation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":359-379",
            "content": "            else:  # if detection\n                image = add_bb_into_image(image, bb, color=(255, 0, 0))  # red\n        return image\nclass Evaluator:\n    def GetPascalVOCMetrics(self,\n                            boundingboxes,\n                            IOUThreshold=0.5,\n                            method=None):\n        \"\"\"Get the metrics used by the VOC Pascal 2012 challenge.\n        Get\n        Args:\n            boundingboxes: Object of the class BoundingBoxes representing ground truth and detected\n            bounding boxes;\n            IOUThreshold: IOU threshold indicating which detections will be considered TP or FP\n            (default value = 0.5);\n            method (default = EveryPointInterpolation): It can be calculated as the implementation\n            in the official PASCAL VOC toolkit (EveryPointInterpolation), or applying the 11-point\n            interpolatio as described in the paper \"The PASCAL Visual Object Classes(VOC) Challenge\"\n            or EveryPointInterpolation\"  (ElevenPointInterpolation);"
        },
        {
            "comment": "The function returns a list of dictionaries, each containing information and metrics of each class. The keys include class representation, precision values, recall values, average precision, interpolated precision, interpolated recall, total positives, total true positives, and total false positives. It initializes an empty list \"ret\" to store the metrics for each class, as well as groundTruths and detection lists.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":380-396",
            "content": "        Returns:\n            A list of dictionaries. Each dictionary contains information and metrics of each class.\n            The keys of each dictionary are:\n            dict['class']: class representing the current dictionary;\n            dict['precision']: array with the precision values;\n            dict['recall']: array with the recall values;\n            dict['AP']: average precision;\n            dict['interpolated precision']: interpolated precision values;\n            dict['interpolated recall']: interpolated recall values;\n            dict['total positives']: total number of ground truth positives;\n            dict['total TP']: total number of True Positive detections;\n            dict['total FP']: total number of False Negative detections;\n        \"\"\"\n        ret = []  # list containing metrics (precision, recall, average precision) of each class\n        # List with all ground truths (Ex: [imageName,class,confidence=1, (bb coordinates XYX2Y2)])\n        groundTruths = []\n        # List with all detections (Ex: [imageName,class,confidence,(bb coordinates XYX2Y2)])"
        },
        {
            "comment": "The code initializes empty lists for detections and classes, then iterates through all bounding boxes. It separates ground truth (GT) bounding boxes from detections, appending them to their respective lists with additional information such as image name, class ID, confidence, and bounding box coordinates. It also keeps track of unique classes and sorts them. The code will then use these lists and sorted classes for precision-recall calculations by individual classes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":397-421",
            "content": "        detections = []\n        # Get all classes\n        classes = []\n        # Loop through all bounding boxes and separate them into GTs and detections\n        for bb in boundingboxes.getBoundingBoxes():\n            # [imageName, class, confidence, (bb coordinates XYX2Y2)]\n            if bb.getBBType() == BBType.GroundTruth:\n                groundTruths.append([\n                    bb.getImageName(),\n                    bb.getClassId(), 1,\n                    bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n                ])\n            else:\n                detections.append([\n                    bb.getImageName(),\n                    bb.getClassId(),\n                    bb.getConfidence(),\n                    bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n                ])\n            # get class\n            if bb.getClassId() not in classes:\n                classes.append(bb.getClassId())\n        classes = sorted(classes)\n        # Precision x Recall is obtained individually by each class\n        # Loop through by classes"
        },
        {
            "comment": "Iterating through classes, the code collects detections and ground truths for each class. It then calculates the number of positive ground truths (npos), sorts detections by confidence level, and initializes True Positive (TP) and False Positive (FP) arrays. The code creates a dictionary to store the amount of ground truths per image, and iterates through detections to find corresponding ground truth images, calculating Intersection over Union (IoU) between detection and ground truth bounding boxes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":422-444",
            "content": "        for c in classes:\n            # Get only detection of class c\n            dects = []\n            [dects.append(d) for d in detections if d[1] == c]\n            # Get only ground truths of class c\n            gts = []\n            [gts.append(g) for g in groundTruths if g[1] == c]\n            npos = len(gts)\n            # sort detections by decreasing confidence\n            dects = sorted(dects, key=lambda conf: conf[2], reverse=True)\n            TP = np.zeros(len(dects))\n            FP = np.zeros(len(dects))\n            # create dictionary with amount of gts for each image\n            det = Counter([cc[0] for cc in gts])\n            for key, val in det.items():\n                det[key] = np.zeros(val)\n            # Loop through detections\n            for d in range(len(dects)):\n                # Find ground truth image\n                gt = [gt for gt in gts if gt[0] == dects[d][0]]\n                iouMax = sys.float_info.min\n                for j in range(len(gt)):\n                    iou = Evaluator.iou(dects[d][3], gt[j][3])"
        },
        {
            "comment": "This code calculates true positives, false positives, and computes precision, recall, and average precision. It checks if a detected object overlaps with ground truth objects using IOU threshold. If the overlap is within the threshold, it counts as a true positive or false positive depending on whether the object has already been marked 'seen'. Finally, based on the method chosen (EveryPointInterpolation in this case), it calls the appropriate average precision calculation function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":445-464",
            "content": "                    if iou > iouMax:\n                        iouMax = iou\n                        jmax = j\n                # Assign detection as true positive/don't care/false positive\n                if iouMax >= IOUThreshold:\n                    if det[dects[d][0]][jmax] == 0:\n                        TP[d] = 1  # count as true positive\n                        det[dects[d][0]][jmax] = 1  # flag as already 'seen'\n                    else:\n                        FP[d] = 1  # count as false positive\n                # - A detected \"cat\" is overlaped with a GT \"cat\" with IOU >= IOUThreshold.\n                else:\n                    FP[d] = 1  # count as false positive\n            # compute precision, recall and average precision\n            acc_FP = np.cumsum(FP)\n            acc_TP = np.cumsum(TP)\n            rec = acc_TP / npos\n            prec = np.divide(acc_TP, (acc_FP + acc_TP))\n            # Depending on the method, call the right implementation\n            if method == MethodAveragePrecision.EveryPointInterpolation:"
        },
        {
            "comment": "Calculates average precision for each class using CalculateAveragePrecision or ElevenPointInterpolatedAP depending on the input. Appends the results to a dictionary, then adds the dictionary to a list and returns it.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":465-494",
            "content": "                [ap, mpre, mrec, ii] = Evaluator.CalculateAveragePrecision(rec, prec)\n            else:\n                [ap, mpre, mrec, _] = Evaluator.ElevenPointInterpolatedAP(rec, prec)\n            # add class result in the dictionary to be returned\n            r = {\n                'class': c,\n                'precision': prec,\n                'recall': rec,\n                'AP': ap,\n                'interpolated precision': mpre,\n                'interpolated recall': mrec,\n                'total positives': npos,\n                'total TP': np.sum(TP),\n                'total FP': np.sum(FP)\n            }\n            ret.append(r)\n        return ret\n    @staticmethod\n    def CalculateAveragePrecision(rec, prec):\n        mrec = [0]\n        [mrec.append(e) for e in rec]\n        mrec.append(1)\n        mpre = [0]\n        [mpre.append(e) for e in prec]\n        mpre.append(0)\n        for i in range(len(mpre) - 1, 0, -1):\n            mpre[i - 1] = max(mpre[i - 1], mpre[i])\n        ii = []\n        for i in range(len(mrec) - 1):"
        },
        {
            "comment": "The code calculates the 11-point interpolated average precision (AP) between recall and precision values. It first appends recall and precision lists in reverse order, then creates a list of recall values from 0 to 1 in reverse order. Next, it iterates over these recall values, finding all recall values greater than or equal to the current value and selecting the maximum precision at that index. Finally, it returns the interpolated AP by summing the maximum precisions for each recall value and dividing by 11. The resulting AP values are stored in a list along with the original recall and precision lists, as well as an indicator list of indices where the recall values were greater than or equal to the current recall value.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":495-522",
            "content": "            if mrec[1:][i] != mrec[0:-1][i]:\n                ii.append(i + 1)\n        ap = 0\n        for i in ii:\n            ap = ap + np.sum((mrec[i] - mrec[i - 1]) * mpre[i])\n        return [ap, mpre[0:len(mpre) - 1], mrec[0:len(mpre) - 1], ii]\n    @staticmethod\n    # 11-point interpolated average precision\n    def ElevenPointInterpolatedAP(rec, prec):\n        mrec = []\n        [mrec.append(e) for e in rec]\n        mpre = []\n        [mpre.append(e) for e in prec]\n        recallValues = np.linspace(0, 1, 11)\n        recallValues = list(recallValues[::-1])\n        rhoInterp = []\n        recallValid = []\n        for r in recallValues:\n            # Obtain all recall values higher or equal than r\n            argGreaterRecalls = np.argwhere(mrec[:] >= r)\n            pmax = 0\n            # If there are recalls above r\n            if argGreaterRecalls.size != 0:\n                pmax = max(mpre[argGreaterRecalls.min():])\n            recallValid.append(r)\n            rhoInterp.append(pmax)\n        # By definition AP = sum(max(precision whose recall is above r))/11"
        },
        {
            "comment": "The code calculates average precision (AP) and Area Under Curve (AUC), then generates recall and precision values for a plot. It also defines a method to calculate the Intersection over Union (IoU) between reference and detection bounding boxes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":523-552",
            "content": "        ap = sum(rhoInterp) / 11\n        # Generating values for the plot\n        rvals = [recallValid[0]]\n        [rvals.append(e) for e in recallValid]\n        rvals.append(0)\n        pvals = [0]\n        [pvals.append(e) for e in rhoInterp]\n        pvals.append(0)\n        # rhoInterp = rhoInterp[::-1]\n        cc = []\n        for i in range(len(rvals)):\n            p = (rvals[i], pvals[i - 1])\n            if p not in cc:\n                cc.append(p)\n            p = (rvals[i], pvals[i])\n            if p not in cc:\n                cc.append(p)\n        recallValues = [i[0] for i in cc]\n        rhoInterp = [i[1] for i in cc]\n        return [ap, rhoInterp, recallValues, None]\n    # For each detections, calculate IOU with reference\n    @staticmethod\n    def _getAllIOUs(reference, detections):\n        ret = []\n        bbReference = reference.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n        # img = np.zeros((200,200,3), np.uint8)\n        for d in detections:\n            bb = d.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n            iou = Evaluator.iou(bbReference, bb)"
        },
        {
            "comment": "The code calculates the IoU (intersection over union) between two bounding boxes, and returns a list of detection results sorted by IoU in descending order. It also includes utility methods to check if two boxes intersect and calculate the intersection area.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":553-582",
            "content": "            ret.append((iou, reference, d))  # iou, reference, detection\n        return sorted(ret, key=lambda i: i[0], reverse=True)  # sort by iou (from highest to lowest)\n    @staticmethod\n    def iou(boxA, boxB):\n        # if boxes dont intersect\n        if Evaluator._boxesIntersect(boxA, boxB) is False:\n            return 0\n        interArea = Evaluator._getIntersectionArea(boxA, boxB)\n        union = Evaluator._getUnionAreas(boxA, boxB, interArea=interArea)\n        # intersection over union\n        iou = interArea / union\n        assert iou >= 0\n        return iou\n    @staticmethod\n    def _boxesIntersect(boxA, boxB):\n        if boxA[0] > boxB[2]:\n            return False  # boxA is right of boxB\n        if boxB[0] > boxA[2]:\n            return False  # boxA is left of boxB\n        if boxA[3] < boxB[1]:\n            return False  # boxA is above boxB\n        if boxA[1] > boxB[3]:\n            return False  # boxA is below boxB\n        return True\n    @staticmethod\n    def _getIntersectionArea(boxA, boxB):\n        xA = max(boxA[0], boxB[0])"
        },
        {
            "comment": "This code contains functions to calculate intersection and union areas of two bounding boxes, and two validation functions for argument formats and mandatory arguments. The ValidateFormats function checks if the format is 'xywh', 'xyrb' or None (default) and returns a corresponding BBFormat type. The ValidateMandatoryArgs function checks if an argument exists and appends an error message to 'errors' if it doesn't meet the requirements.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":583-616",
            "content": "        yA = max(boxA[1], boxB[1])\n        xB = min(boxA[2], boxB[2])\n        yB = min(boxA[3], boxB[3])\n        # intersection area\n        return (xB - xA + 1) * (yB - yA + 1)\n    @staticmethod\n    def _getUnionAreas(boxA, boxB, interArea=None):\n        area_A = Evaluator._getArea(boxA)\n        area_B = Evaluator._getArea(boxB)\n        if interArea is None:\n            interArea = Evaluator._getIntersectionArea(boxA, boxB)\n        return float(area_A + area_B - interArea)\n    @staticmethod\n    def _getArea(box):\n        return (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n# Validate formats\ndef ValidateFormats(argFormat, argName, errors):\n    if argFormat == 'xywh':\n        return BBFormat.XYWH\n    elif argFormat == 'xyrb':\n        return BBFormat.XYX2Y2\n    elif argFormat is None:\n        return BBFormat.XYWH  # default when nothing is passed\n    else:\n        errors.append(\n            'argument %s: invalid value. It must be either \\'xywh\\' or \\'xyrb\\'' % argName)\n# Validate mandatory args\ndef ValidateMandatoryArgs(arg, argName, errors):"
        },
        {
            "comment": "This code defines a function ValidateImageSize that checks if the image size argument is valid. It appends error messages to the errors list if the argument is missing or not in the correct format 'width,height'. The function also handles the case where the argument is relative and requires both width and height to be integers. Finally, it returns a tuple of (width, height) if valid. Additionally, there's a ValidateCoordinatesTypes function that checks if the coordinate type argument is valid and returns the CoordinatesType.Absolute if 'abs'.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":617-647",
            "content": "    if arg is None:\n        errors.append('argument %s: required argument' % argName)\n    else:\n        return True\ndef ValidateImageSize(arg, argName, argInformed, errors):\n    errorMsg = 'argument %s: required argument if %s is relative' % (argName, argInformed)\n    ret = None\n    if arg is None:\n        errors.append(errorMsg)\n    else:\n        arg = arg.replace('(', '').replace(')', '')\n        args = arg.split(',')\n        if len(args) != 2:\n            errors.append(\n                '%s. It must be in the format \\'width,height\\' (e.g. \\'600,400\\')' % errorMsg)\n        else:\n            if not args[0].isdigit() or not args[1].isdigit():\n                errors.append(\n                    '%s. It must be in INdiaTEGER the format \\'width,height\\' (e.g. \\'600,400\\')' %\n                    errorMsg)\n            else:\n                ret = (int(args[0]), int(args[1]))\n    return ret\n# Validate coordinate types\ndef ValidateCoordinatesTypes(arg, argName, errors):\n    if arg == 'abs':\n        return CoordinatesType.Absolute"
        },
        {
            "comment": "This code reads text files containing bounding boxes (ground truth and detections). It handles 'relative' or 'absolute' coordinates, and checks for invalid arguments. The function takes a directory, image format, and coordinate type as inputs, and returns bounding boxes and classes. If allBoundingBoxes or allClasses are None, it initializes them. It changes the working directory to the specified directory and reads all files in alphabetical order.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":648-679",
            "content": "    elif arg == 'rel':\n        return CoordinatesType.Relative\n    elif arg is None:\n        return CoordinatesType.Absolute  # default when nothing is passed\n    errors.append('argument %s: invalid value. It must be either \\'rel\\' or \\'abs\\'' % argName)\ndef getBoundingBoxes(directory,\n                     isGT,\n                     bbFormat,\n                     coordType,\n                     allBoundingBoxes=None,\n                     allClasses=None,\n                     imgSize=(0, 0)):\n    \"\"\"Read txt files containing bounding boxes (ground truth and detections).\"\"\"\n    print(directory)\n    if allBoundingBoxes is None:\n        allBoundingBoxes = BoundingBoxes()\n    if allClasses is None:\n        allClasses = []\n    # Read ground truths\n    os.chdir(directory)\n    files = glob.glob(\"*.txt\")\n    files.sort()\n    for f in files:\n        nameOfImage = f.replace(\".txt\", \"\")\n        fh1 = open(f, \"r\")\n        for line in fh1:\n            line = line.replace(\"\\n\", \"\")\n            if line.replace(' ', '') == '':\n                continue"
        },
        {
            "comment": "This code reads a line of text and determines whether it represents ground truth or predicted bounding boxes. It then initializes BoundingBox objects with the appropriate attributes based on the type (ground truth or prediction) and stores them accordingly.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":680-710",
            "content": "            splitLine = line.split(\" \")\n            if isGT:\n                idClass = (splitLine[0])  # class\n                x = float(splitLine[1])\n                y = float(splitLine[2])\n                w = float(splitLine[3])\n                h = float(splitLine[4])\n                bb = BoundingBox(\n                    nameOfImage,\n                    idClass,\n                    x,\n                    y,\n                    w,\n                    h,\n                    coordType,\n                    imgSize,\n                    BBType.GroundTruth,\n                    format=bbFormat)\n            else:\n                idClass = (splitLine[0])  # class\n                confidence = float(splitLine[1])\n                x = float(splitLine[2])\n                y = float(splitLine[3])\n                w = float(splitLine[4])\n                h = float(splitLine[5])\n                bb = BoundingBox(\n                    nameOfImage,\n                    idClass,\n                    x,\n                    y,\n                    w,"
        },
        {
            "comment": "The code defines a function to calculate the mean average precision (mAP) between ground truth and detected objects in image classification tasks. It takes input folders containing ground truth and detection results, adjustable threshold for determining true positives, and an optional save path for the output file. The code performs argument validation to ensure correct formats and coordinate types.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":711-742",
            "content": "                    h,\n                    coordType,\n                    imgSize,\n                    BBType.Detected,\n                    confidence,\n                    format=bbFormat)\n            allBoundingBoxes.addBoundingBox(bb)\n            if idClass not in allClasses:\n                allClasses.append(idClass)\n        fh1.close()\n    return allBoundingBoxes, allClasses\ndef get_mAP(gtFolder, detFolder, threshold=0.5, savePath=None):\n    gtFormat = 'xyrb'\n    detFormat = 'xyrb'\n    gtCoordinates = 'abs'\n    detCoordinates = 'abs'\n    gtFolder = os.path.join(os.path.abspath('.'), gtFolder)\n    detFolder = os.path.join(os.path.abspath('.'), detFolder)\n    iouThreshold = threshold\n    # Arguments validation\n    errors = []\n    # Validate formats\n    gtFormat = ValidateFormats(gtFormat, 'gtFormat', errors)\n    detFormat = ValidateFormats(detFormat, '-detformat', errors)\n    # Coordinates types\n    gtCoordType = ValidateCoordinatesTypes(gtCoordinates, '-gtCoordinates', errors)\n    detCoordType = ValidateCoordinatesTypes(detCoordinates, '-detCoordinates', errors)"
        },
        {
            "comment": "This code is creating a directory to save results, clearing any previous content in the folder. It then retrieves ground truth and detected bounding boxes, sorts classes, initializes an evaluator object, and calculates average precision (AP) for each class, storing the AP and mean AP results in the AP_res list.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":743-771",
            "content": "    imgSize = (0, 0)\n    # Create directory to save results\n    shutil.rmtree(savePath, ignore_errors=True)  # Clear folder\n    if savePath is not None:\n        os.makedirs(savePath)\n    # Get groundtruth boxes\n    allBoundingBoxes, allClasses = getBoundingBoxes(\n        gtFolder, True, gtFormat, gtCoordType, imgSize=imgSize)\n    # Get detected boxes\n    allBoundingBoxes, allClasses = getBoundingBoxes(\n        detFolder, False, detFormat, detCoordType, allBoundingBoxes, allClasses, imgSize=imgSize)\n    allClasses.sort()\n    evaluator = Evaluator()\n    acc_AP = 0\n    validClasses = 0\n    # Plot Precision x Recall curve\n    detections = evaluator.GetPascalVOCMetrics(allBoundingBoxes, iouThreshold,\n                                               method=MethodAveragePrecision.EveryPointInterpolation)\n    # each detection is a class and store AP and mAP results in AP_res list\n    AP_res = []\n    for metricsPerClass in detections:\n        # Get metric values per each class\n        cl = metricsPerClass['class']\n        ap = metricsPerClass['AP']"
        },
        {
            "comment": "This code calculates mean Average Precision (mAP) for each class and returns it as a list. It iterates through valid classes, calculates Average Precision (AP) for each class if there are positive samples, updates mAP by averaging APs of all valid classes, and appends AP and class labels to the result list. The final mAP value is also formatted and added to the result list before returning it.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/ucf24_utils.py\":772-782",
            "content": "        totalPositives = metricsPerClass['total positives']\n        if totalPositives > 0:\n            validClasses = validClasses + 1\n            acc_AP = acc_AP + ap\n            ap_str = \"{0:.2f}%\".format(ap * 100)\n            AP_res.append('AP: %s (%s)' % (ap_str, cl))\n    mAP = acc_AP / validClasses\n    mAP_str = \"{0:.2f}%\".format(mAP * 100)\n    AP_res.append('mAP: %s' % mAP_str)\n    return AP_res"
        }
    ]
}