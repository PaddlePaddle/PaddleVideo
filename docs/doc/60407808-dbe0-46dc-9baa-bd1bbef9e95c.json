{
    "summary": "PaddleVideo is a Python library for advanced video processing, featuring industry-specific models and data production to deployment pipeline support. The documentation includes sections on distillation, inference deployment, datasets, application scenarios, and licensing information (Apache 2.0).",
    "details": [
        {
            "comment": "PaddleVideo is a Python library for advanced video processing, providing extensive and cutting-edge tools to assist researchers and industry professionals in the field of computer vision. The recent updates include an open-source video annotation tool (BILS), a lightweight action recognition model (PP-TSMv2), knowledge distillation functionality, transformer-based models, and single-stage action detection models (YOWO).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/README.md\":0-21",
            "content": "[English](README_en.md) | \u4e2d\u6587\n# PaddleVideo\n![python version](https://img.shields.io/badge/python-3.7+-orange.svg) ![paddle version](https://img.shields.io/badge/PaddlePaddle-2.3.1-blue)\n## \u7b80\u4ecb\nPaddleVideo\u65e8\u5728\u6253\u9020\u4e00\u5957\u4e30\u5bcc\u3001\u9886\u5148\u4e14\u5b9e\u7528\u7684Video\u5de5\u5177\u5e93\uff0c\u65e8\u5728\u5e2e\u52a9\u5f00\u53d1\u8005\u66f4\u597d\u7684\u8fdb\u884c\u89c6\u9891\u9886\u57df\u7684\u5b66\u672f\u7814\u7a76\u548c\u4ea7\u4e1a\u5b9e\u8df5\u3002\n<div align=\"center\">\n  <img src=\"docs/images/home.gif\" width=\"450px\"/><br>\n</div>\n## \u8fd1\u671f\u66f4\u65b0\n- \u5f00\u6e90\u89c6\u9891\u6807\u6ce8\u5de5\u5177\ud83c\udf1f[BILS](./docs/zh-CN/annotation_tools.md)\uff0c\u6b22\u8fce\u4e0b\u8f7d\u5b89\u88c5\u5305\u4f53\u9a8c\uff5e\n- \u53d1\u5e03\u8f7b\u91cf\u5316\u884c\u4e3a\u8bc6\u522b\u6a21\u578b**\ud83d\udd25[PP-TSMv2](./docs/zh-CN/model_zoo/recognition/pp-tsm_v2.md)**, Kinetics-400\u7cbe\u5ea675.16%\uff0c25fps\u768410s\u89c6\u9891cpu\u63a8\u7406\u65f6\u95f4\u4ec5\u9700456ms.\u5404\u6a21\u578b\u6027\u80fd\u5bf9\u6bd4[benchmark](./docs/zh-CN/benchmark.md).\n- \u65b0\u589e[\u77e5\u8bc6\u84b8\u998f](./docs/zh-CN/distillation.md)\u529f\u80fd.\n- \u65b0\u589e\u57fa\u4e8etransformer\u7684\u884c\u4e3a\u8bc6\u522b\u6a21\u578b[TokenShift](https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/model_zoo/recognition/tokenshift_transformer.md).\n- \u65b0\u589e\u57fa\u4e8e\u9aa8\u9abc\u70b9\u7684\u884c\u4e3a\u8bc6\u522b\u6a21\u578b[2s-ACGN](https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/model_zoo/recognition/agcn2s.md)\u3001[CTR-GCN](./docs/zh-CN/model_zoo/recognition/ctrgcn.md).\n- \u65b0\u589e\u5355\u9636\u6bb5\u65f6\u7a7a\u52a8\u4f5c\u68c0\u6d4b\u6a21\u578b[YOWO](./docs/zh-CN/model_zoo/localization/yowo.md)."
        },
        {
            "comment": "This code is for PaddleVideo, a series of industry-level video technology and application case courses. It supports various video cutting-edge algorithms, creates industry-specific models PP-TSM and PP-TSMv2, and covers the entire data production, model training, compression, and deployment pipeline. The code provides quick start instructions, scene application examples, and documentation for tutorials on different topics such as recognition, model library, and model compression. It also includes links to join discussion groups and course replay.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/README.md\":24-57",
            "content": "\ud83d\udc40 \ud83c\udf1f  **\u300a\u4ea7\u4e1a\u7ea7\u89c6\u9891\u6280\u672f\u4e0e\u5e94\u7528\u6848\u4f8b\u300b\u7cfb\u5217\u8bfe\u7a0b\u56de\u653e\u94fe\u63a5**:  https://aistudio.baidu.com/aistudio/course/introduce/6742 \ud83c\udf1f\n\u200b\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \ud83d\udc96 **\u6b22\u8fce\u5927\u5bb6\u626b\u7801\u5165\u7fa4\u8ba8\u8bba** \ud83d\udc96\n<div align=\"center\">\n  <img src=\"docs/images/user_group.png\" width=250/></div>\n- \u6dfb\u52a0\u6210\u529f\u540e\u56de\u590d\u3010\u89c6\u9891\u3011\u52a0\u5165\u4ea4\u6d41\u7fa4\n## \u7279\u6027\n\u652f\u6301\u591a\u79cdVideo\u76f8\u5173\u524d\u6cbf\u7b97\u6cd5\uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u6253\u9020\u4ea7\u4e1a\u7ea7\u7279\u8272\u6a21\u578b[PP-TSM](docs/zh-CN/model_zoo/recognition/pp-tsm.md)\u548c[PP-TSMv2](docs/zh-CN/model_zoo/recognition/pp-tsm_v2.md)\uff0c\u5e76\u6253\u901a\u6570\u636e\u751f\u4ea7\u3001\u6a21\u578b\u8bad\u7ec3\u3001\u538b\u7f29\u3001\u9884\u6d4b\u90e8\u7f72\u5168\u6d41\u7a0b\u3002\n<div align=\"center\">\n    <img src=\"./docs/images/features.png\" width=\"700\">\n</div>\n## \u5feb\u901f\u5f00\u59cb\n- \u4e00\u884c\u547d\u4ee4\u5feb\u901f\u4f7f\u7528: [\u5feb\u901f\u5f00\u59cb](./docs/zh-CN/quick_start.md)\n## \u573a\u666f\u5e94\u7528\nPaddleVideo\u573a\u666f\u5e94\u7528\u8986\u76d6\u4f53\u80b2\u3001\u4e92\u8054\u7f51\u3001\u5de5\u4e1a\u3001\u533b\u7597\u884c\u4e1a\uff0c\u5728PP-TSM\u7684\u57fa\u7840\u80fd\u529b\u4e4b\u4e0a\uff0c\u4ee5\u6848\u4f8b\u7684\u5f62\u5f0f\u5c55\u793a\u5229\u7528\u573a\u666f\u6570\u636e\u5fae\u8c03\u3001\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\u3001\u6570\u636e\u589e\u5e7f\u7b49\u5185\u5bb9\uff0c\u4e3a\u5f00\u53d1\u8005\u5b9e\u9645\u843d\u5730\u63d0\u4f9b\u793a\u8303\u4e0e\u542f\u53d1\u3002\u8be6\u60c5\u53ef\u67e5\u770b[\u5e94\u7528](./applications/)\u3002\n## \u6587\u6863\u6559\u7a0b\n- [\u5feb\u901f\u5f00\u59cb](./docs/zh-CN/quick_start.md)\n- [\u5b89\u88c5\u8bf4\u660e](./docs/zh-CN/install.md)\n- [\u8bad\u7ec3/\u6d4b\u8bd5/\u63a8\u7406\u5168\u6d41\u7a0b\u4f7f\u7528\u6307\u5357](./docs/zh-CN/usage.md)\n- [PP-TSM\u884c\u4e3a\u8bc6\u522b\ud83d\udd25](./docs/zh-CN/model_zoo/recognition/pp-tsm.md)\n  - [\u6a21\u578b\u5e93](./docs/zh-CN/model_zoo/recognition/pp-tsm.md#7)\n  - [\u6a21\u578b\u8bad\u7ec3](./docs/zh-CN/model_zoo/recognition/pp-tsm.md#4)\n  - [\u6a21\u578b\u538b\u7f29](./deploy/slim/)\n      - [\u6a21\u578b\u91cf\u5316](./deploy/slim/readme.md)"
        },
        {
            "comment": "This code provides a table of contents for the PaddleVideo documentation, including sections on distillation, inference deployment using Python and C++ engines, server-side deployment, converting to ONNX models, state-of-the-art algorithms and models, datasets, application scenarios, data labeling tools, competition support, contributing code, and licensing information (Apache 2.0).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/README.md\":58-74",
            "content": "      - [\u77e5\u8bc6\u84b8\u998f](./docs/zh-CN/distillation.md)\n  - [\u63a8\u7406\u90e8\u7f72](./deploy/)\n      - [\u57fa\u4e8ePython\u9884\u6d4b\u5f15\u64ce\u63a8\u7406](./docs/zh-CN/model_zoo/recognition/pp-tsm.md#62)\n      - [\u57fa\u4e8eC++\u9884\u6d4b\u5f15\u64ce\u63a8\u7406](./deploy/cpp_infer/readme.md)\n      - [\u670d\u52a1\u7aef\u90e8\u7f72](./deploy/python_serving/readme.md)\n      - [Paddle2ONNX\u6a21\u578b\u8f6c\u5316\u4e0e\u9884\u6d4b](./deploy/paddle2onnx/readme.md)\n      - [Benchmark](./docs/zh-CN/benchmark.md)\n- [\u524d\u6cbf\u7b97\u6cd5\u4e0e\u6a21\u578b](./docs/zh-CN/model_zoo/README.md)\ud83d\ude80\n- [\u6570\u636e\u96c6](./docs/zh-CN/dataset/README.md)\n- [\u573a\u666f\u5e94\u7528](./applications/README.md)\n- [\u6570\u636e\u6807\u6ce8](./docs/zh-CN/annotation_tools.md)\n- [\u8d5b\u4e8b\u652f\u6301](./docs/zh-CN/competition.md)\n- [\u8d21\u732e\u4ee3\u7801](./docs/zh-CN/contribute/README.md)\n## \u8bb8\u53ef\u8bc1\u4e66\n\u672c\u9879\u76ee\u7684\u53d1\u5e03\u53d7[Apache 2.0 license](LICENSE)\u8bb8\u53ef\u8ba4\u8bc1\u3002"
        }
    ]
}