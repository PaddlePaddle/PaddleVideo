{
    "summary": "The MetricsCalculator class in PaddleVideo's VideoTag application handles metric calculation, providing methods for finalizing, computing, and accumulating metrics. It calculates average loss and accuracy over multiple batches using a top-k accuracy function, accumulating per batch size before returning the final result.",
    "details": [
        {
            "comment": "This code is part of the PaddleVideo project's VideoTag application, and it defines a class called MetricsCalculator. It handles calculating various metrics for different modes such as train, val, or test. The code imports necessary libraries, initializes logger, and sets up the MetricsCalculator class with an initialization method (__init__) and a reset method to reset the metrics values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/kinetics/accuracy_metrics.py\":0-33",
            "content": "#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n#Licensed under the Apache License, Version 2.0 (the \"License\");\n#you may not use this file except in compliance with the License.\n#You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#Unless required by applicable law or agreed to in writing, software\n#distributed under the License is distributed on an \"AS IS\" BASIS,\n#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#See the License for the specific language governing permissions and\n#limitations under the License.\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nimport numpy as np\nimport datetime\nimport logging\nlogger = logging.getLogger(__name__)\nclass MetricsCalculator():\n    def __init__(self, name, mode):\n        self.name = name\n        self.mode = mode  # 'train', 'val', 'test'\n        self.reset()\n    def reset(self):\n        logger.info('Resetting {} metrics...'.format(self.mode))"
        },
        {
            "comment": "The class initializes variables for accumulating aggregated accuracy, loss, and batch size. The `finalize_metrics` method calculates average metrics by dividing the accumulated values by the total batch size. The `get_computed_metrics` returns a JSON object containing the average loss and accuracy for top 1 and top 5 predictions. The `calculate_metrics` computes the accuracy for top 1 and top 5 predictions, and the `accumulate` method accumulates the loss and updates the batch size if the returned loss is not None.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/kinetics/accuracy_metrics.py\":34-61",
            "content": "        self.aggr_acc1 = 0.0\n        self.aggr_acc5 = 0.0\n        self.aggr_loss = 0.0\n        self.aggr_batch_size = 0\n    def finalize_metrics(self):\n        self.avg_acc1 = self.aggr_acc1 / self.aggr_batch_size\n        self.avg_acc5 = self.aggr_acc5 / self.aggr_batch_size\n        self.avg_loss = self.aggr_loss / self.aggr_batch_size\n    def get_computed_metrics(self):\n        json_stats = {}\n        json_stats['avg_loss'] = self.avg_loss\n        json_stats['avg_acc1'] = self.avg_acc1\n        json_stats['avg_acc5'] = self.avg_acc5\n        return json_stats\n    def calculate_metrics(self, loss, softmax, labels):\n        accuracy1 = compute_topk_accuracy(softmax, labels, top_k=1) * 100.\n        accuracy5 = compute_topk_accuracy(softmax, labels, top_k=5) * 100.\n        return accuracy1, accuracy5\n    def accumulate(self, loss, softmax, labels):\n        cur_batch_size = softmax.shape[0]\n        # if returned loss is None for e.g. test, just set loss to be 0.\n        if loss is None:\n            cur_loss = 0.\n        else:"
        },
        {
            "comment": "This code calculates the average loss and accuracy over multiple batches. It uses a function called \"compute_topk_accuracy\" to calculate the accuracy for top 1 and top 5 predictions. The computed values are then accumulated per batch size, with the final result being returned.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/kinetics/accuracy_metrics.py\":62-89",
            "content": "            cur_loss = np.mean(np.array(loss))  #\n        self.aggr_batch_size += cur_batch_size\n        self.aggr_loss += cur_loss * cur_batch_size\n        accuracy1 = compute_topk_accuracy(softmax, labels, top_k=1) * 100.\n        accuracy5 = compute_topk_accuracy(softmax, labels, top_k=5) * 100.\n        self.aggr_acc1 += accuracy1 * cur_batch_size\n        self.aggr_acc5 += accuracy5 * cur_batch_size\n        return\n# ----------------------------------------------\n# other utils\n# ----------------------------------------------\ndef compute_topk_correct_hits(top_k, preds, labels):\n    '''Compute the number of corret hits'''\n    batch_size = preds.shape[0]\n    top_k_preds = np.zeros((batch_size, top_k), dtype=np.float32)\n    for i in range(batch_size):\n        top_k_preds[i, :] = np.argsort(-preds[i, :])[:top_k]\n    correctness = np.zeros(batch_size, dtype=np.int32)\n    for i in range(batch_size):\n        if labels[i] in top_k_preds[i, :].astype(np.int32).tolist():\n            correctness[i] = 1\n    correct_hits = sum(correctness)"
        },
        {
            "comment": "The function `compute_topk_accuracy` computes the top-k accuracy by first asserting that the batch size of labels and softmax are equal, then it computes the correct hits for each batch element using the `compute_topk_correct_hits` function. Finally, it normalizes the results and returns the computed metric as a float value representing accuracy.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/kinetics/accuracy_metrics.py\":91-106",
            "content": "    return correct_hits\ndef compute_topk_accuracy(softmax, labels, top_k):\n    computed_metrics = {}\n    assert labels.shape[0] == softmax.shape[0], \"Batch size mismatch.\"\n    aggr_batch_size = labels.shape[0]\n    aggr_top_k_correct_hits = compute_topk_correct_hits(top_k, softmax, labels)\n    # normalize results\n    computed_metrics = \\\n        float(aggr_top_k_correct_hits) / aggr_batch_size\n    return computed_metrics"
        }
    ]
}