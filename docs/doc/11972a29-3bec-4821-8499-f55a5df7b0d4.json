{
    "summary": "The SlowFast model, designed for video recognition, utilizes a Multigrid training strategy to speed up training and provides English documentation. It offers testing instructions using PaddleVideo with GPU usage details, retrieves class name from ID, predicts top1 result for \"example.avi\", and is explained in detail in the reference paper.",
    "details": [
        {
            "comment": "This code is the English version of SlowFast model documentation from PaddleVideo's model_zoo. It introduces SlowFast, a video recognition model that combines low and high frame rates for spatial semantic and motion information capture. The training script and data preparation are provided.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/slowfast.md\":0-37",
            "content": "[\u7b80\u4f53\u4e2d\u6587 ](../../../zh-CN/model_zoo/recognition/slowfast.md) | English\n# SlowFast\n---\n## Contents\n- [Introduction](#Introduction)\n- [Data](#Data)\n- [Train](#Train)\n- [Test](#Test)\n- [Inference](#Inference)\n- [Reference](#Reference)\n## Introduction\nSlowFast  involves (i) a Slow pathway, operating at low frame rate, to capture spatial semantics, and (ii) a Fast path-way, operating at high frame rate, to capture motion at fine temporal resolution. The Fast pathway can be made very lightweight by reducing its channel capacity, yet can learn useful temporal information for video recognition.\n<p align=\"center\">\n<img src=\"../../../images/SlowFast.png\" height=300 width=500 hspace='10'/> <br />\nSlowFast Overview\n</p>\n## Data\nWe use Kinetics-400 to train this model\uff0cdata preparation please refer to [Kinetics-400 dataset](../../dataset/k400.md).\n## Train\nYou can start training by\uff1a\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\npython -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_slowfast  main.py --validate -c configs/recognition/slowfast/slowfast.yaml"
        },
        {
            "comment": "This code implements Multigrid training strategy to speed up SlowFast model training, which is time-consuming. The provided training script and performance evaluation show that using the multigrid method reduces the training time by 2.89x compared to normal training. For more details, refer to the accelerate documentation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/slowfast.md\":38-57",
            "content": "```\n- Training would be efficent using our code. The training speed is 2x faster than the original implementation. Details can refer to [benchmark](https://github.com/PaddlePaddle/PaddleVideo/blob/main/docs/en/benchmark.md).\n### Speed up training\nIt's time consuming to train SlowFast model.  So we implement [Multigrid training stragety](https://arxiv.org/abs/1912.00998) to speed up training. Training script:\n```bash\npython -B -m paddle.distributed.launch --selected_gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log-slowfast main.py --validate --multigrid -c configs/recognition/slowfast/slowfast_multigrid.yaml\n```\nPerformance evaluation:\n| training stragety | time cost of one epoch/min | total training time/min | speed-up |\n| :------ | :-----: | :------: |:------: |\n| Multigrid | 27.25 |  9758 (6.7 days) | 2.89x |\n| Normal | 78.76 | 15438 (10.7days) | base |\nFor more details, please refer to [accelerate doc](https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/tutorials/accelerate.md#%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E5%8A%A0%E9%80%9F)."
        },
        {
            "comment": "This code provides instructions for testing the SlowFast model in PaddleVideo. It uses the distributed launch command to run on multiple GPUs, specifying the log directory and the model configuration file slowfast.yaml. The test accuracy for two configurations is also shown, with a note that Acc1 may be lower due to missing data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/slowfast.md\":60-78",
            "content": "## Test\nYou can start testing by\uff1a\n```bash\npython -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=log_slowfast_test main.py --test -c  configs/recognition/slowfast/slowfast.yaml -w output/SlowFast/SlowFast_epoch_000196.pdparams\n```\n-  Args `-w` is used to specifiy the model path\uff0cyou can download our model in [SlowFast.pdparams](https://videotag.bj.bcebos.com/PaddleVideo/SlowFast/SlowFast.pdparams).\nTest accuracy in Kinetics-400:\n| Configs | Acc1 | Acc5 | Weights |\n| :---: | :---: | :---: | :---: |\n|  [slowfast.yaml](../../../../configs/recognition/slowfast/slowfast.yaml) | 74.35 | 91.33 | [slowfast_4x16.pdparams](https://videotag.bj.bcebos.com/PaddleVideo/SlowFast/SlowFast.pdparams) |\n|  [slowfast_multigrid.yaml](../../../../configs/recognition/slowfast/slowfast_multigrid.yaml) | 75.84  | 92.33 | [slowfast_8x8.pdparams](https://videotag.bj.bcebos.com/PaddleVideo/SlowFast/SlowFast_8*8.pdparams) |\n- Acc1 may be lower than that released in papaer, as ~5% data of kinetics-400 is missing. Experiments have verified that if training with the same data, we can get the same accuracy."
        },
        {
            "comment": "This code provides instructions for exporting and using the SlowFast model in PaddleVideo. The first command generates the architecture file (SlowFast.pdmodel) and parameter file (SlowFast.pdiparams). The second command demonstrates how to run inference with these files on an input video, specifying the model configuration and enabling GPU usage if available. It outputs the top-1 class and score for the predicted results.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/slowfast.md\":81-111",
            "content": "## Inference\n### export inference model\n To get model architecture file `SlowFast.pdmodel` and parameters file `SlowFast.pdiparams`, use:\n```bash\npython3.7 tools/export_model.py -c configs/recognition/slowfast/slowfast.yaml \\\n                                -p data/SlowFast.pdparams \\\n                                -o inference/SlowFast\n```\n- Args usage please refer to [Model Inference](https://github.com/PaddlePaddle/PaddleVideo/blob/release/2.0/docs/zh-CN/start.md#2-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86).\n### infer\n```bash\npython3.7 tools/predict.py --input_file data/example.avi \\\n                           --config configs/recognition/slowfast/slowfast.yaml \\\n                           --model_file inference/SlowFast/SlowFast.pdmodel \\\n                           --params_file inference/SlowFast/SlowFast.pdiparams \\\n                           --use_gpu=True \\\n                           --use_tensorrt=False\n```\nexample of logs:\n```\nCurrent video file: data/example.avi\n        top-1 class: 5\n        top-1 score: 1.0"
        },
        {
            "comment": "This code retrieves the class name from a given class ID using a map file and predicts the top1 result for a video named \"example.avi\". The reference provided is related to the SlowFast Networks for Video Recognition paper, which likely explains how this functionality works in detail.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/slowfast.md\":112-119",
            "content": "```\nwe can get the class name using class id and map file `data/k400/Kinetics-400_label_list.txt`. The top1 prediction of `data/example.avi` is `archery`.\n## Reference\n- [SlowFast Networks for Video Recognition](https://arxiv.org/abs/1812.03982), Feichtenhofer C, Fan H, Malik J, et al."
        }
    ]
}