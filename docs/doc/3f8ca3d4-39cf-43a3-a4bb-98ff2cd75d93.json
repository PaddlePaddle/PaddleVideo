{
    "summary": "The code utilizes an ArgumentParser to handle command line arguments, downloads and saves a model, initializes PaddleVideo with GPU/MKLDNN usage for video label prediction, and iterates through results to print top classes/scores/labels.",
    "details": [
        {
            "comment": "This code block is a license notice for the Apache License, Version 2.0, which grants permission to use this file as long as it complies with the terms of the license.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":0-23",
            "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,"
        },
        {
            "comment": "This code imports necessary modules, defines paths and model names for PaddleVideo inference models, and includes a function to parse command line arguments. The code is setting up the environment for using different PaddleVideo models and downloading them if needed.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":24-63",
            "content": "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport os\nimport sys\n__dir__ = os.path.dirname(__file__)\nsys.path.append(os.path.join(__dir__, ''))\nimport numpy as np\nimport tarfile\nimport requests\nfrom tqdm import tqdm\nimport shutil\nfrom paddle import inference\nfrom paddle.inference import Config, create_predictor\nfrom tools.utils import ppTSM_Inference_helper\n__all__ = ['PaddleVideo']\n# path of download model and data\nBASE_DIR = os.path.expanduser(\"~/.paddlevideo_inference/\")\nBASE_INFERENCE_MODEL_DIR = os.path.join(BASE_DIR, 'inference_model')\nBASE_VIDEOS_DIR = os.path.join(BASE_DIR, 'videos')\n# support Models\nMODELS = {\n    'ppTSM':\n    'https://videotag.bj.bcebos.com/PaddleVideo/InferenceModel/ppTSM_infer.tar',\n    'ppTSM_v2':\n    'https://videotag.bj.bcebos.com/PaddleVideo/InferenceModel/ppTSM_v2_infer.tar'\n}\nMODEL_NAMES = list(MODELS.keys())\ndef parse_args(mMain=True, add_help=True):"
        },
        {
            "comment": "This code defines a function that creates an ArgumentParser object for command line arguments. It includes various argument types and default values, such as model name, video file, use GPU flag, number of segments, short and target sizes, and batch size. The function is intended to be used in the main section of a Python script when set to True.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":64-92",
            "content": "    \"\"\"\n    Args:\n        mMain: bool. True for command args, False for python interface\n    \"\"\"\n    import argparse\n    def str2bool(v):\n        return v.lower() in (\"true\", \"t\", \"1\")\n    if mMain == True:\n        # general params\n        parser = argparse.ArgumentParser(add_help=add_help)\n        parser.add_argument(\"--model_name\", type=str, default='')\n        parser.add_argument(\"-v\", \"--video_file\", type=str, default='')\n        parser.add_argument(\"--use_gpu\", type=str2bool, default=True)\n        # params for decode and sample\n        parser.add_argument(\"--num_seg\", type=int, default=16)\n        # params for preprocess\n        parser.add_argument(\"--short_size\", type=int, default=256)\n        parser.add_argument(\"--target_size\", type=int, default=224)\n        # params for predict\n        parser.add_argument(\"--model_file\", type=str, default='')\n        parser.add_argument(\"--params_file\", type=str)\n        parser.add_argument(\"-b\", \"--batch_size\", type=int, default=1)\n        parser.add_argument(\"--use_fp16\", type=str2bool, default=False)"
        },
        {
            "comment": "This code is initializing argument parser with default values for various options like ir_optim, use_tensorrt, gpu_mem, top_k and enable_mkldnn. It then parses the arguments using argparse and returns the resulting Namespace.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":93-114",
            "content": "        parser.add_argument(\"--ir_optim\", type=str2bool, default=True)\n        parser.add_argument(\"--use_tensorrt\", type=str2bool, default=False)\n        parser.add_argument(\"--gpu_mem\", type=int, default=8000)\n        parser.add_argument(\"--top_k\", type=int, default=1)\n        parser.add_argument(\"--enable_mkldnn\", type=bool, default=False)\n        parser.add_argument(\"--label_name_path\", type=str, default='')\n        return parser.parse_args()\n    else:\n        return argparse.Namespace(model_name='',\n                                  video_file='',\n                                  use_gpu=True,\n                                  num_seg=16,\n                                  short_size=256,\n                                  target_size=224,\n                                  model_file='',\n                                  params_file='',\n                                  batch_size=1,\n                                  use_fp16=False,\n                                  ir_optim=True,\n                                  use_tensorrt=False,"
        },
        {
            "comment": "Function `parse_file_paths` takes an input path as a parameter, checks if it is a file or a directory. If it's a file, it returns the file itself; otherwise, it lists all files in the directory, filters out those that don't end with \".avi\" or \".mp4\", and joins the input path with each filtered file to form an absolute path. These paths are then returned as a list.\n\nFunction `download_with_progressbar` downloads data from the given URL in chunks while providing progress updates using tqdm's progress bar. It sets the total size of the download based on the 'content-length' header from the response, and writes each chunk to the specified save path in a 'wb' mode.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":115-144",
            "content": "                                  gpu_mem=8000,\n                                  top_k=1,\n                                  enable_mkldnn=False,\n                                  label_name_path='')\ndef parse_file_paths(input_path: str) -> list:\n    if os.path.isfile(input_path):\n        files = [\n            input_path,\n        ]\n    else:\n        files = os.listdir(input_path)\n        files = [\n            file for file in files\n            if (file.endswith(\".avi\") or file.endswith(\".mp4\"))\n        ]\n        files = [os.path.join(input_path, file) for file in files]\n    return files\ndef download_with_progressbar(url, save_path):\n    response = requests.get(url, stream=True)\n    total_size_in_bytes = int(response.headers.get('content-length', 0))\n    block_size = 1024  # 1 Kibibyte\n    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n    with open(save_path, 'wb') as file:\n        for data in response.iter_content(block_size):\n            progress_bar.update(len(data))\n            file.write(data)"
        },
        {
            "comment": "The code downloads an inference model from a given URL and saves it to the specified directory. It first checks if the required files ('inference.pdiparams' and 'inference.pdmodel') exist, then creates temporary directories for downloading, prints the download progress, extracts the tar archive containing the model files, and raises an exception if any issue occurs during the process.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":145-167",
            "content": "    progress_bar.close()\n    if total_size_in_bytes == 0 or progress_bar.n != total_size_in_bytes:\n        raise Exception(\"Something went wrong while downloading models\")\ndef download_inference_model(model_storage_directory, url):\n    # using custom model\n    tar_file_name_list = [\n        'inference.pdiparams', 'inference.pdiparams.info', 'inference.pdmodel'\n    ]\n    if not os.path.exists(\n            os.path.join(model_storage_directory,\n                         'inference.pdiparams')) or not os.path.exists(\n                             os.path.join(model_storage_directory,\n                                          'inference.pdmodel')):\n        tmp_path = os.path.join(model_storage_directory, url.split('/')[-1])\n        print('download {} to {}'.format(url, tmp_path))\n        os.makedirs(model_storage_directory, exist_ok=True)\n        download_with_progressbar(url, tmp_path)  #download\n        #save to directory\n        with tarfile.open(tmp_path, 'r') as tarObj:\n            for member in tarObj.getmembers():"
        },
        {
            "comment": "This code is initializing a Paddle predictor by reading arguments and configuring the model accordingly. It enables GPU use or MKLDNN based on the provided flags, sets the log level, and switches IR optimization if requested.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":168-196",
            "content": "                filename = None\n                for tar_file_name in tar_file_name_list:\n                    if tar_file_name in member.name:\n                        filename = tar_file_name\n                if filename is None:\n                    continue\n                file = tarObj.extractfile(member)\n                with open(os.path.join(model_storage_directory, filename),\n                          'wb') as f:\n                    f.write(file.read())\n        os.remove(tmp_path)\ndef create_paddle_predictor(args):\n    config = Config(args.model_file, args.params_file)\n    if args.use_gpu:\n        config.enable_use_gpu(args.gpu_mem, 0)\n    else:\n        config.disable_gpu()\n        if args.enable_mkldnn:\n            # cache 10 different shapes for mkldnn to avoid memory leak\n            config.set_mkldnn_cache_capacity(10)\n            config.enable_mkldnn()\n    config.disable_glog_info()\n    config.switch_ir_optim(args.ir_optim)  # default true\n    if args.use_tensorrt:\n        config.enable_tensorrt_engine("
        },
        {
            "comment": "The code snippet is initializing a PaddleVideo object and creating a predictor. It sets the precision mode based on the `args.use_fp16` flag, enables memory optimization, and switches off zero copy operations. It also loads a label name dictionary from the specified path. The purpose of this code is to facilitate model inference using PaddleVideo and provide a user-friendly interface.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":197-231",
            "content": "            precision_mode=Config.Precision.Half\n            if args.use_fp16 else Config.Precision.Float32,\n            max_batch_size=args.batch_size)\n    config.enable_memory_optim()\n    # use zero copy\n    config.switch_use_feed_fetch_ops(False)\n    predictor = create_predictor(config)\n    return predictor\ndef load_label_name_dict(path):\n    result = {}\n    if not os.path.exists(path):\n        print(\n            'Warning: If want to use your own label_dict, please input legal path!\\nOtherwise label_names will be empty!'\n        )\n    else:\n        for line in open(path, 'r'):\n            partition = line.split('\\n')[0].partition(' ')\n            try:\n                result[int(partition[0])] = str(partition[-1])\n            except:\n                result = {}\n                break\n    return result\nclass PaddleVideo(object):\n    def __init__(self, **kwargs):\n        print(\n            '\\nInference models that Paddle provides are listed as follows:\\n{}'\n            .format(MODEL_NAMES), '\\n')\n        process_params = parse_args(mMain=False, add_help=False)"
        },
        {
            "comment": "This code checks if the model file exists, if not it prompts for a model name and downloads a pre-trained model from the provided URL if the model name is in the MODEL_NAMES list. It creates directories for the downloaded files and updates process_params with paths to the inference.pdmodel, inference.pdiparams, label_name_path files.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":232-252",
            "content": "        process_params.__dict__.update(**kwargs)\n        if not os.path.exists(process_params.model_file):\n            if process_params.model_name is None:\n                raise Exception('Please input model name that you want to use!')\n            if process_params.model_name in MODEL_NAMES:\n                url = MODELS[process_params.model_name]\n                download_path = os.path.join(BASE_INFERENCE_MODEL_DIR,\n                                             process_params.model_name)\n                if not os.path.exists(download_path):\n                    os.makedirs(download_path)\n                #create pretrained model download_path\n                download_inference_model(model_storage_directory=download_path,\n                                         url=url)\n                process_params.model_file = os.path.join(\n                    download_path, 'inference.pdmodel')\n                process_params.params_file = os.path.join(\n                    download_path, 'inference.pdiparams')\n                process_params.label_name_path = os.path.join("
        },
        {
            "comment": "The code initializes an object that can predict video labels using PaddleVideo. It checks for the presence of required parameters and allows user-specified models, then loads label name dictionary, and finally defines a \"predict\" method to classify videos.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":253-276",
            "content": "                    __dir__, '../data/k400/Kinetics-400_label_list.txt')\n            else:\n                raise Exception(\n                    'If you want to use your own model, Please input model_file as model path!'\n                )\n        else:\n            print('Using user-specified model and params!')\n        print(\"process params are as follows: \\n{}\".format(process_params))\n        self.label_name_dict = load_label_name_dict(\n            process_params.label_name_path)\n        self.args = process_params\n        self.predictor = create_paddle_predictor(process_params)\n    def predict(self, video):\n        \"\"\"\n        predict label of video with paddlevideo\n        Args:\n            video:input video for clas, support single video , internet url, folder path containing series of videos\n        Returns:\n            list[dict:{videoname: \"\",class_ids: [], scores: [], label_names: []}],if label name path is None,label names will be empty\n        \"\"\"\n        video_list = []\n        assert isinstance(video, (str))"
        },
        {
            "comment": "The code fetches input and output tensor names from the predictor, then retrieves their handles. If the video is a URL, it downloads the internet video and saves it to the BASE_VIDEOS_DIR. The downloaded video file path replaces the original URL. It checks if the video is not legal (not a string) and outputs an error message.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":278-300",
            "content": "        # get input_tensor and output_tensor\n        input_names = self.predictor.get_input_names()\n        output_names = self.predictor.get_output_names()\n        input_tensor_list = []\n        output_tensor_list = []\n        for item in input_names:\n            input_tensor_list.append(self.predictor.get_input_handle(item))\n        for item in output_names:\n            output_tensor_list.append(self.predictor.get_output_handle(item))\n        if isinstance(video, str):\n            # download internet video\n            if video.startswith('http'):\n                if not os.path.exists(BASE_VIDEOS_DIR):\n                    os.makedirs(BASE_VIDEOS_DIR)\n                video_path = os.path.join(BASE_VIDEOS_DIR, 'tmp.mp4')\n                download_with_progressbar(video, video_path)\n                print(\"Current using video from Internet:{}, renamed as: {}\".\n                      format(video, video_path))\n                video = video_path\n            files = parse_file_paths(video)\n        else:\n            print('Please input legal video!')"
        },
        {
            "comment": "Looping over each chunk of files, preprocesses and runs inference on batched inputs, then post-processes the outputs to store in `batched_outputs`.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":302-326",
            "content": "        # Inferencing process\n        InferenceHelper = ppTSM_Inference_helper(\n            num_seg=self.args.num_seg,\n            short_size=self.args.short_size,\n            target_size=self.args.target_size,\n            top_k=self.args.top_k)\n        batch_num = self.args.batch_size\n        for st_idx in range(0, len(files), batch_num):\n            ed_idx = min(st_idx + batch_num, len(files))\n            # Pre process batched input\n            batched_inputs = InferenceHelper.preprocess_batch(\n                files[st_idx:ed_idx])\n            # run inference\n            for i in range(len(input_tensor_list)):\n                input_tensor_list[i].copy_from_cpu(batched_inputs[i])\n            self.predictor.run()\n            batched_outputs = []\n            for j in range(len(output_tensor_list)):\n                batched_outputs.append(output_tensor_list[j].copy_to_cpu())\n            results_list = InferenceHelper.postprocess(batched_outputs,\n                                                       print_output=False,"
        },
        {
            "comment": "This code block is iterating through the 'results_list' and adding labels to each result. If the 'label_name_dict' is not empty, it assigns the corresponding label names from the dictionary to the results. It then prints various information about each result such as video file name and top classes/scores/labels. The main function initializes the PaddleVideo class and calls its 'predict' method with a specific video file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":327-352",
            "content": "                                                       return_result=True)\n            for res in results_list:\n                classes = res[\"topk_class\"]\n                label_names = []\n                if len(self.label_name_dict) != 0:\n                    label_names = [self.label_name_dict[c] for c in classes]\n                res[\"label_names\"] = label_names\n                print(\"Current video file: {0}\".format(res[\"video_id\"]))\n                print(\"\\ttop-{0} classes: {1}\".format(len(res[\"topk_class\"]),\n                                                      res[\"topk_class\"]))\n                print(\"\\ttop-{0} scores: {1}\".format(len(res[\"topk_scores\"]),\n                                                     res[\"topk_scores\"]))\n                print(\"\\ttop-{0} label names: {1}\".format(\n                    len(res[\"label_names\"]), res[\"label_names\"]))\ndef main():\n    # for cmd\n    args = parse_args(mMain=True)\n    clas_engine = PaddleVideo(**(args.__dict__))\n    clas_engine.predict(args.video_file)\nif __name__ == '__main__':"
        },
        {
            "comment": "This line of code likely represents the entry point for the execution of the script, calling the main function to kick off the program's logic. The specific function or operations within this main() function will depend on the rest of the codebase.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/tools/wheel.py\":353-353",
            "content": "    main()"
        }
    ]
}