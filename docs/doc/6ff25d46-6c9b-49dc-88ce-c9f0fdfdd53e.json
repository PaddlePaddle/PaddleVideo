{
    "summary": "This code uses PaddlePaddle and AttentionLstmErnie for multimodal video tagging, including model building, adjusting batch size, calculating metrics, testing, and saving parameters. The main function handles argument parsing and evaluation.",
    "details": [
        {
            "comment": "This code is an evaluation function for a multimodal video tagging application. It imports necessary libraries, disables dynamic memory allocation, sets up the PaddlePaddle environment, and includes functions for reading data, defining the model architecture, and calculating metrics. The code also defines a \"parse_args\" function to handle command line arguments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py\":0-36",
            "content": "\"\"\"\neval main\n\"\"\"\n#  Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport os\nimport sys\nimport time\nimport argparse\nimport logging\nimport pickle\nimport numpy as np\nimport paddle\npaddle.enable_static()\nimport paddle.static as static\nfrom accuracy_metrics import MetricsCalculator\nfrom datareader import get_reader\nfrom config import parse_config, merge_configs, print_configs\nfrom models.attention_lstm_ernie import AttentionLstmErnie\nfrom utils import test_with_pyreader\ndef parse_args():"
        },
        {
            "comment": "This code defines an argument parser for the Paddle Video evaluate script. It allows users to input a model name, config file path, pretrain weights path, output path, use_gpu flag, and save_model_param_dir. The default values are provided for each argument in case they aren't specified by the user.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py\":37-63",
            "content": "    \"\"\"parse_args\n    \"\"\"\n    parser = argparse.ArgumentParser(\"Paddle Video evaluate script\")\n    parser.add_argument('--model_name',\n                        type=str,\n                        default='BaiduNet',\n                        help='name of model to train.')\n    parser.add_argument('--config',\n                        type=str,\n                        default='configs/conf.txt',\n                        help='path to config file of model')\n    parser.add_argument(\n        '--pretrain',\n        type=str,\n        default=None,\n        help=\n        'path to pretrain weights. None to use default weights path in  ~/.paddle/weights.'\n    )\n    parser.add_argument('--output', type=str, default=None, help='output path')\n    parser.add_argument('--use_gpu',\n                        type=bool,\n                        default=True,\n                        help='default use gpu.')\n    parser.add_argument('--save_model_param_dir',\n                        type=str,\n                        default=None,\n                        help='checkpoint path')"
        },
        {
            "comment": "This code defines command-line arguments for saving and evaluating an inference model, parses the configuration file, builds a model using AttentionLstmErnie, and sets up static programs for evaluation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py\":64-93",
            "content": "    parser.add_argument('--save_inference_model',\n                        type=str,\n                        default=None,\n                        help='save inference path')\n    parser.add_argument('--save_only',\n                        action='store_true',\n                        default=False,\n                        help='only save model, do not evaluate model')\n    args = parser.parse_args()\n    return args\ndef evaluate(args):\n    \"\"\"evaluate\n    \"\"\"\n    # parse config\n    config = parse_config(args.config)\n    valid_config = merge_configs(config, 'valid', vars(args))\n    print_configs(valid_config, 'Valid')\n    # build model\n    valid_model = AttentionLstmErnie(args.model_name,\n                                     valid_config,\n                                     mode='valid')\n    startup = static.Program()\n    valid_prog = static.default_main_program().clone(for_test=True)\n    with static.program_guard(valid_prog, startup):\n        paddle.disable_static()\n        valid_model.build_input(True)\n        valid_model.build_model()"
        },
        {
            "comment": "This code is loading the model from a specified directory, compiling the program and running it. It checks if the save weight directory exists and loads the test weights into the model. If necessary, it saves the inference model and if only saving the model is required, it exits. The batch size is adjusted by dividing it by a denominator.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py\":94-122",
            "content": "        valid_feeds = valid_model.feeds()\n        valid_outputs = valid_model.outputs()\n        valid_loss = valid_model.loss()\n        valid_pyreader = valid_model.pyreader()\n        paddle.enable_static()\n    place = paddle.CUDAPlace(0) if args.use_gpu else paddle.CPUPlace()\n    exe = static.Executor(place)\n    exe.run(startup)\n    compiled_valid_prog = static.CompiledProgram(valid_prog)\n    # load weights\n    assert os.path.exists(args.save_model_param_dir), \\\n            \"Given save weight dir {} not exist.\".format(args.save_model_param_dir)\n    valid_model.load_test_weights_file(exe, args.save_model_param_dir,\n                                       valid_prog, place)\n    if args.save_inference_model:\n        save_model_params(exe, valid_prog, valid_model,\n                          args.save_inference_model)\n    if args.save_only is True:\n        print('save model only, exit')\n        return\n    # get reader\n    bs_denominator = 1\n    valid_config.VALID.batch_size = int(valid_config.VALID.batch_size /\n                                        bs_denominator)"
        },
        {
            "comment": "This code retrieves a valid reader, calculates metrics, and decorates the sample list generator with specified execution places. It then tests the model using the reader, program, and fetch list to obtain test loss and accuracy, which are printed. The function `save_model_params` saves the model parameters in the provided directory.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py\":123-144",
            "content": "    valid_reader = get_reader(args.model_name.upper(), 'valid', valid_config)\n    # get metrics\n    valid_metrics = MetricsCalculator(args.model_name.upper(), 'valid',\n                                      valid_config)\n    valid_fetch_list = [valid_loss.name] + [x.name for x in valid_outputs\n                                            ] + [valid_feeds[-1].name]\n    # get reader\n    exe_places = static.cuda_places() if args.use_gpu else static.cpu_places()\n    valid_pyreader.decorate_sample_list_generator(valid_reader,\n                                                  places=exe_places)\n    test_loss, metrics_dict_test = test_with_pyreader(exe, compiled_valid_prog,\n                                                      valid_pyreader,\n                                                      valid_fetch_list,\n                                                      valid_metrics)\n    test_acc1 = metrics_dict_test['avg_acc1']\n    print(test_loss)\n    print(test_acc1)\ndef save_model_params(exe, program, model_object, save_dir):"
        },
        {
            "comment": "This code defines a function \"save_model_params\" that takes the directory path, saves the inference model, and specifies the feeded variable names, main program, target variables, executor, and filenames for the model and parameters. It also includes a main function that parses arguments and evaluates them.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py\":145-158",
            "content": "    \"\"\"save_model_params\n    \"\"\"\n    feeded_var_names = [var.name for var in model_object.feeds()][:-1]\n    static.save_inference_model(dirname=save_dir,\n                                  feeded_var_names=feeded_var_names,\n                                  main_program=program,\n                                  target_vars=model_object.outputs(),\n                                  executor=exe,\n                                  model_filename='model',\n                                  params_filename='params')\nif __name__ == \"__main__\":\n    args = parse_args()\n    evaluate(args)"
        }
    ]
}