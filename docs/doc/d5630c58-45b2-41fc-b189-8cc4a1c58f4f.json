{
    "summary": "The code contains functions for non-maximum suppression, tensor movement, and applying NMS to anchor boxes in images using PaddlePaddle. It transforms YOLOv2 output, generates ground truth targets, calculates IoU, counts instances, updates predictions, and returns masks and transformation parameters for translation, width, and height.",
    "details": [
        {
            "comment": "This code snippet defines a function `truths_length()` that returns the index of the first occurrence where the second element in 'truths' array is 0. It also defines a function `nms()` that applies Non-Maximum Suppression to filter out bounding boxes based on a given NMS threshold. The code checks if there are any bounding boxes, assigns confidence scores, sorts them in descending order of confidence, and removes overlapping bounding boxes with IoU greater than the NMS threshold.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":0-35",
            "content": "# copyright (c) 2021 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport math\nimport paddle\nimport paddle.nn as nn\nimport numpy as np\nfrom builtins import range as xrange\ndef truths_length(truths):\n    for i in range(50):\n        if truths[i][1] == 0:\n            return i\ndef nms(boxes, nms_thresh):\n    if len(boxes) == 0:\n        return boxes\n    det_confs = paddle.zeros([len(boxes)])\n    for i in range(len(boxes)):\n        det_confs[i] = 1 - boxes[i][4]\n    sortIds = paddle.argsort(det_confs)"
        },
        {
            "comment": "This code is defining three functions: \"out_boxes\" appears to perform non-maximum suppression on bounding boxes, \"convert2cpu\" converts a tensor from GPU memory to CPU memory as a float32 type, and \"convert2cpu_long\" performs the same operation but as an int64 type. The \"get_region_boxes\" function takes in output from a model and applies non-maximum suppression for each anchor box in the image, using provided anchors and thresholds. This function also reshapes the input to have shape (batch, num_anchors, 5 + num_classes). The code includes assertions to ensure proper input shapes are being used.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":36-66",
            "content": "    out_boxes = []\n    for i in range(len(boxes)):\n        box_i = boxes[sortIds[i]]\n        if box_i[4] > 0:\n            out_boxes.append(box_i)\n            for j in range(i + 1, len(boxes)):\n                box_j = boxes[sortIds[j]]\n                if bbox_iou(box_i, box_j, x1y1x2y2=False) > nms_thresh:\n                    box_j[4] = 0\n    return out_boxes\ndef convert2cpu(gpu_matrix):\n    float_32_g = gpu_matrix.astype('float32')\n    return float_32_g.cpu()\ndef convert2cpu_long(gpu_matrix):\n    int_64_g = gpu_matrix.astype('int64')\n    return int_64_g.cpu()\ndef get_region_boxes(output, conf_thresh=0.005, num_classes=24,\n                     anchors=[0.70458, 1.18803, 1.26654, 2.55121, 1.59382,\n                              4.08321, 2.30548, 4.94180, 3.52332, 5.91979],\n                     num_anchors=5, only_objectness=1, validation=False):\n    anchor_step = len(anchors) // num_anchors\n    if output.dim() == 3:\n        output = output.unsqueeze(0)\n    batch = output.shape[0]\n    assert (output.shape[1] == (5 + num_classes) * num_anchors)"
        },
        {
            "comment": "This code performs box regression by reshaping the output tensor, creating grids for x and y coordinates, applying sigmoid function to the output, adding grid coordinates to get refined box coordinates. It also converts anchor widths into a tensor for further processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":67-93",
            "content": "    h = output.shape[2]\n    w = output.shape[3]\n    all_boxes = []\n    output = paddle.reshape(\n        output, [batch * num_anchors, 5 + num_classes, h * w])\n    output = paddle.transpose(output, (1, 0, 2))\n    output = paddle.reshape(\n        output, [5 + num_classes, batch * num_anchors * h * w])\n    grid_x = paddle.linspace(0, w - 1, w)\n    grid_x = paddle.tile(grid_x, [h, 1])\n    grid_x = paddle.tile(grid_x, [batch * num_anchors, 1, 1])\n    grid_x = paddle.reshape(grid_x, [batch * num_anchors * h * w]).cuda()\n    grid_y = paddle.linspace(0, h - 1, h)\n    grid_y = paddle.tile(grid_y, [w, 1]).t()\n    grid_y = paddle.tile(grid_y, [batch * num_anchors, 1, 1])\n    grid_y = paddle.reshape(grid_y, [batch * num_anchors * h * w]).cuda()\n    sigmoid = nn.Sigmoid()\n    xs = sigmoid(output[0]) + grid_x\n    ys = sigmoid(output[1]) + grid_y\n    anchor_w = paddle.to_tensor(anchors)\n    anchor_w = paddle.reshape(anchor_w, [num_anchors, anchor_step])\n    anchor_w = paddle.index_select(anchor_w, index=paddle.to_tensor(\n        np.array([0]).astype('int32')), axis=1)"
        },
        {
            "comment": "Code prepares output from a YOLOv2 object detection model, performing necessary reshaping and transformations to obtain the final detections and classifications. It computes the widths (ws) and heights (hs) of the bounding boxes based on the input feature maps, applies sigmoid activation to the fifth output channel for detection confidences, and converts the rest of the outputs to stop_gradient=True tensors for class predictions. The code then performs softmax normalization over class predictions and retrieves the maximum confidence and corresponding class IDs for each bounding box. Finally, it reshapes cls_max_confs to a 1D tensor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":95-121",
            "content": "    anchor_h = paddle.to_tensor(anchors)\n    anchor_h = paddle.reshape(anchor_h, [num_anchors, anchor_step])\n    anchor_h = paddle.index_select(anchor_h, index=paddle.to_tensor(\n        np.array([1]).astype('int32')), axis=1)\n    anchor_w = paddle.tile(anchor_w, [batch, 1])\n    anchor_w = paddle.tile(anchor_w, [1, 1, h * w])\n    anchor_w = paddle.reshape(anchor_w, [batch * num_anchors * h * w]).cuda()\n    anchor_h = paddle.tile(anchor_h, [batch, 1])\n    anchor_h = paddle.tile(anchor_h, [1, 1, h * w])\n    anchor_h = paddle.reshape(anchor_h, [batch * num_anchors * h * w]).cuda()\n    ws = paddle.exp(output[2]) * anchor_w\n    hs = paddle.exp(output[3]) * anchor_h\n    det_confs = sigmoid(output[4])\n    cls_confs = paddle.to_tensor(output[5:5 + num_classes], stop_gradient=True)\n    cls_confs = paddle.transpose(cls_confs, [1, 0])\n    s = nn.Softmax()\n    cls_confs = paddle.to_tensor(s(cls_confs))\n    cls_max_confs = paddle.max(cls_confs, axis=1)\n    cls_max_ids = paddle.argmax(cls_confs, axis=1)\n    cls_max_confs = paddle.reshape(cls_max_confs, [-1])"
        },
        {
            "comment": "The code extracts data from a PaddlePaddle tensor and converts it to CPU memory. It then reshapes the data, applies conditions, and stores box coordinates and confidences in lists for each batch. The extracted data is used to create bounding boxes for objects detected within the input image.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":122-152",
            "content": "    cls_max_ids = paddle.reshape(cls_max_ids, [-1])\n    sz_hw = h * w\n    sz_hwa = sz_hw * num_anchors\n    det_confs = convert2cpu(det_confs)\n    cls_max_confs = convert2cpu(cls_max_confs)\n    cls_max_ids = convert2cpu_long(cls_max_ids)\n    xs = convert2cpu(xs)\n    ys = convert2cpu(ys)\n    ws = convert2cpu(ws)\n    hs = convert2cpu(hs)\n    if validation:\n        cls_confs = convert2cpu(cls_confs.reshape([-1, num_classes]))\n    for b in range(batch):\n        boxes = []\n        for cy in range(h):\n            for cx in range(w):\n                for i in range(num_anchors):\n                    ind = b * sz_hwa + i * sz_hw + cy * w + cx\n                    det_conf = det_confs[ind]\n                    if only_objectness:\n                        conf = det_confs[ind]\n                    else:\n                        conf = det_confs[ind] * cls_max_confs[ind]\n                    if conf > conf_thresh:\n                        bcx = xs[ind]\n                        bcy = ys[ind]\n                        bw = ws[ind]\n                        bh = hs[ind]"
        },
        {
            "comment": "The function `yowo_utils.py` returns a list of boxes with their respective confidences and class ids for each box. It includes only objectness if only_objectness is True, otherwise it also includes the per-class confidences. The function `bbox_iou` calculates the intersection over union between two bounding boxes, considering x1y1x2y2 format where (x1, y1) is the top left corner and (x2, y2) is the bottom right corner.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":153-177",
            "content": "                        cls_max_conf = cls_max_confs[ind]\n                        cls_max_id = cls_max_ids[ind]\n                        box = [bcx / w, bcy / h, bw / w, bh / h,\n                               det_conf, cls_max_conf, cls_max_id]\n                        if (not only_objectness) and validation:\n                            for c in range(num_classes):\n                                tmp_conf = cls_confs[ind][c]\n                                if c != cls_max_id and det_confs[ind] * tmp_conf > conf_thresh:\n                                    box.append(tmp_conf)\n                                    box.append(c)\n                        boxes.append(box)\n        all_boxes.append(boxes)\n    return all_boxes\ndef bbox_iou(box1, box2, x1y1x2y2=True):\n    if x1y1x2y2:\n        mx = min(box1[0], box2[0])\n        Mx = max(box1[2], box2[2])\n        my = min(box1[1], box2[1])\n        My = max(box1[3], box2[3])\n        w1 = box1[2] - box1[0]\n        h1 = box1[3] - box1[1]\n        w2 = box2[2] - box2[0]\n        h2 = box2[3] - box2[1]"
        },
        {
            "comment": "The code calculates the intersection-over-union (IOU) between two bounding boxes, which is commonly used in object detection tasks. It first finds the overlapping area by computing the minimum and maximum coordinates of the bounding boxes, then calculates the union of these boxes, and finally returns the intersection over union ratio. This helps in determining if the two bounding boxes represent the same object or not.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":178-212",
            "content": "    else:\n        mx = min(float(box1[0] - box1[2] / 2.0),\n                 float(box2[0] - box2[2] / 2.0))\n        Mx = max(float(box1[0] + box1[2] / 2.0),\n                 float(box2[0] + box2[2] / 2.0))\n        my = min(float(box1[1] - box1[3] / 2.0),\n                 float(box2[1] - box2[3] / 2.0))\n        My = max(float(box1[1] + box1[3] / 2.0),\n                 float(box2[1] + box2[3] / 2.0))\n        w1 = box1[2]\n        h1 = box1[3]\n        w2 = box2[2]\n        h2 = box2[3]\n    uw = Mx - mx\n    uh = My - my\n    cw = w1 + w2 - uw\n    ch = h1 + h2 - uh\n    carea = 0\n    if cw <= 0 or ch <= 0:\n        return paddle.to_tensor(0.0)\n    area1 = w1 * h1\n    area2 = w2 * h2\n    carea = cw * ch\n    uarea = area1 + area2 - carea\n    return carea / uarea\ndef bbox_ious(boxes1, boxes2, x1y1x2y2=True):\n    if x1y1x2y2:\n        mx = paddle.min(boxes1[0], boxes2[0])\n        Mx = paddle.max(boxes1[2], boxes2[2])\n        my = paddle.min(boxes1[1], boxes2[1])\n        My = paddle.max(boxes1[3], boxes2[3])\n        w1 = boxes1[2] - boxes1[0]"
        },
        {
            "comment": "This code calculates the intersection over union (IoU) between two bounding boxes. It first checks if both boxes have valid dimensions, then computes the coordinates of each box and their widths and heights. If the boxes overlap, it calculates the intersection area and union area of the bounding boxes, taking into account non-overlapping areas by setting them to 0 in the case of non-intersection. Finally, it returns the IoU as the intersection area divided by the union area.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":213-240",
            "content": "        h1 = boxes1[3] - boxes1[1]\n        w2 = boxes2[2] - boxes2[0]\n        h2 = boxes2[3] - boxes2[1]\n    else:\n        mx = paddle.min(paddle.stack(\n            [boxes1[0] - boxes1[2] / 2.0, boxes2[0] - boxes2[2] / 2.0], axis=0), axis=0)\n        Mx = paddle.max(paddle.stack(\n            [boxes1[0] + boxes1[2] / 2.0, boxes2[0] + boxes2[2] / 2.0], axis=0), axis=0)\n        my = paddle.min(paddle.stack(\n            [boxes1[1] - boxes1[3] / 2.0, boxes2[1] - boxes2[3] / 2.0], axis=0), axis=0)\n        My = paddle.max(paddle.stack(\n            [boxes1[1] + boxes1[3] / 2.0, boxes2[1] + boxes2[3] / 2.0], axis=0), axis=0)\n        w1 = boxes1[2]\n        h1 = boxes1[3]\n        w2 = boxes2[2]\n        h2 = boxes2[3]\n    uw = Mx - mx\n    uh = My - my\n    cw = w1 + w2 - uw\n    ch = h1 + h2 - uh\n    mask = paddle.cast(cw <= 0, dtype=\"int32\") + \\\n        paddle.cast(ch <= 0, dtype=\"int32\") > 0\n    area1 = w1 * h1\n    area2 = w2 * h2\n    carea = cw * ch\n    carea[mask] = 0\n    uarea = area1 + area2 - carea\n    return carea / uarea"
        },
        {
            "comment": "This function builds ground truth targets for each grid in the image. It iterates over each batch, anchor, height, and width to create confidence, coordinate, and class masks, as well as target coordinates and classes for each anchor box. The targets are then concatenated into a single tensor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":243-267",
            "content": "# this function works for building the groud truth\ndef build_targets(pred_boxes, target, anchors, num_anchors, num_classes, nH, nW, noobject_scale, object_scale,\n                  sil_thresh):\n    # nH, nW here are number of grids in y and x directions (7, 7 here)\n    nB = target.shape[0]  # batch size\n    nA = num_anchors  # 5 for our case\n    nC = num_classes\n    anchor_step = len(anchors) // num_anchors\n    conf_mask = paddle.ones([nB, nA, nH, nW]) * noobject_scale\n    coord_mask = paddle.zeros([nB, nA, nH, nW])\n    cls_mask = paddle.zeros([nB, nA, nH, nW])\n    tx = paddle.zeros([nB, nA, nH, nW])\n    ty = paddle.zeros([nB, nA, nH, nW])\n    tw = paddle.zeros([nB, nA, nH, nW])\n    th = paddle.zeros([nB, nA, nH, nW])\n    tconf = paddle.zeros([nB, nA, nH, nW])\n    tcls = paddle.zeros([nB, nA, nH, nW])\n    # for each grid there are nA anchors\n    # nAnchors is the number of anchor for one image\n    nAnchors = nA * nH * nW\n    nPixels = nH * nW\n    # for each image\n    for b in xrange(nB):\n        # get all anchor boxes in one image"
        },
        {
            "comment": "This code calculates the IoU (Intersection over Union) between predicted and ground truth boxes for each anchor. It uses a loop to iterate through 50 time steps, breaks if no target is available at the current time step, and calculates the bbox_ious function using cur_pred_boxes and cur_gt_boxes for IoU calculation. The highest IoU value is stored in cur_ious for each anchor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":268-287",
            "content": "        # (4 * nAnchors)\n        cur_pred_boxes = pred_boxes[b * nAnchors:(b + 1) * nAnchors].t()\n        # initialize iou score for each anchor\n        cur_ious = paddle.zeros([nAnchors])\n        for t in xrange(50):\n            # for each anchor 4 coordinate parameters, already in the coordinate system for the whole image\n            # this loop is for anchors in each image\n            # for each anchor 5 parameters are available (class, x, y, w, h)\n            if target[b][t * 5 + 1] == 0:\n                break\n            gx = target[b][t * 5 + 1] * nW\n            gy = target[b][t * 5 + 2] * nH\n            gw = target[b][t * 5 + 3] * nW\n            gh = target[b][t * 5 + 4] * nH\n            # groud truth boxes\n            cur_gt_boxes = paddle.tile(paddle.to_tensor(\n                [gx, gy, gw, gh], dtype='float32').t(), [nAnchors, 1]).t()\n            # bbox_ious is the iou value between orediction and groud truth\n            cur_ious = paddle.max(\n                paddle.stack([cur_ious, bbox_ious(cur_pred_boxes, cur_gt_boxes, x1y1x2y2=False)], axis=0), axis=0)"
        },
        {
            "comment": "This code calculates the IoU (Intersection over Union) between predicted bounding boxes and ground truth bounding boxes, and applies a mask to the confidences based on this IoU. It also counts the number of ground truth instances (nGT) and correct detections (nCorrect). The target values are ratios multiplied by the width and height of the output feature maps.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":288-314",
            "content": "        # if iou > a given threshold, it is seen as it includes an object\n        # conf_mask[b][cur_ious>sil_thresh] = 0\n        conf_mask_t = paddle.reshape(conf_mask, [nB, -1])\n        conf_mask_t[b, cur_ious > sil_thresh] = 0\n        conf_mask_tt = paddle.reshape(conf_mask_t[b], [nA, nH, nW])\n        conf_mask[b] = conf_mask_tt\n    # number of ground truth\n    nGT = 0\n    nCorrect = 0\n    for b in xrange(nB):\n        # anchors for one batch (at least batch size, and for some specific classes, there might exist more than one anchor)\n        for t in xrange(50):\n            if target[b][t * 5 + 1] == 0:\n                break\n            nGT = nGT + 1\n            best_iou = 0.0\n            best_n = -1\n            min_dist = 10000\n            # the values saved in target is ratios\n            # times by the width and height of the output feature maps nW and nH\n            gx = target[b][t * 5 + 1] * nW\n            gy = target[b][t * 5 + 2] * nH\n            gi = int(gx)\n            gj = int(gy)\n            gw = target[b][t * 5 + 3] * nW"
        },
        {
            "comment": "This code iterates over anchor boxes, calculates IoU with ground truth boxes and selects the best matching one. It then updates the corresponding prediction box for that image and marks it as valid in coord_mask and cls_mask matrices.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":315-337",
            "content": "            gh = target[b][t * 5 + 4] * nH\n            gt_box = [0, 0, gw, gh]\n            for n in xrange(nA):\n                # get anchor parameters (2 values)\n                aw = anchors[anchor_step * n]\n                ah = anchors[anchor_step * n + 1]\n                anchor_box = [0, 0, aw, ah]\n                # only consider the size (width and height) of the anchor box\n                iou = bbox_iou(anchor_box, gt_box, x1y1x2y2=False)\n                # get the best anchor form with the highest iou\n                if iou > best_iou:\n                    best_iou = iou\n                    best_n = n\n            # then we determine the parameters for an anchor (4 values together)\n            gt_box = [gx, gy, gw, gh]\n            # find corresponding prediction box\n            pred_box = pred_boxes[b * nAnchors +\n                                  best_n * nPixels + gj * nW + gi]\n            # only consider the best anchor box, for each image\n            coord_mask[b, best_n, gj, gi] = 1\n            cls_mask[b, best_n, gj, gi] = 1"
        },
        {
            "comment": "The code calculates object position, size, and confidence for each detected object. It then counts the number of correct detections by checking if the IOU is greater than 0.5.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":339-356",
            "content": "            # in this cell of the output feature map, there exists an object\n            conf_mask[b, best_n, gj, gi] = object_scale\n            tx[b, best_n, gj, gi] = paddle.cast(\n                target[b][t * 5 + 1] * nW - gi, dtype='float32')\n            ty[b, best_n, gj, gi] = paddle.cast(\n                target[b][t * 5 + 2] * nH - gj, dtype='float32')\n            tw[b, best_n, gj, gi] = math.log(\n                gw / anchors[anchor_step * best_n])\n            th[b, best_n, gj, gi] = math.log(\n                gh / anchors[anchor_step * best_n + 1])\n            iou = bbox_iou(gt_box, pred_box, x1y1x2y2=False)  # best_iou\n            # confidence equals to iou of the corresponding anchor\n            tconf[b, best_n, gj, gi] = paddle.cast(iou, dtype='float32')\n            tcls[b, best_n, gj, gi] = paddle.cast(\n                target[b][t * 5], dtype='float32')\n            # if ious larger than 0.5, we justify it as a correct prediction\n            if iou > 0.5:\n                nCorrect = nCorrect + 1"
        },
        {
            "comment": "The function returns the ground truth values (nGT), correct predictions (nCorrect), and corresponding masks for coordinates, confidence, and class labels, as well as the transformation parameters for translation, width, and height.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_utils.py\":357-358",
            "content": "    # true values are returned\n    return nGT, nCorrect, coord_mask, conf_mask, cls_mask, tx, ty, tw, th, tconf, tcls"
        }
    ]
}