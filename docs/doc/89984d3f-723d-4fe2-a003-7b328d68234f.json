{
    "summary": "The code improves TSN model training speed with DALI in PaddleVideo, using Kinetics400/UCF101 datasets and ResNet50 pretrained models. It provides detailed guidelines for action recognition tasks, including model download, config file usage, and separate sections for tests and inferences.",
    "details": [
        {
            "comment": "This code aims to speed up the TSN (Two-Stream Networks) model training using DALI (Data Augmentation Library for Images and Videos) in PaddleVideo. The author reimplemented segment sampling in VideoReader as NVIDIA DALI does not support TSN sampling way. They tested the performance with a Tesla v100 GPU and reported improvements in batch cost/s, reader cost/s, and instance/sec compared to Dataloader and base implementation. The docker image for this implementation is huangjun12/paddlevideo:tsn_dali_cuda9_0.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/tsn_dali.md\":0-44",
            "content": "[\u7b80\u4f53\u4e2d\u6587](../../../zh-CN/model_zoo/recognition/tsn_dali.md) | English\n# TSN DALI\n- [Introduction](#Introduction)\n- [Requirement](#Requirement)\n- [Data](#Data)\n- [Train](#Train)\n- [Test](#Test)\n- [Inference](#Inference)\n- [Reference](#Reference)\n## Introduction\nWe aims to speed up TSN model training using DALI in this code. As [nvidia DALI](https://github.com/NVIDIA/DALI) not support TSN sampling way, we reimplemented segment sampling in VideoReader.\n### Performance\nTest Environment: \n```\nCard: Tesla v100\nMemory: 4 * 16G\nCuda: 9.0\nbatch_size of single card: 32\n```\n| Training way | batch cost/s  | reader cost/s | ips:instance/sec | Speed up |\n| :--------------- | :--------: | :------------: | :------------: | :------------: |\n| DALI | 2.083 | 1.804 | 15.36597  |  1.41x |\n| Dataloader: num_workers=4 | 2.943 | 2.649 | 10.87460| base |\n| pytorch\u5b9e\u73b0 | TODO | TODO | TODO | TODO | \n## Requirement\ndocker image:\n```\n    huangjun12/paddlevideo:tsn_dali_cuda9_0\n```\nTo build container, you can use:\n```bash\nnvidia-docker run --name t"
        },
        {
            "comment": "This code snippet is a command for running TSN (Two-Stream Network) with DALI (Data Augmentation and Layout Innovation) on PaddleVideo. It utilizes the Kinetics400 and UCF101 datasets, downloads the ResNet50 pretrained model, and starts the training process using Python and PaddlePaddle framework. The command also specifies the GPU usage and log directory for tracking progress.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/tsn_dali.md\":44-81",
            "content": "sn-DALI -v /home:/workspace --network=host -it --shm-size 64g -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,video huangjun12/paddlevideo:tsn_dali_cuda9_0 /bin/bash\n```\n## Data\n- Kinetics400 dataset please refer to [K400 data](../../dataset/k400.md)\n- UCF101 dataset please refer to [UCF101 data](../../dataset/ucf101.md)\n## Train\n### download pretrain-model\n- Please download [ResNet50_pretrain.pdparams](https://videotag.bj.bcebos.com/PaddleVideo/PretrainModel/ResNet50_pretrain.pdparams) as pretraind model:\n```bash\nwget https://videotag.bj.bcebos.com/PaddleVideo/PretrainModel/ResNet50_pretrain.pdparams\n```\nand add path to MODEL.framework.backbone.pretrained in config file as\uff1a\n```yaml\nMODEL:\n    framework: \"Recognizer2D\"\n    backbone:\n        name: \"ResNet\"\n        pretrained: your weight path\n```\n### Start training\nYou can start training by: \n```bash\npython3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3\" --log_dir=log_tsn main.py --train_dali -c configs/recognition/tsn/tsn_dali.yaml -o log_level=\"INFO\"\n```\n- Args -c is used to specify config file\uff0cdefault is ```configs/recognition/tsn/tsn_dali.yaml```\u3002"
        },
        {
            "comment": "This code is providing information on how to use the TSN model for action recognition. It mentions downloading the trained model file, using a config file, and refers users to separate sections for test and inference processes. The reference section includes the original paper link.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/tsn_dali.md\":83-97",
            "content": "- For finetune please download our trained model [TSN.pdparams]()<sup>coming soon</sup>\uff0cand specify file path with --weights. \n- For the config file usage\uff0cplease refer to [config](../../tutorials/config.md).\n## Test\nPlease refer to [TSN Test](./tsn.md)\n## Inference\nPlease refer to [TSN Inference](./tsn.md)\n## Reference\n- [Temporal Segment Networks: Towards Good Practices for Deep Action Recognition](https://arxiv.org/abs/1608.00859), Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, Luc Van Gool"
        }
    ]
}