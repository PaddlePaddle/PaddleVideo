{
    "summary": "The YOWOLocalizer extends BaseLocalizer, performs NMS on detected boxes, matches ground truth with predicted boxes based on IoU threshold, and calculates precision, recall, and F-score for YOWO localizer using test step function.",
    "details": [
        {
            "comment": "Code from PaddleVideo's yowo_localizer.py file defines a YOWOLocalizer class which extends BaseLocalizer and utilizes the backbone function for forwarding image data. It also includes methods forward_net and train_step for processing images in training context.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_localizer.py\":0-32",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nfrom ...registry import LOCALIZERS\nfrom .base import BaseLocalizer\nfrom .yowo_utils import truths_length, nms, get_region_boxes, bbox_iou\n@LOCALIZERS.register()\nclass YOWOLocalizer(BaseLocalizer):\n    \"\"\"YOWO Localization framework\n    \"\"\"\n    def forward_net(self, imgs):\n        \"\"\"Call backbone forward.\n        \"\"\"\n        # imgs.shape=[N,C,T,H,W], for YOWO\n        preds = self.backbone(imgs)\n        return preds\n    def train_step(self, data_batch):\n        \"\"\"Training step.\n        \"\"\"\n        x_data = data_batch[0]"
        },
        {
            "comment": "Function \"forward_net\" is called to perform model's forward pass, and the output of this function call is stored in 'out'. The code then calls another function \"loss\" passing the output from the model (out) and the target data (target). The output from the loss function call is stored in 'loss', along with number of correct predictions ('nCorrect'). A dictionary named 'loss_metrics' is created storing 'loss' and 'nCorrect'. This process is part of training set step. \nThe 'val_step' function performs validation steps like calculating total, proposals, correct and fscore variables using specific values (total = 0.0, proposals = 0.0, correct = 0.0, fscore = 0.0). It also uses an epsilon value of 1e-5 and a nms_thresh and iou_thresh of 0.4 for certain calculations. It calls the model's forward pass (forward_net) to get 'out', then gets all region boxes using get_region_boxes function, then iterates over each box in out, storing them in a list named 'out_boxes'. This process is part of validating step.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_localizer.py\":33-66",
            "content": "        target = data_batch[1].squeeze(1)  # indeed do squeeze to adapt to paddle tensor\n        target.stop_gradient = True\n        # call Model forward\n        out = self.forward_net(x_data)\n        # call Loss forward\n        loss, nCorrect = self.loss(out, target)\n        loss_metrics = dict()\n        loss_metrics['loss'] = loss\n        loss_metrics['nCorrect'] = nCorrect\n        return loss_metrics\n    def val_step(self, data_batch):\n        \"\"\"Validating setp.\n        \"\"\"\n        total = 0.0\n        proposals = 0.0\n        correct = 0.0\n        fscore = 0.0\n        eps = 1e-5\n        nms_thresh = 0.4\n        iou_thresh = 0.5\n        x_data = data_batch[0]\n        target = data_batch[1].squeeze(1)  # indeed do squeeze to adapt to paddle tensor\n        frame_idx = data_batch[2]\n        target.stop_gradient = True\n        # call Model forward\n        out = self.forward_net(x_data)\n        all_boxes = get_region_boxes(out)\n        out_boxes = []\n        for i in range(out.shape[0]):\n            boxes = all_boxes[i]"
        },
        {
            "comment": "This code performs Non-Maximum Suppression (NMS) on detected boxes, selects confident boxes for further processing, and associates ground truth boxes with predicted boxes based on Intersection over Union (IoU) threshold. It counts correct matches, proposals, total ground truth boxes, and calculates precision. The precision is calculated by dividing the number of correct matches by the sum of proposals and a small epsilon value to avoid division by zero.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_localizer.py\":67-89",
            "content": "            boxes = nms(boxes, nms_thresh)\n            out_boxes.append(boxes)\n            truths = target[i].reshape([-1, 5])\n            num_gts = truths_length(truths)\n            total = total + num_gts\n            pred_list = []\n            for i in range(len(boxes)):\n                if boxes[i][4] > 0.25:\n                    proposals = proposals + 1\n                    pred_list.append(i)\n            for i in range(num_gts):\n                box_gt = [truths[i][1], truths[i][2], truths[i][3], truths[i][4], 1.0, 1.0, truths[i][0]]\n                best_iou = 0\n                best_j = -1\n                for j in pred_list:  # ITERATE THROUGH ONLY CONFIDENT BOXES\n                    iou = bbox_iou(box_gt, boxes[j], x1y1x2y2=False)\n                    if iou > best_iou:\n                        best_j = j\n                        best_iou = iou\n                if best_iou > iou_thresh and int(boxes[best_j][6]) == box_gt[6]:\n                    correct = correct + 1\n        precision = 1.0 * correct / (proposals + eps)"
        },
        {
            "comment": "This code defines a localizer for the YOLOv3 model and calculates precision, recall, and F-score using test step function. It initializes variables, processes input data batch, applies non-maximum suppression (NMS) to regions of interest, and returns output metrics including precision, recall, F-score, and frame index.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_localizer.py\":90-124",
            "content": "        recall = 1.0 * correct / (total + eps)\n        fscore = 2.0 * precision * recall / (precision + recall + eps)\n        outs = dict()\n        outs['precision'] = precision\n        outs['recall'] = recall\n        outs['fscore'] = fscore\n        outs['frame_idx'] = frame_idx\n        return outs\n    def test_step(self, data_batch):\n        \"\"\"Test step.\n        \"\"\"\n        total = 0.0\n        proposals = 0.0\n        correct = 0.0\n        fscore = 0.0\n        eps = 1e-5\n        nms_thresh = 0.4\n        iou_thresh = 0.5\n        x_data = data_batch[0]\n        target = data_batch[1].squeeze(1)  # indeed do squeeze to adapt to paddle tensor\n        frame_idx = data_batch[2]\n        target.stop_gradient = True\n        # call Model forward\n        out = self.forward_net(x_data)\n        all_boxes = get_region_boxes(out)\n        out_boxes = []\n        for i in range(out.shape[0]):\n            boxes = all_boxes[i]\n            boxes = nms(boxes, nms_thresh)\n            out_boxes.append(boxes)\n            truths = target[i].reshape([-1, 5])"
        },
        {
            "comment": "The code computes precision, recall, and F-score for each class of the YOWO localizer. It iterates through ground truth boxes and confident proposal boxes to match them based on Intersection over Union (IoU) threshold. It counts correctly matched boxes and total boxes, then calculates precision, recall, and F-score using these values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_localizer.py\":125-146",
            "content": "            num_gts = truths_length(truths)\n            total = total + num_gts\n            pred_list = []\n            for i in range(len(boxes)):\n                if boxes[i][4] > 0.25:\n                    proposals = proposals + 1\n                    pred_list.append(i)\n            for i in range(num_gts):\n                box_gt = [truths[i][1], truths[i][2], truths[i][3], truths[i][4], 1.0, 1.0, truths[i][0]]\n                best_iou = 0\n                best_j = -1\n                for j in pred_list:  # ITERATE THROUGH ONLY CONFIDENT BOXES\n                    iou = bbox_iou(box_gt, boxes[j], x1y1x2y2=False)\n                    if iou > best_iou:\n                        best_j = j\n                        best_iou = iou\n                if best_iou > iou_thresh and int(boxes[best_j][6]) == box_gt[6]:\n                    correct = correct + 1\n        precision = 1.0 * correct / (proposals + eps)\n        recall = 1.0 * correct / (total + eps)\n        fscore = 2.0 * precision * recall / (precision + recall + eps)"
        },
        {
            "comment": "This code defines two functions within the yowo_localizer class. The first function, \"infer_step\", takes in a data batch and feeds it into the forward_net to get an output. The second function returns dictionaries for boxes, precision, recall, fscore, and frame_idx as outputs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/framework/localizers/yowo_localizer.py\":148-160",
            "content": "        outs = dict()\n        outs['boxes'] = out_boxes\n        outs['precision'] = precision\n        outs['recall'] = recall\n        outs['fscore'] = fscore\n        outs['frame_idx'] = frame_idx\n        return outs\n    def infer_step(self, data_batch):\n        \"\"\"Infer step.\n        \"\"\"\n        out = self.forward_net(data_batch[0])\n        return out"
        }
    ]
}