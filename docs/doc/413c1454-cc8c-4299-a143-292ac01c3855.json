{
    "summary": "This code initializes a reader class for PaddleVideo's MultimodalVideoTag application, preprocesses text, formats input sequences for BERT/ERNIE models, creates Record objects, generates batches with padding, and handles data generation for ERNIE models.",
    "details": [
        {
            "comment": "This code is for the \"ernie\" reader, a part of PaddleVideo's MultimodalVideoTag application. It includes licensing information and various import statements for different functionalities like file handling, JSON parsing, random number generation, logging, numpy operations, and namedtuple creation. The log variable is initialized for error reporting.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":0-34",
            "content": "\"\"\"\nernie reader\n\"\"\"\n#   Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import absolute_import\nimport sys\nimport os\nimport json\nimport random\nimport logging\nimport numpy as np\nimport six\nfrom io import open\nfrom collections import namedtuple\nfrom .tokenization import FullTokenizer, convert_to_unicode\nlog = logging.getLogger(__name__)"
        },
        {
            "comment": "This code snippet defines a `BaseReader` class which initializes an object with various parameters related to text preprocessing, including maximum sequence length, tokenizer, and other properties. It also includes a utility function `csv_reader` that reads data from files in CSV format. The code adjusts the Python output stream encoding if running on Python 3, ensuring consistent text handling across all outputs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":36-73",
            "content": "if six.PY3:\n    import io\n    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')\ndef csv_reader(fd, delimiter='\\t'):\n    \"\"\"csv_reader\n    \"\"\"\n    def gen():\n        \"\"\"gen\n        \"\"\"\n        for i in fd:\n            yield i.rstrip('\\n').split(delimiter)\n    return gen()\nclass BaseReader(object):\n    \"\"\"BaseReader\n    \"\"\"\n    def __init__(self,\n                 vocab_path,\n                 label_map_config=None,\n                 max_seq_len=512,\n                 do_lower_case=True,\n                 in_tokens=False,\n                 is_inference=False,\n                 random_seed=None,\n                 tokenizer=\"FullTokenizer\",\n                 is_classify=True,\n                 is_regression=False,\n                 for_cn=True,\n                 task_id=0):\n        self.max_seq_len = max_seq_len\n        self.tokenizer = FullTokenizer(vocab_file=vocab_path,\n                                       do_lower_case=do_lower_case)\n        self.vocab = self.tokenizer.vocab"
        },
        {
            "comment": "This code initializes various attributes of the class and sets up some configurations for tokenizing input data. It also loads a label map from a file if provided, or sets it to None otherwise. The \"_truncate_seq_pair\" function truncates sequence pairs in place to the maximum length specified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":74-101",
            "content": "        self.pad_id = self.vocab[\"[PAD]\"]\n        self.cls_id = self.vocab[\"[CLS]\"]\n        self.sep_id = self.vocab[\"[SEP]\"]\n        self.in_tokens = in_tokens\n        self.is_inference = is_inference\n        self.for_cn = for_cn\n        self.task_id = task_id\n        np.random.seed(random_seed)\n        self.is_classify = is_classify\n        self.is_regression = is_regression\n        self.current_example = 0\n        self.current_epoch = 0\n        self.num_examples = 0\n        if label_map_config:\n            with open(label_map_config, encoding='utf8') as f:\n                self.label_map = json.load(f)\n        else:\n            self.label_map = None\n    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n        # This is a simple heuristic which will always truncate the longer sequence\n        # one token at a time. This makes more sense than truncating an equal percent\n        # of tokens from each, since if one sequence is very short then each token"
        },
        {
            "comment": "This function converts an example into a record. It tokenizes text_a and optionally text_b, then truncates the sequences if they exceed max_seq_length by popping tokens from either tokens_a or tokens_b.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":102-130",
            "content": "        # that's truncated likely contains more information than a longer sequence.\n        while True:\n            total_length = len(tokens_a) + len(tokens_b)\n            if total_length <= max_length:\n                break\n            if len(tokens_a) > len(tokens_b):\n                tokens_a.pop()\n            else:\n                tokens_b.pop()\n    def _convert_example_to_record(self, example, max_seq_length, tokenizer):\n        \"\"\"Converts a single `Example` into a single `Record`.\"\"\"\n        text_a = convert_to_unicode(example.text_a)\n        tokens_a = tokenizer.tokenize(text_a)\n        tokens_b = None\n        has_text_b = False\n        if isinstance(example, dict):\n            has_text_b = \"text_b\" in example.keys()\n        else:\n            has_text_b = \"text_b\" in example._fields\n        if has_text_b:\n            text_b = convert_to_unicode(example.text_b)\n            tokens_b = tokenizer.tokenize(text_b)\n        if tokens_b:\n            # Modifies `tokens_a` and `tokens_b` in place so that the total"
        },
        {
            "comment": "The code ensures that the input sequences for BERT/ERNIE models are formatted correctly. If the sequence length is less than the specified maximum length, it accounts for [CLS], [SEP], and [SEP] tokens with adjustments. If the sequence length exceeds the limit, it truncates the longer token sequence accordingly. The code also assigns type_ids to indicate whether it's the first or second sequence, as these are used in the model's embedding vectors.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":131-150",
            "content": "            # length is less than the specified length.\n            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n            self._truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n        else:\n            # Account for [CLS] and [SEP] with \"- 2\"\n            if len(tokens_a) > max_seq_length - 2:\n                tokens_a = tokens_a[0:(max_seq_length - 2)]\n        # The convention in BERT/ERNIE is:\n        # (a) For sequence pairs:\n        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n        #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n        # (b) For single sequences:\n        #  tokens:   [CLS] the dog is hairy . [SEP]\n        #  type_ids: 0     0   0   0  0     0 0\n        #\n        # Where \"type_ids\" are used to indicate whether this is the first\n        # sequence or the second sequence. The embedding vectors for `type=0` and\n        # `type=1` were learned during pre-training and are added to the wordpiece\n        # embedding vector (and position vector). This is not *strictly* necessary"
        },
        {
            "comment": "This code prepares input data for the ERNIE model by combining tokens from two input sequences (tokens_a and tokens_b) into a single sequence. It appends \"[CLS]\" at the start, \"[SEP]\" to separate the sequences, and assigns text_type_id 0 or 1 based on the source sequence. The code also converts the tokens to token ids and generates position ids for the input data. This is specifically designed for classification tasks where the \"[CLS]\" vector represents the overall sentence vector after fine-tuning the entire model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":151-178",
            "content": "        # since the [SEP] token unambiguously separates the sequences, but it makes\n        # it easier for the model to learn the concept of sequences.\n        #\n        # For classification tasks, the first vector (corresponding to [CLS]) is\n        # used as as the \"sentence vector\". Note that this only makes sense because\n        # the entire model is fine-tuned.\n        tokens = []\n        text_type_ids = []\n        tokens.append(\"[CLS]\")\n        text_type_ids.append(0)\n        for token in tokens_a:\n            tokens.append(token)\n            text_type_ids.append(0)\n        tokens.append(\"[SEP]\")\n        text_type_ids.append(0)\n        if tokens_b:\n            for token in tokens_b:\n                tokens.append(token)\n                text_type_ids.append(1)\n            tokens.append(\"[SEP]\")\n            text_type_ids.append(1)\n        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n        position_ids = list(range(len(token_ids)))\n        if self.is_inference:\n            Record = namedtuple('Record',"
        },
        {
            "comment": "This code defines a function to create a \"Record\" object, which contains token_ids, text_type_ids, position_ids (possibly label_id and qid depending on the example). It also includes another function _prepare_batch_data that generates batch records from examples. The batch size and phase are also taken as parameters in this function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":179-206",
            "content": "                                ['token_ids', 'text_type_ids', 'position_ids'])\n            record = Record(token_ids=token_ids,\n                            text_type_ids=text_type_ids,\n                            position_ids=position_ids)\n        else:\n            if self.label_map:\n                label_id = self.label_map[example.label]\n            else:\n                label_id = example.label\n            Record = namedtuple('Record', [\n                'token_ids', 'text_type_ids', 'position_ids', 'label_id', 'qid'\n            ])\n            qid = None\n            if \"qid\" in example._fields:\n                qid = example.qid\n            record = Record(token_ids=token_ids,\n                            text_type_ids=text_type_ids,\n                            position_ids=position_ids,\n                            label_id=label_id,\n                            qid=qid)\n        return record\n    def _prepare_batch_data(self, examples, batch_size, phase=None):\n        \"\"\"generate batch records\"\"\"\n        batch_records, max_len = [], 0"
        },
        {
            "comment": "This code iterates through examples and converts them to records. It then appends the records to a batch and pads the batch with zeros if it reaches the maximum size. It yields batches of records, ensuring that each batch is padded to the same length before being passed to the next step in the process. This class inherits from BaseReader and is used for getting Ernie embedding. The method _pad_batch_records pads the batch with zeros if it exceeds the maximum size, ensuring all batches are of equal length.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":207-234",
            "content": "        for index, example in enumerate(examples):\n            if phase == \"train\":\n                self.current_example = index\n            record = self._convert_example_to_record(example, self.max_seq_len,\n                                                     self.tokenizer)\n            max_len = max(max_len, len(record.token_ids))\n            if self.in_tokens:\n                to_append = (len(batch_records) + 1) * max_len <= batch_size\n            else:\n                to_append = len(batch_records) < batch_size\n            if to_append:\n                batch_records.append(record)\n            else:\n                yield self._pad_batch_records(batch_records)\n                batch_records, max_len = [record], len(record.token_ids)\n        if batch_records:\n            yield self._pad_batch_records(batch_records)\nclass ExtractEmbeddingReader(BaseReader):\n    \"\"\"\n    data prepare for getting erine embedding \n    \"\"\"\n    def _pad_batch_records(self, batch_records):\n        \"\"\"\n        \u5bf9\u5b57\u6807\u53f7\uff0c\u4f4d\u7f6e\u6807\u53f7\u7279\u5f81\u8fdb\u884c\u56fa\u5b9a\u957f\u5ea6\u8865\u5168\n        batch_records \u5305\u542b\u591a\u6761\u6587\u672c\u7684\u6807\u53f7"
        },
        {
            "comment": "This code is processing a batch of records and padding token ids, text type ids, position ids, and task ids for an ERNIE (Enhanced Refined Network with Incremental Learning and Exploration) model. The processed data will be used as input for the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":235-256",
            "content": "        return [\u5b57\u6807\u53f7\u5217\u8868\uff0c\u6587\u672c\u7c7b\u578b\u5217\u8868\uff0c\u4f4d\u7f6e\u7279\u5f81\u5217\u8868\uff0c\u4efb\u52a1\u6807\u53f7\u5217\u8868\uff0c\u63a9\u7801\u5217\u8868]\n        \"\"\"\n        batch_token_ids = [record.token_ids for record in batch_records]\n        batch_text_type_ids = [\n            record.text_type_ids for record in batch_records\n        ]\n        batch_position_ids = [record.position_ids for record in batch_records]\n        # padding\n        padded_token_ids, input_mask, seq_lens = pad_batch_data(\n            batch_token_ids,\n            pad_idx=self.pad_id,\n            return_input_mask=True,\n            return_seq_lens=True,\n            max_len=self.max_seq_len)\n        padded_text_type_ids = pad_batch_data(batch_text_type_ids,\n                                              pad_idx=self.pad_id,\n                                              max_len=self.max_seq_len)\n        padded_position_ids = pad_batch_data(batch_position_ids,\n                                             pad_idx=self.pad_id,\n                                             max_len=self.max_seq_len)\n        padded_task_ids = np.ones_like(padded_token_ids,"
        },
        {
            "comment": "This code is related to text processing and data generation for a specific task reader. It converts input texts into indexed representations and pads the data to ensure consistent sequence lengths. The function `data_generate_from_text` takes in a single text, converts it into a record, pads the batch of records, and returns the resulting one-hot encoded text representation. The `pad_batch_data` function is used for padding other types of data as well.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":257-288",
            "content": "                                       dtype=\"int64\") * self.task_id\n        return_list = [\n            padded_token_ids, padded_text_type_ids, padded_position_ids,\n            padded_task_ids, input_mask\n        ]\n        return return_list\n    def data_generate_from_text(self, text):\n        \"\"\"\n        trans text to idx\n        input single text\n        return 5*maxlen*1\n        \"\"\"\n        Example = namedtuple('Example', ['text_a', 'label'])\n        example = Example(text, 0)\n        records = [\n            self._convert_example_to_record(example, self.max_seq_len,\n                                            self.tokenizer)\n        ]\n        pad_records = self._pad_batch_records(records)\n        text_one_hot = np.concatenate(pad_records, axis=0).astype('int64')\n        return text_one_hot\ndef pad_batch_data(insts,\n                   pad_idx=0,\n                   max_len=None,\n                   return_pos=False,\n                   return_input_mask=False,\n                   return_max_len=False,\n                   return_num_token=False,"
        },
        {
            "comment": "This function pads instances to the maximum sequence length in a batch. It first calculates the max_len based on instance lengths and then adds padding to shorter instances if necessary. It creates a 3D tensor of input data, position data (if required), and attention masks (if required). These tensors are added to a return list before being returned by the function. The padding is used to make no effect on parameter gradients by being masked out with weights.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":289-316",
            "content": "                   return_seq_lens=False):\n    \"\"\"\n    Pad the instances to the max sequence length in batch, and generate the\n    corresponding position data and attention bias.\n    \"\"\"\n    return_list = []\n    if max_len is None:\n        max_len = max(len(inst) for inst in insts)\n    # Any token included in dict can be used to pad, since the paddings' loss\n    # will be masked out by weights and make no effect on parameter gradients.\n    inst_data = np.array(\n        [inst + list([pad_idx] * (max_len - len(inst))) for inst in insts])\n    return_list += [inst_data.astype(\"int64\").reshape([-1, max_len, 1])]\n    # position data\n    if return_pos:\n        inst_pos = np.array([\n            list(range(0, len(inst))) + [pad_idx] * (max_len - len(inst))\n            for inst in insts\n        ])\n        return_list += [inst_pos.astype(\"int64\").reshape([-1, max_len, 1])]\n    if return_input_mask:\n        # This is used to avoid attention on paddings.\n        input_mask_data = np.array(\n            [[1] * len(inst) + [0] * (max_len - len(inst)) for inst in insts])"
        },
        {
            "comment": "This code prepares a return list by adding various elements like input_mask_data, max_len (if required), number of tokens (if required), and sequence lengths (if required) before returning the final list.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py\":317-333",
            "content": "        input_mask_data = np.expand_dims(input_mask_data, axis=-1)\n        return_list += [input_mask_data.astype(\"float32\")]\n    if return_max_len:\n        return_list += [max_len]\n    if return_num_token:\n        num_token = 0\n        for inst in insts:\n            num_token += len(inst)\n        return_list += [num_token]\n    if return_seq_lens:\n        seq_lens = np.array([len(inst) for inst in insts])\n        return_list += [seq_lens.astype(\"int64\").reshape([-1])]\n    return return_list if len(return_list) > 1 else return_list[0]"
        }
    ]
}