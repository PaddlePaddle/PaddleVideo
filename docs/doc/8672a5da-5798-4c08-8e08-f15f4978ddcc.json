{
    "summary": "The SkeletonMetric class in PaddleVideo measures skeleton-based model performance metrics, supports batch size 1 and single card testing, and calculates top1 and top5 accuracy for batches with labels. It logs processing info, updates progress, and accumulates metrics while saving results to 'submission.csv'.",
    "details": [
        {
            "comment": "This code is for the SkeletonMetric class in PaddleVideo, a machine learning framework. The class measures performance metrics for skeleton-based models. It supports batch size 1 and single card testing. Results can be saved to a file named 'submission.csv'.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/skeleton_metric.py\":0-37",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nimport numpy as np\nimport paddle\nimport csv\nimport paddle.nn.functional as F\nfrom .registry import METRIC\nfrom .base import BaseMetric\nfrom paddlevideo.utils import get_logger\nlogger = get_logger(\"paddlevideo\")\n@METRIC.register\nclass SkeletonMetric(BaseMetric):\n    \"\"\"\n    Test for Skeleton based model.\n    note: only support batch size = 1, single card test.\n    Args:\n        out_file: str, file to save test results.\n    \"\"\"\n    def __init__(self,\n                 data_size,\n                 batch_size,\n                 out_file='submission.csv',"
        },
        {
            "comment": "This code initializes a metrics class for tracking accuracy metrics during training. The `__init__` function sets up the top1, top5, and values lists to store metric results, as well as an output file path and the desired top k value. The `update` method processes data from each batch iteration, updating the metrics based on whether the input data contains labels or not. It also handles distributed training by averaging across multiple workers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/skeleton_metric.py\":38-64",
            "content": "                 log_interval=1,\n                 top_k=5):\n        \"\"\"prepare for metrics\n        \"\"\"\n        super().__init__(data_size, batch_size, log_interval)\n        self.top1 = []\n        self.top5 = []\n        self.values = []\n        self.out_file = out_file\n        self.k = top_k\n    def update(self, batch_id, data, outputs):\n        \"\"\"update metrics during each iter\n        \"\"\"\n        if data[0].shape[0] != outputs.shape[0]:\n            num_segs = data[0].shape[1]\n            batch_size = outputs.shape[0]\n            outputs = outputs.reshape(\n                [batch_size // num_segs, num_segs, outputs.shape[-1]])\n            outputs = outputs.mean(axis=1)\n        if len(data) == 2:  # data with label\n            labels = data[1]\n            top1 = paddle.metric.accuracy(input=outputs, label=labels, k=1)\n            top5 = paddle.metric.accuracy(input=outputs, label=labels, k=self.k)\n            if self.world_size > 1:\n                top1 = paddle.distributed.all_reduce(\n                    top1, op=paddle.distributed.ReduceOp.SUM) / self.world_size"
        },
        {
            "comment": "This code segment is part of a class that handles metrics for a testing process. It calculates top1 and top5 accuracy for batches with labels and stores them. For batches without labels, it performs softmax on outputs and gets the class with highest probability. It logs processing information and updates progress. Finally, it accumulates metrics when all iterations are done.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/skeleton_metric.py\":65-87",
            "content": "                top5 = paddle.distributed.all_reduce(\n                    top5, op=paddle.distributed.ReduceOp.SUM) / self.world_size\n            self.top1.append(top1.numpy())\n            self.top5.append(top5.numpy())\n        else:  # data without label, only support batch_size=1. Used for fsd-10.\n            prob = F.softmax(outputs)\n            clas = paddle.argmax(prob, axis=1).numpy()[0]\n            self.values.append((batch_id, clas))\n        # preds ensemble\n        if batch_id % self.log_interval == 0:\n            logger.info(\"[TEST] Processing batch {}/{} ...\".format(\n                batch_id,\n                self.data_size // (self.batch_size * self.world_size)))\n    def accumulate(self):\n        \"\"\"accumulate metrics when finished all iters.\n        \"\"\"\n        if self.top1:  # data with label\n            logger.info('[TEST] finished, avg_acc1= {}, avg_acc5= {}'.format(\n                np.mean(np.array(self.top1)), np.mean(np.array(self.top5))))\n        else:\n            headers = ['sample_index', 'predict_category']"
        },
        {
            "comment": "Writes headers and values from self.values to file, saves results in out_file and logs success.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/skeleton_metric.py\":88-95",
            "content": "            with open(\n                    self.out_file,\n                    'w',\n            ) as fp:\n                writer = csv.writer(fp)\n                writer.writerow(headers)\n                writer.writerows(self.values)\n            logger.info(\"Results saved in {} !\".format(self.out_file))"
        }
    ]
}