{
    "summary": "The code defines an Ernie model configuration and initializes the ERNIE model using Paddle's embedding layer. It also includes a multimodal video tagging model, embeddings, data pre-processing, attention mask creation, encoder usage, and TextCNN for sequence feature extraction. The code creates 1D convolutional layers with specified parameters and returns the output.",
    "details": [
        {
            "comment": "This code snippet contains the Ernie model class definition. It imports necessary modules, defines logging, and initializes a class for configuring the Ernie model. The class inherits from `object` and represents the configuration to be used in the Ernie model architecture.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":0-32",
            "content": "#   Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Ernie model.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import absolute_import\nimport json\nimport six\nimport logging\nimport paddle\nimport paddle.static as static\nfrom io import open\nfrom .transformer_encoder import encoder, pre_process_layer\nlog = logging.getLogger(__name__)\nclass ErnieConfig(object):"
        },
        {
            "comment": "This code defines a class for an Ernie model configuration. It initializes the config with a given path, parses the config file using JSON, allows getting and setting items from/to the configuration dictionary, and provides a print_config method to display the configuration in a readable format.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":33-72",
            "content": "    \"\"\"\n    Erine model config\n    \"\"\"\n    def __init__(self, config_path):\n        \"\"\"\n        init\n        \"\"\"\n        self._config_dict = self._parse(config_path)\n    def _parse(self, config_path):\n        \"\"\"\n        parse config\n        \"\"\"\n        try:\n            with open(config_path, 'r', encoding='utf8') as json_file:\n                config_dict = json.load(json_file)\n        except Exception:\n            raise IOError(\"Error in parsing Ernie model config file '%s'\" %\n                          config_path)\n        else:\n            return config_dict\n    def __getitem__(self, key):\n        \"\"\"\n        get item\n        \"\"\"\n        return self._config_dict.get(key, None)\n    def __setitem__(self, key, value):\n        \"\"\"\n        set item\n        \"\"\"\n        self._config_dict[key] = value\n    def print_config(self):\n        \"\"\"\n        print config\n        \"\"\"\n        for arg, value in sorted(six.iteritems(self._config_dict)):\n            log.info('%s: %s' % (arg, value))\n        log.info('------------------------------------------------')"
        },
        {
            "comment": "The code defines the ErnieModel class, which initializes an ERINE model with parameters such as source ids, position ids, sentence ids, task ids, input mask, configuration, weight sharing, and use of fp16. The class attributes are initialized based on the provided configuration.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":75-105",
            "content": "class ErnieModel(object):\n    \"\"\"\n    ERINE Model\n    \"\"\"\n    def __init__(self,\n                 src_ids,\n                 position_ids,\n                 sentence_ids,\n                 task_ids,\n                 input_mask,\n                 config,\n                 weight_sharing=True,\n                 use_fp16=False):\n        \"\"\"\n        init model\n        \"\"\"\n        self._emb_size = config['hidden_size']\n        self._n_layer = config['num_hidden_layers']\n        self._n_head = config['num_attention_heads']\n        self._voc_size = config['vocab_size']\n        self._max_position_seq_len = config['max_position_embeddings']\n        if config['sent_type_vocab_size']:\n            self._sent_types = config['sent_type_vocab_size']\n        else:\n            self._sent_types = config['type_vocab_size']\n        self._use_task_id = config['use_task_id']\n        if self._use_task_id:\n            self._task_types = config['task_type_vocab_size']\n        self._hidden_act = config['hidden_act']\n        self._prepostprocess_dropout = config['hidden_dropout_prob']"
        },
        {
            "comment": "This code initializes the ERNIE model parameters and builds the model. It sets various attributes such as attention dropout probability, embedding names for word, position, sentence, and task, data types, and initializer range. The _build_model function is then called to create the model using Paddle's embedding layer.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":106-131",
            "content": "        self._attention_dropout = config['attention_probs_dropout_prob']\n        self._weight_sharing = weight_sharing\n        self._word_emb_name = \"word_embedding\"\n        self._pos_emb_name = \"pos_embedding\"\n        self._sent_emb_name = \"sent_embedding\"\n        self._task_emb_name = \"task_embedding\"\n        self._dtype = \"float16\" if use_fp16 else \"float32\"\n        self._emb_dtype = \"float32\"\n        # Initialize all weigths by truncated normal initializer, and all biases\n        # will be initialized by constant zero by default.\n        self._param_initializer = paddle.nn.initializer.TruncatedNormal(\n            std=config['initializer_range'])\n        self._build_model(src_ids, position_ids, sentence_ids, task_ids,\n                          input_mask)\n    def _build_model(self, src_ids, position_ids, sentence_ids, task_ids,\n                     input_mask):\n        \"\"\"\n        build  model\n        \"\"\"\n        # padding id in vocabulary must be set to 0\n        emb_out = static.nn.embedding(\n            input=src_ids,"
        },
        {
            "comment": "This code initializes and concatenates three embeddings - word, position, and sentence - in a multimodal video tagging model. The embeddings are defined with specific sizes and data types. Two embeddings (position_emb_out and sent_emb_out) are added to the original embedding (emb_out), and then these combined embeddings are returned.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":132-157",
            "content": "            size=[self._voc_size, self._emb_size],\n            dtype=self._emb_dtype,\n            param_attr=paddle.ParamAttr(\n                name=self._word_emb_name, initializer=self._param_initializer),\n            is_sparse=False)\n        position_emb_out = static.nn.embedding(\n            input=position_ids,\n            size=[self._max_position_seq_len, self._emb_size],\n            dtype=self._emb_dtype,\n            param_attr=paddle.ParamAttr(\n                name=self._pos_emb_name, initializer=self._param_initializer))\n        sent_emb_out = static.nn.embedding(\n            sentence_ids,\n            size=[self._sent_types, self._emb_size],\n            dtype=self._emb_dtype,\n            param_attr=paddle.ParamAttr(\n                name=self._sent_emb_name, initializer=self._param_initializer))\n        # emb_out = emb_out + position_emb_out\n        # emb_out = emb_out + sent_emb_out\n        emb_out = paddle.add(x=emb_out, y=position_emb_out)\n        emb_out = paddle.add(x=emb_out, y=sent_emb_out)\n        if self._use_task_id:"
        },
        {
            "comment": "This code initializes an embedding layer for task types, adds it to the embeddings, applies pre-processing with dropout if necessary, and casts the embeddings to the desired dtype. It also creates a self-attention mask, stacks it for each attention head, sets its gradient to stop during backpropagation, and passes the embeddings through an encoder.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":158-183",
            "content": "            task_emb_out = static.nn.embedding(\n                task_ids,\n                size=[self._task_types, self._emb_size],\n                dtype=self._emb_dtype,\n                param_attr=paddle.ParamAttr(\n                    name=self._task_emb_name,\n                    initializer=self._param_initializer))\n            emb_out = emb_out + task_emb_out\n        emb_out = pre_process_layer(\n            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')\n        if self._dtype == \"float16\":\n            emb_out = paddle.cast(x=emb_out, dtype=self._dtype)\n            input_mask = paddle.cast(x=input_mask, dtype=self._dtype)\n        self_attn_mask = paddle.matmul(\n            x=input_mask, y=input_mask, transpose_y=True)\n        self_attn_mask = paddle.scale(\n            x=self_attn_mask, scale=10000.0, bias=-1.0, bias_after_scale=False)\n        n_head_self_attn_mask = paddle.stack(\n            x=[self_attn_mask] * self._n_head, axis=1)\n        n_head_self_attn_mask.stop_gradient = True\n        self._enc_out = encoder("
        },
        {
            "comment": "This code is defining and initializing a model for an encoder layer in a deep learning application. The model takes several parameters such as embedding size, number of layers and heads, dropout rates, activation function, etc. It then casts the output to the specified data type if necessary. The `get_sequence_output` method returns the sequence output from the encoder layer and `get_sequence_textcnn_output` takes in a feature sequence and an input mask to generate the output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":184-214",
            "content": "            enc_input=emb_out,\n            attn_bias=n_head_self_attn_mask,\n            n_layer=self._n_layer,\n            n_head=self._n_head,\n            d_key=self._emb_size // self._n_head,\n            d_value=self._emb_size // self._n_head,\n            d_model=self._emb_size,\n            d_inner_hid=self._emb_size * 4,\n            prepostprocess_dropout=self._prepostprocess_dropout,\n            attention_dropout=self._attention_dropout,\n            relu_dropout=0,\n            hidden_act=self._hidden_act,\n            preprocess_cmd=\"\",\n            postprocess_cmd=\"dan\",\n            param_initializer=self._param_initializer,\n            name='encoder')\n        if self._dtype == \"float16\":\n            self._enc_out = paddle.cast(\n                x=self._enc_out, dtype=self._emb_dtype)\n    def get_sequence_output(self):\n        \"\"\"\n        get sequence output\n        \"\"\"\n        return self._enc_out\n    def get_sequence_textcnn_output(self, sequence_feature, input_mask):\n        \"\"\"\n        get sequence output\n        \"\"\""
        },
        {
            "comment": "This code defines a TextCNN model for sequence feature extraction. It pads the input sequence, applies convolutions with various window sizes, and pools the results. The get_pooled_output function extracts the first feature of each sequence for classification by applying an FC layer with tanh activation. The textcnn function initializes a TextCNN model with specified window sizes and hidden dimensions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":215-242",
            "content": "        seq_len = paddle.sum(x=input_mask, axis=[1, 2])\n        seq_len = paddle.cast(seq_len, 'int64')\n        sequence_feature = paddle.static.nn.sequence_unpad(sequence_feature, seq_len)\n        return self.textcnn(sequence_feature)\n    def get_pooled_output(self):\n        \"\"\"Get the first feature of each sequence for classification\"\"\"\n        next_sent_feat = paddle.slice(\n            input=self._enc_out, axes=[1], starts=[0], ends=[1])\n        next_sent_feat = static.nn.fc(\n            x=next_sent_feat,\n            size=self._emb_size,\n            activation=\"tanh\",\n            weight_attr=paddle.ParamAttr(\n                name=\"pooled_fc.w_0\", initializer=self._param_initializer),\n            bias_attr=\"pooled_fc.b_0\")\n        return next_sent_feat\n    def textcnn(self, feature, name='text_cnn'):\n        \"\"\"\n        TextCNN sequence feature extraction\n        \"\"\"\n        win_sizes = [2, 3, 4]\n        hid_dim = 256\n        convs = []\n        for win_size in win_sizes:\n            conv_h = paddle.fluid.nets.sequence_conv_pool(input=feature,"
        },
        {
            "comment": "This code is creating a 1D convolutional layer with specified parameters, including the number of filters, filter size, activation function, and pooling type. The resulting convolutional layers are appended to the `convs` list, and then concatenated along axis 1 to form `convs_out`. Finally, the function returns `convs_out`.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/models/ernie.py\":243-249",
            "content": "                                                   num_filters=hid_dim,\n                                                   filter_size=win_size,\n                                                   act=\"tanh\",\n                                                   pool_type=\"max\")\n            convs.append(conv_h)\n        convs_out = paddle.concat(x=convs, axis=1)\n        return convs_out"
        }
    ]
}