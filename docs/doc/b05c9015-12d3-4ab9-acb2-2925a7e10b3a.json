{
    "summary": "This code utilizes the BAIDU CLOUD action to classify videos, extracts features, and performs prediction using a pre-trained model. It saves proposal counts and bounding box results in a JSON file with UTF-8 encoding and indentation.",
    "details": [
        {
            "comment": "This code is loading a model for video classification using the BAIDU CLOUD action. It first loads the configuration file, then prints the configurations, and finally initializes the InferModel class with the loaded configurations. The `video_classify` function takes a video name as input, likely to perform feature extraction or prediction on that video.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/extractor/extract_bmn.py\":0-48",
            "content": "#!./python27-gcc482/bin/python\n# coding: utf-8\n\"\"\"\nBAIDU CLOUD action\n\"\"\"\nimport os\nimport sys\nimport pickle\nimport json\nimport time\nimport shutil\nimport numpy as np\nsys.path.append(\"../predict/action_detect\")\nimport models.bmn_infer as prop_model\nfrom utils.preprocess import get_images\nfrom utils.config_utils import parse_config, print_configs\nimport utils.config_utils as config_utils\nimport logger\nlogger = logger.Logger()\ndef load_model(cfg_file=\"configs/configs.yaml\"):\n    \"\"\"\n    load_model\n    \"\"\"\n    logger.info(\"load model ... \")\n    global infer_configs\n    infer_configs = parse_config(cfg_file)\n    print_configs(infer_configs, \"Infer\")\n    t0 = time.time()\n    global prop_model\n    prop_model = prop_model.InferModel(infer_configs)\n    t1 = time.time()\n    logger.info(\"step0: load model time: {} min\\n\".format((t1 - t0) * 1.0 / 60))\ndef video_classify(video_name):\n    \"\"\"\n    extract_feature\n    \"\"\"\n    logger.info('predict ... ')\n    logger.info(video_name)\n    imgs_path = video_name.replace(\".mp4\", \"\").replace(\"mp4\", \"frames\")"
        },
        {
            "comment": "This code extracts features from videos and predicts proposals using a pre-trained model. It loads the necessary configurations, creates feature directories if they don't exist, reads video URLs from a file, processes each video to obtain bounding box results, and saves these results into a list of dictionaries for further analysis or processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/extractor/extract_bmn.py\":49-82",
            "content": "    pcm_path = video_name.replace(\".mp4\", \".pcm\").replace(\"mp4\", \"pcm\")\n    # step 1: extract feature\n    feature_path = video_name.replace(\".mp4\", \".pkl\").replace(\"mp4\", \"features\")\n    video_features = pickle.load(open(feature_path, 'rb'))\n    # step2: get proposal\n    t0 = time.time()\n    bmn_results = prop_model.predict(infer_configs, material=video_features)\n    t1 = time.time()\n    logger.info(np.array(bmn_results).shape)\n    logger.info(\"step2: proposal time: {} min\".format((t1 - t0) * 1.0 / 60))\n    return bmn_results\nif __name__ == '__main__':\n    dataset_dir = \"../datasets/EuroCup2016\"\n    if not os.path.exists(dataset_dir + '/feature_bmn'):\n        os.mkdir(dataset_dir + '/feature_bmn')\n    results = []\n    load_model()\n    video_url = os.path.join(dataset_dir, 'url.list')\n    with open(video_url, 'r') as f:\n        lines = f.readlines()\n    lines = [os.path.join(dataset_dir, k.strip()) for k in lines]\n    for line in lines:\n        bmn_results = video_classify(line)\n        results.append({\n            'video_name': os.path.basename(line).split('.')[0],"
        },
        {
            "comment": "This code saves the number of proposals and a list of bounding box results for each proposal in a JSON file, formatting it with indentation and using UTF-8 encoding.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/extractor/extract_bmn.py\":83-90",
            "content": "            'num_proposal': len(bmn_results),\n            'bmn_results': bmn_results\n        })\n    with open(dataset_dir + '/feature_bmn/prop.json', 'w',\n              encoding='utf-8') as f:\n        data = json.dumps(results, indent=4, ensure_ascii=False)\n        f.write(data)"
        }
    ]
}