{
    "summary": "This code defines a PyTorch class for batch normalization, initializing a BatchNorm3D layer and including methods to compute mean and standard deviation. It also supports aggregating statistics from multiple splits and performs forward pass for training or evaluation.",
    "details": [
        {
            "comment": "This code defines a function `get_norm` that returns the normalization layer based on the provided bn_norm_type and bn_num_splits. If bn_norm_type is 'batchnorm', it returns paddle.nn.BatchNorm3D, otherwise if it's 'sub_batchnorm', it returns a partially applied SubBatchNorm3D function with num_splits parameter set to bn_num_splits. If the norm type isn't supported, it raises a NotImplementedError. It also defines `aggregate_sub_bn_stats` function that recursively finds all SubBN modules in the given model and aggregates sub-BN stats by calling aggregate_stats() on each found SubBatchNorm3D module. It returns the count of SubBN modules found.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/batchnorm_helper.py\":0-35",
            "content": "from functools import partial\nimport paddle\ndef get_norm(bn_norm_type, bn_num_splits):\n    \"\"\"\n    Args:\n        cfg (CfgNode): model building configs, details are in the comments of\n            the config file.\n    Returns:\n        nn.Layer: the normalization layer.\n    \"\"\"\n    if bn_norm_type == \"batchnorm\":\n        return paddle.nn.BatchNorm3D\n    elif bn_norm_type == \"sub_batchnorm\":\n        return partial(SubBatchNorm3D, num_splits=bn_num_splits)\n    else:\n        raise NotImplementedError(\n            \"Norm type {} is not supported\".format(bn_norm_type))\ndef aggregate_sub_bn_stats(model):\n    \"\"\"\n    Recursively find all SubBN modules and aggregate sub-BN stats.\n    Args:\n        model (nn.Layer): model to be aggregate sub-BN stats\n    Returns:\n        count (int): number of SubBN module found.\n    \"\"\"\n    count = 0\n    for child in model.children():\n        if isinstance(child, SubBatchNorm3D):\n            child.aggregate_stats()\n            count += 1\n        else:\n            count += aggregate_sub_bn_stats(child)"
        },
        {
            "comment": "The code defines a SubBatchNorm3D class that implements Batch Normalization with the option to split the batch dimension into N splits. It computes stats for each subset of examples independently during training and aggregates them during evaluation. The class takes num_splits as an argument and other parameters such as num_features, weight_attr, and bias_attr are set in its constructor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/batchnorm_helper.py\":36-63",
            "content": "    return count\nclass SubBatchNorm3D(paddle.nn.Layer):\n    \"\"\"\n    Implement based on paddle2.0.\n    The standard BN layer computes stats across all examples in a GPU. In some\n    cases it is desirable to compute stats across only a subset of examples\n    SubBatchNorm3D splits the batch dimension into N splits, and run BN on\n    each of them separately (so that the stats are computed on each subset of\n    examples (1/N of batch) independently. During evaluation, it aggregates\n    the stats from all splits into one BN.\n    \"\"\"\n    def __init__(self, num_splits, **args):\n        \"\"\"\n        Args:\n            num_splits (int): number of splits.\n            args (list): list of args\n        \"\"\"\n        super(SubBatchNorm3D, self).__init__()\n        self.num_splits = num_splits\n        self.num_features = args[\"num_features\"]\n        self.weight_attr = args[\"weight_attr\"]\n        self.bias_attr = args[\"bias_attr\"]\n        # Keep only one set of weight and bias (outside).\n        if self.weight_attr == False:\n            self.weight = self.create_parameter("
        },
        {
            "comment": "This code initializes the weight and bias parameters of a BatchNorm layer in PaddlePaddle. If learning rate is 0, it sets weight to have no gradient update, and if `bias_attr` is False, it sets the bias to True and stops its gradients from being updated.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/batchnorm_helper.py\":64-84",
            "content": "                attr=None,\n                shape=[self.num_features],\n                default_initializer=paddle.nn.initializer.Constant(1.0))\n            self.weight.stop_gradient = True\n        else:\n            self.weight = self.create_parameter(\n                attr=self.weight_attr,\n                shape=[self.num_features],\n                default_initializer=paddle.nn.initializer.Constant(1.0))\n            self.weight.stop_gradient = self.weight_attr is not None \\\n                                        and self.weight_attr.learning_rate == 0.\n        if self.bias_attr == False:\n            self.bias = self.create_parameter(attr=None,\n                                              shape=[self.num_features],\n                                              is_bias=True)\n            self.bias.stop_gradient = True\n        else:\n            self.bias = self.create_parameter(attr=self.bias_attr,\n                                              shape=[self.num_features],\n                                              is_bias=True)"
        },
        {
            "comment": "Class is initializing a BatchNorm3D layer and storing two instances of it (self.bn and self.split_bn). The first instance has its weights and bias set as fixed (inner), while the second instance handles splitting the features for a specified number of splits. The function _get_aggregated_mean_std calculates the aggregated mean and standard deviation by summing each set's means and stds, then dividing them by the total count to get the average values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/batchnorm_helper.py\":85-107",
            "content": "            self.bias.stop_gradient = self.bias_attr is not None \\\n                                      and self.bias_attr.learning_rate == 0.\n        # set weights and bias fixed (inner).\n        args[\"weight_attr\"] = False\n        args[\"bias_attr\"] = False\n        self.bn = paddle.nn.BatchNorm3D(**args)\n        # update number of features used in split_bn\n        args[\"num_features\"] = self.num_features * self.num_splits\n        self.split_bn = paddle.nn.BatchNorm3D(**args)\n    def _get_aggregated_mean_std(self, means, stds, n):\n        \"\"\"\n        Calculate the aggregated mean and stds.\n        Use the method of update mean and std when merge multi-part data.\n        Args:\n            means (tensor): mean values.\n            stds (tensor): standard deviations.\n            n (int): number of sets of means and stds.\n        \"\"\"\n        mean = paddle.sum(paddle.reshape(means, (n, -1)), axis=0) / n\n        std = (paddle.sum(paddle.reshape(stds, (n, -1)), axis=0) / n +\n               paddle.sum(paddle.reshape("
        },
        {
            "comment": "This code is defining a class that implements batch normalization in PyTorch. The class has methods to compute the mean and standard deviation, aggregate statistics from multiple splits of batch normalization, and perform forward pass for training or evaluation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/batchnorm_helper.py\":108-134",
            "content": "                   paddle.pow((paddle.reshape(means, (n, -1)) - mean), 2),\n                   (n, -1)),\n                          axis=0) / n)\n        return mean, std\n    def aggregate_stats(self):\n        \"\"\"\n        Synchronize running_mean, and running_var to self.bn.\n        Call this before eval, then call model.eval();\n        When eval, forward function will call self.bn instead of self.split_bn,\n        During this time the running_mean, and running_var of self.bn has been obtained from\n        self.split_bn.\n        \"\"\"\n        if self.split_bn.training:\n            bn_mean_tensor, bn_variance_tensor = self._get_aggregated_mean_std(\n                self.split_bn._mean,\n                self.split_bn._variance,\n                self.num_splits,\n            )\n            self.bn._mean.set_value(bn_mean_tensor)\n            self.bn._variance.set_value(bn_variance_tensor)\n    def forward(self, x):\n        if self.training:\n            n, c, t, h, w = x.shape\n            x = paddle.reshape(\n                x, (n // self.num_splits, c * self.num_splits, t, h, w))"
        },
        {
            "comment": "The code applies batch normalization to the input tensor and multiplies it by a weight matrix. Then, it adds a bias vector and returns the normalized tensor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/batchnorm_helper.py\":135-141",
            "content": "            x = self.split_bn(x)\n            x = paddle.reshape(x, (n, c, t, h, w))\n        else:\n            x = self.bn(x)\n        x = paddle.multiply(x, paddle.reshape(self.weight, (-1, 1, 1, 1)))\n        x = paddle.add(x, paddle.reshape(self.bias, (-1, 1, 1, 1)))\n        return x"
        }
    ]
}