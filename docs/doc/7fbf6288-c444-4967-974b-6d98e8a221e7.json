{
    "summary": "This code defines the PaddleVideo framework's \"Recognizer2D\" class for 2D model training, with methods train_step(), recognizer2d.py, val_step, and test_step handling loss metrics calculation in different modes.",
    "details": [
        {
            "comment": "This code snippet is part of the PaddleVideo framework and defines a class called \"Recognizer2D\" which is a 2D recognizer model for training. It inherits from \"BaseRecognizer\" and has a method \"train_step()\" that handles how the model trains, taking input data batch as argument and returning output. The \"recognizers\" registry is used to register this class.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/recognizer2d.py\":0-28",
            "content": "\"\"\"\n# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\"\"\"\nfrom ...registry import RECOGNIZERS\nfrom .base import BaseRecognizer\nimport paddle\nfrom paddlevideo.utils import get_logger\nlogger = get_logger(\"paddlevideo\")\n@RECOGNIZERS.register()\nclass Recognizer2D(BaseRecognizer):\n    \"\"\"2D recognizer model framework.\"\"\"\n    def train_step(self, data_batch):\n        \"\"\"Define how the model is going to train, from input to output.\n        \"\"\"\n        #NOTE: As the num_segs is an attribute of dataset phase, and didn't pass to build_head phase, should obtain it from imgs(paddle.Tensor) now, then call self.head method."
        },
        {
            "comment": "These code snippets define three different methods: recognizer2d.py, val_step, and test_step. The first method appears to be a base for the other two and is used to calculate loss metrics from input images and labels using the head's loss function. The val_step also calculates loss metrics, but in valid mode only. Lastly, the test_step does not call the head's loss function and instead returns the class scores directly.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/recognizer2d.py\":30-51",
            "content": "        #labels = labels.squeeze()\n        #XXX: unsqueeze label to [label] ?\n        imgs = data_batch[0]\n        labels = data_batch[1:]\n        cls_score = self(imgs)\n        loss_metrics = self.head.loss(cls_score, labels)\n        return loss_metrics\n    def val_step(self, data_batch):\n        imgs = data_batch[0]\n        labels = data_batch[1:]\n        cls_score = self(imgs)\n        loss_metrics = self.head.loss(cls_score, labels, valid_mode=True)\n        return loss_metrics\n    def test_step(self, data_batch):\n        \"\"\"Define how the model is going to test, from input to output.\"\"\"\n        #NOTE: (shipping) when testing, the net won't call head.loss, we deal with the test processing in /paddlevideo/metrics\n        imgs = data_batch[0]\n        cls_score = self(imgs)\n        return cls_score"
        }
    ]
}