{
    "summary": "This code defines a `FrozenBatchNorm2d` class for batch normalization without updating statistics and a `DeepLab` class with backbone, ASPP module, decoder, and methods to freeze batch norm layers. It also provides a function that iterates through certain modules, yielding parameters requiring gradient updates for potentially applying different learning rates.",
    "details": [
        {
            "comment": "The code defines a `FrozenBatchNorm2d` class that extends the `nn.Layer` and overrides the `forward()` function to perform batch normalization without updating statistics. The `DeepLab` class inherits from `nn.Layer` and serves as a backbone for the deeplab network architecture, incorporating a backbone network, ASPP module, and decoder.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/deeplab.py\":0-30",
            "content": "import paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as F\nfrom networks.aspp import build_aspp\nfrom networks.decoder import build_decoder\nfrom networks.backbone import build_backbone\nclass FrozenBatchNorm2d(nn.Layer):\n    def __init__(self, n):\n        super(FrozenBatchNorm2d, self).__init__()\n        self.register_buffer(\"weight\", paddle.ones(n))\n        self.register_buffer(\"bias\", paddle.zeros(n))\n        self.register_buffer(\"running_mean\", paddle.zeros(n))\n        self.register_buffer(\"running_var\", paddle.ones(n))\n    def forward(self, x):\n        if x.dtype == paddle.float16:\n            self.weight = self.weight.half()\n            self.bias = self.bias.half()\n            self.running_mean = self.running_mean.half()\n            self.running_var = self.running_var.half()\n        scale = self.weight * self.running_var.rsqrt()\n        bias = self.bias - self.running_mean * scale\n        scale = scale.reshape(1, -1, 1, 1)\n        bias = bias.reshape(1, -1, 1, 1)\n        return x * scale + bias\nclass DeepLab(nn.Layer):"
        },
        {
            "comment": "This code defines the DeepLab class with an initializer that takes arguments for backbone, output stride, number of classes, and whether to freeze batch normalization layers. It also includes methods to freeze batch norm layers, retrieve parameters for 1x learning rate, and a forward pass function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/deeplab.py\":31-63",
            "content": "    def __init__(self,\n                 backbone='resnet',\n                 output_stride=16,\n                 num_classes=21,\n                 sync_bn=True,\n                 freeze_bn=False):\n        super(DeepLab, self).__init__()\n        if backbone == 'drn':\n            output_stride = 8\n        if freeze_bn == True:\n            print(\"Use frozen BN in DeepLab\")\n            BatchNorm = FrozenBatchNorm2d\n        else:\n            BatchNorm = nn.BatchNorm2D\n        self.backbone = build_backbone(backbone, output_stride, BatchNorm)\n        self.aspp = build_aspp(backbone, output_stride, BatchNorm)\n        self.decoder = build_decoder(num_classes, backbone, BatchNorm)\n    def forward(self, input):\n        x, low_level_feat = self.backbone(input)\n        x = self.aspp(x)\n        x = self.decoder(x, low_level_feat)\n        return x\n    def freeze_bn(self):\n        for m in self.sublayers():\n            if isinstance(m, nn.BatchNorm2D):\n                m.eval()\n    def get_1x_lr_params(self):\n        modules = [self.backbone]"
        },
        {
            "comment": "This code defines a function that iterates through certain modules of the network, specifically looking for convolution and batch normalization layers. It then yields the parameters of these layers that require gradient updates. This process is used in both the main body and the get_10x_lr_params method to potentially apply different learning rates to specific parts of the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/deeplab.py\":64-80",
            "content": "        for i in range(len(modules)):\n            for m in modules[i].named_modules():\n                if isinstance(m[1], nn.Conv2D) or isinstance(\n                        m[1], nn.BatchNorm2D):\n                    for p in m[1].parameters():\n                        if p.requires_grad:\n                            yield p\n    def get_10x_lr_params(self):\n        modules = [self.aspp, self.decoder]\n        for i in range(len(modules)):\n            for m in modules[i].named_modules():\n                if isinstance(m[1], nn.Conv2D) or isinstance(\n                        m[1], nn.BatchNorm2D):\n                    for p in m[1].parameters():\n                        if p.requires_grad:\n                            yield p"
        }
    ]
}