{
    "summary": "This code uses Paddle Serving for postprocessing and PaddleVideo framework for video processing, initializing client, preprocessing input, sending data to server, receiving prediction, and printing output.",
    "details": [
        {
            "comment": "This code snippet is importing necessary libraries and defining a function for postprocessing prediction outputs from a Paddle Serving client. The function takes raw predictions in the form of a numpy array and returns the postprocessed prediction as a dictionary containing any desired data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_serving/serving_client.py\":0-31",
            "content": "# Copyright (c) 2021 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport argparse\nfrom typing import Any, Dict\nimport numpy as np\nfrom paddle_serving_client import Client\nfrom preprocess_ops import get_preprocess_func, np_softmax\ndef postprocess(fetch_map: Dict[str, np.ndarray]) -> Dict[str, Any]:\n    \"\"\"postprocess\n    Args:\n        fetch_map (Dict[str, np.ndarray]): raw prediction\n    Returns:\n        Dict[str, Any]: postprocessed prediction\n    \"\"\"\n    score_list = fetch_map[\"outputs\"]  # [b,num_classes]"
        },
        {
            "comment": "The code defines a function that calculates the class id and probability based on scores, converts them to strings, and returns a dictionary with these values. It also includes a function for parsing arguments such as model name, serving client config file path, and URL to access the CPP serving.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_serving/serving_client.py\":32-61",
            "content": "    fetch_dict = {\"class_id\": [], \"prob\": []}\n    for score in score_list:\n        score = np_softmax(score, axis=0)\n        score = score.tolist()\n        max_score = max(score)\n        fetch_dict[\"class_id\"].append(score.index(max_score))\n        fetch_dict[\"prob\"].append(max_score)\n    fetch_dict[\"class_id\"] = str(fetch_dict[\"class_id\"])\n    fetch_dict[\"prob\"] = str(fetch_dict[\"prob\"])\n    return fetch_dict\ndef parse_args():\n    # general params\n    parser = argparse.ArgumentParser(\"PaddleVideo CPP Serving model script\")\n    parser.add_argument(\"-n\",\n                        \"--name\",\n                        type=str,\n                        default=\"PPTSM\",\n                        help=\"model's name, such as PPTSM, PPTSN...\")\n    parser.add_argument(\n        \"-c\",\n        \"--config\",\n        type=str,\n        help=\"serving client config file(serving_client_conf.prototxt) path\")\n    parser.add_argument(\"--url\",\n                        type=str,\n                        default=\"127.0.0.1:9993\",\n                        help=\"url to access cpp serving\")"
        },
        {
            "comment": "This code is a Python function that parses command line arguments, initializes a client object for video processing, preprocesses input video file, sends data to server, receives prediction, post-processes results and prints output. It uses the PaddleVideo framework with specific model configuration file and preprocessing function based on input name.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_serving/serving_client.py\":62-94",
            "content": "    parser.add_argument(\"--logid\", type=int, default=\"10000\", help=\"log id\")\n    parser.add_argument(\"--input_file\",\n                        type=str,\n                        default=\"../../data/example.avi\",\n                        help=\"input video file\")\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    # parse args\n    args = parse_args()\n    url = args.url\n    logid = args.logid\n    input_file_path = args.input_file\n    model_name = args.name\n    # get preprocess by model name\n    preprocess = get_preprocess_func(model_name)\n    # initialize client object & connect\n    client = Client()\n    client.load_client_config(args.config)\n    client.connect([url])\n    # preprocess\n    feed, fetch = preprocess(input_file_path)\n    # send data & get prediction from server\n    fetch_map = client.predict(feed=feed, fetch=fetch)\n    # postprocess & output\n    result = postprocess(fetch_map)\n    print(result)"
        }
    ]
}