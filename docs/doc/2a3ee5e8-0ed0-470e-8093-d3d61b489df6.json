{
    "summary": "OctConv3D is a configurable 3D convolutional layer in TransNetV2's backbone, utilizing features such as max pooling and SDDCNNV2 blocks for shot transition detection. ConvNextV2 applies feature extraction and pooling, while the code defines models using Linear and ConvexCombinationRegularization layers for classification tasks.",
    "details": [
        {
            "comment": "This code defines a 3D convolutional neural network layer called OctConv3D. It takes input and output channels, kernel size, dilation rate, alpha (for octave pooling), use_bias flag, and initializer as parameters for creating the layer. This layer can be used in other models by utilizing the BACKBONES registry.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":0-27",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport numpy as np\nimport paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as functional\nimport random\nfrom paddle import ParamAttr\nfrom ..registry import BACKBONES\nclass OctConv3D(nn.Layer):\n    def __init__(self, in_filters, filters, kernel_size=3, dilation_rate=(1, 1, 1), alpha=0.25,\n                 use_bias=True, kernel_initializer=nn.initializer.KaimingNormal()):\n        super(OctConv3D, self).__init__()"
        },
        {
            "comment": "Defines a 3D Convolutional network with interleaved low and high-resolution paths. Low-to-high and high-to-low convolutions are performed to maintain spatial resolution while reducing dimensionality for the TransNetV2 backbone model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":29-42",
            "content": "        self.low_channels = int(filters * alpha)\n        self.high_channels = filters - self.low_channels\n        self.high_to_high = nn.Conv3D(in_filters, self.high_channels, kernel_size=kernel_size,\n                                      dilation=dilation_rate, padding=(dilation_rate[0], 1, 1),\n                                      weight_attr=ParamAttr(initializer=kernel_initializer),\n                                      bias_attr=ParamAttr(\n                                          initializer=nn.initializer.Constant(value=0.)) if use_bias else use_bias)\n        self.high_to_low = nn.Conv3D(self.high_channels, self.low_channels, kernel_size=kernel_size,\n                                     dilation=dilation_rate, padding=(dilation_rate[0], 1, 1),\n                                     weight_attr=ParamAttr(initializer=kernel_initializer),\n                                     bias_attr=False)\n        self.low_to_high = nn.Conv3D(in_filters, self.high_channels, kernel_size=kernel_size,\n                                     dilation=dilation_rate, padding=(dilation_rate[0], 1, 1),"
        },
        {
            "comment": "This code defines a TransNetV2 backbone model for video analysis. It includes convolutional layers, an upsampler, and downsampler to process input data. The `pad_to` function pads the tensor with zeros to match a target shape, useful for maintaining consistent dimensions throughout the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":43-57",
            "content": "                                     weight_attr=ParamAttr(initializer=kernel_initializer),\n                                     bias_attr=False)\n        self.low_to_low = nn.Conv3D(self.high_channels, self.low_channels, kernel_size=kernel_size,\n                                    dilation=dilation_rate, padding=(dilation_rate[0], 1, 1),\n                                    weight_attr=ParamAttr(initializer=kernel_initializer),\n                                    bias_attr=ParamAttr(\n                                        initializer=nn.initializer.Constant(value=0.)) if use_bias else use_bias)\n        self.upsampler = nn.Upsample(size=(1, 2, 2), data_format='NCDHW')\n        self.downsampler = nn.AvgPool3D(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 1, 1))\n    @staticmethod\n    def pad_to(tensor, target_shape):\n        shape = tensor.shape\n        padding = [[0, tar - curr] for curr, tar in zip(shape, target_shape)]\n        return functional.pad(tensor, padding, \"CONSTANT\", data_format='NCDHW')"
        },
        {
            "comment": "The code defines a forward function that takes inputs and performs high-to-high, high-to-low, low-to-high, and low-to-low transformations. It also includes a Conv3DConfigurable class with parameters for in_filters, filters, dilation_rate, separable, octave, and use_bias. The code asserts that separable and octave cannot both be True.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":59-89",
            "content": "    @staticmethod\n    def crop_to(tensor, target_width, target_height):\n        return tensor[:, :, :target_height, :target_width]\n    def forward(self, inputs):\n        low_inputs, high_inputs = inputs\n        high_to_high = self.high_to_high(high_inputs)\n        high_to_low = self.high_to_low(self.downsampler(high_inputs))\n        low_to_high = self.upsampler(self.low_to_high(low_inputs))\n        low_to_low = self.low_to_low(low_inputs)\n        high_output = high_to_high[:, :, :, :low_to_high.shape[3], :low_to_high.shape[4]] + low_to_high\n        low_output = low_to_low + high_to_low[:, :, :, :low_to_low.shape[3], :low_to_low.shape[4]]\n        return low_output, high_output\nclass Conv3DConfigurable(nn.Layer):\n    def __init__(self,\n                 in_filters,\n                 filters,\n                 dilation_rate,\n                 separable=True,\n                 octave=False,\n                 use_bias=True):\n        super(Conv3DConfigurable, self).__init__()\n        assert not (separable and octave)\n        if separable:"
        },
        {
            "comment": "The code initializes a Conv3D layer and an optional octave convolution layer for the TransNetV2 backbone. The Conv3D layers apply 3x3 kernel with varying dilation rates, while the optional OctConv3D layer has a 3x1x1 kernel and dilation rate (dilation_rate, 1, 1). The layers are added to a LayerList for further processing in the network.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":90-103",
            "content": "            conv1 = nn.Conv3D(in_filters, 2 * filters, kernel_size=(1, 3, 3),\n                              dilation=(1, 1, 1), padding=(0, 1, 1),\n                              weight_attr=ParamAttr(initializer=nn.initializer.KaimingNormal()),\n                              bias_attr=False)\n            conv2 = nn.Conv3D(2 * filters, filters, kernel_size=(3, 1, 1),\n                              dilation=(dilation_rate, 1, 1), padding=(dilation_rate, 0, 0),\n                              weight_attr=ParamAttr(initializer=nn.initializer.KaimingNormal()),\n                              bias_attr=ParamAttr(\n                                  initializer=nn.initializer.Constant(value=0.)) if use_bias else use_bias)\n            self.layers = nn.LayerList([conv1, conv2])\n        elif octave:\n            conv = OctConv3D(in_filters, filters, kernel_size=3, dilation_rate=(dilation_rate, 1, 1),\n                             use_bias=use_bias,\n                             kernel_initializer=nn.initializer.KaimingNormal())"
        },
        {
            "comment": "This code defines a neural network backbone called TransnetV2, which consists of convolutional layers. The Conv3DConfigurable class is used to configure the layers with specified input and output filters, kernel size, dilation rate, padding, and whether to use bias or batch normalization. The DilatedDCNNV2 class extends this concept by allowing the choice between octave convolution and batch normalization. Both classes inherit from nn.Layer and have a forward method for processing inputs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":104-130",
            "content": "            self.layers = [conv]\n        else:\n            conv = nn.Conv3D(in_filters, filters, kernel_size=3,\n                             dilation=(dilation_rate, 1, 1), padding=(dilation_rate, 1, 1),\n                             weight_attr=ParamAttr(initializer=nn.initializer.KaimingNormal()),\n                             bias_attr=ParamAttr(\n                                 initializer=nn.initializer.Constant(value=0.)) if use_bias else use_bias)\n            self.layers = nn.LayerList([conv])\n    def forward(self, inputs):\n        x = inputs\n        for layer in self.layers:\n            x = layer(x)\n        return x\nclass DilatedDCNNV2(nn.Layer):\n    def __init__(self,\n                 in_filters,\n                 filters,\n                 batch_norm=True,\n                 activation=None,\n                 octave_conv=False):\n        super(DilatedDCNNV2, self).__init__()\n        assert not (octave_conv and batch_norm)\n        self.Conv3D_1 = Conv3DConfigurable(in_filters, filters, 1, use_bias=not batch_norm, octave=octave_conv)"
        },
        {
            "comment": "This code defines a TransNetV2 model, which uses multiple Conv3D layers to process input data. The model includes configurable convolution layers with different filter sizes (2, 4, and 8), batch normalization, and activation functions. The forward method applies these layers to the inputs and concatenates their outputs along the channel dimension.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":131-149",
            "content": "        self.Conv3D_2 = Conv3DConfigurable(in_filters, filters, 2, use_bias=not batch_norm, octave=octave_conv)\n        self.Conv3D_4 = Conv3DConfigurable(in_filters, filters, 4, use_bias=not batch_norm, octave=octave_conv)\n        self.Conv3D_8 = Conv3DConfigurable(in_filters, filters, 8, use_bias=not batch_norm, octave=octave_conv)\n        self.octave = octave_conv\n        self.bn = nn.BatchNorm3D(filters * 4, momentum=0.99, epsilon=1e-03,\n                                 weight_attr=ParamAttr(initializer=nn.initializer.Constant(value=1.)),\n                                 bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.))\n                                 ) if batch_norm else None\n        self.activation = activation\n    def forward(self, inputs):\n        conv1 = self.Conv3D_1(inputs)\n        conv2 = self.Conv3D_2(inputs)\n        conv3 = self.Conv3D_4(inputs)\n        conv4 = self.Conv3D_8(inputs)\n        # shape of convi[j]/convi is [B, 3, T, H, W], concat in channel dimension\n        if self.octave:"
        },
        {
            "comment": "The code defines a StackedDDCNNV2 class that is a type of neural network layer. It takes in parameters such as number of input filters, number of blocks, and output filters. The class uses convolutions with optional batch normalization and activation functions. The convolutions can be either octave or non-octave depending on the parameter setting. The pooling type is either max or average pooling, and there is a stochastic depth drop probability parameter.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":150-178",
            "content": "            x = [paddle.concat([conv1[0], conv2[0], conv3[0], conv4[0]], axis=1),\n                 paddle.concat([conv1[1], conv2[1], conv3[1], conv4[1]], axis=1)]\n        else:\n            x = paddle.concat([conv1, conv2, conv3, conv4], axis=1)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.activation is not None:\n            if self.octave:\n                x = [self.activation(x[0]), self.activation(x[1])]\n            else:\n                x = self.activation(x)\n        return x\nclass StackedDDCNNV2(nn.Layer):\n    def __init__(self,\n                 in_filters,\n                 n_blocks,\n                 filters,\n                 shortcut=True,\n                 use_octave_conv=False,\n                 pool_type=\"avg\",\n                 stochastic_depth_drop_prob=0.0):\n        super(StackedDDCNNV2, self).__init__()\n        assert pool_type == \"max\" or pool_type == \"avg\"\n        if use_octave_conv and pool_type == \"max\":\n            print(\"WARN: Octave convolution was designed with average pooling, not max pooling.\")"
        },
        {
            "comment": "Initializes backbone layers and sets parameters. Applies octave convolution if use_octave_conv is True, and performs max or avg pooling depending on pool_type. Stochastic depth is applied with probability stochastic_depth_drop_prob. Forward pass applies blocks of DDCNNV2, concatenates and applies ReLU activation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":180-206",
            "content": "        self.shortcut = shortcut\n        self.DDCNN = nn.LayerList([\n            DilatedDCNNV2(in_filters if i == 1 else filters * 4, filters, octave_conv=use_octave_conv,\n                          activation=functional.relu if i != n_blocks else None) for i in range(1, n_blocks + 1)\n        ])\n        self.pool = nn.MaxPool3D(kernel_size=(1, 2, 2)) if pool_type == \"max\" else nn.AvgPool3D(kernel_size=(1, 2, 2))\n        self.octave = use_octave_conv\n        self.stochastic_depth_drop_prob = stochastic_depth_drop_prob\n    def forward(self, inputs):\n        x = inputs\n        shortcut = None\n        if self.octave:\n            x = [self.pool(x), x]\n        for block in self.DDCNN:\n            x = block(x)\n            if shortcut is None:\n                shortcut = x\n        # shape of x[i] is [B, 3, T, H, W], concat in channel dimension\n        if self.octave:\n            x = paddle.concat([x[0], self.pool(x[1])], axis=1)\n        x = functional.relu(x)\n        if self.shortcut is not None:\n            if self.stochastic_depth_drop_prob != 0.:"
        },
        {
            "comment": "This code defines a ResNetBlock class that consists of Conv2D layer and BatchNorm2D layer. The stochastic depth is applied during training by randomly dropping connections with a specified probability, while in non-octave cases, it applies pooling to the output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":207-231",
            "content": "                if self.training:\n                    if random.random() < self.stochastic_depth_drop_prob:\n                        x = shortcut\n                    else:\n                        x = x + shortcut\n                else:\n                    x = (1 - self.stochastic_depth_drop_prob) * x + shortcut\n            else:\n                x += shortcut\n        if not self.octave:\n            x = self.pool(x)\n        return x\nclass ResNetBlock(nn.Layer):\n    def __init__(self, in_filters, filters, strides=(1, 1)):\n        super(ResNetBlock, self).__init__()\n        self.conv1 = nn.Conv2D(in_filters, filters, kernel_size=(3, 3), stride=strides, padding=(1, 1),\n                               weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                               bias_attr=False)\n        self.bn1 = nn.BatchNorm2D(filters,\n                                  weight_attr=ParamAttr(initializer=nn.initializer.Constant(value=1.)),\n                                  bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.)))"
        },
        {
            "comment": "The code defines a Conv2D layer and BatchNorm2D layer in the `TransNetV2` class, followed by a forward function that applies these layers in sequence. The ResNetFeatures class initializes a Conv2D layer for extracting features from input images. Both classes are part of an object-oriented model architecture.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":233-259",
            "content": "        self.conv2 = nn.Conv2D(filters, filters, kernel_size=(3, 3), padding=(1, 1),\n                               weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                               bias_attr=False)\n        self.bn2 = nn.BatchNorm2D(filters,\n                                  weight_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.)),\n                                  bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.)))\n    def forward(self, inputs):\n        x = self.conv1(inputs)\n        x = self.bn1(x)\n        x = functional.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        shortcut = inputs\n        x += shortcut\n        return functional.relu(x)\nclass ResNetFeatures(nn.Layer):\n    def __init__(self, in_filters=3,\n                 mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]):\n        super(ResNetFeatures, self).__init__()\n        self.conv1 = nn.Conv2D(in_channels=in_filters, out_channels=64, kernel_size=(7, 7),"
        },
        {
            "comment": "This code is for TransNetV2 backbone model initialization. It includes a convolution layer with padding, batch normalization, max pooling, and ResNetBlocks (layer2a, layer2b). The forward function performs normalization, reshaping, convolution, and batch normalization on the input.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":260-281",
            "content": "                               stride=(2, 2), padding=(3, 3),\n                               weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                               bias_attr=False)\n        self.bn1 = nn.BatchNorm2D(num_features=64, momentum=0.99, epsilon=1e-03,\n                                  weight_attr=ParamAttr(initializer=nn.initializer.Constant(value=1.)),\n                                  bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.))\n                                  )\n        self.max_pool = nn.MaxPool2D(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        self.layer2a = ResNetBlock(64, 64)\n        self.layer2b = ResNetBlock(64, 64)\n        self.mean = paddle.to_tensor(mean)\n        self.std = paddle.to_tensor(std)\n    def forward(self, inputs):\n        shape = inputs.shape\n        x = paddle.reshape(inputs, [shape[0] * shape[2], shape[1], shape[3], shape[4]])\n        x = (x - self.mean) / self.std\n        x = self.conv1(x)\n        x = self.bn1(x)"
        },
        {
            "comment": "This code defines a class \"FrameSimilarity\" that takes in filters, similarity dimension, lookup window, output dimension, stop_gradient flag, and use_bias as parameters. It initializes the layer with a projection linear layer and an fc linear layer. The projection layer maps input features to a specified similarity dimension using XavierUniform initialization. The fc layer maps the lookup window to the output dimension, using XavierUniform initialization for weights and Constant initialization for biases.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":282-306",
            "content": "        x = functional.relu(x)\n        x = self.max_pool(x)\n        x = self.layer2a(x)\n        x = self.layer2b(x)\n        new_shape = x.shape\n        x = paddle.reshape(x, [shape[0], new_shape[1], shape[2], new_shape[2], new_shape[3]])\n        return x\nclass FrameSimilarity(nn.Layer):\n    def __init__(self,\n                 in_filters,\n                 similarity_dim=128,\n                 lookup_window=101,\n                 output_dim=128,\n                 stop_gradient=False,\n                 use_bias=False):\n        super(FrameSimilarity, self).__init__()\n        self.projection = nn.Linear(in_filters, similarity_dim,\n                                    weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                                    bias_attr=use_bias)\n        self.fc = nn.Linear(lookup_window, output_dim,\n                            weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                            bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.)))"
        },
        {
            "comment": "The code initializes a TransNetV2 model with lookup window and stop_gradient options. It then calculates similarities between time windows using batch mean, transpose, projection, and normalization. Finally, it pads the similarities for further calculations.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":308-329",
            "content": "        self.lookup_window = lookup_window\n        self.stop_gradient = stop_gradient\n        assert lookup_window % 2 == 1, \"`lookup_window` must be odd integer\"\n    def forward(self, inputs):\n        x = paddle.concat([paddle.mean(x, axis=[3, 4]) for x in inputs], axis=1)\n        x = paddle.transpose(x, (0, 2, 1))\n        if self.stop_gradient:\n            x = x.stop_gradient\n        x = self.projection(x)\n        x = functional.normalize(x, p=2, axis=2)\n        batch_size = paddle.slice(x.shape, starts=[0], ends=[1], axes=[0]) if x.shape[0] == -1 else x.shape[0]\n        time_window = x.shape[1]\n        similarities = paddle.bmm(x, x.transpose([0, 2, 1]))  # [batch_size, time_window, time_window]\n        similarities_padded = functional.pad(similarities,\n                                             [(self.lookup_window - 1) // 2, (self.lookup_window - 1) // 2],\n                                             data_format='NCL')\n        batch_indices = paddle.arange(0, batch_size).reshape([batch_size, 1, 1])"
        },
        {
            "comment": "This code is calculating the indices for gathering similarities from a padded tensor. It tiles and stacks batch, time, and lookup indices to create an array of valid indices. Then it uses these indices to gather similarities from the padded tensor and applies ReLU activation on top of an FC layer to return the output. The ConvexCombinationRegularization class initializes a projection layer with specified parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":330-345",
            "content": "        batch_indices = paddle.tile(batch_indices, [1, time_window, self.lookup_window])\n        time_indices = paddle.arange(0, time_window).reshape([1, time_window, 1])\n        time_indices = paddle.tile(time_indices, [batch_size, 1, self.lookup_window])\n        lookup_indices = paddle.arange(0, self.lookup_window).reshape([1, 1, self.lookup_window])\n        lookup_indices = paddle.tile(lookup_indices, [batch_size, time_window, 1]) + time_indices\n        indices = paddle.stack([batch_indices, time_indices, lookup_indices], -1)\n        similarities = paddle.gather_nd(similarities_padded, indices)\n        return functional.relu(self.fc(similarities))\nclass ConvexCombinationRegularization(nn.Layer):\n    def __init__(self, in_filters, filters=32, delta_scale=10., loss_weight=0.01):\n        super(ConvexCombinationRegularization, self).__init__()\n        self.projection = nn.Conv3D(in_filters, filters, kernel_size=1, dilation=1, padding=(0, 0, 0),\n                                    weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),"
        },
        {
            "comment": "This code defines a Conv3D model for the TransNetV2 backbone. It has a projection layer, relu activation, and takes in image_inputs and feature_inputs. The forward function processes these inputs, extracting the first and last frame windows.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":346-363",
            "content": "                                    bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.)))\n        self.features = nn.Conv3D((filters * 3), filters * 2,\n                                  kernel_size=(3, 3, 3), dilation=1, padding=(1, 1, 1),\n                                  weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                                  bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.)))\n        self.dense = nn.Linear(64, 1, weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()), bias_attr=True)\n        self.loss = nn.SmoothL1Loss(reduction='none')\n        self.delta_scale = delta_scale\n        self.loss_weight = loss_weight\n    def forward(self, image_inputs, feature_inputs):\n        x = feature_inputs\n        x = self.projection(x)\n        x = functional.relu(x)\n        batch_size = x.shape[0]\n        window_size = x.shape[2]\n        first_frame = paddle.tile(x[:, :, :1], [1, 1, window_size, 1, 1])\n        last_frame = paddle.tile(x[:, :, -1:], [1, 1, window_size, 1, 1])"
        },
        {
            "comment": "This code is part of the TransnetV2 model in PaddleVideo. It concatenates frames, processes them through layers, and calculates alpha values for first and last images. It then combines these images based on the calculated alphas and performs loss calculation using a loss function. The ColorHistograms layer is initialized with a linear transformation layer.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":364-389",
            "content": "        x = paddle.concat([x, first_frame, last_frame], 1)\n        x = self.features(x)\n        x = functional.relu(x)\n        x = paddle.mean(x, axis=[3, 4])\n        x = paddle.transpose(x, (0, 2, 1))\n        alpha = self.dense(x)\n        alpha = paddle.transpose(alpha, (0, 2, 1))\n        first_img = paddle.tile(image_inputs[:, :, :1], [1, 1, window_size, 1, 1])\n        last_img = paddle.tile(image_inputs[:, :, -1:], [1, 1, window_size, 1, 1])\n        alpha_ = functional.sigmoid(alpha)\n        alpha_ = paddle.reshape(alpha_, [batch_size, 1, window_size, 1, 1])\n        predictions_ = (alpha_ * first_img + (1 - alpha_) * last_img)\n        loss_ = self.loss(label=image_inputs / self.delta_scale, input=predictions_ / self.delta_scale)\n        loss_ = self.loss_weight * paddle.mean(loss_)\n        return alpha, loss_\nclass ColorHistograms(nn.Layer):\n    def __init__(self,\n                 lookup_window=101,\n                 output_dim=None):\n        super(ColorHistograms, self).__init__()\n        self.fc = nn.Linear(lookup_window, output_dim,"
        },
        {
            "comment": "This code defines a function to compute color histograms of frames. It first converts the frame values to int32, then defines a function get_bin which extracts and scales RGB values. The batch size is extracted from the frames shape, and the frames are flattened into a 3-dimensional array if the number of channels is 3 or 6.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":390-410",
            "content": "                            weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                            bias_attr=ParamAttr(\n                                initializer=nn.initializer.Constant(value=0.))) if output_dim is not None else None\n        self.lookup_window = lookup_window\n        assert lookup_window % 2 == 1, \"`lookup_window` must be odd integer\"\n    def compute_color_histograms(self, frames):\n        frames = frames.astype('int32')\n        def get_bin(frames):\n            # returns 0 .. 511\n            R, G, B = frames[:, :, 0], frames[:, :, 1], frames[:, :, 2]\n            R, G, B = R // 32, G // 32, B // 32\n            return (R * 64) + (G * 8) + B\n        batch_size = paddle.slice(frames.shape, starts=[0], ends=[1], axes=[0]) if frames.shape[0] == -1 else frames.shape[0]\n        time_window, height, width, no_channels = frames.shape[1:]\n        assert no_channels == 3 or no_channels == 6\n        if no_channels == 3:\n            frames_flatten = frames.reshape([-1, height * width, 3])"
        },
        {
            "comment": "This code computes color histograms for each frame in a video and then calculates similarities between frames using batch matrix multiplication. It first checks the input shape to determine whether it should extract only the batch size and time window or use the total shape. It then reshapes and bins the frame values, normalizes the histograms, and finally computes the similarity matrix for each frame pair. The purpose is likely for video sequence analysis or comparison.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":411-428",
            "content": "        else:\n            frames_flatten = frames.reshape([-1, height * width * 2, 3])\n        binned_values = get_bin(frames_flatten)\n        frame_bin_prefix = (paddle.arange(0, batch_size * time_window) * 512).reshape([-1, 1])\n        binned_values = (binned_values + frame_bin_prefix).reshape([-1, 1])\n        histograms = paddle.zeros_like(frame_bin_prefix, dtype='int32').tile([512]).reshape([-1])\n        histograms = histograms.scatter_nd_add(binned_values, paddle.ones_like(binned_values, dtype='int32').reshape([-1]))\n        histograms = histograms.reshape([batch_size, time_window, 512]).astype('float32')\n        histograms_normalized = functional.normalize(histograms, p=2, axis=2)\n        return histograms_normalized\n    def forward(self, inputs):\n        x = self.compute_color_histograms(inputs)\n        batch_size = paddle.slice(x.shape, starts=[0], ends=[1], axes=[0]) if x.shape[0] == -1 else x.shape[0]\n        time_window = x.shape[1]\n        similarities = paddle.bmm(x, x.transpose([0, 2, 1]))  # [batch_size, time_window, time_window]"
        },
        {
            "comment": "This code performs lookup on a padded tensor using gathered indices from batch, time window, and lookup window. It then applies an optional fully connected layer with ReLU activation function if present.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":429-445",
            "content": "        similarities_padded = functional.pad(similarities,\n                                             [(self.lookup_window - 1) // 2, (self.lookup_window - 1) // 2],\n                                             data_format='NCL')\n        batch_indices = paddle.arange(0, batch_size).reshape([batch_size, 1, 1])\n        batch_indices = paddle.tile(batch_indices, [1, time_window, self.lookup_window])\n        time_indices = paddle.arange(0, time_window).reshape([1, time_window, 1])\n        time_indices = paddle.tile(time_indices, [batch_size, 1, self.lookup_window])\n        lookup_indices = paddle.arange(0, self.lookup_window).reshape([1, 1, self.lookup_window])\n        lookup_indices = paddle.tile(lookup_indices, [batch_size, time_window, 1]) + time_indices\n        indices = paddle.stack([batch_indices, time_indices, lookup_indices], -1)\n        similarities = paddle.gather_nd(similarities_padded, indices)\n        if self.fc is not None:\n            return functional.relu(self.fc(similarities))\n        return similarities"
        },
        {
            "comment": "The code defines the TransNetV2 model, a deep network architecture for shot transition detection. It has multiple input sources and various options to use or not use different features and operations. The mean and std are provided as initialization parameters to standardize the input data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":448-472",
            "content": "@BACKBONES.register()\nclass TransNetV2(nn.Layer):\n    \"\"\"TransNetV2 model from\n    `\"TransNet V2: An effective deep network architecture for fast shot transition detection\" <https://arxiv.org/abs/2008.04838>`_\n    \"\"\"\n    def __init__(self,\n                 F=16, L=3, S=2, D=1024,\n                 use_many_hot_targets=True,\n                 use_frame_similarity=True,\n                 use_color_histograms=True,\n                 use_mean_pooling=False,\n                 dropout_rate=0.5,\n                 use_convex_comb_reg=False,\n                 use_resnet_features=False,\n                 use_resnet_like_top=False,\n                 frame_similarity_on_last_layer=False,\n                 mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]):\n        super(TransNetV2, self).__init__()\n        self.mean = np.array(mean, np.float32).reshape([1, 3, 1, 1]) * 255\n        self.std = np.array(std, np.float32).reshape([1, 3, 1, 1]) * 255\n        self.use_resnet_features = use_resnet_features\n        s"
        },
        {
            "comment": "Code snippet is from PaddleVideo's TransNetV2 model. It checks if use_resnet_features is True and if so, initializes resnet_layers with ResNetFeatures. If resnet_like_top is also True, it then initializes resnet_like_top_conv and resnet_like_top_bn for ResNet-like top layers with specified parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":472-483",
            "content": "elf.resnet_layers = ResNetFeatures(in_filters=3, mean=self.mean, std=self.std) if self.use_resnet_features else None\n        self.resnet_like_top = use_resnet_like_top\n        if self.resnet_like_top:\n            self.resnet_like_top_conv = nn.Conv3D(64 if self.use_resnet_features else 3, 32, kernel_size=(3, 7, 7),\n                                                  stride=(1, 2, 2),\n                                                  padding=(1, 3, 3),\n                                                  weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                                                  bias_attr=False)\n            self.resnet_like_top_bn = nn.BatchNorm3D(32, momentum=0.99, epsilon=1e-03,\n                                                     weight_attr=ParamAttr(\n                                                         initializer=nn.initializer.Constant(value=1.)),\n                                                     bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.)))"
        },
        {
            "comment": "This code initializes the model components of a TransNetv2 backbone. It sets up max pooling, creates a LayerList for SDDCNNV2 blocks, initializes frame similarity and color histogram layers based on flags, and includes dropout layer if needed.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":484-507",
            "content": "            self.resnet_like_top_max_pool = nn.MaxPool3D(kernel_size=(1, 3, 3), stride=(1, 2, 2),\n                                                         padding=(0, 1, 1))\n        if self.resnet_like_top:\n            in_filters = 32\n        elif self.use_resnet_features:\n            in_filters = 64\n        else:\n            in_filters = 3\n        self.SDDCNN = nn.LayerList(\n            [StackedDDCNNV2(in_filters=in_filters, n_blocks=S, filters=F,\n                            stochastic_depth_drop_prob=0.)] +\n            [StackedDDCNNV2(in_filters=(F * 2 ** (i - 1)) * 4, n_blocks=S, filters=F * 2 ** i) for i in range(1, L)]\n        )\n        self.frame_sim_layer = FrameSimilarity(\n            sum([(F * 2 ** i) * 4 for i in range(L)]), lookup_window=101, output_dim=128, similarity_dim=128,\n            use_bias=True\n        ) if use_frame_similarity else None\n        self.color_hist_layer = ColorHistograms(\n            lookup_window=101, output_dim=128\n        ) if use_color_histograms else None\n        self.dropout = nn.Dropout(dropout_rate) if dropout_rate is not None else None"
        },
        {
            "comment": "This code initializes a neural network model with a linear layer (`self.fc1`) that takes an input dimension of 512 if certain conditions are met, otherwise it takes the output_dim calculated earlier. The layer has D output dimensions and uses Xavier uniform initialization for weights and constant initialization for biases. Additionally, there's another linear layer (`self.cls_layer1`) with 1 output dimension that is initialized with Xavier uniform initialization for weights and a constant value of 0 for biases. It takes an input dimension of either 1152 or D based on whether frame similarity is added to the last layer or not.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":509-525",
            "content": "        output_dim = ((F * 2 ** (L - 1)) * 4) * 3 * 6  # 3x6 for spatial dimensions\n        if use_frame_similarity: output_dim += 128\n        if use_color_histograms: output_dim += 128\n        self.use_mean_pooling = use_mean_pooling\n        self.has_downsample = False\n        if self.use_resnet_features or self.resnet_like_top or self.use_mean_pooling:\n            self.has_downsample = True\n        self.fc1 = nn.Linear(512 if self.has_downsample else output_dim, D,\n                             weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                             bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.))\n                             )\n        self.frame_similarity_on_last_layer = frame_similarity_on_last_layer\n        self.cls_layer1 = nn.Linear(1152 if self.frame_similarity_on_last_layer else D, 1,\n                                    weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                                    bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.))"
        },
        {
            "comment": "The code defines a model with two layers, a Linear layer and ConvexCombinationRegularization, depending on the use_many_hot_targets and use_convex_comb_reg parameters. The Linear layer has 1 output for each frame, unless frame_similarity_on_last_layer is set, in which case it has D outputs. If use_many_hot_targets is False, the layer is None. The forward function receives inputs of shape [B, T, H, W, 3] and performs transpose, resnet_features processing (if use_resnet_features=True), and normalization to apply the model layers. It also clips the input values between 0 and 255 before applying the regularization if use_convex_comb_reg is True.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":526-547",
            "content": "                                    )\n        self.cls_layer2 = nn.Linear(1152 if self.frame_similarity_on_last_layer else D, 1,\n                                    weight_attr=ParamAttr(initializer=nn.initializer.XavierUniform()),\n                                    bias_attr=ParamAttr(initializer=nn.initializer.Constant(value=0.))\n                                    ) if use_many_hot_targets else None\n        self.convex_comb_reg = ConvexCombinationRegularization(\n            in_filters=(F * 2 ** (L - 1) * 4)) if use_convex_comb_reg else None\n    def forward(self, inputs):\n        assert list(inputs.shape[2:]) == [27, 48, 3] and inputs.dtype == paddle.float32, \\\n            \"incorrect input type and/or shape\"\n        out_dict = {}\n        # shape [B, T, H, W, 3] to shape [B, 3, T, H, W]\n        x = inputs.transpose([0, 4, 1, 2, 3])\n        if self.use_resnet_features:\n            x = self.resnet_layers(x)\n        else:\n            x = x / 255.\n        inputs = inputs.clip(min=0).astype('uint8')\n        if self.resnet_like_top:"
        },
        {
            "comment": "This code performs feature extraction and pooling operations for a ConvNextV2 backbone model. It applies residual blocks, top convolutions, batch normalization, and max pooling to the input. Then it calculates convex combination regression if required. The code either applies mean pooling or 3D reshaping based on the use_mean_pooling flag. Finally, it concatenates frame similarity layer outputs and color histogram layer outputs before performing fully connected layer calculations and applying relu activation and dropout if necessary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":548-570",
            "content": "            x = self.resnet_like_top_conv(x)\n            x = self.resnet_like_top_bn(x)\n            x = self.resnet_like_top_max_pool(x)\n        block_features = []\n        for block in self.SDDCNN:\n            x = block(x)\n            block_features.append(x)\n        if self.convex_comb_reg is not None:\n            out_dict[\"alphas\"], out_dict[\"comb_reg_loss\"] = self.convex_comb_reg(inputs.transpose([0, 4, 1, 2, 3]), x)\n        if self.use_mean_pooling:\n            x = paddle.mean(x, axis=[3, 4])\n            x = x.transpose([0, 2, 1])\n        else:\n            x = x.transpose([0, 2, 3, 4, 1])\n            x = x.reshape([x.shape[0], x.shape[1], x.shape[2]*x.shape[3]*x.shape[4]])\n        if self.frame_sim_layer is not None:\n            x = paddle.concat([self.frame_sim_layer(block_features), x], 2)\n        if self.color_hist_layer is not None:\n            x = paddle.concat([self.color_hist_layer(inputs), x], 2)\n        x = self.fc1(x)\n        x = functional.relu(x)\n        if self.dropout is not None:\n            x = self.dropout(x)"
        },
        {
            "comment": "This code checks if the frame similarity layer and classifier layers are not None, then performs a concatenation operation on block features and x. It applies the classifier layer to the resulting output and optionally applies another classifier layer. The function returns one_hot and an optional out_dict if they exist.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/transnetv2.py\":571-580",
            "content": "        if self.frame_sim_layer is not None and self.frame_similarity_on_last_layer:\n            x = paddle.concat([self.frame_sim_layer(block_features), x], 2)\n        one_hot = self.cls_layer1(x)\n        if self.cls_layer2 is not None:\n            out_dict[\"many_hot\"] = self.cls_layer2(x)\n        if len(out_dict) > 0:\n            return one_hot, out_dict\n        return one_hot"
        }
    ]
}