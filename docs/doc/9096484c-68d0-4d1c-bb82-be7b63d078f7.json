{
    "summary": "This code introduces SampleFrames class for PaddleVideo's loader pipelines using OpenCV, supports various modes and training, includes storage backend classes, converts images to numpy arrays, defines pipeline, and provides SampleAVAFrames class for sampling video frames.",
    "details": [
        {
            "comment": "This code is importing necessary libraries and registering a class SampleFrames under PaddleVideo's loader pipelines. The class appears to sample frames from video, supporting different reading modes (color/grayscale/unchanged). It uses OpenCV (cv2) as the image processing backend.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":0-34",
            "content": "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport random\nfrom PIL import Image\nfrom ..registry import PIPELINES\nimport os\nimport numpy as np\nimport io\nimport os.path as osp\nfrom abc import ABCMeta, abstractmethod\nimport cv2\nfrom cv2 import IMREAD_COLOR, IMREAD_GRAYSCALE, IMREAD_UNCHANGED\nimport inspect\nimread_backend = 'cv2'\nimread_flags = {\n    'color': IMREAD_COLOR,\n    'grayscale': IMREAD_GRAYSCALE,\n    'unchanged': IMREAD_UNCHANGED\n}\n@PIPELINES.register()\nclass SampleFrames:"
        },
        {
            "comment": "The function `__init__` initializes the parameters for sampling frames from a video, including clip length, frame interval, number of clips, temporal jittering options, and out-of-bound handling. The `_get_train_clips` function calculates the clip offsets in training mode by determining the average interval between clips based on the total number of frames. It then generates random base offsets and adds random offsets to create the final clip offsets.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":35-60",
            "content": "    \"\"\"Sample frames from the video. \"\"\"\n    def __init__(self,\n                 clip_len,\n                 frame_interval=1,\n                 num_clips=1,\n                 temporal_jitter=False,\n                 twice_sample=False,\n                 out_of_bound_opt='loop',\n                 test_mode=False):\n        self.clip_len = clip_len\n        self.frame_interval = frame_interval\n        self.num_clips = num_clips\n        self.temporal_jitter = temporal_jitter\n        self.twice_sample = twice_sample\n        self.out_of_bound_opt = out_of_bound_opt\n        self.test_mode = test_mode\n        assert self.out_of_bound_opt in ['loop', 'repeat_last']\n    def _get_train_clips(self, num_frames):\n        \"\"\"Get clip offsets in train mode. \"\"\"\n        ori_clip_len = self.clip_len * self.frame_interval\n        avg_interval = (num_frames - ori_clip_len + 1) // self.num_clips\n        if avg_interval > 0:\n            base_offsets = np.arange(self.num_clips) * avg_interval\n            clip_offsets = base_offsets + np.random.randint("
        },
        {
            "comment": "This code calculates clip offsets for video sampling based on the number of frames and other parameters. It handles different scenarios, such as when the number of frames exceeds or equals the original clip length, when average interval is 0, and in test mode. The clip_offsets are returned at the end.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":61-81",
            "content": "                avg_interval, size=self.num_clips)\n        elif num_frames > max(self.num_clips, ori_clip_len):\n            clip_offsets = np.sort(\n                np.random.randint(\n                    num_frames - ori_clip_len + 1, size=self.num_clips))\n        elif avg_interval == 0:\n            ratio = (num_frames - ori_clip_len + 1.0) / self.num_clips\n            clip_offsets = np.around(np.arange(self.num_clips) * ratio)\n        else:\n            clip_offsets = np.zeros((self.num_clips, ), dtype=np.int)\n        return clip_offsets\n    def _get_test_clips(self, num_frames):\n        \"\"\"Get clip offsets in test mode. \"\"\"\n        ori_clip_len = self.clip_len * self.frame_interval\n        avg_interval = (num_frames - ori_clip_len + 1) / float(self.num_clips)\n        if num_frames > ori_clip_len - 1:\n            base_offsets = np.arange(self.num_clips) * avg_interval\n            clip_offsets = (base_offsets + avg_interval / 2.0).astype(np.int)\n            if self.twice_sample:\n                clip_offsets = np.concatenate([clip_offsets, base_offsets])"
        },
        {
            "comment": "This code defines a class that samples video clips and loads frames based on different modes, such as testing or training. It takes the total number of frames in a video and returns the corresponding clip offsets and frame indices for loading. The sampling mode, temporal jitter, and out-of-bound options can be specified to customize the sampling process.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":82-106",
            "content": "        else:\n            clip_offsets = np.zeros((self.num_clips, ), dtype=np.int)\n        return clip_offsets\n    def _sample_clips(self, num_frames):\n        \"\"\"Choose clip offsets for the video in a given mode. \"\"\"\n        if self.test_mode:\n            clip_offsets = self._get_test_clips(num_frames)\n        else:\n            clip_offsets = self._get_train_clips(num_frames)\n        return clip_offsets\n    def __call__(self, results):\n        \"\"\"Perform the SampleFrames loading. \"\"\"\n        total_frames = results['total_frames']\n        clip_offsets = self._sample_clips(total_frames)\n        frame_inds = clip_offsets[:, None] + np.arange(\n            self.clip_len)[None, :] * self.frame_interval\n        frame_inds = np.concatenate(frame_inds)\n        if self.temporal_jitter:\n            perframe_offsets = np.random.randint(\n                self.frame_interval, size=len(frame_inds))\n            frame_inds += perframe_offsets\n        frame_inds = frame_inds.reshape((-1, self.clip_len))\n        if self.out_of_bound_opt == 'loop':"
        },
        {
            "comment": "Code handles out-of-bound frame indices by wrapping them around, repeating the last frame, or throwing an error. It then updates results with frame indices, clip length, and number of clips.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":107-128",
            "content": "            frame_inds = np.mod(frame_inds, total_frames)\n        elif self.out_of_bound_opt == 'repeat_last':\n            safe_inds = frame_inds < total_frames\n            unsafe_inds = 1 - safe_inds\n            last_ind = np.max(safe_inds * frame_inds, axis=1)\n            new_inds = (safe_inds * frame_inds + (unsafe_inds.T * last_ind).T)\n            frame_inds = new_inds\n        else:\n            raise ValueError('Illegal out_of_bound option.')\n        start_index = results['start_index']\n        frame_inds = np.concatenate(frame_inds) + start_index\n        results['frame_inds'] = frame_inds.astype(np.int)\n        results['clip_len'] = self.clip_len\n        results['frame_interval'] = self.frame_interval\n        results['num_clips'] = self.num_clips\n        return results\n    def __repr__(self):\n        repr_str = (f'{self.__class__.__name__}('\n                    f'clip_len={self.clip_len}, '\n                    f'frame_interval={self.frame_interval}, '\n                    f'num_clips={self.num_clips}, '"
        },
        {
            "comment": "This code defines three classes: `BaseStorageBackend` (abstract class), `HardDiskBackend`, and a generic file client called `FileClient`. The `BaseStorageBackend` is an abstract class that provides two methods, `get()` and `get_text()`, which are expected to be implemented by subclasses. The `HardDiskBackend` implements these methods for handling files stored on the hard disk. Finally, the `FileClient` serves as a generic file client to access files in different backends.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":129-165",
            "content": "                    f'temporal_jitter={self.temporal_jitter}, '\n                    f'twice_sample={self.twice_sample}, '\n                    f'out_of_bound_opt={self.out_of_bound_opt}, '\n                    f'test_mode={self.test_mode})')\n        return repr_str\nclass BaseStorageBackend(metaclass=ABCMeta):\n    \"\"\"Abstract class of storage backends. \"\"\"\n    @abstractmethod\n    def get(self, filepath):\n        pass\n    @abstractmethod\n    def get_text(self, filepath):\n        pass\nclass HardDiskBackend(BaseStorageBackend):\n    \"\"\"Raw hard disks storage backend.\"\"\"\n    def get(self, filepath):\n        filepath = str(filepath)\n        with open(filepath, 'rb') as f:\n            value_buf = f.read()\n        return value_buf\n    def get_text(self, filepath):\n        filepath = str(filepath)\n        with open(filepath, 'r') as f:\n            value_buf = f.read()\n        return value_buf\nclass FileClient:\n    \"\"\"A general file client to access files in different backend. \"\"\"\n    _backends = {\n        'disk': HardDiskBackend,"
        },
        {
            "comment": "This code defines a class with an initializer and a class method for registering backends. The initializer takes a backend argument, checks if it is supported, and initializes the client object with that backend. If the name or backend type is incorrect, it raises TypeError. The _register_backend method allows for backend registration by name, checking if it is a string and if the backend is a subclass of BaseStorageBackend. Raises KeyError if already registered.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":166-189",
            "content": "    }\n    def __init__(self, backend='disk', **kwargs):\n        if backend not in self._backends:\n            raise ValueError(\n                f'Backend {backend} is not supported. Currently supported ones'\n                f' are {list(self._backends.keys())}')\n        self.backend = backend\n        self.client = self._backends[backend](**kwargs)\n    @classmethod\n    def _register_backend(cls, name, backend, force=False):\n        if not isinstance(name, str):\n            raise TypeError('the backend name should be a string, '\n                            f'but got {type(name)}')\n        if not inspect.isclass(backend):\n            raise TypeError(\n                f'backend should be a class but got {type(backend)}')\n        if not issubclass(backend, BaseStorageBackend):\n            raise TypeError(\n                f'backend {backend} is not a subclass of BaseStorageBackend')\n        if not force and name in cls._backends:\n            raise KeyError(\n                f'{name} is already registered as a storage backend, '"
        },
        {
            "comment": "This code defines a class called FileClient, which handles file operations like registration and retrieval. It also registers a pipeline named RawFrameDecode for loading and decoding frames using specified backends for I/O and decoding. The class has an _pillow2array method to convert PIL image to numpy array in specific channel order.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":190-224",
            "content": "                'add \"force=True\" if you want to override it')\n        cls._backends[name] = backend\n    @classmethod\n    def register_backend(cls, name, backend=None, force=False):\n        \"\"\"Register a backend to FileClient. \"\"\"\n        if backend is not None:\n            cls._register_backend(name, backend, force=force)\n            return\n        def _register(backend_cls):\n            cls._register_backend(name, backend_cls, force=force)\n            return backend_cls\n        return _register\n    def get(self, filepath):\n        return self.client.get(filepath)\n    def get_text(self, filepath):\n        return self.client.get_text(filepath)\n@PIPELINES.register()\nclass RawFrameDecode:\n    \"\"\"Load and decode frames with given indices. \"\"\"\n    def __init__(self, io_backend='disk', decoding_backend='cv2', **kwargs):\n        self.io_backend = io_backend\n        self.decoding_backend = decoding_backend\n        self.kwargs = kwargs\n        self.file_client = None\n    def _pillow2array(self,img, flag='color', channel_order='bgr'):"
        },
        {
            "comment": "This code converts a Pillow image to a numpy array. It checks the channel order and flag, then either keeps the array unchanged or converts it from RGB to BGR if necessary. If the image mode is not RGB, it converts it to RGB first using convert('RGB'). If the mode is LA, a random color is used for the canvas to avoid shadowing black objects in the foreground.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":225-246",
            "content": "        \"\"\"Convert a pillow image to numpy array. \"\"\"\n        channel_order = channel_order.lower()\n        if channel_order not in ['rgb', 'bgr']:\n            raise ValueError('channel order must be either \"rgb\" or \"bgr\"')\n        if flag == 'unchanged':\n            array = np.array(img)\n            if array.ndim >= 3 and array.shape[2] >= 3:  # color image\n                array[:, :, :3] = array[:, :, (2, 1, 0)]  # RGB to BGR\n        else:\n            # If the image mode is not 'RGB', convert it to 'RGB' first.\n            if img.mode != 'RGB':\n                if img.mode != 'LA':\n                    # Most formats except 'LA' can be directly converted to RGB\n                    img = img.convert('RGB')\n                else:\n                    # When the mode is 'LA', the default conversion will fill in\n                    #  the canvas with black, which sometimes shadows black objects\n                    #  in the foreground.\n                    #\n                    # Therefore, a random color (124, 117, 104) is used for canvas"
        },
        {
            "comment": "The code reads an image from bytes and converts it into a numpy array based on the provided flag (color or grayscale) and channel order. It first checks if the flag is valid, then decodes the image using OpenCV's imdecode function. If the flag is color and channel order is rgb, it returns the image as is. For other combinations, it converts the image to RGB or grayscale before returning the numpy array.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":247-269",
            "content": "                    img_rgba = img.convert('RGBA')\n                    img = Image.new('RGB', img_rgba.size, (124, 117, 104))\n                    img.paste(img_rgba, mask=img_rgba.split()[3])  # 3 is alpha\n            if flag == 'color':\n                array = np.array(img)\n                if channel_order != 'rgb':\n                    array = array[:, :, ::-1]  # RGB to BGR\n            elif flag == 'grayscale':\n                img = img.convert('L')\n                array = np.array(img)\n            else:\n                raise ValueError(\n                    'flag must be \"color\", \"grayscale\" or \"unchanged\", '\n                    f'but got {flag}')\n        return array\n    def _imfrombytes(self,content, flag='color', channel_order='bgr'):#, backend=None):\n        \"\"\"Read an image from bytes. \"\"\"\n        img_np = np.frombuffer(content, np.uint8)\n        flag = imread_flags[flag] if isinstance(flag, str) else flag\n        img = cv2.imdecode(img_np, flag)\n        if flag == IMREAD_COLOR and channel_order == 'rgb':"
        },
        {
            "comment": "This code defines a pipeline for decoding frames using the RawFrameDecode transform. It reads image files from the specified directory and suffix, handles different frame indices, and utilizes a file client to retrieve images in binary format. The cv2.cvtColor function is used to convert the color of images from BGR to RGB. The code also checks if the frame indices have the correct dimensions and squeezes them if necessary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":270-300",
            "content": "            cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)\n        return img\n    def __call__(self, results):\n        \"\"\"Perform the ``RawFrameDecode`` to pick frames given indices.\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"\n        # mmcv.use_backend(self.decoding_backend)\n        directory = results['frame_dir']\n        suffix = results['suffix']\n        #modality = results['modality']\n        if self.file_client is None:\n            self.file_client = FileClient(self.io_backend, **self.kwargs)\n        imgs = list()\n        if results['frame_inds'].ndim != 1:\n            results['frame_inds'] = np.squeeze(results['frame_inds'])\n        offset = results.get('offset', 0)\n        for frame_idx in results['frame_inds']:\n            frame_idx += offset\n            filepath = osp.join(directory, suffix.format(frame_idx))\n            img_bytes = self.file_client.get(filepath) #\u4ee5\u4e8c\u8fdb\u5236\u65b9\u5f0f\u8bfb\u53d6\u56fe\u7247\n            # Get frame with channel order RGB directly."
        },
        {
            "comment": "Function applies image processing and resizing to input, appends frames to a list, and scales gt_bboxes and proposals accordingly. It then returns the results. The __repr__ function provides a string representation of the object's class and arguments.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":302-325",
            "content": "            cur_frame = self._imfrombytes(img_bytes, channel_order='rgb')\n            imgs.append(cur_frame)\n        results['imgs'] = imgs\n        results['original_shape'] = imgs[0].shape[:2]\n        results['img_shape'] = imgs[0].shape[:2]\n        # we resize the gt_bboxes and proposals to their real scale\n        h, w = results['img_shape']\n        scale_factor = np.array([w, h, w, h])\n        if 'gt_bboxes' in results:\n            gt_bboxes = results['gt_bboxes']\n            gt_bboxes_new = (gt_bboxes * scale_factor).astype(np.float32)\n            results['gt_bboxes'] = gt_bboxes_new\n        if 'proposals' in results and results['proposals'] is not None:\n            proposals = results['proposals']\n            proposals = (proposals * scale_factor).astype(np.float32)\n            results['proposals'] = proposals\n        return results\n    def __repr__(self):\n        repr_str = (f'{self.__class__.__name__}('\n                    f'io_backend={self.io_backend}, '\n                    f'decoding_backend={self.decoding_backend})')"
        },
        {
            "comment": "The code defines a class called SampleAVAFrames, which inherits from SampleFrames. It takes clip length, frame interval, and test mode as arguments during initialization. The _get_clips method calculates the start and end indices for a given center index, taking into account skip offsets and shot information. The __call__ method retrieves fps, timestamp, timestamp_start, and shot_info from the results dictionary, and then calculates the center index to sample video frames around that index.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":326-353",
            "content": "        return repr_str\n@PIPELINES.register()\nclass SampleAVAFrames(SampleFrames):\n    def __init__(self, clip_len, frame_interval=2, test_mode=False):\n        super().__init__(clip_len, frame_interval, test_mode=test_mode)\n    def _get_clips(self, center_index, skip_offsets, shot_info):\n        start = center_index - (self.clip_len // 2) * self.frame_interval\n        end = center_index + ((self.clip_len + 1) // 2) * self.frame_interval\n        frame_inds = list(range(start, end, self.frame_interval))\n        frame_inds = frame_inds + skip_offsets\n        frame_inds = np.clip(frame_inds, shot_info[0], shot_info[1] - 1)\n        return frame_inds\n    def __call__(self, results):\n        fps = results['fps']\n        timestamp = results['timestamp']\n        timestamp_start = results['timestamp_start']\n        shot_info = results['shot_info']\n        #delta=(timestamp - timestamp_start) \u4e3a\u8be5\u5e27\u8ddd\u79bb15min\u89c6\u9891\u5f00\u5934\u6709\u51e0\u79d2\n        #center_index=fps*delta\u4e3a\u8be5\u5e27\u8ddd\u79bb15min\u89c6\u9891\u5f00\u5934\u6709\u51e0\u5e27\n        #center_index+1\u662f\u4e3a\u4e86\u907f\u514d\u540e\u7eed\u91c7\u6837\u65f6\u51fa\u73b0\u8d1f\u6570? \n        #\u540e\u7eed\u9700\u8981\u4ee5center_index\u4e3a\u4e2d\u5fc3\u524d\u540e\u91c7\u6837\u89c6\u9891\u5e27\u7247\u6bb5"
        },
        {
            "comment": "This function samples a video clip by calculating the center index and generating random skip offsets to select frames. It returns frame indices, clip length, frame interval, number of clips, and crop quadruple in a dictionary format for further processing. The `__repr__` method provides a concise string representation of the object's attributes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/sample_ava.py\":354-373",
            "content": "        center_index = fps * (timestamp - timestamp_start) + 1\n        skip_offsets = np.random.randint(\n            -self.frame_interval // 2, (self.frame_interval + 1) // 2,\n            size=self.clip_len)\n        frame_inds = self._get_clips(center_index, skip_offsets, shot_info)\n        results['frame_inds'] = np.array(frame_inds, dtype=np.int)\n        results['clip_len'] = self.clip_len\n        results['frame_interval'] = self.frame_interval\n        results['num_clips'] = 1\n        results['crop_quadruple'] = np.array([0, 0, 1, 1], dtype=np.float32)\n        return results\n    def __repr__(self):\n        repr_str = (f'{self.__class__.__name__}('\n                    f'clip_len={self.clip_len}, '\n                    f'frame_interval={self.frame_interval}, '\n                    f'test_mode={self.test_mode})')\n        return repr_str"
        }
    ]
}