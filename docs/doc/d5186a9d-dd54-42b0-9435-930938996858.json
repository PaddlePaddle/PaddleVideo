{
    "summary": "This function creates mask matrices and BMN class in Paddle.ai, initializes 2D convolutional layers for the BMSN backbone, and defines a video analysis model with layers, activation functions, and returns processed input xp.",
    "details": [
        {
            "comment": "This function generates a sample mask for a boundary-matching pair. It calculates the number of samples per bin and total samples based on segment bounds, total length, and desired numbers of samples.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":0-27",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport math\nimport numpy as np\nimport paddle\nfrom paddle import ParamAttr\nfrom ..registry import BACKBONES\ndef _get_interp1d_bin_mask(seg_xmin, seg_xmax, tscale, num_sample,\n                           num_sample_perbin):\n    \"\"\" generate sample mask for a boundary-matching pair \"\"\"\n    plen = float(seg_xmax - seg_xmin)\n    plen_sample = plen / (num_sample * num_sample_perbin - 1.0)\n    total_samples = [\n        seg_xmin + plen_sample * ii"
        },
        {
            "comment": "This code generates sample masks for each point in a Boundary-Matching Map. It iterates through samples, creates binary vectors for each, and then scales them to obtain the final mask. The resulting masks are stored in an array and returned.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":28-52",
            "content": "        for ii in range(num_sample * num_sample_perbin)\n    ]\n    p_mask = []\n    for idx in range(num_sample):\n        bin_samples = total_samples[idx * num_sample_perbin:(idx + 1) *\n                                    num_sample_perbin]\n        bin_vector = np.zeros([tscale])\n        for sample in bin_samples:\n            sample_upper = math.ceil(sample)\n            sample_decimal, sample_down = math.modf(sample)\n            if (tscale - 1) >= int(sample_down) >= 0:\n                bin_vector[int(sample_down)] += 1 - sample_decimal\n            if (tscale - 1) >= int(sample_upper) >= 0:\n                bin_vector[int(sample_upper)] += sample_decimal\n        bin_vector = 1.0 / num_sample_perbin * bin_vector\n        p_mask.append(bin_vector)\n    p_mask = np.stack(p_mask, axis=1)\n    return p_mask\ndef get_interp1d_mask(tscale, dscale, prop_boundary_ratio, num_sample,\n                      num_sample_perbin):\n    \"\"\" generate sample mask for each point in Boundary-Matching Map \"\"\"\n    mask_mat = []\n    for start_index in range(tscale):"
        },
        {
            "comment": "This code generates mask matrices for video frames. It iterates over different duration scales and starts from a given start index. For each duration scale, it creates binary masks using interpolation. If the duration is smaller than the total time scale, it adjusts the sample range to include boundaries. Zero paddings are used if the duration exceeds the total time scale. The generated mask vectors are stacked together and reshaped for final output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":53-76",
            "content": "        mask_mat_vector = []\n        for duration_index in range(dscale):\n            if start_index + duration_index < tscale:\n                p_xmin = start_index\n                p_xmax = start_index + duration_index\n                center_len = float(p_xmax - p_xmin) + 1\n                sample_xmin = p_xmin - center_len * prop_boundary_ratio\n                sample_xmax = p_xmax + center_len * prop_boundary_ratio\n                p_mask = _get_interp1d_bin_mask(sample_xmin, sample_xmax,\n                                                tscale, num_sample,\n                                                num_sample_perbin)\n            else:\n                p_mask = np.zeros([tscale, num_sample])\n            mask_mat_vector.append(p_mask)\n        mask_mat_vector = np.stack(mask_mat_vector, axis=2)\n        mask_mat.append(mask_mat_vector)\n    mask_mat = np.stack(mask_mat, axis=3)\n    mask_mat = mask_mat.astype(np.float32)\n    sample_mask = np.reshape(mask_mat, [tscale, -1])\n    return sample_mask\ndef init_params(name, in_channels, kernel_size):"
        },
        {
            "comment": "This code defines a BMN class as a Paddle.ai layer implementing the BMN model for temporal action proposal generation from the paper \"BMN: Boundary-Matching Network for Temporal Action Proposal Generation\". It has parameters tscale, dscale, prop_boundary_ratio, num_sample, and num_sample_perbin which determine the sequence length, max duration length, ratio of expanded temporal region in proposal boundary, number of samples between starting and ending boundaries of each proposal, and number of selected points in each sample respectively. The code also initializes a ParamAttr with Uniform initializer for weight initialization.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":77-102",
            "content": "    fan_in = in_channels * kernel_size * 1\n    k = 1. / math.sqrt(fan_in)\n    param_attr = ParamAttr(name=name,\n                           initializer=paddle.nn.initializer.Uniform(low=-k,\n                                                                     high=k))\n    return param_attr\n@BACKBONES.register()\nclass BMN(paddle.nn.Layer):\n    \"\"\"BMN model from\n    `\"BMN: Boundary-Matching Network for Temporal Action Proposal Generation\" <https://arxiv.org/abs/1907.09702>`_\n    Args:\n        tscale (int): sequence length, default 100.\n        dscale (int): max duration length, default 100.\n        prop_boundary_ratio (float): ratio of expanded temporal region in proposal boundary, default 0.5.\n        num_sample (int): number of samples betweent starting boundary and ending boundary of each propoasl, default 32.\n        num_sample_perbin (int):  number of selected points in each sample, default 3.\n    \"\"\"\n    def __init__(\n        self,\n        tscale,\n        dscale,\n        prop_boundary_ratio,\n        num_sample,"
        },
        {
            "comment": "This code defines the BMN class, which is a backbone model. It initializes parameters and includes convolutional layers with ReLU activation functions for feature extraction. The code also includes instance variables for controlling the model's behavior and dimensionality of the hidden states.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":103-136",
            "content": "        num_sample_perbin,\n        feat_dim=400,\n    ):\n        super(BMN, self).__init__()\n        #init config\n        self.feat_dim = feat_dim\n        self.tscale = tscale\n        self.dscale = dscale\n        self.prop_boundary_ratio = prop_boundary_ratio\n        self.num_sample = num_sample\n        self.num_sample_perbin = num_sample_perbin\n        self.hidden_dim_1d = 256\n        self.hidden_dim_2d = 128\n        self.hidden_dim_3d = 512\n        # Base Module\n        self.b_conv1 = paddle.nn.Conv1D(\n            in_channels=self.feat_dim,\n            out_channels=self.hidden_dim_1d,\n            kernel_size=3,\n            padding=1,\n            groups=4,\n            weight_attr=init_params('Base_1_w', self.feat_dim, 3),\n            bias_attr=init_params('Base_1_b', self.feat_dim, 3))\n        self.b_conv1_act = paddle.nn.ReLU()\n        self.b_conv2 = paddle.nn.Conv1D(\n            in_channels=self.hidden_dim_1d,\n            out_channels=self.hidden_dim_1d,\n            kernel_size=3,\n            padding=1,\n            groups=4,"
        },
        {
            "comment": "This code defines a Conv1D block for the BMN model, including an input layer, a temporal evaluation module, and two convolutional layers with ReLU activation functions. The weights and biases are initialized using the 'init_params' function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":137-162",
            "content": "            weight_attr=init_params('Base_2_w', self.hidden_dim_1d, 3),\n            bias_attr=init_params('Base_2_b', self.hidden_dim_1d, 3))\n        self.b_conv2_act = paddle.nn.ReLU()\n        # Temporal Evaluation Module\n        self.ts_conv1 = paddle.nn.Conv1D(\n            in_channels=self.hidden_dim_1d,\n            out_channels=self.hidden_dim_1d,\n            kernel_size=3,\n            padding=1,\n            groups=4,\n            weight_attr=init_params('TEM_s1_w', self.hidden_dim_1d, 3),\n            bias_attr=init_params('TEM_s1_b', self.hidden_dim_1d, 3))\n        self.ts_conv1_act = paddle.nn.ReLU()\n        self.ts_conv2 = paddle.nn.Conv1D(\n            in_channels=self.hidden_dim_1d,\n            out_channels=1,\n            kernel_size=1,\n            padding=0,\n            groups=1,\n            weight_attr=init_params('TEM_s2_w', self.hidden_dim_1d, 1),\n            bias_attr=init_params('TEM_s2_b', self.hidden_dim_1d, 1))\n        self.ts_conv2_act = paddle.nn.Sigmoid()\n        self.te_conv1 = paddle.nn.Conv1D("
        },
        {
            "comment": "This code initializes the TEM and PEM modules of a backbone network. It defines several convolutional layers with specific configurations for each module, followed by activation functions. The weight and bias attributes are initialized using the init_params function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":163-188",
            "content": "            in_channels=self.hidden_dim_1d,\n            out_channels=self.hidden_dim_1d,\n            kernel_size=3,\n            padding=1,\n            groups=4,\n            weight_attr=init_params('TEM_e1_w', self.hidden_dim_1d, 3),\n            bias_attr=init_params('TEM_e1_b', self.hidden_dim_1d, 3))\n        self.te_conv1_act = paddle.nn.ReLU()\n        self.te_conv2 = paddle.nn.Conv1D(\n            in_channels=self.hidden_dim_1d,\n            out_channels=1,\n            kernel_size=1,\n            padding=0,\n            groups=1,\n            weight_attr=init_params('TEM_e2_w', self.hidden_dim_1d, 1),\n            bias_attr=init_params('TEM_e2_b', self.hidden_dim_1d, 1))\n        self.te_conv2_act = paddle.nn.Sigmoid()\n        #Proposal Evaluation Module\n        self.p_conv1 = paddle.nn.Conv1D(\n            in_channels=self.hidden_dim_1d,\n            out_channels=self.hidden_dim_2d,\n            kernel_size=3,\n            padding=1,\n            groups=1,\n            weight_attr=init_params('PEM_1d_w', self.hidden_dim_1d, 3),"
        },
        {
            "comment": "This code initializes a backbone model for the BMN architecture. It includes convolutional layers, ReLU activations, and a tensor mask for sampling. The model uses 1D, 2D, and 3D convolutions with specific parameters, as well as applies bias attributes to the weights and biases of the convolutions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":189-214",
            "content": "            bias_attr=init_params('PEM_1d_b', self.hidden_dim_1d, 3))\n        self.p_conv1_act = paddle.nn.ReLU()\n        # init to speed up\n        sample_mask = get_interp1d_mask(self.tscale, self.dscale,\n                                        self.prop_boundary_ratio,\n                                        self.num_sample, self.num_sample_perbin)\n        self.sample_mask = paddle.to_tensor(sample_mask)\n        self.sample_mask.stop_gradient = True\n        self.p_conv3d1 = paddle.nn.Conv3D(\n            in_channels=128,\n            out_channels=self.hidden_dim_3d,\n            kernel_size=(self.num_sample, 1, 1),\n            stride=(self.num_sample, 1, 1),\n            padding=0,\n            weight_attr=ParamAttr(name=\"PEM_3d1_w\"),\n            bias_attr=ParamAttr(name=\"PEM_3d1_b\"))\n        self.p_conv3d1_act = paddle.nn.ReLU()\n        self.p_conv2d1 = paddle.nn.Conv2D(\n            in_channels=512,\n            out_channels=self.hidden_dim_2d,\n            kernel_size=1,\n            stride=1,\n            padding=0,"
        },
        {
            "comment": "This code initializes a series of 2D convolutional layers with ReLU activation functions for the Batch Multi-Scale Network (BMSN) backbone in PaddleVideo. Each convolutional layer has a specified number of output channels, kernel size, and stride. The weights and biases for each layer are defined using ParamAttr.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":215-245",
            "content": "            weight_attr=ParamAttr(name=\"PEM_2d1_w\"),\n            bias_attr=ParamAttr(name=\"PEM_2d1_b\"))\n        self.p_conv2d1_act = paddle.nn.ReLU()\n        self.p_conv2d2 = paddle.nn.Conv2D(\n            in_channels=128,\n            out_channels=self.hidden_dim_2d,\n            kernel_size=3,\n            stride=1,\n            padding=1,\n            weight_attr=ParamAttr(name=\"PEM_2d2_w\"),\n            bias_attr=ParamAttr(name=\"PEM_2d2_b\"))\n        self.p_conv2d2_act = paddle.nn.ReLU()\n        self.p_conv2d3 = paddle.nn.Conv2D(\n            in_channels=128,\n            out_channels=self.hidden_dim_2d,\n            kernel_size=3,\n            stride=1,\n            padding=1,\n            weight_attr=ParamAttr(name=\"PEM_2d3_w\"),\n            bias_attr=ParamAttr(name=\"PEM_2d3_b\"))\n        self.p_conv2d3_act = paddle.nn.ReLU()\n        self.p_conv2d4 = paddle.nn.Conv2D(\n            in_channels=128,\n            out_channels=2,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            weight_attr=ParamAttr(name=\"PEM_2d4_w\"),"
        },
        {
            "comment": "The code is defining a backbone model for video analysis. It consists of base, TEM (temporal-inspired module), PEM (position-inspired module), and BM (block-matching module) layers. The layers are sequentially applied to the input data with appropriate activation functions and reshaping operations in between. Finally, it performs matrix multiplication with a sample mask and applies additional convolutions and activations.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":246-282",
            "content": "            bias_attr=ParamAttr(name=\"PEM_2d4_b\"))\n        self.p_conv2d4_act = paddle.nn.Sigmoid()\n    def init_weights(self):\n        pass\n    def forward(self, x):\n        #Base Module\n        x = self.b_conv1(x)\n        x = self.b_conv1_act(x)\n        x = self.b_conv2(x)\n        x = self.b_conv2_act(x)\n        #TEM\n        xs = self.ts_conv1(x)\n        xs = self.ts_conv1_act(xs)\n        xs = self.ts_conv2(xs)\n        xs = self.ts_conv2_act(xs)\n        xs = paddle.squeeze(xs, axis=[1])\n        xe = self.te_conv1(x)\n        xe = self.te_conv1_act(xe)\n        xe = self.te_conv2(xe)\n        xe = self.te_conv2_act(xe)\n        xe = paddle.squeeze(xe, axis=[1])\n        #PEM\n        xp = self.p_conv1(x)\n        xp = self.p_conv1_act(xp)\n        #BM layer\n        xp = paddle.matmul(xp, self.sample_mask)\n        xp = paddle.reshape(xp, shape=[0, 0, -1, self.dscale, self.tscale])\n        xp = self.p_conv3d1(xp)\n        xp = self.p_conv3d1_act(xp)\n        xp = paddle.squeeze(xp, axis=[2])\n        xp = self.p_conv2d1(xp)\n        xp = self.p_conv2d1_act(xp)"
        },
        {
            "comment": "This code is part of a neural network backbone model. It applies multiple convolution layers with activation functions and returns the processed input xp, along with other variables xs and xe.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/bmn.py\":283-289",
            "content": "        xp = self.p_conv2d2(xp)\n        xp = self.p_conv2d2_act(xp)\n        xp = self.p_conv2d3(xp)\n        xp = self.p_conv2d3_act(xp)\n        xp = self.p_conv2d4(xp)\n        xp = self.p_conv2d4_act(xp)\n        return xp, xs, xe"
        }
    ]
}