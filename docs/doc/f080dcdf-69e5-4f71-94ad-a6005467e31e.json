{
    "summary": "This code imports libraries, defines functions for data processing and categorizing experts, adjusts input features, ensures Tensor format, and includes utility functions.",
    "details": [
        {
            "comment": "This code imports necessary libraries and defines several functions. The 'filter_cmd_args' function removes specified keys from a list of command arguments while preserving the order. The 'set_seeds' function sets seeds for randomization libraries, ensuring consistent results. The 'memory_summary' function provides a summary of virtual memory usage using the 'psutil' library.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":0-49",
            "content": "\"\"\"\nExclude from autoreload\n%aimport -util.utils\n\"\"\"\nimport os\nimport json\nimport random\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import List\nfrom itertools import repeat\nfrom collections import OrderedDict\nimport numpy as np\nimport paddle\nimport psutil\nimport humanize\nfrom PIL import Image\nfrom typeguard import typechecked\n@typechecked\ndef filter_cmd_args(cmd_args: List[str], remove: List[str]) -> List[str]:\n    drop = []\n    for key in remove:\n        if key not in cmd_args:\n            continue\n        pos = cmd_args.index(key)\n        drop.append(pos)\n        if len(cmd_args) > (pos + 1) and not cmd_args[pos + 1].startswith(\"--\"):\n            drop.append(pos + 1)\n    for pos in reversed(drop):\n        cmd_args.pop(pos)\n    return cmd_args\n@typechecked\ndef set_seeds(seed: int):\n    \"\"\"Set seeds for randomisation libraries.\n    Args:\n        seed: the seed value\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    paddle.seed(seed)\ndef memory_summary():\n    vmem = psutil.virtual_memory()\n    msg = ("
        },
        {
            "comment": "This code defines three functions. The first function, `print_memory`, prints the current system memory usage in a readable format. The second function, `flatten_dict`, recursively flattens nested dictionaries into a single-level dictionary. The third function, `expert_tensor_storage`, categorizes experts based on their temporal configurations into fixed, variable, and flaky sets.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":50-75",
            "content": "        f\">>> Currently using {vmem.percent}% of system memory \"\n        f\"{humanize.naturalsize(vmem.used)}/{humanize.naturalsize(vmem.available)}\"\n    )\n    print(msg)\ndef flatten_dict(x, keysep=\"-\"):\n    flat_dict = {}\n    for key, val in x.items():\n        if isinstance(val, dict):\n            flat_subdict = flatten_dict(val)\n            flat_dict.update({f\"{key}{keysep}{subkey}\": subval\n                              for subkey, subval in flat_subdict.items()})\n        else:\n            flat_dict.update({key: val})\n    return flat_dict\ndef expert_tensor_storage(experts, feat_aggregation):\n    expert_storage = {\"fixed\": set(), \"variable\": set(), \"flaky\": set()}\n    # fixed_sz_experts, variable_sz_experts, flaky_experts = set(), set(), set()\n    for expert, config in feat_aggregation.items():\n        if config[\"temporal\"] in {\"vlad\",  \"fixed_seg\"}:\n            expert_storage[\"variable\"].add(expert)\n        elif config[\"temporal\"] in {\"avg\", \"max\", \"avg-max\", \"max-avg\", \"avg-max-ent\", \n                                    \"max-avg-ent\"}:"
        },
        {
            "comment": "This code snippet contains a function that takes in an expert and its configuration, adds it to the appropriate storage based on its temporal strategy, and handles flaky experts. It also defines two utility functions - read_json for parsing JSON files and path2str for converting pathlib objects to strings for serialization.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":76-102",
            "content": "            expert_storage[\"fixed\"].add(expert)\n        else:\n            raise ValueError(f\"unknown temporal strategy: {config['temporal']}\")\n        # some \"flaky\" experts are only available for a fraction of videos - we need\n        # to pass this information (in the form of indices) into the network for any\n        # experts present in the current dataset\n        if config.get(\"flaky\", False):\n            expert_storage[\"flaky\"].add(expert)\n    # we only allocate storage for experts used by the current dataset\n    for key, value in expert_storage.items():\n        expert_storage[key] = value.intersection(set(experts))\n    return expert_storage\ndef read_json(fname):\n    with fname.open('rt') as handle:\n        return json.load(handle, object_hook=OrderedDict)\ndef path2str(x):\n    \"\"\"Recursively convert pathlib objects to strings to enable serialization\"\"\"\n    for key, val in x.items():\n        if isinstance(val, dict):\n            path2str(val)\n        elif isinstance(val, Path):\n            x[key] = str(val)"
        },
        {
            "comment": "This code includes a function for writing JSON data, an infinite loop wrapper for data loaders, two classes for hashable dictionaries, a function to compute training configuration from a given config file, and a function to compute dimensions from the same config file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":105-142",
            "content": "def write_json(content, fname, paths2strs=False):\n    if paths2strs:\n        path2str(content)\n    with fname.open('wt') as handle:\n        json.dump(content, handle, indent=4, sort_keys=False)\ndef inf_loop(data_loader):\n    ''' wrapper function for endless data loader. '''\n    for loader in repeat(data_loader):\n        yield from loader\nclass HashableDict(dict):\n    def __hash__(self):\n        return hash(frozenset(self))\nclass HashableOrderedDict(dict):\n    def __hash__(self):\n        return hash(frozenset(self))\ndef compute_trn_config(config, logger=None):\n    trn_config = {}\n    feat_agg = config[\"data_loader\"][\"args\"][\"feat_aggregation\"]\n    for static_expert in feat_agg.keys():\n        if static_expert in feat_agg:\n            if \"trn_seg\" in feat_agg[static_expert].keys():\n                trn_config[static_expert] = feat_agg[static_expert][\"trn_seg\"]\n    return trn_config\ndef compute_dims(config, logger=None):\n    if logger is None:\n        logger = config.get_logger('utils')\n    experts = config[\"experts\"]"
        },
        {
            "comment": "This code is organizing modalities, extracting expert settings and dimensions for different modalities like face, features_scene, features_s3d, and features_flow. It also checks if any feature should be dropped and sorts them accordingly. Finally, it assigns the input and output dimensions based on the modality and temporal aggregation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":143-164",
            "content": "    # TODO(Samuel): clean up the logic since it's a little convoluted\n    ordered = sorted(config[\"experts\"][\"modalities\"])\n    if experts[\"drop_feats\"]:\n        to_drop = experts[\"drop_feats\"].split(\",\")\n        logger.info(f\"dropping: {to_drop}\")\n        ordered = [x for x in ordered if x not in to_drop]\n    feat_agg = config[\"data_loader\"][\"args\"][\"feat_aggregation\"]\n    dims = []\n    arch_args = config[\"arch\"][\"args\"]\n    vlad_clusters = arch_args[\"vlad_clusters\"]\n    for expert in ordered:\n        temporal = feat_agg[expert][\"temporal\"]\n        if expert == \"face\":\n            in_dim, out_dim = experts[\"face_dim\"], experts[\"face_dim\"]\n        elif expert == \"features_scene\" and temporal == \"vlad\":\n            in_dim, out_dim = 2208 * vlad_clusters[\"features_scene\"], 2208\n        elif expert == \"features_s3d\" and temporal == \"vlad\":\n            in_dim, out_dim = 1024 * vlad_clusters[\"features_s3d\"], 1024\n        elif expert == \"features_flow\" and temporal == \"vlad\":\n            in_dim, out_dim = 1024 * vlad_clusters[\"features_flow\"], 1024"
        },
        {
            "comment": "This code snippet is determining the input and output dimensions based on the expert type and temporal method used. It sets the input dimension by multiplying vlad_clusters value with respective constants, and the output dimension remains constant for each expert type and temporal method combination.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":165-180",
            "content": "        elif expert == \"features_rgb\" and temporal == \"vlad\":\n            in_dim, out_dim = 2048 * vlad_clusters[\"features_rgb\"], 2048\n        elif expert == \"features_ocr\" and temporal == \"vlad\":\n            in_dim, out_dim = 300 * vlad_clusters[\"features_ocr\"], 300\n        elif expert == \"features_face\" and temporal == \"vlad\":\n            in_dim, out_dim = 512 * vlad_clusters[\"features_face\"], 512\n        elif expert == \"features_speech\" and temporal == \"vlad\":\n            in_dim, out_dim = 300 * vlad_clusters[\"features_speech\"], 300\n        elif expert == \"features_audio\" and temporal == \"vlad\":\n            in_dim, out_dim = 128 * vlad_clusters[\"features_audio\"], 128\n        elif expert == \"audio\" and temporal == \"vlad\":\n            in_dim, out_dim = 128 * vlad_clusters[\"audio\"], 128\n        elif expert == \"audio\" and temporal == \"vlad\":\n            in_dim, out_dim = 128 * vlad_clusters[\"audio\"], 128\n        elif expert == \"speech\" and temporal == \"vlad\":\n            in_dim, out_dim = 300 * vlad_clusters[\"speech\"], 300"
        },
        {
            "comment": "This code block assigns the input and output dimensions for different experts (e.g., OCR, detection, detection-sem, openpose) based on their respective configurations and cluster settings. It also considers aggregation types like avg or max pooling.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":181-201",
            "content": "        elif expert == \"ocr\" and temporal == \"vlad\":\n            in_dim, out_dim = 300 * vlad_clusters[\"ocr\"], 300\n        elif expert == \"detection\":\n            # allow for avg pooling\n            det_clusters = arch_args[\"vlad_clusters\"].get(\"detection\", 1)\n            in_dim, out_dim = 1541 * det_clusters, 1541\n        elif expert == \"detection-sem\":\n            if config[\"data_loader\"][\"args\"].get(\"spatial_feats\", False):\n                base = 300 + 16\n            else:\n                base = 300 + 5\n            det_clusters = arch_args[\"vlad_clusters\"].get(\"detection-sem\", 1)\n            in_dim, out_dim = base * det_clusters, base\n        elif expert == \"openpose\":\n            base = 54\n            det_clusters = arch_args[\"vlad_clusters\"].get(\"openpose\", 1)\n            in_dim, out_dim = base * det_clusters, base\n        else:\n            common_dim = feat_agg[expert][\"feat_dims\"][feat_agg[expert][\"type\"]]\n            # account for aggregation of multilpe forms (e.g. avg + max pooling)\n            common_dim = common_dim * len(feat_agg[expert][\"temporal\"].split(\"-\"))"
        },
        {
            "comment": "This code configures the expert dimensions for a machine learning model. It checks if certain conditions are met, such as disabling VLAD for text with single tokens and using averaging only with text using single tokens. To avoid dependencies between dataloader and model architecture, it creates a second copy of expert dimensions accounting for the number of VLAD clusters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":202-225",
            "content": "            in_dim, out_dim = common_dim, common_dim\n        # For the CE architecture, we need to project all features to a common\n        # dimensionality\n        if arch_args.get(\"mimic_ce_dims\", False):\n            out_dim = experts[\"ce_shared_dim\"]\n        dims.append((expert, (in_dim, out_dim)))\n    expert_dims = OrderedDict(dims)\n    if vlad_clusters[\"text\"] == 0:\n        msg = \"vlad can only be disabled for text with single tokens\"\n        assert config[\"data_loader\"][\"args\"][\"max_tokens\"][\"text\"] == 1, msg\n    if config[\"experts\"][\"text_agg\"] == \"avg\":\n        msg = \"averaging can only be performed with text using single tokens\"\n        assert config[\"arch\"][\"args\"][\"vlad_clusters\"][\"text\"] == 0\n        assert config[\"data_loader\"][\"args\"][\"max_tokens\"][\"text\"] == 1\n    # To remove the dependency of dataloader on the model architecture, we create a\n    # second copy of the expert dimensions which accounts for the number of vlad\n    # clusters\n    raw_input_dims = OrderedDict()\n    for expert, dim_pair in expert_dims.items():"
        },
        {
            "comment": "This code is adjusting the dimensionality of input features for different expert models and ensuring they are in Tensor format. It also provides utility functions like Timer for measuring time durations and tensor2im to convert Tensors into numpy images.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":226-257",
            "content": "        raw_dim = dim_pair[0]\n        if expert in {\"audio\", \"speech\", \"ocr\", \"detection\", \"detection-sem\", \"openpose\", \"features_audio\", \"features_speech\", \"features_face\", \"features_ocr\",  \"features_rgb\", \"features_flow\", \"features_s3d\", \"features_scene\",\n                      \"speech.mozilla.0\"}:\n            if feat_agg[expert][\"temporal\"] == \"vlad\":\n                raw_dim = raw_dim // vlad_clusters.get(expert, 1)\n        raw_input_dims[expert] = raw_dim\n    return expert_dims, raw_input_dims\ndef ensure_tensor(x):\n    if not isinstance(x, paddle.Tensor): #if not isinstance(x, torch.Tensor):\n        x = paddle.to_tensor(x) #    x = torch.from_numpy(x)\n    return x\nclass Timer:\n    def __init__(self):\n        self.cache = datetime.now()\n    def check(self):\n        now = datetime.now()\n        duration = now - self.cache\n        self.cache = now\n        return duration.total_seconds()\n    def reset(self):\n        self.cache = datetime.now()\ndef tensor2im(input_image, imtype=np.uint8):\n    \"\"\"\"Converts a Tensor array into a numpy image array."
        },
        {
            "comment": "The function normalizes and converts the input image tensor array to a numpy array. It also handles different data types and saves the numpy image to disk.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":259-283",
            "content": "    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"\n    if not isinstance(input_image, np.ndarray):\n        if isinstance(input_image, paddle.Tensor): #if isinstance(input_image, torch.Tensor):  # get the data from a variable\n            image_tensor = input_image #image_tensor = input_image.data\n        else:\n            return input_image\n        # convert it into a numpy array\n        image_numpy = image_tensor[0].cpu().float().numpy()\n        if image_numpy.shape[0] == 1:  # grayscale to RGB\n            image_numpy = np.tile(image_numpy, (3, 1, 1))\n        # post-processing: tranpose and scaling\n        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n    else:  # if it is a numpy array, do nothing\n        image_numpy = input_image\n    return image_numpy.astype(imtype)\ndef save_image(image_numpy, image_path):\n    \"\"\"Save a numpy image to the disk\n    Parameters:\n        image_numpy (numpy array) -- input numpy array"
        },
        {
            "comment": "util.py contains several utility functions:\n1. \"image_to_path\" converts an image numpy array to a PIL Image and saves it at the given path.\n2. \"print_numpy\" prints statistics (mean, min, max, median, std) of a numpy array if specified.\n3. \"mkdirs\" creates empty directories if they don't exist, accepting either a list of paths or a single path.\n4. \"mkdir\" is a helper function for \"mkdirs,\" creating a single directory if it doesn't exist.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":284-320",
            "content": "        image_path (str)          -- the path of the image\n    \"\"\"\n    image_pil = Image.fromarray(image_numpy)\n    image_pil.save(image_path)\ndef print_numpy(x, val=True, shp=False):\n    \"\"\"Print the mean, min, max, median, std, and size of a numpy array\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"\n    x = x.astype(np.float64)\n    if shp:\n        print('shape,', x.shape)\n    if val:\n        x = x.flatten()\n        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))\ndef mkdirs(paths):\n    \"\"\"create empty directories if they don't exist\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)\ndef mkdir(path):\n    \"\"\"create a single empty directory if it didn't exist"
        },
        {
            "comment": "This function creates a directory if it does not exist at the given path.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/utils/util.py\":322-326",
            "content": "    Parameters:\n        path (str) -- a single directory path\n    \"\"\"\n    if not os.path.exists(path):\n        os.makedirs(path)"
        }
    ]
}