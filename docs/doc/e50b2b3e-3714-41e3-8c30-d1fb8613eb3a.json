{
    "summary": "The Python code's `AveragePrecisionCalculator` class calculates interpolated average precision, supports large datasets, and handles sparse prediction scores and ground truth labels for classification tasks.",
    "details": [
        {
            "comment": "This code is for a Python class that calculates the interpolated average precision (IAP) of ranked items in a list. It follows the definition provided in the given link and can be used as a static function to directly calculate IAP from a short ranked list.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":0-22",
            "content": "# Copyright 2016 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Calculate or keep track of the interpolated average precision.\nIt provides an interface for calculating interpolated average precision for an\nentire list or the top-n ranked items. For the definition of the\n(non-)interpolated average precision:\nhttp://trec.nist.gov/pubs/trec15/appendices/CE.MEASURES06.pdf\nExample usages:\n1) Use it as a static function call to directly calculate average precision for\na short ranked list in the memory."
        },
        {
            "comment": "The code creates an instance of the AveragePrecisionCalculator class and uses its accumulate method to process parts of a ranked list that cannot be stored in memory or observed at once. After processing all parts, it uses the peek_interpolated_ap_at_n method to get the interpolated average precision at a given number of elements. The code also imports heapq and random modules for priority queue and random number generation respectively.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":24-54",
            "content": "```\nimport random\np = np.array([random.random() for _ in xrange(10)])\na = np.array([random.choice([0, 1]) for _ in xrange(10)])\nap = average_precision_calculator.AveragePrecisionCalculator.ap(p, a)\n```\n2) Use it as an object for long ranked list that cannot be stored in memory or\nthe case where partial predictions can be observed at a time (Tensorflow\npredictions). In this case, we first call the function accumulate many times\nto process parts of the ranked list. After processing all the parts, we call\npeek_interpolated_ap_at_n.\n```\np1 = np.array([random.random() for _ in xrange(5)])\na1 = np.array([random.choice([0, 1]) for _ in xrange(5)])\np2 = np.array([random.random() for _ in xrange(5)])\na2 = np.array([random.choice([0, 1]) for _ in xrange(5)])\n# interpolated average precision at 10 using 1000 break points\ncalculator = average_precision_calculator.AveragePrecisionCalculator(10)\ncalculator.accumulate(p1, a1)\ncalculator.accumulate(p2, a2)\nap3 = calculator.peek_ap_at_n()\n```\n\"\"\"\nimport heapq\nimport random\nimport numbers"
        },
        {
            "comment": "This code defines a class `AveragePrecisionCalculator` that calculates average precision and average precision at n for a single label. It takes a `top_n` argument to specify the average precision at n or uses all provided data points if None. The class maintains a max heap of (prediction, actual) and provides a `heap_size` property to get the heap size.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":56-85",
            "content": "import numpy\nclass AveragePrecisionCalculator(object):\n    \"\"\"Calculate the average precision and average precision at n.\"\"\"\n    def __init__(self, top_n=None):\n        \"\"\"Construct an AveragePrecisionCalculator to calculate average precision.\n    This class is used to calculate the average precision for a single label.\n    Args:\n      top_n: A positive Integer specifying the average precision at n, or\n        None to use all provided data points.\n    Raises:\n      ValueError: An error occurred when the top_n is not a positive integer.\n    \"\"\"\n        if not ((isinstance(top_n, int) and top_n >= 0) or top_n is None):\n            raise ValueError(\"top_n must be a positive integer or None.\")\n        self._top_n = top_n  # average precision at n\n        self._total_positives = 0  # total number of positives have seen\n        self._heap = []  # max heap of (prediction, actual)\n    @property\n    def heap_size(self):\n        \"\"\"Gets the heap size maintained in the class.\"\"\"\n        return len(self._heap)\n    @property"
        },
        {
            "comment": "This function accumulates prediction scores and ground truth labels, allowing for the calculation of average precision after the call. The function requires both predictions and actuals to have the same shape. If inputs are incomplete, you can provide 'num_positives' to accurately track recall.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":86-107",
            "content": "    def num_accumulated_positives(self):\n        \"\"\"Gets the number of positive samples that have been accumulated.\"\"\"\n        return self._total_positives\n    def accumulate(self, predictions, actuals, num_positives=None):\n        \"\"\"Accumulate the predictions and their ground truth labels.\n    After the function call, we may call peek_ap_at_n to actually calculate\n    the average precision.\n    Note predictions and actuals must have the same shape.\n    Args:\n      predictions: a list storing the prediction scores.\n      actuals: a list storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives = If the 'predictions' and 'actuals' inputs aren't complete,\n      then it's possible some true positives were missed in them. In that case,\n      you can provide 'num_positives' in order to accurately track recall.\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match."
        },
        {
            "comment": "This code snippet is a class method that checks the shape compatibility of 'predictions' and 'actuals', verifies if 'num_positives' is a nonzero number, calculates the total positives, and populates a heap. It also ensures the correctness of the predictions by comparing them to the actuals and updating the heap accordingly.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":108-133",
            "content": "    \"\"\"\n        if len(predictions) != len(actuals):\n            raise ValueError(\n                \"the shape of predictions and actuals does not match.\")\n        if not num_positives is None:\n            if not isinstance(num_positives,\n                              numbers.Number) or num_positives < 0:\n                raise ValueError(\n                    \"'num_positives' was provided but it wan't a nonzero number.\"\n                )\n        if not num_positives is None:\n            self._total_positives += num_positives\n        else:\n            self._total_positives += numpy.size(numpy.where(actuals > 0))\n        topk = self._top_n\n        heap = self._heap\n        for i in range(numpy.size(predictions)):\n            if topk is None or len(heap) < topk:\n                heapq.heappush(heap, (predictions[i], actuals[i]))\n            else:\n                if predictions[i] > heap[0][0]:  # heap[0] is the smallest\n                    heapq.heappop(heap)\n                    heapq.heappush(heap, (predictions[i], actuals[i]))"
        },
        {
            "comment": "This code is part of a class that calculates average precision for video tagging. It includes methods to clear accumulated predictions, peek the non-interpolated average precision at a specific point (n), and calculate the non-interpolated average precision using prediction and actual scores arrays.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":135-165",
            "content": "    def clear(self):\n        \"\"\"Clear the accumulated predictions.\"\"\"\n        self._heap = []\n        self._total_positives = 0\n    def peek_ap_at_n(self):\n        \"\"\"Peek the non-interpolated average precision at n.\n    Returns:\n      The non-interpolated average precision at n (default 0).\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    \"\"\"\n        if self.heap_size <= 0:\n            return 0\n        predlists = numpy.array(list(zip(*self._heap)))\n        ap = self.ap_at_n(predlists[0],\n                          predlists[1],\n                          n=self._top_n,\n                          total_num_positives=self._total_positives)\n        return ap\n    @staticmethod\n    def ap(predictions, actuals):\n        \"\"\"Calculate the non-interpolated average precision.\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives."
        },
        {
            "comment": "This code calculates the non-interpolated average precision at 'n' in a list. It takes sparse prediction scores and ground truth labels as input, with any value larger than 0 treated as positives. It also allows specifying the total number of positive items in the list, which can be used for calculation if provided.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":167-191",
            "content": "    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"\n        return AveragePrecisionCalculator.ap_at_n(predictions, actuals, n=None)\n    @staticmethod\n    def ap_at_n(predictions, actuals, n=20, total_num_positives=None):\n        \"\"\"Calculate the non-interpolated average precision.\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      n: the top n items to be considered in ap@n.\n      total_num_positives : (optionally) you can specify the number of total\n        positive\n      in the list. If specified, it will be used in calculation.\n    Returns:"
        },
        {
            "comment": "The code defines a function that calculates the average precision at a specific rank, n. It checks the shape of predictions and actuals arrays and if n is positive integer or None. If any error occurs, it raises ValueError. The code also shuffles the predictions and actuals to avoid overestimating the average precision.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":192-219",
            "content": "      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    Raises:\n      ValueError: An error occurred when\n      1) the format of the input is not the numpy 1-D array;\n      2) the shape of predictions and actuals does not match;\n      3) the input n is not a positive integer.\n    \"\"\"\n        if len(predictions) != len(actuals):\n            raise ValueError(\n                \"the shape of predictions and actuals does not match.\")\n        if n is not None:\n            if not isinstance(n, int) or n <= 0:\n                raise ValueError(\"n must be 'None' or a positive integer.\"\n                                 \" It was '%s'.\" % n)\n        ap = 0.0\n        predictions = numpy.array(predictions)\n        actuals = numpy.array(actuals)\n        # add a shuffler to avoid overestimating the ap\n        predictions, actuals = AveragePrecisionCalculator._shuffle(\n            predictions, actuals)\n        sortidx = sorted(range(len(predictions)),"
        },
        {
            "comment": "This code calculates the average precision of a classification task by first shuffling the predictions and actuals, then iterating through the sorted list to calculate the precision at each recall step. It handles cases where total_num_positives is given or automatically calculated.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":220-255",
            "content": "                         key=lambda k: predictions[k],\n                         reverse=True)\n        if total_num_positives is None:\n            numpos = numpy.size(numpy.where(actuals > 0))\n        else:\n            numpos = total_num_positives\n        if numpos == 0:\n            return 0\n        if n is not None:\n            numpos = min(numpos, n)\n        delta_recall = 1.0 / numpos\n        poscount = 0.0\n        # calculate the ap\n        r = len(sortidx)\n        if n is not None:\n            r = min(r, n)\n        for i in range(r):\n            if actuals[sortidx[i]] > 0:\n                poscount += 1\n                ap += poscount / (i + 1) * delta_recall\n        return ap\n    @staticmethod\n    def _shuffle(predictions, actuals):\n        random.seed(0)\n        suffidx = random.sample(range(len(predictions)), len(predictions))\n        predictions = predictions[suffidx]\n        actuals = actuals[suffidx]\n        return predictions, actuals\n    @staticmethod\n    def _zero_one_normalize(predictions, epsilon=1e-7):"
        },
        {
            "comment": "This function normalizes the predictions to a range of 0.0 to 1.0 by subtracting the minimum prediction and dividing by the maximum denominator (prediction difference) with an optional epsilon value to prevent division by zero.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py\":256-273",
            "content": "        \"\"\"Normalize the predictions to the range between 0.0 and 1.0.\n    For some predictions like SVM predictions, we need to normalize them before\n    calculate the interpolated average precision. The normalization will not\n    change the rank in the original list and thus won't change the average\n    precision.\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      epsilon: a small constant to avoid denominator being zero.\n    Returns:\n      The normalized prediction.\n    \"\"\"\n        denominator = numpy.max(predictions) - numpy.min(predictions)\n        ret = (predictions - numpy.min(predictions)) / numpy.max(\n            denominator, epsilon)\n        return ret"
        }
    ]
}