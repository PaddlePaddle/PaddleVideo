{
    "summary": "This code calculates BMN metric for object detection in computer vision frameworks, supports batch_size and world_size as 1, initializes class variables, processes video data, logs progress, saves results, performs soft NMS, calculates proposal lists, evaluates performance using the \"cal_metrics\" function.",
    "details": [
        {
            "comment": "This code imports necessary libraries and defines a function to compute the Intersection over Union (IoU) between a box and anchors. It appears to be related to object detection or proposal generation within a computer vision framework.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":0-31",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nimport os\nimport json\nimport numpy as np\nimport pandas as pd\nimport multiprocessing as mp\nfrom .registry import METRIC\nfrom .base import BaseMetric\nfrom .ActivityNet import ANETproposal\nfrom paddlevideo.utils import get_logger\nlogger = get_logger(\"paddlevideo\")\ndef iou_with_anchors(anchors_min, anchors_max, box_min, box_max):\n    \"\"\"Compute jaccard score between a box and the anchors.\n    \"\"\"\n    len_anchors = anchors_max - anchors_min\n    int_xmin = np.maximum(anchors_min, box_min)\n    int_xmax = np.minimum(anchors_max, box_max)"
        },
        {
            "comment": "inter_len calculates the intersection length between two bounding boxes. union_len computes the total length of both boxes and jaccard index is calculated by dividing inter_len with union_len. This function returns the Jaccard index.\nThe boundary_choose() function selects start and end boundaries based on a given score list. It identifies the highest score and creates three arrays - score_list, score_front, score_back for comparison. mask_peak is created by comparing these arrays, followed by generating a binary mask of True values.\nSoft_nms function sorts proposals generated by network based on scores in descending order. It takes alpha value (Gaussian decaying function), and two threshold values t1, t2.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":32-62",
            "content": "    inter_len = np.maximum(int_xmax - int_xmin, 0.)\n    union_len = len_anchors - inter_len + box_max - box_min\n    jaccard = np.divide(inter_len, union_len)\n    return jaccard\ndef boundary_choose(score_list):\n    \"\"\"Choose start and end boundary from score.\n    \"\"\"\n    max_score = max(score_list)\n    mask_high = (score_list > max_score * 0.5)\n    score_list = list(score_list)\n    score_middle = np.array([0.0] + score_list + [0.0])\n    score_front = np.array([0.0, 0.0] + score_list)\n    score_back = np.array(score_list + [0.0, 0.0])\n    mask_peak = ((score_middle > score_front) & (score_middle > score_back))\n    mask_peak = mask_peak[1:-1]\n    mask = (mask_high | mask_peak).astype('float32')\n    return mask\ndef soft_nms(df, alpha, t1, t2):\n    '''\n    df: proposals generated by network;\n    alpha: alpha value of Gaussian decaying function;\n    t1, t2: threshold for soft nms.\n    '''\n    df = df.sort_values(by=\"score\", ascending=False)\n    tstart = list(df.xmin.values[:])\n    tend = list(df.xmax.values[:])\n    tscore = list(df.score.values[:])"
        },
        {
            "comment": "The code calculates BMN metric for object detection by iterating through a list of scores and appending the maximum score, along with its corresponding start and end positions, to new lists. It then creates a new DataFrame using these lists before returning it as the final output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":64-97",
            "content": "    rstart = []\n    rend = []\n    rscore = []\n    while len(tscore) > 1 and len(rscore) < 101:\n        max_index = tscore.index(max(tscore))\n        tmp_iou_list = iou_with_anchors(np.array(tstart), np.array(tend),\n                                        tstart[max_index], tend[max_index])\n        for idx in range(0, len(tscore)):\n            if idx != max_index:\n                tmp_iou = tmp_iou_list[idx]\n                tmp_width = tend[max_index] - tstart[max_index]\n                if tmp_iou > t1 + (t2 - t1) * tmp_width:\n                    tscore[idx] = tscore[idx] * np.exp(\n                        -np.square(tmp_iou) / alpha)\n        rstart.append(tstart[max_index])\n        rend.append(tend[max_index])\n        rscore.append(tscore[max_index])\n        tstart.pop(max_index)\n        tend.pop(max_index)\n        tscore.pop(max_index)\n    newDf = pd.DataFrame()\n    newDf['score'] = rscore\n    newDf['xmin'] = rstart\n    newDf['xmax'] = rend\n    return newDf\n@METRIC.register\nclass BMNMetric(BaseMetric):\n    \"\"\"\n    Metrics for BMN. Two Stages in this metric:"
        },
        {
            "comment": "This code initializes an instance of BMNMetric class with various parameters such as data_size, batch_size, tscale, dscale, file_path, ground_truth_filename, subset, output_path, result_path, get_metrics, and log_interval. It also performs assertions to ensure batch_size is 1 and world_size is 1, as the code currently supports only these conditions. The class is a part of PaddleVideo library for video analysis tasks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":98-126",
            "content": "    (1) Get test results using trained model, results will be saved in BMNMetric.result_path;\n    (2) Calculate metrics using results file from stage (1).\n    \"\"\"\n    def __init__(self,\n                 data_size,\n                 batch_size,\n                 tscale,\n                 dscale,\n                 file_path,\n                 ground_truth_filename,\n                 subset,\n                 output_path,\n                 result_path,\n                 get_metrics=True,\n                 log_interval=1):\n        \"\"\"\n        Init for BMN metrics.\n        Params:\n            get_metrics: whether to calculate AR@N and AUC metrics or not, default True.\n        \"\"\"\n        super().__init__(data_size, batch_size, log_interval)\n        assert self.batch_size == 1, \" Now we just support batch_size==1 test\"\n        assert self.world_size == 1, \" Now we just support single-card test\"\n        self.tscale = tscale\n        self.dscale = dscale\n        self.file_path = file_path\n        self.ground_truth_filename = ground_truth_filename"
        },
        {
            "comment": "The code initializes the class variables and checks if the output and result directories exist, creating them if not. It then calls a method to get the dataset dictionary and list based on the provided file path and subset. The update method takes batch ID, data, and outputs as inputs to update metrics during each iteration.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":127-155",
            "content": "        self.subset = subset\n        self.output_path = output_path\n        self.result_path = result_path\n        self.get_metrics = get_metrics\n        if not os.path.isdir(self.output_path):\n            os.makedirs(self.output_path)\n        if not os.path.isdir(self.result_path):\n            os.makedirs(self.result_path)\n        self.video_dict, self.video_list = self.get_dataset_dict(\n            self.file_path, self.subset)\n    def get_dataset_dict(self, file_path, subset):\n        annos = json.load(open(file_path))\n        video_dict = {}\n        for video_name in annos.keys():\n            video_subset = annos[video_name][\"subset\"]\n            if subset in video_subset:\n                video_dict[video_name] = annos[video_name]\n        video_list = list(video_dict.keys())\n        video_list.sort()\n        return video_dict, video_list\n    def update(self, batch_id, data, outputs):\n        \"\"\"update metrics during each iter\n        \"\"\"\n        fid = data[4].numpy()\n        pred_bm, pred_start, pred_end = outputs"
        },
        {
            "comment": "Code snippet performs boundary detection and creates a score vector list for each detection. It uses the provided prediction, start and end values to calculate the xmin and xmax values within the defined time scale. Then it checks if the start and end mask conditions are met and adds the corresponding score value to the score vector list. This information is used for further analysis or evaluation of video frames.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":156-181",
            "content": "        pred_bm = pred_bm.numpy()\n        pred_start = pred_start[0].numpy()\n        pred_end = pred_end[0].numpy()\n        snippet_xmins = [1.0 / self.tscale * i for i in range(self.tscale)]\n        snippet_xmaxs = [\n            1.0 / self.tscale * i for i in range(1, self.tscale + 1)\n        ]\n        cols = [\"xmin\", \"xmax\", \"score\"]\n        video_name = self.video_list[fid[0]]\n        pred_bm = pred_bm[0, 0, :, :] * pred_bm[0, 1, :, :]\n        start_mask = boundary_choose(pred_start)\n        start_mask[0] = 1.\n        end_mask = boundary_choose(pred_end)\n        end_mask[-1] = 1.\n        score_vector_list = []\n        for idx in range(self.dscale):\n            for jdx in range(self.tscale):\n                start_index = jdx\n                end_index = start_index + idx\n                if end_index < self.tscale and start_mask[\n                        start_index] == 1 and end_mask[end_index] == 1:\n                    xmin = snippet_xmins[start_index]\n                    xmax = snippet_xmaxs[end_index]\n                    xmin_score = pred_start[start_index]"
        },
        {
            "comment": "This code snippet performs post-processing on video data and calculates metrics. It first processes the video data, then accumulates the metrics for each batch during processing. The code uses numpy arrays to handle score vectors, Pandas DataFrame to store and manipulate data, and logging to provide progress updates. The results are saved in a CSV file at the specified output path.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":182-205",
            "content": "                    xmax_score = pred_end[end_index]\n                    bm_score = pred_bm[idx, jdx]\n                    conf_score = xmin_score * xmax_score * bm_score\n                    score_vector_list.append([xmin, xmax, conf_score])\n        score_vector_list = np.stack(score_vector_list)\n        video_df = pd.DataFrame(score_vector_list, columns=cols)\n        video_df.to_csv(os.path.join(self.output_path, \"%s.csv\" % video_name),\n                        index=False)\n        if batch_id % self.log_interval == 0:\n            logger.info(\"Processing................ batch {}\".format(batch_id))\n    def accumulate(self):\n        \"\"\"accumulate metrics when finished all iters.\n        \"\"\"\n        # check clip index of each video\n        #Stage1\n        self.bmn_post_processing(self.video_dict, self.subset, self.output_path,\n                                 self.result_path)\n        if self.get_metrics:\n            logger.info(\"[TEST] calculate metrics...\")\n            #Stage2\n            uniform_average_nr_proposals_valid, uniform_average_recall_valid, uniform_recall_valid = self.cal_metrics("
        },
        {
            "comment": "This code is initializing a bmn_post_processing function that will process multiple videos in parallel using multiple processes. It creates a result dictionary and divides the video list into equal parts to assign each part to a separate process. It also logs the average recall at different thresholds for different numbers of detections.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":206-228",
            "content": "                self.ground_truth_filename,\n                os.path.join(self.result_path, \"bmn_results_validation.json\"),\n                max_avg_nr_proposals=100,\n                tiou_thresholds=np.linspace(0.5, 0.95, 10),\n                subset='validation')\n            logger.info(\"AR@1; AR@5; AR@10; AR@100\")\n            logger.info(\"%.02f %.02f %.02f %.02f\" %\n                        (100 * np.mean(uniform_recall_valid[:, 0]),\n                         100 * np.mean(uniform_recall_valid[:, 4]),\n                         100 * np.mean(uniform_recall_valid[:, 9]),\n                         100 * np.mean(uniform_recall_valid[:, -1])))\n    def bmn_post_processing(self, video_dict, subset, output_path, result_path):\n        video_list = list(video_dict.keys())\n        global result_dict\n        result_dict = mp.Manager().dict()\n        pp_num = 12\n        num_videos = len(video_list)\n        num_videos_per_thread = int(num_videos / pp_num)\n        processes = []\n        for tid in range(pp_num - 1):\n            tmp_video_list = video_list[tid * num_videos_per_thread:(tid + 1) *"
        },
        {
            "comment": "The code creates multiple processes to handle video processing tasks in parallel, using multiprocessing. It then joins all the results together into a single output dictionary before writing it to a JSON file. This approach allows for efficient and concurrent processing of large numbers of videos.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":229-255",
            "content": "                                        num_videos_per_thread]\n            p = mp.Process(target=self.video_process,\n                           args=(tmp_video_list, video_dict, output_path,\n                                 result_dict))\n            p.start()\n            processes.append(p)\n        tmp_video_list = video_list[(pp_num - 1) * num_videos_per_thread:]\n        p = mp.Process(target=self.video_process,\n                       args=(tmp_video_list, video_dict, output_path,\n                             result_dict))\n        p.start()\n        processes.append(p)\n        for p in processes:\n            p.join()\n        result_dict = dict(result_dict)\n        output_dict = {\n            \"version\": \"VERSION 1.3\",\n            \"results\": result_dict,\n            \"external_data\": {}\n        }\n        outfile = open(\n            os.path.join(result_path, \"bmn_results_%s.json\" % subset), \"w\")\n        # json.dump(output_dict, outfile)\n        # in case of file name in chinese\n        json.dump(output_dict, outfile, ensure_ascii=False)"
        },
        {
            "comment": "This function takes a list of video names, corresponding metadata dictionaries, output path, and result dictionary. It processes each video by reading its CSV file, performs soft NMS if the dataframe has more than one row, calculates proposal list for each video, and appends them to the result dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":256-281",
            "content": "        outfile.close()\n    def video_process(self,\n                      video_list,\n                      video_dict,\n                      output_path,\n                      result_dict,\n                      snms_alpha=0.4,\n                      snms_t1=0.55,\n                      snms_t2=0.9):\n        for video_name in video_list:\n            logger.info(\"Processing video........\" + video_name)\n            df = pd.read_csv(os.path.join(output_path, video_name + \".csv\"))\n            if len(df) > 1:\n                df = soft_nms(df, snms_alpha, snms_t1, snms_t2)\n            video_duration = video_dict[video_name][\"duration_second\"]\n            proposal_list = []\n            for idx in range(min(100, len(df))):\n                tmp_prop={\"score\":df.score.values[idx], \\\n                          \"segment\":[max(0,df.xmin.values[idx])*video_duration, \\\n                                     min(1,df.xmax.values[idx])*video_duration]}\n                proposal_list.append(tmp_prop)\n            video_name = video_name[2:] if video_name[:2] == 'v_' else video_name"
        },
        {
            "comment": "The code defines a function \"cal_metrics\" that takes in ground truth and proposal filenames, calculates the average recall, average proposals per video, and overall recall using ANETproposal class. This function is used to evaluate performance based on given thresholds and subsets of data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/metrics/bmn_metric.py\":282-303",
            "content": "            result_dict[video_name] = proposal_list\n    def cal_metrics(self,\n                    ground_truth_filename,\n                    proposal_filename,\n                    max_avg_nr_proposals=100,\n                    tiou_thresholds=np.linspace(0.5, 0.95, 10),\n                    subset='validation'):\n        anet_proposal = ANETproposal(ground_truth_filename,\n                                     proposal_filename,\n                                     tiou_thresholds=tiou_thresholds,\n                                     max_avg_nr_proposals=max_avg_nr_proposals,\n                                     subset=subset,\n                                     verbose=True,\n                                     check_status=False)\n        anet_proposal.evaluate()\n        recall = anet_proposal.recall\n        average_recall = anet_proposal.avg_recall\n        average_nr_proposals = anet_proposal.proposals_per_video\n        return (average_nr_proposals, average_recall, recall)"
        }
    ]
}