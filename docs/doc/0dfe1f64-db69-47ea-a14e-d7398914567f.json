{
    "summary": "This code develops a PaddlePaddle 2.1 video quality assessment model using ppTSM network on KonVid-150k dataset, supports multigpu distributed training and evaluation, and references two papers for improved user experience and SROCC/PLCC scores.",
    "details": [
        {
            "comment": "This code is for a video quality assessment model developed using PaddlePaddle 2.1. It uses the ppTSM network and is trained on KonVid-150k dataset, which contains 153842 UGC videos. The model can analyze video content to determine its quality, improve video previews, and enhance user experience. Requires specific environment setup and dependencies like Python 3.7, CUDA 10.1, and cuDNN 7.6.4.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/README.md\":0-57",
            "content": "# \u89c6\u9891\u8d28\u91cf\u8bc4\u4ef7\u6a21\u578b\n---\n## \u5185\u5bb9\n- [\u6a21\u578b\u7b80\u4ecb](#\u6a21\u578b\u7b80\u4ecb)\n- [\u6570\u636e\u51c6\u5907](#\u6570\u636e\u51c6\u5907)\n- [\u6a21\u578b\u8bad\u7ec3](#\u6a21\u578b\u8bad\u7ec3)\n- [\u6a21\u578b\u6d4b\u8bd5](#\u6a21\u578b\u6d4b\u8bd5)\n- [\u6a21\u578b\u4f18\u5316](#\u6a21\u578b\u4f18\u5316)\n- [\u6a21\u578b\u90e8\u7f72](#\u6a21\u578b\u90e8\u7f72)\n- [\u53c2\u8003\u8bba\u6587](#\u53c2\u8003\u8bba\u6587)\n## \u6a21\u578b\u7b80\u4ecb\n\u8be5\u4ee3\u7801\u5e93\u4e3b\u8981\u57fa\u4e8epaddle2.1\u7248\u672c\u5f00\u53d1\uff0c\u4e3b\u8981\u662f\u5728ppTSM\u7f51\u7edc\u6a21\u578b\u7684\u57fa\u7840\u4e0a\u4fee\u6539\u7684\u4e00\u79cd\u65e0\u53c2\u8003\u89c6\u9891\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bfb\u5165\u89c6\u9891\u7684\u89c6\u9891\u5e27\u6765\u5224\u65ad\u8be5\u89c6\u9891\u7684\u8d28\u91cf\u3002\n\u9488\u5bf9\u89c6\u9891\u5185\u5bb9\u7684\u7406\u89e3\uff0c\u53ef\u4ee5\u81ea\u52a8\u5206\u6790\u89c6\u9891\u5185\u5bb9\u7684\u8d28\u91cf\uff0c\u5e2e\u52a9\u9009\u51fa\u6700\u4f18\u7684\u5173\u952e\u5e27\u6216\u5173\u952e\u7247\u6bb5\u4f5c\u4e3a\u89c6\u9891\u5c01\u9762\uff0c\u63d0\u5347\u89c6\u9891\u7684\u70b9\u51fb\u8f6c\u6362\u548c\u7528\u6237\u4f53\u9a8c\u3002\n\u672c\u9879\u76ee\u76ee\u524d\u652f\u6301Linux\u4e0b\u7684GPU\u5355\u5361\u548c\u591a\u5361\u8fd0\u884c\u73af\u5883\u3002\n## \u6570\u636e\u51c6\u5907\n```\n\u6570\u636e\u96c6\u6765\u81ea\u516c\u5f00\u6570\u636e\u96c6KonVid-150k\uff0c\u5171153842\u4e2augc\u89c6\u9891\uff0c\u5176\u4e2d\u8bad\u7ec3\u96c6(KonVid-150k-A)152265\u4e2a\uff0c\u9a8c\u8bc1\u96c6(KonVid-150k-B)1577\u4e2a\n\u793a\u4f8b\u6570\u636e\u96c6\u4ee5\u53ca\u6570\u636e\u96c6\u5b98\u7f51\u5730\u5740: datasets/dataset_url.list\n\u6570\u636e\u96c6\u6807\u6ce8\u6587\u4ef6\u4e3adataset\u4e2d\u7684train.txt\u548ceval.txt\n```\n## \u6a21\u578b\u8bad\u7ec3\n\u73af\u5883\u5b89\u88c5\uff1a\n- PaddlePaddle >= 2.1.0\n- Python >= 3.7\n- PaddleX >= 2.0.0\n- CUDA >= 10.1\n- cuDNN >= 7.6.4\n- nccl >= 2.1.2\n\u5b89\u88c5Python\u4f9d\u8d56\u5e93\uff1a\nPython\u4f9d\u8d56\u5e93\u5728[requirements.txt](https://github.com/PaddlePaddle/PaddleVideo/blob/master/requirements.txt)\u4e2d\u7ed9\u51fa\uff0c\u53ef\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u5b89\u88c5\uff1a\n```\npython3.7 -m pip install --upgrade pip\npip3.7 install --upgrade -r requirements.txt\n```\n\u4f7f\u7528`paddle.distributed.launch`\u542f\u52a8\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u811a\u672c\uff08`main.py`\uff09\uff0c\u53ef\u4ee5\u66f4\u65b9\u4fbf\u5730\u542f\u52a8\u591a\u5361\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\uff0c\u6216\u76f4\u63a5\u8fd0\u884c(./run.sh)\n```shell\nsh run.sh\n```\n\u6211\u4eec\u5c06\u6240\u6709\u6807\u51c6\u7684\u542f\u52a8\u547d\u4ee4\u90fd\u653e\u5728\u4e86```run.sh```\u4e2d\uff0c\u6ce8\u610f\u9009\u62e9\u60f3\u8981\u8fd0\u884c\u7684\u811a\u672c\u3002\n\u53c2\u8003\u5982\u4e0b\u65b9\u5f0f\u542f\u52a8\u6a21\u578b\u8bad\u7ec3\uff0c`paddle.distributed.launch`\u901a\u8fc7\u8bbe\u7f6e`gpus`\u6307\u5b9aGPU\u8fd0\u884c\u5361\u53f7\uff0c"
        },
        {
            "comment": "This code is running PaddleVideo's multigpu distributed training in launch mode. It specifies the GPU devices to use, sets up the log directory, and uses AMP for mixed precision training. The `--validate` flag starts the evaluation during training and allows for updating configurations using the `-o` parameter. It also prints various metrics like loss, learning rate, batch cost, reader cost, and instances per second during train and eval phases.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/README.md\":58-97",
            "content": "\u6307\u5b9a`--validate`\u6765\u542f\u52a8\u8bad\u7ec3\u65f6\u8bc4\u4f30\u3002\n```bash\n# PaddleVideo\u901a\u8fc7launch\u65b9\u5f0f\u542f\u52a8\u591a\u5361\u591a\u8fdb\u7a0b\u8bad\u7ec3\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npython3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    --log_dir=log_pptsm \\\n    main.py \\\n    --amp \\\n    --validate \\\n    -c ./configs/recognition/tsm/pptsm_regression.yaml\n```\n\u5176\u4e2d\uff0c`-c`\u7528\u4e8e\u6307\u5b9a\u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\uff0c\u53ef\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u4fee\u6539\u76f8\u5173\u8bad\u7ec3\u914d\u7f6e\u4fe1\u606f\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6dfb\u52a0`-o`\u53c2\u6570\u6765\u66f4\u65b0\u914d\u7f6e\uff1a\n```bash\npython -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    -c ./configs/recognition/tsm/pptsm_regression.yaml \\\n    --validate \\\n    -o DATASET.batch_size=16\n```\n`-o`\u7528\u4e8e\u6307\u5b9a\u9700\u8981\u4fee\u6539\u6216\u8005\u6dfb\u52a0\u7684\u53c2\u6570\uff0c\u5176\u4e2d`-o DATASET.batch_size=16`\u8868\u793a\u66f4\u6539batch_size\u5927\u5c0f\u4e3a16\u3002\n\u8fd0\u884c\u4e0a\u8ff0\u547d\u4ee4\uff0c\u5c06\u4f1a\u8f93\u51fa\u8fd0\u884c\u65e5\u5fd7\uff0c\u5e76\u9ed8\u8ba4\u4fdd\u5b58\u5728./log\u76ee\u5f55\u4e0b\uff0c\u5982\uff1a`worker.0` , `worker.1` ... , worker\u65e5\u5fd7\u6587\u4ef6\u5bf9\u5e94\u6bcf\u5f20\u5361\u4e0a\u7684\u8f93\u51fa\n\u3010train\u9636\u6bb5\u3011\u6253\u5370\u5f53\u524d\u65f6\u95f4\uff0c\u5f53\u524depoch/epoch\u603b\u6570\uff0c\u5f53\u524dbatch id\uff0c\u8bc4\u4f30\u6307\u6807\uff0c\u8017\u65f6\uff0cips\u7b49\u4fe1\u606f\uff1a\n    [11/16 04:40:37] epoch:[  1/1  ] train step:100  loss: 5.31382 lr: 0.000250 batch_cost: 0.73082 sec, reader_cost: 0.38075 sec, ips: 5.47330 instance/sec.\n\u3010eval\u9636\u6bb5\u3011\u6253\u5370\u5f53\u524d\u65f6\u95f4\uff0c\u5f53\u524depoch/epoch\u603b\u6570\uff0c\u5f53\u524dbatch id\uff0c\u8bc4\u4f30\u6307\u6807\uff0c\u8017\u65f6\uff0cips\u7b49\u4fe1\u606f\uff1a\n    [11/16 04:40:37] epoch:[  1/1  ] val step:0    loss: 4.42741 batch_cost: 1.37882 sec, reader_cost: 0.00000 sec, ips: 2.90104 instance/sec."
        },
        {
            "comment": "Epoch completion: Prints current time, learning rate, evaluation metrics, training duration, and instances per second.\nBest epoch detection: Prints best precision achieved during training.\nResuming training: Loads checkpoint weights to continue training from a specified epoch.\nModel fine-tuning: Loads pre-trained model for custom dataset fine-tuning.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/README.md\":100-143",
            "content": "\u3010epoch\u7ed3\u675f\u3011\u6253\u5370\u5f53\u524d\u65f6\u95f4\uff0c\u5b66\u4e60\u7387\uff0c\u8bc4\u4f30\u6307\u6807\uff0c\u8017\u65f6\uff0cips\u7b49\u4fe1\u606f\uff1a\n    [11/16 04:40:37] lr=0.00012487\n    [11/16 04:40:37] train_SROCC=0.4456697876616565\n    [11/16 04:40:37] train_PLCC=0.48071880604403616\n    [11/16 04:40:37] END epoch:1   val loss_avg: 5.21620 avg_batch_cost: 0.04321 sec, avg_reader_cost: 0.00000 sec, batch_cost_sum: 112.69575 sec, avg_ips: 8.41203 instance/sec.\n\u5f53\u524d\u4e3a\u8bc4\u4f30\u7ed3\u679c\u6700\u597d\u7684epoch\u65f6\uff0c\u6253\u5370\u6700\u4f18\u7cbe\u5ea6\uff1a\n    [11/16 04:40:57] max_SROCC=0.7116468111328617\n    [11/16 04:40:57] max_PLCC=0.733503995526737\n### \u6a21\u578b\u6062\u590d\u8bad\u7ec3\n\u5982\u679c\u8bad\u7ec3\u4efb\u52a1\u7ec8\u6b62\uff0c\u53ef\u4ee5\u52a0\u8f7d\u65ad\u70b9\u6743\u91cd\u6587\u4ef6(\u4f18\u5316\u5668-\u5b66\u4e60\u7387\u53c2\u6570\uff0c\u65ad\u70b9\u6587\u4ef6)\u7ee7\u7eed\u8bad\u7ec3\u3002\n\u9700\u8981\u6307\u5b9a`-o resume_epoch`\u53c2\u6570\uff0c\u8be5\u53c2\u6570\u8868\u793a\u4ece```resume_epoch```\u8f6e\u5f00\u59cb\u7ee7\u7eed\u8bad\u7ec3.\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npython3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    --amp \\\n    -c ./configs/recognition/tsm/pptsm_regression.yaml \\\n    --validate \\\n    -o resume_epoch=5\n```\n### \u6a21\u578b\u5fae\u8c03\n\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\uff08Finetune\uff09\uff0c\u5bf9\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\uff0c\u9700\u8981\u6307\u5b9a `--weights` \u53c2\u6570\u6765\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u3002\n```bash\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npython3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    --amp \\\n    -c ./configs/recognition/tsm/pptsm_regression.yaml \\"
        },
        {
            "comment": "The code is launching PaddleVideo application for video quality assessment. It uses the TSM model with regression and loads the best trained weights from \"./output/model_name/ppTSM_best.pdparams\". The --test flag is used to run the model in test mode. The code also suggests optimizing strategies like using original input instead of RandomCrop, changing input size for better performance, and considering aspect ratios of 16:9 and 4:3 for improved results.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/README.md\":144-178",
            "content": "    --validate \\\n    --weights=./output/model_name/ppTSM_best.pdparams\n```\nPaddleVideo\u4f1a\u81ea\u52a8**\u4e0d\u52a0\u8f7d**shape\u4e0d\u5339\u914d\u7684\u53c2\u6570\n## \u6a21\u578b\u6d4b\u8bd5\n\u9700\u8981\u6307\u5b9a `--test`\u6765\u542f\u52a8\u6d4b\u8bd5\u6a21\u5f0f\uff0c\u5e76\u6307\u5b9a`--weights`\u6765\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u3002\n```bash\npython3 -m paddle.distributed.launch \\\n    --gpus=\"0,1,2,3\" \\\n    main.py \\\n    -c ./configs/recognition/tsm/pptsm_regression.yaml \\\n    --test \\\n    --weights=./output/model_name/ppTSM_best.pdparams\n```\n## \u6a21\u578b\u4f18\u5316\n\u5728\u5b9e\u9645\u4f7f\u7528\u573a\u666f\u4e2d\u53ef\u6839\u636e\u89c6\u9891\u8d28\u91cf\u4ee5\u53ca\u5c3a\u5bf8\u5c1d\u8bd5\u4f18\u5316\u7b56\u7565\n- \u53ef\u901a\u8fc7\u539f\u56fe\u8f93\u5165\u6765\u66ff\u6362RandomCrop:224\u64cd\u4f5c\uff0c\u51c6\u786e\u7387\u7531SROCC=0.8176,PLCC=0.8361\u63d0\u5347\u5230SROCC=0.8617,PLCC=0.8910,\u4e0d\u540c\u6a21\u578b\u4ee5\u53ca\u7279\u5f81\u589e\u5f3a\u64cd\u4f5c\u7684\u6548\u679c\u5bf9\u6bd4\u5982\u4e0b\u8868\u6240\u793a\n  |  \u6a21\u578b  |                  \u7279\u5f81\u589e\u5f3a                   | val_SROCC | val_PLCC |\n  | :----: | :-----------------------------------------: | :-------: | :------: |\n  | GSTVQA |                  \u539f\u56fe\u8f93\u5165                   |  0.7932   |  0.8006  |\n  | ppTSM  | train--RandomCrop=224  val--center_crop=224 |  0.8176   |  0.8361  |\n  | ppTSM  | train--RandomCrop=512  val--center_crop=512 |  0.8603   |  0.8822  |\n  | ppTSM  |                  \u539f\u56fe\u8f93\u5165                   |  0.8617   |  0.8910  |\n- \u8003\u8651\u5e94\u7528\u573a\u666f\u89c6\u9891\u7684 aspect ratio \u5927\u90fd\u4e3a 16\uff1a9 \u548c 4\uff1a3 \u7b49\uff0c\u540c\u65f6\u4e3a\u4e86\u907f\u514d\u975e\u5747\u5300\u7f29\u653e\u62c9\u4f38\u5e26\u6765\u7684\u5e72\u6270 \uff0c\u53ef\u4ee5\u91c7\u7528\u4e86\uff08224x3\uff09x(224x2)=672x448 \u7684\u8f93\u5165\u5c3a\u5bf8\u6765\u66f4\u5145\u5206\u5f97\u5229\u7528\u6709\u9650\u7684\u8f93\u5165\u5c3a\u5bf8\u3002 "
        },
        {
            "comment": "This code provides a solution for video quality assessment with SROCC and PLCC scores on official validation dataset. It references two papers: TSM: Temporal Shift Module for Efficient Video Understanding and Quality Assessment of In-the-Wild Videos.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/README.md\":180-188",
            "content": "## \u6a21\u578b\u90e8\u7f72\n\u672c\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\u5728\u5b98\u65b9\u9a8c\u8bc1\u96c6(KonVid-150k-B)\u4e0a\u7684\u6307\u6807\u6548\u679c\u4e3aSROCC=0.8176,PLCC=0.8361\u3002\n## \u53c2\u8003\u8bba\u6587\n- [TSM: Temporal Shift Module for Efficient Video Understanding](https://arxiv.org/pdf/1811.08383.pdf), Ji Lin, Chuang Gan, Song Han\n- [Quality Assessment of In-the-Wild Videos](https://dl.acm.org/citation.cfm?doid=3343031.3351028), Dingquan Li, Tingting Jiang, and Ming Jiang"
        }
    ]
}