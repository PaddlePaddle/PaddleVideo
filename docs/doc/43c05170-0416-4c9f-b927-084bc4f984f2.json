{
    "summary": "The code documents a SlowFast_FasterRCNN model for action detection tasks, providing installation and processing instructions. It trains and tests the model with PaddleDetection and exports it for inference, using GPU acceleration and disabling TensorRT optimization.",
    "details": [
        {
            "comment": "This code provides documentation for the SlowFast_FasterRCNN model, a high-precision video model used for action detection tasks. It takes human detection results and video frames as input, uses the SlowFast model to extract spatiotemporal features, and employs FasterRCNN's head to obtain the actions and positions of humans in the frame. Users need to install additional dependencies before getting started.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md\":0-23",
            "content": "[\u7b80\u4f53\u4e2d\u6587](../../../zh-CN/model_zoo/detection/SlowFast_FasterRCNN.md) | English\n# SlowFast_FasterRCNN\n## Contents\n- [Introduction](#Introduction)\n- [Data](#Data)\n- [Train](#Train)\n- [Test](#Test)\n- [Inference](#Inference)\nBefore getting started, you need to install additional dependencies as follows:\n```bash\npython -m pip install moviepy\npython -m pip install et_xmlfile\npython -m pip install paddledet\n```\n## Introduction\nThe [SlowFast](https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/model_zoo/recognition/slowfast.md) model is one of the high-precision models in the video field. For action detection task, it is also neccessary to detect the person in current frame. Therefore, the SlowFast_FasterRCNN model takes human detection results and video frames as input, extracts spatiotemporal features through the SlowFast model, and then uses FasterRCNN's head gets the actions and positions of humans in the frame.\nThe corresponding AI Studio Notebook Link\uff1a[\u57fa\u4e8eSlowFast+FasterRCNN\u7684\u52a8\u4f5c\u8bc6\u522b](https://aistudio.baidu.com/aistudio/projectdetail/3267637?contributionType=1)"
        },
        {
            "comment": "The provided code is a set of instructions for downloading videos, annotations, and proposals as well as cutting videos and extracting frames from the AVA dataset. This dataset contains 430 videos annotated in 1 second intervals for action detection using SlowFast Networks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md\":25-63",
            "content": "For details, please refer to the paper [SlowFast Networks for Video Recognition](https://arxiv.org/pdf/1812.03982.pdf).\n## Data\nWe use [AVA dataset](https://research.google.com/ava/download.html) for action detection. The AVA v2.2 dataset contains 430 videos split into 235 for training, 64 for validation, and 131 for test. Each video has 15 minutes annotated in 1 second intervals.\n### 1 Dowload Videos\n```\nbash  download_videos.sh\n```\n### 2 Download Annotations\n```\nbash  download_annotations.sh\n```\n### 3 Download Proposals\n```\nbash  fetch_ava_proposals.sh\n```\n### 4 Cut Videos\n```\nbash  cut_videos.sh\n```\n### 5 Extract Frames\n```\nbash  extract_rgb_frames.sh\n```\nFor AVA v2.1, there is a simple introduction to some key files\uff1a\n* 'ava_videos_15min_frames' dir stores video frames extracted with FPS as the frame rate\uff1b\n* 'ava_train_v2.1.csv' file stores the trainning annotations\uff1b\n* 'ava_train_excluded_timestamps_v2.1.csv' file stores excluded timestamps\uff1b\n* 'ava_dense_proposals_train.FAIR.recall_93.9.pkl' file stores humans' bboxes and scores of key frames\uff1b"
        },
        {
            "comment": "This code describes the training and testing procedures for a SlowFast model using Faster RCNN on AVA dataset. The training process requires a config file, pre-trained model weights, and evaluates the model during training with the --validate flag. Testing is done based on the best model provided with specifications like architecture, depth, pretrain model, frame length, sample rate, MAP, AVA version, and a link to the trained model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md\":64-89",
            "content": "* 'ava_action_list_v2.1_for_activitynet_2018.pbtxt' file stores\u4e3a action list.\n## Train\n* `-c`: config file path;\n* `-w`: weights of model. The pretrained model can be downloaded from the table below;\n* `--validate`: evaluate model during training.\n```\nexport CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\npython -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\" --log_dir=logdir.ava main.py --validate -w paddle.init_param.pdparams -c configs/detection/ava/ava.yaml\n```\n## Test\nTest model based on the best model:\n```\npython main.py --test \\\n   -w output/AVA_SlowFast_FastRcnn/AVA_SlowFast_FastRcnn_best.pdparams \\\n   -c configs/detection/ava/ava.yaml\n```\n| architecture | depth | Pretrain Model |  frame length x sample rate  | MAP | AVA version | model |\n| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |------------- |\n| SlowFast | R50 | [Kinetics 400](https://videotag.bj.bcebos.com/PaddleVideo/SlowFast/SlowFast_8*8.pdparams) | 8 x 8 | 23.2 | 2.1 | [`link`](https://videotag.bj.bcebos.com/PaddleVideo-release2.2/SlowFastRCNN_AVA.pdparams) |"
        },
        {
            "comment": "In this code, the inference process is outlined for an action detection project using SlowFast+FasterRCNN model. It requires installing PaddleDetection and downloading a detection model from provided URL. The \"export_model\" script prepares the model for inference, while the \"predict.py\" script performs inference based on the exported model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md\":92-125",
            "content": "## Inference\nThe action detection of this project is divided into two stages. In the first stage, humans' proposals are obtained, and then input into the SlowFast+FasterRCNN model for action recognition.\nFor human detection\uff0cyou can use the trained model in [PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection).\nInstall PaddleDetection:\n```\ncd PaddleDetection/\npip install -r requirements.txt\n!python setup.py install\n```\nDownload detection model:\n```\n# faster_rcnn_r50_fpn_1x_coco as an example\nwget https://paddledet.bj.bcebos.com/models/faster_rcnn_r50_fpn_1x_coco.pdparams\n```\nexport model:\n```\npython tools/export_model.py \\\n  -c configs/detection/ava/ava.yaml \\\n  -o inference_output \\\n  -p output/AVA_SlowFast_FastRcnn/AVA_SlowFast_FastRcnn_best.pdparams\n```\ninference based on the exported model:\n```\npython tools/predict.py \\\n    -c configs/detection/ava/ava.yaml \\\n    --input_file \"data/-IELREHXDEMO.mp4\" \\\n    --model_file \"inference_output/AVA_SlowFast_FastRcnn.pdmodel\" \\\n    --params_file \"inference_output/AVA_SlowFast_FastRcnn.pdiparams\" \\"
        },
        {
            "comment": "The code sets `use_gpu` to True and `use_tensorrt` to False. This means the model will use GPU acceleration and not utilize TensorRT for optimizing performance.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md\":126-128",
            "content": "    --use_gpu=True \\\n    --use_tensorrt=False\n```"
        }
    ]
}