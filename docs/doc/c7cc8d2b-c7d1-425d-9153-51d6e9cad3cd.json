{
    "summary": "The MultigridSchedule class manages multigrid training schedules, batch sizes, sampling rates, and long cycle updates. The update_long_cycle() function adjusts these parameters based on the epoch in PaddleVideo. It also calculates final learning rate schedules and provides a function for determining long cycle base shape.",
    "details": [
        {
            "comment": "This code defines a MultigridSchedule class for multigrid training schedule and updates cfg according to multigrid settings. The init_multigrid function takes in configs (cfg) as input, updates it based on multigrid settings, and returns the updated cfg. It stores original values of batch size, temporal size, and crop size in cfg's MULTIGRID subsection as global variables for later use.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":0-24",
            "content": "\"\"\"Functions for multigrid training.\"\"\"\nimport numpy as np\nclass MultigridSchedule(object):\n    \"\"\"\n    This class defines multigrid training schedule and update cfg accordingly.\n    \"\"\"\n    def init_multigrid(self, cfg):\n        \"\"\"\n        Update cfg based on multigrid settings.\n        Args:\n            cfg (configs): configs that contains training and multigrid specific\n                hyperparameters.\n        Returns:\n            cfg (configs): the updated cfg.\n        \"\"\"\n        self.schedule = None\n        # We may modify cfg.DATASET.batch_size, cfg.PIPELINE.train.decode_sampler.num_frames, and\n        # cfg.PIPELINE.train.transform[1]['MultiCrop']['target_size'] during training, so we store their original\n        # value in cfg and use them as global variables.\n        cfg.MULTIGRID.default_batch_size = cfg.DATASET.batch_size  # total bs,64\n        cfg.MULTIGRID.default_temporal_size = cfg.PIPELINE.train.decode_sampler.num_frames  # 32\n        cfg.MULTIGRID.default_crop_size = cfg.PIPELINE.train.transform[1]["
        },
        {
            "comment": "The code initializes the multi-grid training schedule for the given configuration (cfg). If a long cycle is enabled, it sets learning rate steps and adjusts them for fine-tuning. It also updates the maximum epoch count based on the schedule.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":25-49",
            "content": "            'MultiCrop']['target_size']  # 224\n        if cfg.MULTIGRID.LONG_CYCLE:\n            self.schedule = self.get_long_cycle_schedule(cfg)\n            cfg.OPTIMIZER.learning_rate.steps = [0] + [\n                s[-1] for s in self.schedule\n            ]\n            # Fine-tuning phase.\n            cfg.OPTIMIZER.learning_rate.steps[-1] = (\n                cfg.OPTIMIZER.learning_rate.steps[-2] +\n                cfg.OPTIMIZER.learning_rate.steps[-1]) // 2\n            cfg.OPTIMIZER.learning_rate.lrs = [\n                cfg.OPTIMIZER.learning_rate.gamma**s[0] * s[1][0]\n                for s in self.schedule\n            ]\n            # Fine-tuning phase.\n            cfg.OPTIMIZER.learning_rate.lrs = cfg.OPTIMIZER.learning_rate.lrs[:-1] + [\n                cfg.OPTIMIZER.learning_rate.lrs[-2],\n                cfg.OPTIMIZER.learning_rate.lrs[-1],\n            ]\n            cfg.OPTIMIZER.learning_rate.max_epoch = self.schedule[-1][-1]\n        elif cfg.MULTIGRID.SHORT_CYCLE:\n            cfg.OPTIMIZER.learning_rate.steps = ["
        },
        {
            "comment": "This function, update_long_cycle(), checks if the long cycle shape should change before every epoch. If it should, it updates cfg accordingly. It takes in configs (cfg) and current epoch index (cur_epoch), and returns the updated cfg and a boolean indicating whether the long cycle shape changed. The function also retrieves the base_b, base_t, and base_s using get_current_long_cycle_shape(). If these values differ from the target size or number of frames in the cfg, it implies that the long cycle shape should change.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":50-73",
            "content": "                int(s * cfg.MULTIGRID.epoch_factor)\n                for s in cfg.OPTIMIZER.learning_rate.steps\n            ]\n            cfg.OPTIMIZER.learning_rate.max_epoch = int(\n                cfg.OPTIMIZER.learning_rate.max_epoch *\n                cfg.OPTIMIZER.learning_rate.max_epoch)\n        return cfg\n    def update_long_cycle(self, cfg, cur_epoch):\n        \"\"\"\n        Before every epoch, check if long cycle shape should change. If it\n            should, update cfg accordingly.\n        Args:\n            cfg (configs): configs that contains training and multigrid specific\n                hyperparameters.\n            cur_epoch (int): current epoch index.\n        Returns:\n            cfg (configs): the updated cfg.\n            changed (bool): whether to change long cycle shape at this epoch\n        \"\"\"\n        base_b, base_t, base_s = get_current_long_cycle_shape(\n            self.schedule, cur_epoch)\n        if base_s != cfg.PIPELINE.train.transform[1]['MultiCrop'][\n                'target_size'] or base_t != cfg.PIPELINE.train.decode_sampler.num_frames:"
        },
        {
            "comment": "This code sets the number of frames and crop size for the head and transform, adjusts batch size based on multigrid configuration, determines whether to use \"batchnorm\" or \"sub_batchnorm\", and sets the long cycle sampling rate. The output is a message stating if long cycle updates are enabled.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":74-93",
            "content": "            #NOTE Modify\n            # no need to modify, used by pool_size in head, None when multigrid\n            # cfg.MODEL.head.num_frames = base_t\n            # cfg.MODEL.head.crop_size  = base_s\n            cfg.PIPELINE.train.decode_sampler.num_frames = base_t\n            cfg.PIPELINE.train.transform[1]['MultiCrop']['target_size'] = base_s\n            cfg.DATASET.batch_size = base_b * cfg.MULTIGRID.default_batch_size  #change bs\n            bs_factor = (float(cfg.DATASET.batch_size) /\n                         cfg.MULTIGRID.bn_base_size)\n            if bs_factor == 1:  #single bs == bn_base_size (== 8)\n                cfg.MODEL.backbone.bn_norm_type = \"batchnorm\"\n            else:\n                cfg.MODEL.backbone.bn_norm_type = \"sub_batchnorm\"\n                cfg.MODEL.backbone.bn_num_splits = int(bs_factor)\n            cfg.MULTIGRID.long_cycle_sampling_rate = cfg.PIPELINE.train.decode_sampler.sampling_rate * (\n                cfg.MULTIGRID.default_temporal_size // base_t)\n            print(\"Long cycle updates:\")"
        },
        {
            "comment": "The code is a function that checks the configuration for certain parameters related to multigrid training. It prints specific values and returns two values: a boolean indicating if the long cycle schedule should be used, and the original config unchanged.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":94-114",
            "content": "            print(\"\\tbn_norm_type: {}\".format(cfg.MODEL.backbone.bn_norm_type))\n            if cfg.MODEL.backbone.bn_norm_type == \"sub_batchnorm\":\n                print(\"\\tbn_num_splits: {}\".format(\n                    cfg.MODEL.backbone.bn_num_splits))\n            print(\"\\tTRAIN.batch_size[single card]: {}\".format(\n                cfg.DATASET.batch_size))\n            print(\"\\tDATA.NUM_FRAMES x LONG_CYCLE_SAMPLING_RATE: {}x{}\".format(\n                cfg.PIPELINE.train.decode_sampler.num_frames,\n                cfg.MULTIGRID.long_cycle_sampling_rate))\n            print(\"\\tDATA.train_crop_size: {}\".format(\n                cfg.PIPELINE.train.transform[1]['MultiCrop']['target_size']))\n            return cfg, True\n        else:\n            return cfg, False\n    def get_long_cycle_schedule(self, cfg):\n        \"\"\"\n        Based on multigrid hyperparameters, define the schedule of a long cycle.\n        Args:\n            cfg (configs): configs that contains training and multigrid specific\n                hyperparameters."
        },
        {
            "comment": "This code calculates the schedule for multi-grid training, iterating over long cycle factor pairs in `cfg.MULTIGRID.long_cycle_factors`. It determines base shapes for each cycle, calculating `base_t` based on `cfg.PIPELINE.train.decode_sampler.num_frames` and `t_factor`, and `base_s` based on target size from `cfg.PIPELINE.train.transform[1]['MultiCrop']['target_size']` and `s_factor`. It also considers short cycle training flag, `cfg.MULTIGRID.SHORT_CYCLE`.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":115-140",
            "content": "        Returns:\n            schedule (list): Specifies a list long cycle base shapes and their\n                corresponding training epochs.\n        \"\"\"\n        steps = cfg.OPTIMIZER.learning_rate.steps\n        default_size = float(\n            cfg.PIPELINE.train.decode_sampler.num_frames *\n            cfg.PIPELINE.train.transform[1]['MultiCrop']['target_size']**\n            2)  # 32 * 224 * 224  C*H*W\n        default_iters = steps[-1]  # 196\n        # Get shapes and average batch size for each long cycle shape.\n        avg_bs = []\n        all_shapes = []\n        #        for t_factor, s_factor in cfg.MULTIGRID.long_cycle_factors:\n        for item in cfg.MULTIGRID.long_cycle_factors:\n            t_factor, s_factor = item[\"value\"]\n            base_t = int(\n                round(cfg.PIPELINE.train.decode_sampler.num_frames * t_factor))\n            base_s = int(\n                round(\n                    cfg.PIPELINE.train.transform[1]['MultiCrop']['target_size']\n                    * s_factor))\n            if cfg.MULTIGRID.SHORT_CYCLE:"
        },
        {
            "comment": "This code defines the multigrid training schedule for PaddleVideo. It sets the shapes for different grid levels, converts them to batch sizes, and calculates the average batch size. The code then computes the total number of iterations and generates the multigrid training schedule based on the steps provided.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":141-168",
            "content": "                shapes = [\n                    [\n                        base_t,\n                        cfg.MULTIGRID.default_crop_size *\n                        cfg.MULTIGRID.short_cycle_factors[0],\n                    ],\n                    [\n                        base_t,\n                        cfg.MULTIGRID.default_crop_size *\n                        cfg.MULTIGRID.short_cycle_factors[1],\n                    ],\n                    [base_t, base_s],\n                ]  #first two is short_cycle, last is the base long_cycle\n            else:\n                shapes = [[base_t, base_s]]\n            # (T, S) -> (B, T, S)\n            shapes = [[\n                int(round(default_size / (s[0] * s[1] * s[1]))), s[0], s[1]\n            ] for s in shapes]\n            avg_bs.append(np.mean([s[0] for s in shapes]))\n            all_shapes.append(shapes)\n        # Get schedule regardless of cfg.MULTIGRID.epoch_factor.\n        total_iters = 0\n        schedule = []\n        for step_index in range(len(steps) - 1):\n            step_epochs = steps[step_index + 1] - steps[step_index]"
        },
        {
            "comment": "This code calculates the number of iterations for each sequence based on average batch sizes, and then appends the schedule with corresponding step index, shape, and epochs. It also ensures that the fine-tuning phase has the same number of iterations as the rest of the training.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":170-190",
            "content": "            for long_cycle_index, shapes in enumerate(all_shapes):\n                #ensure each of 4 sequences run the same num of iters\n                cur_epochs = (step_epochs * avg_bs[long_cycle_index] /\n                              sum(avg_bs))\n                # get cur_iters from cur_epochs\n                cur_iters = cur_epochs / avg_bs[long_cycle_index]\n                total_iters += cur_iters\n                schedule.append((step_index, shapes[-1], cur_epochs))\n        iter_saving = default_iters / total_iters  # ratio between default iters and real iters\n        final_step_epochs = cfg.OPTIMIZER.learning_rate.max_epoch - steps[-1]\n        # We define the fine-tuning phase to have the same amount of iteration\n        # saving as the rest of the training.\n        #final_step_epochs / iter_saving make fine-tune having the same iters as training\n        ft_epochs = final_step_epochs / iter_saving * avg_bs[-1]\n        #        schedule.append((step_index + 1, all_shapes[-1][2], ft_epochs))\n        schedule.append((step_index + 1, all_shapes[-1][-1], ft_epochs))"
        },
        {
            "comment": "This code calculates the final learning rate schedule for multigrid training based on a provided schedule, max_epoch, and epoch_factor. It then prints this new schedule. The function get_current_long_cycle_shape takes in this same schedule and current epoch index to return the long cycle base shape for the given epoch.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":192-223",
            "content": "        # Obtrain final schedule given desired cfg.MULTIGRID.epoch_factor.\n        x = (cfg.OPTIMIZER.learning_rate.max_epoch *\n             cfg.MULTIGRID.epoch_factor / sum(s[-1] for s in schedule))\n        final_schedule = []\n        total_epochs = 0\n        for s in schedule:\n            epochs = s[2] * x\n            total_epochs += epochs\n            final_schedule.append((s[0], s[1], int(round(total_epochs))))\n        print_schedule(final_schedule)\n        return final_schedule\ndef print_schedule(schedule):\n    \"\"\"\n    Log schedule.\n    \"\"\"\n    print(\n        \"Long_cycle_index\\tBase_shape(bs_factor,temporal_size,crop_size)\\tEpochs\"\n    )\n    for s in schedule:\n        print(\"{}\\t\\t\\t{}\\t\\t\\t\\t\\t{}\".format(s[0], s[1], s[2]))\ndef get_current_long_cycle_shape(schedule, epoch):\n    \"\"\"\n    Given a schedule and epoch index, return the long cycle base shape.\n    Args:\n        schedule (configs): configs that contains training and multigrid specific\n            hyperparameters.\n        cur_epoch (int): current epoch index."
        },
        {
            "comment": "This function returns a list describing the base shape in a long cycle based on the current epoch and a given schedule. It iterates through the schedule, returning the appropriate shape if the current epoch is less than the scheduled value, otherwise it returns the last shape in the schedule.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/multigrid.py\":224-232",
            "content": "    Returns:\n        shapes (list): A list describing the base shape in a long cycle:\n            [batch size relative to default,\n            number of frames, spatial dimension].\n    \"\"\"\n    for s in schedule:\n        if epoch < s[-1]:\n            return s[1]\n    return schedule[-1][1]"
        }
    ]
}