{
    "summary": "This code presents PP-TSM, an optimized TSM model for action recognition on UCF101 and Kinetics-400 datasets using PaddlePaddle and ResNet101 as backbone. It offers pre-trained models for video classification inference and predicts 'archery' as top1 class for 'example.avi'.",
    "details": [
        {
            "comment": "This code describes the PP-TSM model, an optimized version of TSM for action recognition. It significantly improves accuracy in UCF101 and Kinetics-400 datasets without increasing parameters. Two sampling methods are used, Dense and Uniform, with respective top1 accuracies shown.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/pp-tsm.md\":0-30",
            "content": "[\u7b80\u4f53\u4e2d\u6587](../../../zh-CN/model_zoo/recognition/pp-tsm.md) | English\n# PP-TSM\n---\n## Contents\n- [Introduction](#Introduction)\n- [Data](#Data)\n- [Train](#Train)\n- [Test](#Test)\n- [Inference](#Inference)\n- [Reference](#Reference)\n## Introduction\nWe optimized TSM model and proposed **PP-TSM** in this repo. Without increasing the number of parameters, the accuracy of TSM was significantly improved in UCF101 and Kinetics-400 datasets. Please refer to [**Tricks on PP-TSM**](https://zhuanlan.zhihu.com/p/382134297) for more details.\n| Version | Sampling method | Top1 |\n| :------ | :----------: | :----: |\n| Ours (distill) | Dense | **76.16** |\n| Ours | Dense | 75.69 |\n| [mmaction2](https://github.com/open-mmlab/mmaction2/blob/master/configs/recognition/tsm/README.md) | Dense | 74.55 |\n| [mit-han-lab](https://github.com/mit-han-lab/temporal-shift-module) | Dense | 74.1 |\n| Version | Sampling method | Top1 |\n| :------ | :----------: | :----: |\n| Ours (distill) | Uniform | **75.11** |\n| Ours | Uniform | 74.54 |\n| [mmaction"
        },
        {
            "comment": "Code snippet provides a guide for training TSM model on Kinetics-400 and UCF101 datasets. It explains how to download the pre-trained ResNet50_vd_ssld_v2 model, specifies the configuration file modification required, and provides links to related data preparation documents.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/pp-tsm.md\":30-63",
            "content": "2](https://github.com/open-mmlab/mmaction2/blob/master/configs/recognition/tsm/README.md) |  Uniform | 71.90 |\n| [mit-han-lab](https://github.com/mit-han-lab/temporal-shift-module)  | Uniform | 71.16 |\n## Data\nPlease refer to Kinetics400 data download and preparation doc [k400-data](../../dataset/K400.md)\nPlease refer to UCF101 data download and preparation doc [ucf101-data](../../dataset/ucf101.md)\n## Train\n### Train on kinetics-400\n#### download pretrain-model\nPlease download [ResNet50_vd_ssld_v2](https://videotag.bj.bcebos.com/PaddleVideo/PretrainModel/ResNet50_vd_ssld_v2_pretrained.pdparams) as pretraind model:\n```bash\nwget https://videotag.bj.bcebos.com/PaddleVideo/PretrainModel/ResNet50_vd_ssld_v2_pretrained.pdparams\n```\nand add path to `MODEL.framework.backbone.pretrained` in config file as\uff1a\n```yaml\nMODEL:\n    framework: \"Recognizer2D\"\n    backbone:\n        name: \"ResNetTweaksTSM\"\n        pretrained: your weight path\n```\n- If use ResNet101 as backbone, please download [ResNet101_vd_ssld_pretrained."
        },
        {
            "comment": "Loading pretrained model \"pdparams\" from the provided link.\nStarting training for PP-TSM on kinetics-400 using specified scripts and configurations.\nUsing AMP to speed up training.\nTraining with dense sampling also available.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/pp-tsm.md\":63-89",
            "content": "pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.2/ResNet101_vd_ssld_pretrained.pdparams) as pretraind model.\n#### Start training\n- Train PP-TSM on kinetics-400 scripts:\n```bash\npython3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsm  main.py  --validate -c configs/recognition/pptsm/pptsm_k400_frames_uniform.yaml\n```\n- Train PP-TSM on kinetics-400 video data using scripts:\n```bash\npython3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsm  main.py  --validate -c configs/recognition/pptsm/pptsm_k400_videos_uniform.yaml\n```\n- AMP is useful for speeding up training:\n```bash\nexport FLAGS_conv_workspace_size_limit=800 #MB\nexport FLAGS_cudnn_exhaustive_search=1\nexport FLAGS_cudnn_batchnorm_spatial_persistent=1\npython3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsm  main.py  --amp --validate -c configs/recognition/pptsm/pptsm_k400_frames_uniform.yaml\n```\n- Train PP-TSM on kinetics-400 with dense sampling:"
        },
        {
            "comment": "This code is used to train and test the PP-TSM model on Kinetics-400 dataset. The training process utilizes PaddlePaddle distributed launch, with GPUs 0-7 for execution. It uses ResNet101 as backbone and dense sampling method for training. To obtain test accuracy, a separate script is used, specifying the configuration file and weight file path. The code also displays accuracy metrics in terms of backbone, distillation, sampling method, number of segments, target size, and top-1 accuracy for the Kinetics400 dataset.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/pp-tsm.md\":91-121",
            "content": "```bash\npython3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsm  main.py  --validate -c configs/recognition/pptsm/pptsm_k400_frames_dense.yaml\n```\n- Train PP-TSM on kinetics-400 with ResNet101 as backbone using dense sampling:\n```bash\npython3.7 -B -m paddle.distributed.launch --gpus=\"0,1,2,3,4,5,6,7\"  --log_dir=log_pptsm  main.py  --validate -c configs/recognition/pptsm/pptsm_k400_frames_dense_r101.yaml\n```\n## Test\n- For uniform sampling, test accuracy can be found in training-logs by search key word `best`, such as:\n```txt\nAlready save the best model (top1 acc)0.7454\n```\n- For dense sampling, test accuracy can be obtained using scripts:\n```bash\npython3 main.py --test -c configs/recognition/pptsm/pptsm_k400_frames_dense.yaml -w output/ppTSM/ppTSM_best.pdparams\n```\nAccuracy on Kinetics400:\n| backbone | distill | Sampling method | num_seg | target_size | Top-1 | checkpoints |\n| :------: | :----------: | :----: | :----: | :----: | :----: | :---- |\n| ResNet50 | False | Uniform"
        },
        {
            "comment": "This code is a table of pre-trained models for PaddlePaddle Temporal Shift Module (ppTSM) with different configurations. Models are based on ResNet50 and ResNet101 architectures, using both uniform and dense distillation methods. They have different parameters, input sizes, and accuracy levels. The pdparams files are the pre-trained model weights available for download from specified URLs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/pp-tsm.md\":121-126",
            "content": " | 8 | 224 | 74.54 | [ppTSM_k400_uniform.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.1/PPTSM/ppTSM_k400_uniform.pdparams) |\n| ResNet50 | False | Dense | 8 | 224 | 75.69 | [ppTSM_k400_dense.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.1/PPTSM/ppTSM_k400_dense.pdparams) |\n| ResNet50 | True | Uniform | 8 | 224 | 75.11 | [ppTSM_k400_uniform_distill.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.1/PPTSM/ppTSM_k400_uniform_distill.pdparams) |\n| ResNet50 | True | Dense | 8 | 224 | 76.16 | [ppTSM_k400_dense_distill.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.1/PPTSM/ppTSM_k400_dense_distill.pdparams) |\n| ResNet101 | True | Uniform | 8 | 224 | 76.35 | [ppTSM_k400_uniform_distill_r101.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.2/ppTSM_k400_uniform_distill_r101.pdparams) |\n| ResNet101 | False | Dense | 8 | 224 | 77.15 | [ppTSM_k400_dense_r101.pdparams](https://videotag.bj.bcebos.com/PaddleVideo-release2.2/ppTSM_k400_dense_r101.pdparams) |"
        },
        {
            "comment": "This code exports the PPTSM model for inference and demonstrates how to use it for video classification. It requires the user to run two commands: one to export the model architecture file (ppTSM.pdmodel) and parameters file (ppTSM.pdiparams), and another to use the model for prediction on a video file (example.avi). The predicted output includes the top-1 class and its corresponding score.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/pp-tsm.md\":128-158",
            "content": "## Inference\n### export inference model\n To get model architecture file `ppTSM.pdmodel` and parameters file `ppTSM.pdiparams`, use:\n```bash\npython3.7 tools/export_model.py -c configs/recognition/pptsm/pptsm_k400_frames_uniform.yaml \\\n                                -p data/ppTSM_k400_uniform.pdparams \\\n                                -o inference/ppTSM\n```\n- Args usage please refer to [Model Inference](https://github.com/PaddlePaddle/PaddleVideo/blob/release/2.0/docs/zh-CN/start.md#2-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86).\n### infer\n```bash\npython3.7 tools/predict.py --input_file data/example.avi \\\n                           --config configs/recognition/pptsm/pptsm_k400_frames_uniform.yaml \\\n                           --model_file inference/ppTSM/ppTSM.pdmodel \\\n                           --params_file inference/ppTSM/ppTSM.pdiparams \\\n                           --use_gpu=True \\\n                           --use_tensorrt=False\n```\nexample of logs:\n```\nCurrent video file: data/example.avi\n\ttop-1 class: 5\n\ttop-1 score: 0.9907386302947998"
        },
        {
            "comment": "The code retrieves the class name from class id and a map file, then shows that the top1 prediction of 'data/example.avi' is 'archery'.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/model_zoo/recognition/pp-tsm.md\":159-166",
            "content": "```\nwe can get the class name using class id and map file `data/k400/Kinetics-400_label_list.txt`. The top1 prediction of `data/example.avi` is `archery`.\n## Reference\n- [TSM: Temporal Shift Module for Efficient Video Understanding](https://arxiv.org/pdf/1811.08383.pdf), Ji Lin, Chuang Gan, Song Han\n- [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531), Geoffrey Hinton, Oriol Vinyals, Jeff Dean"
        }
    ]
}