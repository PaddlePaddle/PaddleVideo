{
    "summary": "YouTube-8M is a large video classification dataset containing over 8 million URLs and covers more than 3800 knowledge graph entities. The code splits the pkl files into smaller files for easier processing.",
    "details": [
        {
            "comment": "English | [\u7b80\u4f53\u4e2d\u6587](../../zh-CN/dataset/youtube8m.md)\n# YouTube-8M Data Preparation\n- [Introduction](#Introduction)\n- [Download](#Download)\n- [Conversion](#Conversion)\n## Introduction\nYouTube-8M is a large-scale video classification data set, containing more than 8 million video URLs. The tag system covers more than 3800 knowledge graph entities. One video corresponds to multiple tags (3-4 on average) and is labeled by machine.\n**The length of each video is between 120s and 500s\nDue to the large amount of video data, the image classification model was used to extract frame-level features in advance, and PCA was used to reduce the dimensionality of the features to obtain multi-frame 1024-dimensional features. Similarly, the audio model was used to obtain multi-frame 128-dimensional features. Audio characteristics. **\n> The dataset used here is the updated YouTube-8M data set in 2018 (May 2018 version (current): 6.1M videos, 3862 classes, 3.0 labels/video, 2.6B audio-visual features).\n## Download\n1. Create a new directory for storing features (take the PaddleVideo directory as an example)",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/dataset/youtube8m.md\":0-19",
            "content": "English | [\u7b80\u4f53\u4e2d\u6587](../../zh-CN/dataset/youtube8m.md)\n# YouTube-8M Data Preparation\n- [Introduction](#Introduction)\n- [Download](#Download)\n- [Conversion](#Conversion)\n## Introduction\nYouTube-8M is a large-scale video classification data set, containing more than 8 million video URLs. The tag system covers more than 3800 knowledge graph entities. One video corresponds to multiple tags (3-4 on average) and is labeled by machine.\n**The length of each video is between 120s and 500s\nDue to the large amount of video data, the image classification model was used to extract frame-level features in advance, and PCA was used to reduce the dimensionality of the features to obtain multi-frame 1024-dimensional features. Similarly, the audio model was used to obtain multi-frame 128-dimensional features. Audio characteristics. **\n> The dataset used here is the updated YouTube-8M data set in 2018 (May 2018 version (current): 6.1M videos, 3862 classes, 3.0 labels/video, 2.6B audio-visual features).\n## Download\n1. Create a new directory for storing features (take the PaddleVideo directory as an example)"
        },
        {
            "comment": "Creates a frame directory, downloads the training and validation sets to it using curl, installs TensorFlow for reading TFRecord data, then converts the TFRecord files to pickle format for PaddlePaddle usage.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/dataset/youtube8m.md\":20-43",
            "content": "    ```bash\n    cd data/yt8m\n    mkdir frame\n    cd frame\n    ```\n2. Download the training and validation set to the frame folder\n    ```bash\n    curl data.yt8m.org/download.py | partition=2/frame/train mirror=asia python\n    curl data.yt8m.org/download.py | partition=2/frame/validate mirror=asia python\n    ```\n    The download process is shown in the figure\n    ![image](https://user-images.githubusercontent.com/23737287/140709613-1e2d6ec0-a82e-474d-b220-7803065b0153.png)\n    After the data download is complete, you will get 3844 training data files and 3844 verification data files (TFRecord format)\n## Conversion\n1. Install tensorflow to read tfrecord data\n    ```bash\n    python3.7 -m pip install tensorflow-gpu==1.14.0\n    ```\n2. Convert the downloaded TFRecord file into a pickle file for PaddlePaddle to use\n    ```bash\n    cd .. # From the frame directory back to the yt8m directory\n    python3.7 tf2pkl.py ./frame ./pkl_frame/ # Convert train*.tfrecord and validate*.tfrecord in the frame folder to pkl format"
        },
        {
            "comment": "This code generates a single pkl file path set and splits the pkl files into smaller files based on given file lists. It first writes the paths of \"train*.pkl\" and \"validate*.pkl\" to \"train.list\" and \"val.list\" respectively. Then, it uses the \"split_yt8m.py\" script to split each \"train*.pkl\" into multiple \"train*_split*.pkl\" files and each \"validate*.pkl\" into multiple \"validate*_split*.pkl\" files. Finally, it rewrites the paths of the smaller pkl files back into \"train.list\" and \"val.list\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/english_documents/dataset/youtube8m.md\":44-55",
            "content": "    ```\n3. Generate a single pkl file path set, and split pkl into multiple small pkl files based on this file, and generate the final split pkl file path required\n    ```bash\n    ls pkl_frame/train*.pkl> train.list # Write the path of train*.pkl to train.list\n    ls pkl_frame/validate*.pkl> val.list # Write the path of validate*.pkl into val.list\n    python3.7 split_yt8m.py train.list # Split each train*.pkl into multiple train*_split*.pkl\n    python3.7 split_yt8m.py val.list # Split each validate*.pkl into multiple validate*_split*.pkl\n    ls pkl_frame/train*_split*.pkl> train.list # Rewrite the path of train*_split*.pkl into train.list\n    ls pkl_frame/validate*_split*.pkl> val.list # Rewrite the path of validate*_split*.pkl into val.list\n    ``` "
        }
    ]
}