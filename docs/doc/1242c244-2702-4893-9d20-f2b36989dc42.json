{
    "summary": "The script prepares PaddleVideo's UR FALL dataset keypoints, normalizing them and handling inconsistencies for training. It also prepares a dataset for PPHuman, reading annotations, extracting data, and saving for training.",
    "details": [
        {
            "comment": "This script converts keypoint results of UR FALL dataset into a format suitable for training by PaddleVideo. It normalizes keypoints using bounding boxes and adjusts the shape to be compatible with the PaddleVideo framework. The function also handles cases where the number of frames is more or less than 100.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/datasets/prepare_dataset.py\":0-33",
            "content": "import os\nimport json\nimport numpy as np\nimport pickle\n\"\"\"\n This python script is used to convert keypoint results of UR FALL dataset\n   for training by PaddleVideo\n\"\"\"\ndef self_norm(kpt, bbox):\n    # kpt: (2, T, 17, 1),  bbox: (T, 4)\n    tl = bbox[:, 0:2]\n    wh = bbox[:, 2:]\n    tl = np.expand_dims(np.transpose(tl, (1, 0)), (2, 3))\n    wh = np.expand_dims(np.transpose(wh, (1, 0)), (2, 3))\n    res = (kpt - tl) / wh\n    res *= np.expand_dims(np.array([[384.], [512.]]), (2, 3))\n    return res\ndef convert_to_ppvideo(all_kpts, all_scores, all_bbox):\n    # shape of all_kpts is (T, 17, 2)\n    keypoint = np.expand_dims(np.transpose(all_kpts, [2, 0, 1]),\n                              -1)  #(2, T, 17, 1)\n    keypoint = self_norm(keypoint, all_bbox)\n    scores = all_scores\n    if keypoint.shape[1] > 100:\n        frame_start = (keypoint.shape[1] - 100) // 2\n        keypoint = keypoint[:, frame_start:frame_start + 100:2, :, :]\n        scores = all_scores[frame_start:frame_start + 100:2, :, :]\n    elif keypoint.shape[1] < 100:"
        },
        {
            "comment": "The function `prepare_dataset` receives keypoint and scores as inputs. If the length of either is not divisible by 2, it pads them with zeros to maintain consistency. The else block simply takes every other value in both arrays. The `decode_json_path` function loads a JSON file, sorts its contents, extracts bounding boxes, keypoints, and scores from each entry, ignoring cases where there is more than one bounding box, and appends the processed data to separate lists for further processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/datasets/prepare_dataset.py\":34-68",
            "content": "        keypoint = np.concatenate([\n            keypoint,\n            np.zeros((2, 100 - keypoint.shape[1], 17, 1), dtype=keypoint.dtype)\n        ], 1)[:, ::2, :, :]\n        scores = np.concatenate([\n            all_scores,\n            np.zeros((100 - all_scores.shape[0], 17, 1), dtype=keypoint.dtype)\n        ], 0)[::2, :, :]\n    else:\n        keypoint = keypoint[:, ::2, :, :]\n        scores = scores[::2, :, :]\n    return keypoint, scores\ndef decode_json_path(json_path):\n    content = json.load(open(json_path))\n    content = sorted(content, key=lambda x: x[0])\n    all_kpts = []\n    all_score = []\n    all_bbox = []\n    for annos in content:\n        bboxes = annos[1]\n        kpts = annos[2][0]\n        frame_id = annos[0]\n        if len(bboxes) != 1:\n            continue\n        kpt_res = []\n        kpt_score = []\n        for kpt in kpts[0]:\n            x, y, score = kpt\n            kpt_res.append([x, y])\n            kpt_score.append([score])\n        all_kpts.append(np.array(kpt_res))\n        all_score.append(np.array(kpt_score))"
        },
        {
            "comment": "This code prepares a dataset for PaddleVideo's PPHuman application. It reads annotations from \"annotations\" folder, extracts keypoints, labels, and scores, then saves them into numpy arrays and pickle file for training.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/datasets/prepare_dataset.py\":69-97",
            "content": "        all_bbox.append([\n            bboxes[0][0], bboxes[0][1], bboxes[0][2] - bboxes[0][0],\n            bboxes[0][3] - bboxes[0][1]\n        ])\n    all_kpts_np = np.array(all_kpts)\n    all_score_np = np.array(all_score)\n    all_bbox_np = np.array(all_bbox)\n    video_anno, scores = convert_to_ppvideo(all_kpts_np, all_score_np,\n                                            all_bbox_np)\n    return video_anno, scores\nif __name__ == '__main__':\n    all_keypoints = []\n    all_labels = [[], []]\n    all_scores = []\n    for i, path in enumerate(os.listdir(\"annotations\")):\n        video_anno, score = decode_json_path(os.path.join(\"annotations\", path))\n        all_keypoints.append(video_anno)\n        all_labels[0].append(str(i))\n        all_labels[1].append(0)  #label 0 means falling\n        all_scores.append(score)\n    all_data = np.stack(all_keypoints, 0)\n    all_score_data = np.stack(all_scores, 0)\n    np.save(f\"train_data.npy\", all_data)\n    pickle.dump(all_labels, open(f\"train_label.pkl\", \"wb\"))\n    np.save(\"kptscore_data.npy\", all_score_data)"
        }
    ]
}