{
    "summary": "This function ensures state dict consistency by comparing optimizer and model parameters, saving/loading checkpoints, and converting sub-bn to normal bn. It checks if certain layers are set to load and prints a message for unloaded weights before loading pre-trained weights and setting the optimizer's state dictionary.",
    "details": [
        {
            "comment": "This function converts Sub-BN parameters to normal BN parameters in a state dict. It renames `bn.bn` to `bn`, and modifies `_mean` and `_variance` accordingly. This is done before saving or evaluation to maintain consistency with normal BN layers. The modifications are made by iterating through the dictionary and checking if the key ends with the appropriate string, then updating it accordingly.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":0-30",
            "content": "import os\nimport numpy as np\nimport paddle\nimport copy\ndef sub_to_normal_bn(sd):\n    \"\"\"\n    When save, Convert the Sub-BN paprameters to normal BN parameters in a state dict.\n    There are two copies of BN layers in a Sub-BN implementation: `bn.bn` and\n    `bn.split_bn`. `bn.split_bn` is used during training and\n    \"compute_precise_bn\". Before saving or evaluation, its stats are copied to\n    `bn.bn`. We rename `bn.bn` to `bn` and store it to be consistent with normal\n    BN layers.\n    Args:\n        sd (OrderedDict): a dict of parameters which might contain Sub-BN\n        parameters.\n    Returns:\n        new_sd (OrderedDict): a dict with Sub-BN parameters reshaped to\n        normal parameters.\n    \"\"\"\n    modifications = [\n        (\"bn.bn._mean\", \"bn._mean\"),\n        (\"bn.bn._variance\", \"bn._variance\"),\n    ]\n    to_remove = [\"bn.bn.\", \".split_bn.\"]\n    key_list = list(sd.keys())  #odict_keys to list\n    for key in key_list:\n        for before, after in modifications:\n            if key.endswith(before):\n                new_key = key.split(before)[0] + after"
        },
        {
            "comment": "This function converts BN parameters to Sub-BN parameters when loading a checkpoint into a model containing Sub-BNs. It loops through the model's parameters, if a parameter has the \"bn.split_bn.\" prefix and is not the weight or bias of BN, it renames and moves the corresponding value from the checkpoint dict to the bn.bn key in the same subdict. Finally, it adjusts the shape of the Sub-BN parameters to match the original BN parameters' shape.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":31-57",
            "content": "                sd[new_key] = sd.pop(key)\n        for rm in to_remove:\n            if rm in key and key in sd:\n                del sd[key]\ndef normal_to_sub_bn(checkpoint_sd, model_sd):\n    \"\"\"\n    When load, Convert BN parameters to Sub-BN parameters if model contains Sub-BNs.\n    Args:\n        checkpoint_sd (OrderedDict): source dict of parameters.\n        model_sd (OrderedDict): target dict of parameters.\n    Returns:\n        new_sd (OrderedDict): converted dict of parameters.\n    \"\"\"\n    for key in model_sd:\n        if key not in checkpoint_sd:\n            # not to replace bn.weight and bn.bias\n            if \"bn.split_bn.\" in key and \"bn.weight\" not in key and \"bn.bias\" not in key:\n                load_key = key.replace(\"bn.split_bn.\", \"bn.\")\n                bn_key = key.replace(\"bn.split_bn.\", \"bn.bn.\")\n                checkpoint_sd[key] = checkpoint_sd.pop(load_key)\n                checkpoint_sd[bn_key] = checkpoint_sd[key]\n    # match the shape of bn.split_bn._xx\n    # model_sd: split_bn.rm.shape = num_feature*num_split"
        },
        {
            "comment": "This code is comparing the shape of certain keys in the model and checkpoint dictionaries. If they match certain criteria, it will concatenate the checkpoint key to expand its size based on the model's shape. This is done for specific keys in the dictionary, except 'split_bn'. The function prints out the before and after shapes of the affected keys.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":58-80",
            "content": "    # checkpoint_sd: split_bn.rm.shape = bn.rm.shape = num_feature\n    for key in model_sd:\n        if key in checkpoint_sd:\n            model_blob_shape = model_sd[key].shape  #bn.split_bn\n            c2_blob_shape = checkpoint_sd[key].shape  #bn.bn\n            if (len(model_blob_shape) == 1 and len(c2_blob_shape) == 1\n                    and model_blob_shape[0] > c2_blob_shape[0]\n                    and model_blob_shape[0] % c2_blob_shape[0] == 0):\n                before_shape = checkpoint_sd[key].shape\n                checkpoint_sd[key] = np.concatenate(\n                    [checkpoint_sd[key]] *\n                    (model_blob_shape[0] // c2_blob_shape[0]))\n                if 'split_bn' not in key:  #split_bn is excepted\n                    print(\"{} {} -> {}\".format(key, before_shape,\n                                               checkpoint_sd[key].shape))\n    return checkpoint_sd\ndef mapping_opt_dict(opt_dict, model_key_list):\n    \"\"\"\n    Paddle Name schedule: conv_1.w -> conv_2.w\n    Sometimes: sub_bn -> bn"
        },
        {
            "comment": "This function takes an optimizer state dict and a list of parameter names from a rebuilt model. It aims to modify the keys in the optimizer state dict to match the new parameters' names, while also considering any added index for better compatibility. The function then returns the modified optimizer state dict.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":81-102",
            "content": "    when re-build model, we desire the parameter name to be coincident,\n    but the parameters name index will be added, as conv_1 to conv_2, not conv_1.\n    It will raise error if we set old saved parameters to new created optimizer.\n    as conv_2 cannot find in state_dict(only conv_1).\n    Args:\n        opt_dict: optimizer state dict, including the name and value of parameters gradient.\n        model_key_list: the parameters name list of re-build model.\n    Return: optimizer state dict with modified keys\n    \"\"\"\n    def get_name_info(PNAME, PN_key_list, key_list):\n        min_index = float('inf')\n        max_index = 0\n        for name in PN_key_list[1:]:\n            for key in key_list:\n                if name in key:\n                    index = int(key.split('.')[0].split(name)[-1])\n                    if index < min_index:\n                        min_index = index\n                    if index > max_index:\n                        max_index = index\n            num_name = max_index - min_index + 1\n            PNAME[name].append((min_index, max_index, num_name))"
        },
        {
            "comment": "This code appears to be a part of a larger program that compares the parameters in an optimizer state dict with those in a re-built model. It calculates and prints information about the number of parameters associated with each prefix, checks if batch normalization layers need their names changed, and potentially removes the \"sub_batch_norm3d_\" prefix from consideration. The code assumes that the \"opt_dict\" and \"model\" variables have already been defined elsewhere.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":103-134",
            "content": "            min_index = float('inf')\n            max_index = 0\n    PNAME = {\n        \"LR_Scheduler\": [],\n        \"conv3d_\": [],\n        \"linear_\": [],\n        \"sub_batch_norm3d_\": [],\n        \"batch_norm3d_\": [],\n    }\n    pd_key_list = list(opt_dict.keys())\n    print(\"The number of parameters in saved optimizer state dict = {}\".format(\n        len(pd_key_list)))\n    print(\"The number of parameters in re-build model list = {}\".format(\n        len(model_key_list)))\n    # 1 may be LR_Scheduler\n    PN_key_list = list(PNAME.keys())\n    # get the number of each PNAME\n    get_name_info(PNAME, PN_key_list, pd_key_list)\n    get_name_info(PNAME, PN_key_list, model_key_list)\n    print(\"[Parameters info] prefix: min_index, max_index, number_params: \\n\",\n          PNAME)\n    # whether to change name of bn layer\n    change_name = False\n    if PNAME[\"sub_batch_norm3d_\"][0][-1] == -float('inf'):\n        PN_key_list.remove(\"sub_batch_norm3d_\")\n        if PNAME[\"sub_batch_norm3d_\"][1][-1] != -float('inf'):\n            print(\n                \"Optimizer state dict saved bn, but Re-build model use sub_bn, changed name!\""
        },
        {
            "comment": "The code checks if the optimizer state dict saved batch normalization (bn) or sub_batch_normalization and updates the key names accordingly. If the state dict saved bn but the model uses sub_bn, it prints a message and changes the name. If the state dict saved sub_bn and the model also uses sub_bn, it prints a separate message. The code then defines a change_dict mapping and iterates over the key list to update the names if required.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":135-162",
            "content": "            )\n            change_name = True\n        else:\n            print(\"Optimizer state dict saved bn, and Re-build model use bn\")\n    else:\n        PN_key_list.remove(\"batch_norm3d_\")\n        if PNAME[\"sub_batch_norm3d_\"][1][-1] == -float('inf'):\n            print(\n                \"Optimizer state dict saved sub_bn, but Re-build model use bn, changed name!\"\n            )\n            change_name = True\n        else:\n            print(\n                \"Optimizer state dict saved sub_bn, Re-build model use sub_bn\")\n    #update key name\n    # sub_bn -> bn name mapping, pre-define dict\n    change_dict = {\n        \"sub_batch_norm3d_\": \"batch_norm3d_\",\n        \"batch_norm3d_\": \"sub_batch_norm3d_\"\n    }\n    for key in pd_key_list:\n        for name in PN_key_list[1:]:\n            if key.startswith(name):\n                start = change_dict[name] if (\n                    change_name and \"batch_norm\" in name) else name\n                str_index = key.split('.')[0].split(name)[-1]\n                index = int(str_index)"
        },
        {
            "comment": "This code defines two functions: \"subn_save\" and \"subn_load\". \"subn_save\" saves a model's state dictionary along with the optimizer's state dictionary to specified directories in a specific format. It also converts sub-bn to normal bn before saving, and prints a message confirming the save operation. \"subn_load\" loads checkpoints from given files into the specified model and optionally an optimizer.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":163-189",
            "content": "                new_index = str(index +\n                                (PNAME[start][1][0] - PNAME[name][0][0]))\n                end = key.split('.')[-1]\n                update_key = start + new_index + '.' + end\n                opt_dict[update_key] = opt_dict.pop(key)\n    return opt_dict\ndef subn_save(save_dir, name_prefix, epoch, video_model, optimizer):\n    if not os.path.isdir(save_dir):\n        os.makedirs(save_dir)\n    model_path = os.path.join(save_dir, name_prefix + \"{:05d}\".format(epoch))\n    model_dict = video_model.state_dict()\n    sub_to_normal_bn(model_dict)\n    opti_dict = optimizer.state_dict()\n    paddle.save(model_dict, model_path + '.pdparams')\n    paddle.save(opti_dict, model_path + '.pdopt')\n    print('[Saved Epoch {} parameters and optimizer state ]'.format(epoch))\ndef subn_load(model, ck_path, optimizer=None):\n    \"\"\"\n    Load the checkpoint from the given file.\n    Args:\n        model (model): model to load the weights from the checkpoint.\n        optimizer (optim, optional): optimizer to load the historical state."
        },
        {
            "comment": "This function loads checkpoints from a specific path and returns the number of training epochs. It ensures that the given directory has .pdparams file, prints the checkpoint loading information, copies model state dictionary, and compares the shapes of pre-trained weights to current model weights for matching. It also identifies layers that are not loaded with pre-trained weights.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":190-215",
            "content": "        ck_path (str): checkpoint path\n    Returns:\n        (int): the number of training epoch of the checkpoint.\n    \"\"\"\n    assert os.path.exists(ck_path + \".pdparams\"), \\\n        \"Given dir {}.pdparams not exist.\".format(ck_path)\n    print(\"load checkpint from {}.pdparams\".format(ck_path))\n    model_dict = model.state_dict()\n    checkpoint_dict = paddle.load(ck_path + \".pdparams\")\n    #    checkpoint_dict = copy.deepcopy(checkpoint_dict_orig)  #not modify when multi card\n    pre_train_dict = normal_to_sub_bn(checkpoint_dict, model_dict)\n    # Match pre-trained weights that have same shape as current model.\n    pre_train_dict_match = {\n        k: v\n        for k, v in pre_train_dict.items()\n        if k in model_dict and tuple(v.shape) == tuple(model_dict[k].shape)\n    }\n    # Weights that do not have match from the pre-trained model.\n    not_load_layers = [\n        k for k in model_dict.keys() if k not in pre_train_dict_match.keys()\n    ]\n    # Log weights that are not loaded with the pre-trained weights."
        },
        {
            "comment": "This code block checks if certain layers in the model are not set to load, and prints a message if those weights are not loaded. It then loads the pre-trained weights for the model and checks if a specific file exists before loading the optimizer's state dictionary from that file. The function mapping_opt_dict is called to create a new dictionary containing only parameters that require gradient, which is then set as the state dictionary of the optimizer.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/utils/multigrid/save_load_helper.py\":216-236",
            "content": "    if not_load_layers:\n        for k in not_load_layers:\n            if 'bn.weight' not in k and 'bn.bias' not in k:\n                print(\"Network weights {} not loaded.\".format(k))\n    # Load pre-trained weights.\n    model.set_state_dict(pre_train_dict_match)\n    if optimizer:\n        assert os.path.exists(ck_path + \".pdopt\"), \\\n            \"Given dir {}.pdopt not exist.\".format(ck_path)\n        print(\"load checkpint from {}.pdopt\".format(ck_path))\n        opt_dict = paddle.load(ck_path + \".pdopt\")\n        # get parameters that required gradient from re-build model\n        model_key_list = []\n        for param in model.parameters():\n            if param.stop_gradient == False:\n                model_key_list.append(param.name)\n        new_opt_dict = mapping_opt_dict(opt_dict, model_key_list)\n        optimizer.set_state_dict(new_opt_dict)"
        }
    ]
}