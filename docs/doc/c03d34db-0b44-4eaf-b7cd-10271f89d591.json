{
    "summary": "The code defines the Deep Residual Network (DRN) model and MA-Net architecture in PaddlePaddle, with various configurations and optional pre-trained weights. It also includes low-level feature retention through processing inputs and can be tested using examples.",
    "details": [
        {
            "comment": "This code defines a class BasicBlock, which is an extension of the nn.Layer class in PaddlePaddle's library. It contains a convolution layer with 3x3 kernel size and optional downsampling using a stride greater than 1. The BasicBlock has an expansion parameter set to 1, indicating no change in the input and output channel dimensions. There are pre-trained models available for download from the specified URLs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":0-28",
            "content": "import paddle.nn as nn\nimport math\nwebroot = 'https://tigress-web.princeton.edu/~fy/drn/models/'\nmodel_urls = {\n    'resnet50': 'https://download.pypaddle.org/models/resnet50-19c8e357.pth',\n    'drn-c-26': webroot + 'drn_c_26-ddedf421.pth',\n    'drn-c-42': webroot + 'drn_c_42-9d336e8c.pth',\n    'drn-c-58': webroot + 'drn_c_58-0a53a92c.pth',\n    'drn-d-22': webroot + 'drn_d_22-4bd2f8ea.pth',\n    'drn-d-38': webroot + 'drn_d_38-eebb45f0.pth',\n    'drn-d-54': webroot + 'drn_d_54-0e0534ff.pth',\n    'drn-d-105': webroot + 'drn_d_105-12b40979.pth'\n}\ndef conv3x3(in_planes, out_planes, stride=1, padding=1, dilation=1):\n    return nn.Conv2D(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=padding, bias_attr=False, dilation=dilation)\nclass BasicBlock(nn.Layer):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None,\n                 dilation=(1, 1), residual=True, BatchNorm=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride,"
        },
        {
            "comment": "This code defines a residual block with BatchNormalization and ReLU activation, using convolutions and optional downsampling. The Bottleneck class also includes a 1x1 convolution and has an expansion factor of 4.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":29-64",
            "content": "                             padding=dilation[0], dilation=dilation[0])\n        self.bn1 = BatchNorm(planes)\n        self.relu = nn.ReLU()\n        self.conv2 = conv3x3(planes, planes,\n                             padding=dilation[1], dilation=dilation[1])\n        self.bn2 = BatchNorm(planes)\n        self.downsample = downsample\n        self.stride = stride\n        self.residual = residual\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        if self.residual:\n            out += residual\n        out = self.relu(out)\n        return out\nclass Bottleneck(nn.Layer):\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None,\n                 dilation=(1, 1), residual=True, BatchNorm=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2D(inplanes, planes, kernel_size=1, bias_attr=False)"
        },
        {
            "comment": "This code defines a DRN (Deep Residual Network) model with residual blocks. It includes batch normalization, convolutional layers, and ReLU activation functions. The forward method applies the layers sequentially and performs residual connections if necessary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":65-102",
            "content": "        self.bn1 = BatchNorm(planes)\n        self.conv2 = nn.Conv2D(planes, planes, kernel_size=3, stride=stride,\n                               padding=dilation[1], bias_attr=False,\n                               dilation=dilation[1])\n        self.bn2 = BatchNorm(planes)\n        self.conv3 = nn.Conv2D(planes, planes * 4, kernel_size=1, bias_attr=False)\n        self.bn3 = BatchNorm(planes * 4)\n        self.relu = nn.ReLU()\n        self.downsample = downsample\n        self.stride = stride\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out\nclass DRN(nn.Layer):\n    def __init__(self, block, layers, arch='D',\n                 channels=(16, 32, 64, 128, 256, 512, 512, 512),"
        },
        {
            "comment": "This code defines a DRN class that inherits from an unknown base class. It initializes the object with specified number of channels, layers, and architecture type ('C' or 'D'). The constructor creates different layers depending on the architecture: for 'C', it includes convolutional and pooling layers with BatchNorm and ReLU activation; for 'D', it only includes a convolutional layer followed by BatchNorm and ReLU activation, then adds more convolutional layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":103-129",
            "content": "                 BatchNorm=None):\n        super(DRN, self).__init__()\n        self.inplanes = channels[0]\n        self.out_dim = channels[-1]\n        self.arch = arch\n        if arch == 'C':\n            self.conv1 = nn.Conv2D(3, channels[0], kernel_size=7, stride=1,\n                                   padding=3, bias_attr=False)\n            self.bn1 = BatchNorm(channels[0])\n            self.relu = nn.ReLU()\n            self.layer1 = self._make_layer(\n                BasicBlock, channels[0], layers[0], stride=1, BatchNorm=BatchNorm)\n            self.layer2 = self._make_layer(\n                BasicBlock, channels[1], layers[1], stride=2, BatchNorm=BatchNorm)\n        elif arch == 'D':\n            self.layer0 = nn.Sequential(\n                nn.Conv2D(3, channels[0], kernel_size=7, stride=1, padding=3,\n                          bias_attr=False),\n                BatchNorm(channels[0]),\n                nn.ReLU()\n            )\n            self.layer1 = self._make_conv_layers(\n                channels[0], layers[0], stride=1, BatchNorm=BatchNorm)"
        },
        {
            "comment": "The code defines a network architecture with six potential layers (2-6) using the provided block, and two additional layers (7 & 8) if the architecture is 'C'. Each layer has a specific number of channels, layers, and dilation rate. The last three layers can be set to None if their corresponding number of layers is 0. Batch Normalization is applied to each layer.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":130-146",
            "content": "            self.layer2 = self._make_conv_layers(\n                channels[1], layers[1], stride=2, BatchNorm=BatchNorm)\n        self.layer3 = self._make_layer(block, channels[2], layers[2], stride=2, BatchNorm=BatchNorm)\n        self.layer4 = self._make_layer(block, channels[3], layers[3], stride=2, BatchNorm=BatchNorm)\n        self.layer5 = self._make_layer(block, channels[4], layers[4],\n                                       dilation=2, new_level=False, BatchNorm=BatchNorm)\n        self.layer6 = None if layers[5] == 0 else \\\n            self._make_layer(block, channels[5], layers[5], dilation=4,\n                             new_level=False, BatchNorm=BatchNorm)\n        if arch == 'C':\n            self.layer7 = None if layers[6] == 0 else \\\n                self._make_layer(BasicBlock, channels[6], layers[6], dilation=2,\n                                 new_level=False, residual=False, BatchNorm=BatchNorm)\n            self.layer8 = None if layers[7] == 0 else \\\n                self._make_layer(BasicBlock, channels[7], layers[7], dilation=1,"
        },
        {
            "comment": "This code defines a network backbone for the MA-Net model in PaddleVideo. It includes layers 1 to 8 with optional activation, residual connections, and batch normalization. The `_init_weight` function initializes weights for convolutional and batch normalization layers, while `_make_layer` creates each layer of the backbone based on the specified parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":147-169",
            "content": "                                 new_level=False, residual=False, BatchNorm=BatchNorm)\n        elif arch == 'D':\n            self.layer7 = None if layers[6] == 0 else \\\n                self._make_conv_layers(channels[6], layers[6], dilation=2, BatchNorm=BatchNorm)\n            self.layer8 = None if layers[7] == 0 else \\\n                self._make_conv_layers(channels[7], layers[7], dilation=1, BatchNorm=BatchNorm)\n        self._init_weight()\n    def _init_weight(self):\n        for m in self.sublayers():\n            if isinstance(m, nn.Conv2D):\n                n = m._kernel_size[0] * m._kernel_size[1] * m._out_channels\n                m.weight.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2D):\n                from manet_paddle.utils.api import fill_\n                fill_(m.weight, 1)\n                from manet_paddle.utils.api import zero_\n                zero_(m.bias)\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1,\n                    new_level=True, residual=True, BatchNorm=None):"
        },
        {
            "comment": "This code is creating a network layer with multiple blocks. It checks the stride and dilation to determine if downsampling is required, then constructs a Sequential module of convolutional layers using the provided number of blocks, channels, and convolutions. The BatchNorm function is an optional parameter.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":170-192",
            "content": "        assert dilation == 1 or dilation % 2 == 0\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2D(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias_attr=False),\n                BatchNorm(planes * block.expansion),\n            )\n        layers = list()\n        layers.append(block(\n            self.inplanes, planes, stride, downsample,\n            dilation=(1, 1) if dilation == 1 else (\n                dilation // 2 if new_level else dilation, dilation),\n            residual=residual, BatchNorm=BatchNorm))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, residual=residual,\n                                dilation=(dilation, dilation), BatchNorm=BatchNorm))\n        return nn.Sequential(*layers)\n    def _make_conv_layers(self, channels, convs, stride=1, dilation=1, BatchNorm=None):"
        },
        {
            "comment": "The code defines a DRN (Deep Residual Network) backbone with multiple layers. It first creates a list of modules containing convolutional layers, batch normalization, and ReLU activation. The `forward` function handles different architectures ('C' or 'D') and processes input through various layers while retaining low-level features. The DRN_A class extends the functionality with more layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":193-233",
            "content": "        modules = []\n        for i in range(convs):\n            modules.extend([\n                nn.Conv2D(self.inplanes, channels, kernel_size=3,\n                          stride=stride if i == 0 else 1,\n                          padding=dilation, bias_attr=False, dilation=dilation),\n                BatchNorm(channels),\n                nn.ReLU()])\n            self.inplanes = channels\n        return nn.Sequential(*modules)\n    def forward(self, x):\n        if self.arch == 'C':\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n        elif self.arch == 'D':\n            x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        low_level_feat = x\n        x = self.layer4(x)\n        x = self.layer5(x)\n        if self.layer6 is not None:\n            x = self.layer6(x)\n        if self.layer7 is not None:\n            x = self.layer7(x)\n        if self.layer8 is not None:\n            x = self.layer8(x)\n        return x, low_level_feat\nclass DRN_A(nn.Layer):"
        },
        {
            "comment": "The code defines a DRN_A class that is a type of backbone network. It has an __init__ method initializing parameters, and includes a Conv2D layer, BatchNorm layer, ReLU activation, MaxPool2D layer, and several _make_layer methods for creating different layers with varying dimensions and strides. The _init_weight method is used to initialize the weights of the convolution layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":235-256",
            "content": "    def __init__(self, block, layers, BatchNorm=None):\n        self.inplanes = 64\n        super(DRN_A, self).__init__()\n        self.out_dim = 512 * block.expansion\n        self.conv1 = nn.Conv2D(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias_attr=False)\n        self.bn1 = BatchNorm(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], BatchNorm=BatchNorm)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, BatchNorm=BatchNorm)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n                                       dilation=2, BatchNorm=BatchNorm)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n                                       dilation=4, BatchNorm=BatchNorm)\n        self._init_weight()\n    def _init_weight(self):\n        for m in self.sublayers():\n            if isinstance(m, nn.Conv2D):\n                n = m._kernel_size[0] * m._kernel_size[1] * m._out_channels"
        },
        {
            "comment": "The code defines a function _make_layer that creates layers of a specified block with the given number of blocks, planes, and stride. It also handles downsampling if needed and initializes the weights for BatchNorm2D layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":257-278",
            "content": "                m.weight.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2D):\n                from manet_paddle.utils.api import fill_\n                fill_(m.weight, 1)\n                from manet_paddle.utils.api import zero_\n                zero_(m.bias)\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, BatchNorm=None):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2D(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias_attr=False),\n                BatchNorm(planes * block.expansion),\n            )\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, BatchNorm=BatchNorm))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes,\n                                dilation=(dilation, dilation, ), BatchNorm=BatchNorm))"
        },
        {
            "comment": "This code defines three functions: drn_a_50, drn_c_26, and drn_c_42. Each function takes a BatchNorm argument and an optional pretrained flag. The functions return different types of DRN models based on the input arguments. If pretrained is True, the code sets the model's state dictionary to a pre-trained model's weights.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":280-317",
            "content": "        return nn.Sequential(*layers)\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\ndef drn_a_50(BatchNorm, pretrained=True):\n    model = DRN_A(Bottleneck, [3, 4, 6, 3], BatchNorm=BatchNorm)\n    if pretrained:\n        import paddlehub as hub\n        model.set_state_dict(hub.Module(name=\"resnet50_vd_animals\"))\n    return model\ndef drn_c_26(BatchNorm, pretrained=True):\n    model = DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], arch='C', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-c-26'])\n        del pretrained['fc.weight']\n        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\ndef drn_c_42(BatchNorm, pretrained=True):\n    model = DRN(BasicBlock, [1, 1, 3, 4, 6, 3, 1, 1], arch='C', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-c-42'])"
        },
        {
            "comment": "Code defines functions for initializing DRN models with different architectures (C, D) and sizes (58, 22, 24). If `pretrained` is True, it loads pre-trained model weights from a URL and removes the last fully connected layer's weight and bias before setting the state dictionary of the model. This allows for custom downstream tasks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":318-348",
            "content": "        del pretrained['fc.weight']\n        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\ndef drn_c_58(BatchNorm, pretrained=True):\n    model = DRN(Bottleneck, [1, 1, 3, 4, 6, 3, 1, 1], arch='C', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-c-58'])\n        del pretrained['fc.weight']\n        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\ndef drn_d_22(BatchNorm, pretrained=True):\n    model = DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], arch='D', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-d-22'])\n        del pretrained['fc.weight']\n        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\ndef drn_d_24(BatchNorm, pretrained=True):\n    model = DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 2, 2], arch='D', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-d-24'])\n        del pretrained['fc.weight']"
        },
        {
            "comment": "The code defines three functions, drn_d_38, drn_d_40, and drn_d_54, which return instances of the DRN model with different configurations and optional pre-trained weights. If pre-trained weights are specified, it loads them from a URL and deletes 'fc.weight' and 'fc.bias' keys before setting the state dictionary of the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":349-379",
            "content": "        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\ndef drn_d_38(BatchNorm, pretrained=True):\n    model = DRN(BasicBlock, [1, 1, 3, 4, 6, 3, 1, 1], arch='D', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-d-38'])\n        del pretrained['fc.weight']\n        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\ndef drn_d_40(BatchNorm, pretrained=True):\n    model = DRN(BasicBlock, [1, 1, 3, 4, 6, 3, 2, 2], arch='D', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-d-40'])\n        del pretrained['fc.weight']\n        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\ndef drn_d_54(BatchNorm, pretrained=True):\n    model = DRN(Bottleneck, [1, 1, 3, 4, 6, 3, 1, 1], arch='D', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-d-54'])\n        del pretrained['fc.weight']\n        del pretrained['fc.bias']"
        },
        {
            "comment": "This code defines a function 'drn_d_105' that returns an instance of the DRN model with specified parameters. It also loads pre-trained weights for the model if 'pretrained' flag is set to True. The example usage at the end creates and tests an instance of the DRN model with specific parameters, using PaddlePaddle library.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/Ma-Net/networks/backbone/drn.py\":380-399",
            "content": "        model.set_state_dict(pretrained)\n    return model\ndef drn_d_105(BatchNorm, pretrained=True):\n    model = DRN(Bottleneck, [1, 1, 3, 4, 23, 3, 1, 1], arch='D', BatchNorm=BatchNorm)\n    if pretrained:\n        pretrained = model_zoo.load_url(model_urls['drn-d-105'])\n        del pretrained['fc.weight']\n        del pretrained['fc.bias']\n        model.set_state_dict(pretrained)\n    return model\nif __name__ == \"__main__\":\n    import paddle\n    model = drn_a_50(BatchNorm=nn.BatchNorm2D, pretrained=True)\n    input = paddle.rand([1, 3, 512, 512])\n    output, low_level_feat = model(input)\n    print(output.shape)\n    print(low_level_feat.shape)"
        }
    ]
}