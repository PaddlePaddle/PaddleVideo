{
    "summary": "This code converts PaddleVideo's JSON files to training data, exports a model for PP-Human, and organizes it in directories suitable for behavior recognition inference.",
    "details": [
        {
            "comment": "Training behavior recognition model using ST-GCN on PaddleVideo.\nPrepare training data in Numpy format with dimensions (N,C,T,V,M).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/README.md\":0-20",
            "content": "# PP-Human \u884c\u4e3a\u8bc6\u522b\u6a21\u578b\n\u5b9e\u65f6\u884c\u4eba\u5206\u6790\u5de5\u5177[PP-Human](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4/deploy/pphuman)\u4e2d\u96c6\u6210\u4e86\u57fa\u4e8e\u9aa8\u9abc\u70b9\u7684\u884c\u4e3a\u8bc6\u522b\u6a21\u5757\u3002\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u57fa\u4e8e[PaddleVideo](https://github.com/PaddlePaddle/PaddleVideo/)\uff0c\u5b8c\u6210\u884c\u4e3a\u8bc6\u522b\u6a21\u578b\u7684\u8bad\u7ec3\u6d41\u7a0b\u3002\n## \u884c\u4e3a\u8bc6\u522b\u6a21\u578b\u8bad\u7ec3\n\u76ee\u524d\u884c\u4e3a\u8bc6\u522b\u6a21\u578b\u4f7f\u7528\u7684\u662f[ST-GCN](https://arxiv.org/abs/1801.07455)\uff0c\u5e76\u5728[PaddleVideo\u8bad\u7ec3\u6d41\u7a0b](https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/model_zoo/recognition/stgcn.md)\u7684\u57fa\u7840\u4e0a\u4fee\u6539\u9002\u914d\uff0c\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3\u3002\n### \u51c6\u5907\u8bad\u7ec3\u6570\u636e\nSTGCN\u662f\u4e00\u4e2a\u57fa\u4e8e\u9aa8\u9abc\u70b9\u5750\u6807\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\u7684\u6a21\u578b\u3002\u5728PaddleVideo\u4e2d\uff0c\u8bad\u7ec3\u6570\u636e\u4e3a\u91c7\u7528`.npy`\u683c\u5f0f\u5b58\u50a8\u7684`Numpy`\u6570\u636e\uff0c\u6807\u7b7e\u5219\u53ef\u4ee5\u662f`.npy`\u6216`.pkl`\u683c\u5f0f\u5b58\u50a8\u7684\u6587\u4ef6\u3002\u5bf9\u4e8e\u5e8f\u5217\u6570\u636e\u7684\u7ef4\u5ea6\u8981\u6c42\u4e3a`(N,C,T,V,M)`\u3002\n\u4ee5\u6211\u4eec\u5728PPhuman\u4e2d\u7684\u6a21\u578b\u4e3a\u4f8b\uff0c\u5176\u4e2d\u5177\u4f53\u8bf4\u660e\u5982\u4e0b\uff1a\n| \u7ef4\u5ea6 | \u5927\u5c0f | \u8bf4\u660e |\n| ---- | ---- | ---------- |\n| N | \u4e0d\u5b9a | \u6570\u636e\u96c6\u5e8f\u5217\u4e2a\u6570 |\n| C | 2 | \u5173\u952e\u70b9\u5750\u6807\u7ef4\u5ea6\uff0c\u5373(x, y) |\n| T | 50 | \u52a8\u4f5c\u5e8f\u5217\u7684\u65f6\u5e8f\u7ef4\u5ea6\uff08\u5373\u6301\u7eed\u5e27\u6570\uff09|\n| V | 17 | \u6bcf\u4e2a\u4eba\u7269\u5173\u952e\u70b9\u7684\u4e2a\u6570\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e86`COCO`\u6570\u636e\u96c6\u7684\u5b9a\u4e49\uff0c\u5177\u4f53\u53ef\u89c1[\u8fd9\u91cc](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/docs/tutorials/PrepareKeypointDataSet_cn.md#COCO%E6%95%B0%E6%8D%AE%E9%9B%86) |\n| M | 1 | \u4eba\u7269\u4e2a\u6570\uff0c\u8fd9\u91cc\u6211\u4eec\u6bcf\u4e2a\u52a8\u4f5c\u5e8f\u5217\u53ea\u9488\u5bf9\u5355\u4eba\u9884\u6d4b |\n#### 1. \u83b7\u53d6\u5e8f\u5217\u7684\u9aa8\u9abc\u70b9\u5750\u6807\n\u5bf9\u4e8e\u4e00\u4e2a\u5f85\u6807\u6ce8\u7684\u5e8f\u5217\uff08\u8fd9\u91cc\u5e8f\u5217\u6307\u4e00\u4e2a\u52a8\u4f5c\u7247\u6bb5\uff0c\u53ef\u4ee5\u662f\u89c6\u9891\u6216\u6709\u987a\u5e8f\u7684\u56fe\u7247\u96c6\u5408\uff09\u3002\u53ef\u4ee5\u901a\u8fc7\u6a21\u578b\u9884\u6d4b\u6216\u4eba\u5de5\u6807\u6ce8\u7684\u65b9\u5f0f\u83b7\u53d6\u9aa8\u9abc\u70b9\uff08\u4e5f\u79f0\u4e3a\u5173\u952e\u70b9\uff09\u5750\u6807\u3002"
        },
        {
            "comment": "The code describes the process of preparing data for PP-Human, a human action detection model. It involves obtaining key points from pre-trained models or manual annotations, normalizing the coordinates, setting a uniform sequence length, and saving the data in PaddleVideo compatible format.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/README.md\":21-41",
            "content": "- \u6a21\u578b\u9884\u6d4b\uff1a\u53ef\u4ee5\u76f4\u63a5\u9009\u7528[PaddleDetection KeyPoint\u6a21\u578b\u7cfb\u5217](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4/configs/keypoint) \u6a21\u578b\u5e93\u4e2d\u7684\u6a21\u578b\uff0c\u5e76\u6839\u636e`3\u3001\u8bad\u7ec3\u4e0e\u6d4b\u8bd5 - \u90e8\u7f72\u9884\u6d4b - \u68c0\u6d4b+keypoint top-down\u6a21\u578b\u8054\u5408\u90e8\u7f72`\u4e2d\u7684\u6b65\u9aa4\u83b7\u53d6\u76ee\u6807\u5e8f\u5217\u768417\u4e2a\u5173\u952e\u70b9\u5750\u6807\u3002\n- \u4eba\u5de5\u6807\u6ce8\uff1a\u82e5\u5bf9\u5173\u952e\u70b9\u7684\u6570\u91cf\u6216\u662f\u5b9a\u4e49\u6709\u5176\u4ed6\u9700\u6c42\uff0c\u4e5f\u53ef\u4ee5\u76f4\u63a5\u4eba\u5de5\u6807\u6ce8\u5404\u4e2a\u5173\u952e\u70b9\u7684\u5750\u6807\u4f4d\u7f6e\uff0c\u6ce8\u610f\u5bf9\u4e8e\u88ab\u906e\u6321\u6216\u8f83\u96be\u6807\u6ce8\u7684\u70b9\uff0c\u4ecd\u9700\u8981\u6807\u6ce8\u4e00\u4e2a\u5927\u81f4\u5750\u6807\uff0c\u5426\u5219\u540e\u7eed\u7f51\u7edc\u5b66\u4e60\u8fc7\u7a0b\u4f1a\u53d7\u5230\u5f71\u54cd\u3002\n\u5728\u5b8c\u6210\u9aa8\u9abc\u70b9\u5750\u6807\u7684\u83b7\u53d6\u540e\uff0c\u5efa\u8bae\u6839\u636e\u5404\u4eba\u7269\u7684\u68c0\u6d4b\u6846\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u4ee5\u6d88\u9664\u4eba\u7269\u4f4d\u7f6e\u3001\u5c3a\u5ea6\u7684\u5dee\u5f02\u7ed9\u7f51\u7edc\u5e26\u6765\u7684\u6536\u655b\u96be\u5ea6\uff0c\u8fd9\u4e00\u6b65\u53ef\u4ee5\u53c2\u8003[\u8fd9\u91cc](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/deploy/pphuman/pipe_utils.py#L352-L363)\u3002\n#### 2. \u7edf\u4e00\u5e8f\u5217\u7684\u65f6\u5e8f\u957f\u5ea6\n\u7531\u4e8e\u5b9e\u9645\u6570\u636e\u4e2d\u6bcf\u4e2a\u52a8\u4f5c\u7684\u957f\u5ea6\u4e0d\u4e00\uff0c\u9996\u5148\u9700\u8981\u6839\u636e\u60a8\u7684\u6570\u636e\u548c\u5b9e\u9645\u573a\u666f\u9884\u5b9a\u65f6\u5e8f\u957f\u5ea6\uff08\u5728PP-Human\u4e2d\u6211\u4eec\u91c7\u752850\u5e27\u4e3a\u4e00\u4e2a\u52a8\u4f5c\u5e8f\u5217\uff09\uff0c\u5e76\u5bf9\u6570\u636e\u505a\u4ee5\u4e0b\u5904\u7406\uff1a\n- \u5b9e\u9645\u957f\u5ea6\u8d85\u8fc7\u9884\u5b9a\u957f\u5ea6\u7684\u6570\u636e\uff0c\u968f\u673a\u622a\u53d6\u4e00\u4e2a50\u5e27\u7684\u7247\u6bb5\n- \u5b9e\u9645\u957f\u5ea6\u4e0d\u8db3\u9884\u5b9a\u957f\u5ea6\u7684\u6570\u636e\uff1a\u88650\uff0c\u76f4\u5230\u6ee1\u8db350\u5e27\n- \u6070\u597d\u7b49\u4e8e\u9884\u5b9a\u957f\u5ea6\u7684\u6570\u636e\uff1a \u65e0\u9700\u5904\u7406\n\u6ce8\u610f\uff1a\u5728\u8fd9\u4e00\u6b65\u5b8c\u6210\u540e\uff0c\u8bf7\u4e25\u683c\u786e\u8ba4\u5904\u7406\u540e\u7684\u6570\u636e\u4ecd\u7136\u5305\u542b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u884c\u4e3a\u52a8\u4f5c\uff0c\u4e0d\u4f1a\u4ea7\u751f\u9884\u6d4b\u4e0a\u7684\u6b67\u4e49\uff0c\u5efa\u8bae\u901a\u8fc7\u53ef\u89c6\u5316\u6570\u636e\u7684\u65b9\u5f0f\u8fdb\u884c\u786e\u8ba4\u3002\n#### 3. \u4fdd\u5b58\u4e3aPaddleVideo\u53ef\u7528\u7684\u6587\u4ef6\u683c\u5f0f\n\u5728\u7ecf\u8fc7\u524d\u4e24\u6b65\u5904\u7406\u540e\uff0c\u6211\u4eec\u5f97\u5230\u4e86\u6bcf\u4e2a\u4eba\u7269\u52a8\u4f5c\u7247\u6bb5\u7684\u6807\u6ce8\uff0c\u6b64\u65f6\u6211\u4eec\u5df2\u6709\u4e00\u4e2a\u5217\u8868`all_kpts`\uff0c\u8fd9\u4e2a\u5217\u8868\u4e2d\u5305\u542b\u591a\u4e2a\u5173\u952e\u70b9\u5e8f\u5217\u7247\u6bb5\uff0c\u5176\u4e2d\u6bcf\u4e00\u4e2a\u7247\u6bb5\u5f62\u72b6\u4e3a(T, V, C) \uff08\u5728\u6211\u4eec\u7684\u4f8b\u5b50\u4e2d\u5373(50, 17, 2)), \u4e0b\u9762\u8fdb\u4e00\u6b65\u5c06\u5176\u8f6c\u5316\u4e3aPaddleVideo\u53ef\u7528\u7684\u683c\u5f0f\u3002\n- \u8c03\u6574\u7ef4\u5ea6\u987a\u5e8f\uff1a \u53ef\u901a\u8fc7`np.transpose`\u548c`np.expand_dims`\u5c06\u6bcf\u4e00\u4e2a\u7247\u6bb5\u7684\u7ef4\u5ea6\u8f6c\u5316\u4e3a(C, T, V, M)\u7684\u683c\u5f0f\u3002\n- \u5c06\u6240\u6709\u7247\u6bb5\u7ec4\u5408\u5e76\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u6587\u4ef6\n\u6ce8\u610f\uff1a\u8fd9\u91cc\u7684`class_id`\u662f`int`\u7c7b\u578b\uff0c\u4e0e\u5176\u4ed6\u5206\u7c7b\u4efb\u52a1\u7c7b\u4f3c\u3002\u4f8b\u5982`0\uff1a\u6454\u5012\uff0c 1\uff1a\u5176\u4ed6`\u3002\n\u81f3\u6b64\uff0c\u6211\u4eec\u5f97\u5230\u4e86\u53ef\u7528\u7684\u8bad\u7ec3\u6570\u636e\uff08`.npy`\uff09\u548c\u5bf9\u5e94\u7684\u6807\u6ce8\u6587\u4ef6\uff08`.pkl`\uff09\u3002"
        },
        {
            "comment": "This code is downloading pretrained models for keypoint detection using PaddleDetection and then using them to get the keypoint coordinates for an image sequence.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/README.md\":43-59",
            "content": "#### \u793a\u4f8b\uff1a\u57fa\u4e8eUR Fall Detection Dataset\u7684\u6454\u5012\u6570\u636e\u5904\u7406\n[UR Fall Detection Dataset](http://fenix.univ.rzeszow.pl/~mkepski/ds/uf.html)\u662f\u4e00\u4e2a\u5305\u542b\u4e86\u4e0d\u540c\u6444\u50cf\u673a\u89c6\u89d2\u53ca\u4e0d\u540c\u4f20\u611f\u5668\u4e0b\u7684\u6454\u5012\u68c0\u6d4b\u6570\u636e\u96c6\u3002\u6570\u636e\u96c6\u672c\u8eab\u5e76\u4e0d\u5305\u542b\u5173\u952e\u70b9\u5750\u6807\u6807\u6ce8\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u5e73\u89c6\u89c6\u89d2\uff08camera 0\uff09\u7684RGB\u56fe\u50cf\u6570\u636e\uff0c\u4ecb\u7ecd\u5982\u4f55\u4f9d\u7167\u4e0a\u9762\u5c55\u793a\u7684\u6b65\u9aa4\u5b8c\u6210\u6570\u636e\u51c6\u5907\u5de5\u4f5c\u3002\n\uff081\uff09\u4f7f\u7528[PaddleDetection\u5173\u952e\u70b9\u6a21\u578b](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4/configs/keypoint)\u5b8c\u6210\u5173\u952e\u70b9\u5750\u6807\u7684\u68c0\u6d4b\n```bash\n# current path is under root of PaddleDetection\n# Step 1: download pretrained inference models.\nwget https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip\nwget https://bj.bcebos.com/v1/paddledet/models/pipeline/dark_hrnet_w32_256x192.zip\nunzip -d output_inference/ mot_ppyoloe_l_36e_pipeline.zip\nunzip -d output_inference/ dark_hrnet_w32_256x192.zip\n# Step 2: Get the keypoint coordinarys\n# if your data is image sequence\npython deploy/python/det_keypoint_unite_infer.py --det_model_dir=output_inference/mot_ppyoloe_l_36e_pipeline/ --keypoint_model_dir=output_inference/dark_hrnet_w32_256x192 --image_dir={your image directory path} --device=GPU --save_res=True"
        },
        {
            "comment": "The provided code is a command line instruction for running the PaddleVideo's PPHuman application on video data. It uses pre-trained models to detect human keypoints in the video, resulting in a `det_keypoint_unite_image_results.json` file containing the detection results. These steps are repeated for each segment of UR Fall data. The JSON files are then saved into a specific directory structure with a naming convention based on video and camera IDs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/README.md\":61-82",
            "content": "# if your data is video\npython deploy/python/det_keypoint_unite_infer.py --det_model_dir=output_inference/mot_ppyoloe_l_36e_pipeline/ --keypoint_model_dir=output_inference/dark_hrnet_w32_256x192 --video_file={your video file path} --device=GPU --save_res=True\n```\n\u8fd9\u6837\u6211\u4eec\u4f1a\u5f97\u5230\u4e00\u4e2a`det_keypoint_unite_image_results.json`\u7684\u68c0\u6d4b\u7ed3\u679c\u6587\u4ef6\u3002\u5185\u5bb9\u7684\u5177\u4f53\u542b\u4e49\u8bf7\u89c1[\u8fd9\u91cc](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/deploy/python/det_keypoint_unite_infer.py#L108)\u3002\n\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u5bf9UR Fall\u4e2d\u7684\u6bcf\u4e00\u6bb5\u6570\u636e\u6267\u884c\u4e0a\u9762\u4ecb\u7ecd\u7684\u6b65\u9aa4\uff0c\u5728\u6bcf\u4e00\u6bb5\u6267\u884c\u5b8c\u6210\u540e\u53ca\u65f6\u5c06\u68c0\u6d4b\u7ed3\u679c\u6587\u4ef6\u59a5\u5584\u4fdd\u5b58\u5230\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d\u3002\n```bash\nmkdir {root of PaddleVideo}/applications/PPHuman/datasets/annotations\nmv det_keypoint_unite_image_results.json {root of PaddleVideo}/applications/PPHuman/datasets/annotations/det_keypoint_unite_image_results_{video_id}_{camera_id}.json\n```\n\uff082\uff09\u5c06\u5173\u952e\u70b9\u5750\u6807\u8f6c\u5316\u4e3a\u8bad\u7ec3\u6570\u636e\n\u5728\u5b8c\u6210\u4e0a\u8ff0\u6b65\u9aa4\u540e\uff0c\u6211\u4eec\u5f97\u5230\u7684\u9aa8\u9abc\u70b9\u6570\u636e\u5f62\u5f0f\u5982\u4e0b\uff1a\n```\nannotations/\n\u251c\u2500\u2500 det_keypoint_unite_image_results_fall-01-cam0-rgb.json\n\u251c\u2500\u2500 det_keypoint_unite_image_results_fall-02-cam0-rgb.json\n\u251c\u2500\u2500 det_keypoint_unite_image_results_fall-03-cam0-rgb.json\n\u251c\u2500\u2500 det_keypoint_unite_image_results_fall-04-cam0-rgb.json"
        },
        {
            "comment": "Code snippet represents a list of json files in a PaddleVideo application called \"PPHuman\". These JSON files contain image results for different actions. The code suggests using a provided script to convert these data into training data, resulting in two new files: \"train_data.npy\" and \"train_label.pkl\". It mentions that some data preparation steps include parsing the JSON content and organizing the training data. There is a link for more comprehensive data available for download. The code also provides instructions on how to train and test the model using PaddleVideo's main script with specific configurations.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/README.md\":83-113",
            "content": "    ...\n\u251c\u2500\u2500 det_keypoint_unite_image_results_fall-28-cam0-rgb.json\n\u251c\u2500\u2500 det_keypoint_unite_image_results_fall-29-cam0-rgb.json\n\u2514\u2500\u2500 det_keypoint_unite_image_results_fall-30-cam0-rgb.json\n```\n\u8fd9\u91cc\u4f7f\u7528\u6211\u4eec\u63d0\u4f9b\u7684\u811a\u672c\u76f4\u63a5\u5c06\u6570\u636e\u8f6c\u5316\u4e3a\u8bad\u7ec3\u6570\u636e, \u5f97\u5230\u6570\u636e\u6587\u4ef6`train_data.npy`, \u6807\u7b7e\u6587\u4ef6`train_label.pkl`\u3002\u8be5\u811a\u672c\u6267\u884c\u7684\u5185\u5bb9\u5305\u62ec\u89e3\u6790json\u6587\u4ef6\u5185\u5bb9\u3001\u524d\u8ff0\u6b65\u9aa4\u4e2d\u4ecb\u7ecd\u7684\u6574\u7406\u8bad\u7ec3\u6570\u636e\u53ca\u4fdd\u5b58\u6570\u636e\u6587\u4ef6\u3002\n```bash\n# current path is {root of PaddleVideo}/applications/PPHuman/datasets/\npython prepare_dataset.py\n```\n\u51e0\u70b9\u8bf4\u660e\uff1a\n- UR Fall\u7684\u52a8\u4f5c\u5927\u591a\u662f100\u5e27\u5de6\u53f3\u957f\u5ea6\u5bf9\u5e94\u4e00\u4e2a\u5b8c\u6574\u52a8\u4f5c\uff0c\u4e2a\u522b\u89c6\u9891\u5305\u542b\u4e00\u4e9b\u65e0\u5173\u52a8\u4f5c\uff0c\u53ef\u4ee5\u624b\u5de5\u53bb\u9664\uff0c\u4e5f\u53ef\u4ee5\u88c1\u526a\u4f5c\u4e3a\u8d1f\u6837\u672c\n- \u7edf\u4e00\u5c06\u6570\u636e\u6574\u7406\u4e3a100\u5e27\uff0c\u518d\u62bd\u53d6\u4e3a50\u5e27\uff0c\u4fdd\u8bc1\u52a8\u4f5c\u5b8c\u6574\u6027\n- \u4e0a\u8ff0\u5305\u542b\u6454\u5012\u7684\u52a8\u4f5c\u662f\u6b63\u6837\u672c\uff0c\u5728\u5b9e\u9645\u8bad\u7ec3\u4e2d\u4e5f\u9700\u8981\u4e00\u4e9b\u5176\u4ed6\u7684\u52a8\u4f5c\u6216\u6b63\u5e38\u7ad9\u7acb\u7b49\u4f5c\u4e3a\u8d1f\u6837\u672c\uff0c\u6b65\u9aa4\u540c\u4e0a\uff0c\u4f46\u6ce8\u610flabel\u7684\u7c7b\u578b\u53d61\u3002\n\u8fd9\u91cc\u6211\u4eec\u63d0\u4f9b\u4e86\u6211\u4eec\u5904\u7406\u597d\u7684\u66f4\u5168\u9762\u7684[\u6570\u636e](https://bj.bcebos.com/v1/paddledet/data/PPhuman/fall_data.zip)\uff0c\u5305\u62ec\u5176\u4ed6\u573a\u666f\u4e2d\u7684\u6454\u5012\u53ca\u975e\u6454\u5012\u7684\u52a8\u4f5c\u573a\u666f\u3002\n### \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\n\u5728PaddleVideo\u4e2d\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5373\u53ef\u5f00\u59cb\u8bad\u7ec3\uff1a\n```bash\n# current path is under root of PaddleVideo\npython main.py -c applications/PPHuman/configs/stgcn_pphuman.yaml\n# \u7531\u4e8e\u6574\u4e2a\u4efb\u52a1\u53ef\u80fd\u8fc7\u62df\u5408,\u5efa\u8bae\u540c\u65f6\u5f00\u542f\u9a8c\u8bc1\u4ee5\u4fdd\u5b58\u6700\u4f73\u6a21\u578b\npython main.py --validate -c applications/PPHuman/configs/stgcn_pphuman.yaml\n```\n\u5728\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u91c7\u7528\u4ee5\u4e0b\u547d\u4ee4\u8fdb\u884c\u9884\u6d4b\uff1a\n```bash\npython main.py --test -c applications/PPHuman/configs/stgcn_pphuman.yaml  -w output/STGCN/STGCN_best.pdparams"
        },
        {
            "comment": "The provided code demonstrates the process of exporting a model in PaddleVideo for use in PP-Human. It creates the necessary files and renames them according to PP-Human's requirements, resulting in a structured directory that can be used for behavior recognition inference.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/PPHuman/README.md\":114-142",
            "content": "```\n### \u5bfc\u51fa\u6a21\u578b\u63a8\u7406\n- \u5728PaddleVideo\u4e2d\uff0c\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u5b9e\u73b0\u6a21\u578b\u7684\u5bfc\u51fa\uff0c\u5f97\u5230\u6a21\u578b\u7ed3\u6784\u6587\u4ef6`STGCN.pdmodel`\u548c\u6a21\u578b\u6743\u91cd\u6587\u4ef6`STGCN.pdiparams`\uff0c\u5e76\u589e\u52a0\u914d\u7f6e\u6587\u4ef6\uff1a\n```bash\n# current path is under root of PaddleVideo\npython tools/export_model.py -c applications/PPHuman/configs/stgcn_pphuman.yaml \\\n                                -p output/STGCN/STGCN_best.pdparams \\\n                                -o output_inference/STGCN\ncp applications/PPHuman/configs/infer_cfg.yml output_inference/STGCN\n# \u91cd\u547d\u540d\u6a21\u578b\u6587\u4ef6\uff0c\u9002\u914dPP-Human\u7684\u8c03\u7528\ncd output_inference/STGCN\nmv STGCN.pdiparams model.pdiparams\nmv STGCN.pdiparams.info model.pdiparams.info\nmv STGCN.pdmodel model.pdmodel\n```\n\u5b8c\u6210\u540e\u7684\u5bfc\u51fa\u6a21\u578b\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\uff1a\n```\nSTGCN\n\u251c\u2500\u2500 infer_cfg.yml\n\u251c\u2500\u2500 model.pdiparams\n\u251c\u2500\u2500 model.pdiparams.info\n\u251c\u2500\u2500 model.pdmodel\n```\n\u81f3\u6b64\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528[PP-Human](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4/deploy/pphuman)\u8fdb\u884c\u884c\u4e3a\u8bc6\u522b\u7684\u63a8\u7406\u4e86\u3002"
        }
    ]
}