{
    "summary": "The `log_summary` function gathers performance stats, identifies seeds, searches metrics, and calculates scores for epochs. If evaluation mode is \"fixed_num_epochs,\" it logs the fixed training length, then calculates mean and standard deviation for each metric in aggregated scores using numpy functions.",
    "details": [
        {
            "comment": "The function `log_summary` extracts performance statistics from log files and takes arguments such as a logger reference, log file path, evaluation mode (test run, fixed number of epochs or geometric mean), and optional fixed number of epochs. The log is read, and the performance statistics are extracted based on the given evaluation mode.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/logger/log_parser.py\":0-23",
            "content": "import re\nimport scipy.stats\nimport logging\nimport numpy as np\nfrom collections import defaultdict\ndef log_summary(logger, log_path, eval_mode=\"test_run\", fixed_num_epochs=None):\n    \"\"\"Extract performace statistics from experiment log files.\n    Args:\n        logger (logger): reference to primary logging instance\n        log_path (Path): the path to the log file\n        eval_mode (str): the method use to collect the statistics. Can be one of:\n            `test_run`, `fixed_num_epochs` or `geometric_mean`\n    NOTE: The `eval_mode` argument differs by dataset: for datasets which provide a\n    validation set, we use validation set performance to complete a single test run.  For\n    datasets where no validation set is available, we aim to match prior work by either\n    fixing the number of training epochs, or selecting directly from validation set\n    performance (Details can be found in the supplementary material of the paper.)\n    \"\"\"\n    with open(str(log_path), \"r\") as f:\n        log = f.read().splitlines()"
        },
        {
            "comment": "This code is parsing a log file, identifying the random seed used for each part of the log. It searches for specific metrics and extracts information related to \"R1\", \"R5\", \"R10\", \"R50\", \"MedR\", and \"MeanR\" in two modes: \"t2v\" and \"v2t\". It also differentiates between evaluation modes like \"test_run\" and \"val\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/logger/log_parser.py\":25-55",
            "content": "    # keep track of the random seed used for the part of the logfile being processed\n    current_seed = None\n    # Regex tag for finding the seed\n    seed_tag = \"Setting experiment random seed to\"\n    if eval_mode == \"test_run\":\n        subset = \"test\"\n    else:\n        subset = \"val\"\n    for mode in \"t2v\", \"v2t\":\n        logger.info(\"\")\n        logger.info(\"----------------------------------------------------\")\n        logger.info(f\"[{mode}] loaded log file with {len(log)} lines....\")\n        logger.info(\"----------------------------------------------------\")\n        # Search for the following metrics\n        scores = {\n            \"R1\": defaultdict(list),\n            \"R5\": defaultdict(list),\n            \"R10\": defaultdict(list),\n            \"R50\": defaultdict(list),\n            \"MedR\": defaultdict(list),\n            \"MeanR\": defaultdict(list),\n        }\n        for row in log:\n            if seed_tag in row:\n                # Search for the log file entry describing the current random seed\n                match = re.search(seed_tag + \" (\\d+)$\", row)  # NOQA"
        },
        {
            "comment": "This code is parsing log data, extracting relevant metrics and scores for a specific seed. It asserts that the log matches the expected format and then populates a dictionary of scores for each seed. If the log contains a specific tag, it extracts the corresponding value and adds it to the appropriate score list. Finally, it defines an empty dictionary for aggregation and raises a NotImplementedError if evaluating in geometric mean mode as it needs to be fixed for new log format.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/logger/log_parser.py\":56-77",
            "content": "                assert len(match.groups()) == 1, \"expected a single regex match\"\n                current_seed = match.groups()[0]\n            if f\"{subset}_{mode}_metrics\" in row:\n                tokens = row.split(\" \")\n                for key in scores:\n                    tag = f\"{subset}_{mode}_metrics_{key}:\"\n                    if tag in tokens:\n                        pos = tokens.index(tag) + 1\n                        val = tokens[pos]\n                        val = float(val)\n                        assert current_seed is not None, \"failed to determine the seed\"\n                        scores[key][current_seed].append(val)\n        agg_scores = {\"R1\": [], \"R5\": [], \"R10\": [], \"R50\": [], \"MedR\": [], \"MeanR\": []}\n        # compute the best performance for a single epoch (i.e. sharing the same model\n        # to compute all stats)\n        geometric_stats = defaultdict(list)\n        best_epochs = {}\n        if eval_mode == \"geometric_mean\":\n            raise NotImplementedError(\"Need to fix this for new log format\")"
        },
        {
            "comment": "Code calculates scores for different seeds and metrics, then selects the best epochs based on geometric means. It then determines the final score statistic for each metric depending on the eval_mode, and appends it to agg_scores.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/logger/log_parser.py\":78-98",
            "content": "            consider = [\"R1\", \"R5\", \"R10\"]\n            seeds = list(scores[\"R1\"].keys())\n            for seed in seeds:\n                for metric, subdict in scores.items():\n                    if metric in consider:\n                        geometric_stats[seed].append(subdict[seed])\n                gms_raw = np.array(geometric_stats[seed])\n                geo_means = scipy.stats.mstats.gmean(gms_raw, axis=0)\n                best_epochs[seed] = np.argmax(geo_means)\n        for metric, subdict in scores.items():\n            for seed, values in subdict.items():\n                if eval_mode == \"test_run\":\n                    stat = values[0]\n                elif eval_mode == \"fixed_num_epochs\":\n                    stat = values[fixed_num_epochs - 1]\n                elif \"LSMDC\" in log_path and eval_mode == \"geometric_mean\":\n                    stat = values[best_epochs[seed]]\n                else:\n                    raise ValueError(f\"unrecognised eval_mode: {eval_mode}\")\n                agg_scores[metric].append(stat)"
        },
        {
            "comment": "This code snippet checks if the evaluation mode is set to \"fixed_num_epochs\". If so, it logs a message indicating the fixed training length. Then, for each metric in the aggregated scores, it calculates the mean and standard deviation using numpy's `np.mean()` and `np.std()`, respectively, and logs the values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/T2VLAD/logger/log_parser.py\":100-103",
            "content": "        if eval_mode == \"fixed_num_epochs\":\n            logger.info(f\"Reporting stats with fixed training length: {fixed_num_epochs}\")\n        for metric, values in agg_scores.items():\n            logger.info(f\"{metric}: {np.mean(values):.1f}, {np.std(values, ddof=1):.1f}\")"
        }
    ]
}