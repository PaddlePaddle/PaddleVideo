{
    "summary": "The code defines a MoViNet model configuration with MobileNetV2 layers and parameters, constructing CNN layers and a MoViNet backbone class for video analysis. The model is configurable and can be causal or non-causal based on the 'causal' parameter.",
    "details": [
        {
            "comment": "This code contains the configuration for a MOViNet model. It specifies the number of blocks, convolutional layers, and filter sizes for each stage of the network. The configuration is stored in a dictionary format with keys like 'A0', 'b2_l0', and so on, representing different parts of the model architecture.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":0-26",
            "content": "import collections.abc\nfrom itertools import repeat\nfrom typing import Any, Callable, Optional, Tuple, Union\nimport paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as F\nfrom paddle.nn.layer import Identity\nfrom ..registry import BACKBONES\nfrom collections import OrderedDict\ncontainer_abcs = collections.abc\n\"\"\"Model Config\n\"\"\"\nA0 = {'block_num': [0, 1, 3, 3, 4, 4]}\nA0['conv1'] = [3, 8, (1, 3, 3), (1, 2, 2), (0, 1, 1)]\nA0['b2_l0'] = [8, 8, 24, (1, 5, 5), (1, 2, 2), (0, 2, 2), (0, 1, 1)]\nA0['b3_l0'] = [8, 32, 80, (3, 3, 3), (1, 2, 2), (1, 0, 0), (0, 0, 0)]\nA0['b3_l1'] = [32, 32, 80, (3, 3, 3), (1, 1, 1), (1, 1, 1), (0, 1, 1)]\nA0['b3_l2'] = [32, 32, 80, (3, 3, 3), (1, 1, 1), (1, 1, 1), (0, 1, 1)]\nA0['b4_l0'] = [32, 56, 184, (5, 3, 3), (1, 2, 2), (2, 0, 0), (0, 0, 0)]\nA0['b4_l1'] = [56, 56, 112, (3, 3, 3), (1, 1, 1), (1, 1, 1), (0, 1, 1)]\nA0['b4_l2'] = [56, 56, 184, (3, 3, 3), (1, 1, 1), (1, 1, 1), (0, 1, 1)]\nA0['b5_l0'] = [56, 56, 184, (5, 3, 3), (1, 1, 1), (2, 1, 1), (0, 1, 1)]\nA0['b5_l1'] = [56, 56, 184, (3, 3, 3), (1, 1, 1), (1, 1, 1), (0, 1, 1)]"
        },
        {
            "comment": "This code defines a model architecture for the MobileNetV2 network, specifying the number of filters, kernel sizes, and stride values at each layer. The `_ntuple` function parses layer configurations, and `_make_divisible` ensures all layers have a divisible channel number. The dictionary `MODEL_CONFIG` stores these configuration parameters for the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":27-54",
            "content": "A0['b5_l2'] = [56, 56, 184, (3, 3, 3), (1, 1, 1), (1, 1, 1), (0, 1, 1)]\nA0['b5_l3'] = [56, 56, 184, (3, 3, 3), (1, 1, 1), (1, 1, 1), (0, 1, 1)]\nA0['b6_l0'] = [56, 104, 384, (5, 3, 3), (1, 2, 2), (2, 1, 1), (0, 1, 1)]\nA0['b6_l1'] = [104, 104, 280, (1, 5, 5), (1, 1, 1), (0, 2, 2), (0, 1, 1)]\nA0['b6_l2'] = [104, 104, 280, (1, 5, 5), (1, 1, 1), (0, 2, 2), (0, 1, 1)]\nA0['b6_l3'] = [104, 104, 344, (1, 5, 5), (1, 1, 1), (0, 2, 2), (0, 1, 1)]\nA0['conv7'] = [104, 480, (1, 1, 1), (1, 1, 1), (0, 0, 0)]\nMODEL_CONFIG = {'A0': A0}\ndef _ntuple(n):\n    def parse(x):\n        if isinstance(x, container_abcs.Iterable):\n            return x\n        return tuple(repeat(x, n))\n    return parse\ndef _make_divisible(v: float,\n                    divisor: int,\n                    min_value: Optional[int] = None) -> int:\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8.\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py"
        },
        {
            "comment": "The code defines a CausalModule class that contains an activation layer and resets it when needed. Conv2dBNActivation is a Sequential module with optional normalization and activation layers, used in the construction of the MoviNet backbone model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":55-93",
            "content": "    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n_single = _ntuple(1)\n_pair = _ntuple(2)\n_triple = _ntuple(3)\n_quadruple = _ntuple(4)\nclass CausalModule(nn.Layer):\n    def __init__(self) -> None:\n        super().__init__()\n        self.activation = None\n    def reset_activation(self) -> None:\n        self.activation = None\nclass Conv2dBNActivation(nn.Sequential):\n    def __init__(\n        self,\n        in_planes: int,\n        out_planes: int,\n        kernel_size: Union[int, Tuple[int, int]],\n        padding: Union[int, Tuple[int, int]],\n        stride: Union[int, Tuple[int, int]] = 1,\n        groups: int = 1,\n        norm_layer: Optional[Callable[..., nn.Layer]] = None,\n        activation_layer: Optional[Callable[..., nn.Layer]] = None,\n        **kwargs: Any,\n    ) -> None:\n        kernel_size = _pair(kernel_size)"
        },
        {
            "comment": "This code defines two classes, `Conv2dBNActivation` and `Conv3DBNActivation`, which are convolutional neural network layers with batch normalization and activation functions. The layers have adjustable input (in_planes), output (out_planes), kernel size, stride, padding, and groups parameters. The batch normalization layer uses a momentum of 0.1, and the activation function is an Identity function by default but can be overridden with another specified activation function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":94-120",
            "content": "        stride = _pair(stride)\n        padding = _pair(padding)\n        if norm_layer is None:\n            norm_layer = Identity\n        if activation_layer is None:\n            activation_layer = Identity\n        self.kernel_size = kernel_size\n        self.stride = stride\n        dict_layers = (nn.Conv2D(in_planes,\n                                 out_planes,\n                                 kernel_size=kernel_size,\n                                 stride=stride,\n                                 padding=padding,\n                                 groups=groups,\n                                 **kwargs), norm_layer(out_planes,\n                                                       momentum=0.1),\n                       activation_layer())\n        self.out_channels = out_planes\n        super(Conv2dBNActivation, self).__init__(dict_layers[0], dict_layers[1],\n                                                 dict_layers[2])\nclass Conv3DBNActivation(nn.Sequential):\n    def __init__(\n        self,\n        in_planes: int,"
        },
        {
            "comment": "This function is creating a Conv3D layer with specified parameters, including the number of input and output planes, kernel size, padding, stride, groups, and optional norm and activation layers. The function also ensures that the input values for kernel_size, stride, and padding are correctly formatted as triples.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":121-146",
            "content": "        out_planes: int,\n        kernel_size: Union[int, Tuple[int, int, int]],\n        padding: Union[int, Tuple[int, int, int]],\n        stride: Union[int, Tuple[int, int, int]] = 1,\n        groups: int = 1,\n        norm_layer: Optional[Callable[..., nn.Layer]] = None,\n        activation_layer: Optional[Callable[..., nn.Layer]] = None,\n        **kwargs: Any,\n    ) -> None:\n        kernel_size = _triple(kernel_size)\n        stride = _triple(stride)\n        padding = _triple(padding)\n        if norm_layer is None:\n            norm_layer = Identity\n        if activation_layer is None:\n            activation_layer = Identity\n        self.kernel_size = kernel_size\n        self.stride = stride\n        dict_layers = (nn.Conv3D(in_planes,\n                                 out_planes,\n                                 kernel_size=kernel_size,\n                                 stride=stride,\n                                 padding=padding,\n                                 groups=groups,\n                                 **kwargs), norm_layer(out_planes,"
        },
        {
            "comment": "The code defines a class named `ConvBlock3D` as a subclass of `CausalModule`. It takes inputs such as the number of input and output planes, kernel size, causality status, convolution type, padding, stride, normalization layer, activation layer, bias attribute, and optional keyword arguments. It initializes the class variables and creates an instance of the `Conv3DBNActivation` class.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":147-176",
            "content": "                                                       momentum=0.1),\n                       activation_layer())\n        self.out_channels = out_planes\n        super(Conv3DBNActivation, self).__init__(dict_layers[0], dict_layers[1],\n                                                 dict_layers[2])\nclass ConvBlock3D(CausalModule):\n    def __init__(\n        self,\n        in_planes: int,\n        out_planes: int,\n        kernel_size: Union[int, Tuple[int, int, int]],\n        causal: bool,\n        conv_type: str,\n        padding: Union[int, Tuple[int, int, int]] = 0,\n        stride: Union[int, Tuple[int, int, int]] = 1,\n        norm_layer: Optional[Callable[..., nn.Layer]] = None,\n        activation_layer: Optional[Callable[..., nn.Layer]] = None,\n        bias_attr: bool = False,\n        **kwargs: Any,\n    ) -> None:\n        super().__init__()\n        kernel_size = _triple(kernel_size)\n        stride = _triple(stride)\n        padding = _triple(padding)\n        self.conv_2 = None\n        if causal is True:\n            padding = (0, padding[1], padding[2])"
        },
        {
            "comment": "This code is checking the convolution type and raising a ValueError if it's neither \"2plus1d\" nor \"3d\". If the type is \"2plus1d\", it initializes two Conv2dBNActivation layers with appropriate parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":177-195",
            "content": "        if conv_type != \"2plus1d\" and conv_type != \"3d\":\n            raise ValueError(\"only 2plus2d or 3d are \" +\n                             \"allowed as 3d convolutions\")\n        if conv_type == \"2plus1d\":\n            self.conv_1 = Conv2dBNActivation(in_planes,\n                                             out_planes,\n                                             kernel_size=(kernel_size[1],\n                                                          kernel_size[2]),\n                                             padding=(padding[1], padding[2]),\n                                             stride=(stride[1], stride[2]),\n                                             activation_layer=activation_layer,\n                                             norm_layer=norm_layer,\n                                             bias_attr=bias_attr,\n                                             **kwargs)\n            if kernel_size[0] > 1:\n                self.conv_2 = Conv2dBNActivation(\n                    in_planes,\n                    out_planes,"
        },
        {
            "comment": "The code defines a layer with different convolution types (\"2d\" or \"3d\") and initializes the corresponding Conv2D or Conv3D layers with specified parameters such as input/output planes, kernel size, padding, activation layer, norm layer, stride, bias attribute and other keyword arguments. It also stores the padding and kernel size for future use.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":196-215",
            "content": "                    kernel_size=(kernel_size[0], 1),\n                    padding=(padding[0], 0),\n                    stride=(stride[0], 1),\n                    activation_layer=activation_layer,\n                    norm_layer=norm_layer,\n                    bias_attr=bias_attr,\n                    **kwargs)\n        elif conv_type == \"3d\":\n            self.conv_1 = Conv3DBNActivation(in_planes,\n                                             out_planes,\n                                             kernel_size=kernel_size,\n                                             padding=padding,\n                                             activation_layer=activation_layer,\n                                             norm_layer=norm_layer,\n                                             stride=stride,\n                                             bias_attr=bias_attr,\n                                             **kwargs)\n        self.padding = padding\n        self.kernel_size = kernel_size\n        self.dim_pad = self.kernel_size[0] - 1"
        },
        {
            "comment": "This code defines a class with an attribute `_forward` method. The constructor takes stride, causal, and conv_type as parameters. If causal is True, stream buffer is concatenated to the input tensor. Depending on conv_type, the tensor shape may be reshaped for proper processing. Finally, if conv_2 is not None, it applies a convolution operation to the tensor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":216-237",
            "content": "        self.stride = stride\n        self.causal = causal\n        self.conv_type = conv_type\n    def _forward(self, x: paddle.Tensor) -> paddle.Tensor:\n        if self.dim_pad > 0 and self.conv_2 is None and self.causal is True:\n            x = self._cat_stream_buffer(x)\n        b, c, t, h, w = x.shape\n        if self.conv_type == \"2plus1d\":\n            x = paddle.transpose(x, (0, 2, 1, 3, 4))  # bcthw --> btchw\n            x = paddle.reshape_(x, (-1, c, h, w))  # btchw --> bt,c,h,w\n        x = self.conv_1(x)\n        if self.conv_type == \"2plus1d\":\n            b, c, h, w = x.shape\n            x = paddle.reshape_(x, (-1, t, c, h, w))  # bt,c,h,w --> b,t,c,h,w\n            x = paddle.transpose(x, (0, 2, 1, 3, 4))  # b,t,c,h,w --> b,c,t,h,w\n            if self.conv_2 is not None:\n                if self.dim_pad > 0 and self.causal is True:\n                    x = self._cat_stream_buffer(x)\n                b, c, t, h, w = x.shape\n                x = paddle.reshape_(x, (b, c, t, h * w))\n                x = self.conv_2(x)"
        },
        {
            "comment": "1. Reshapes input tensor to (b, c, t, h, w).\n2. Defines a forward function that applies the _forward function and returns the result.\n3. Concatenates the activation tensor with the input along dimension 2.\n4. Saves the last self.dim_pad rows of the input in the activation tensor.\n5. Sets up the activation tensor with zeros and self.dim_pad rows for future use.\n6. TemporalCGAvgPool3D is a CausalModule class.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":238-268",
            "content": "                b, c, t, _ = x.shape\n                x = paddle.reshape_(x, (b, c, t, h, w))\n        return x\n    def forward(self, x: paddle.Tensor) -> paddle.Tensor:\n        x = self._forward(x)\n        return x\n    def _cat_stream_buffer(self, x: paddle.Tensor) -> paddle.Tensor:\n        if self.activation is None:\n            self._setup_activation(x.shape)\n        x = paddle.concat((self.activation, x), 2)\n        self._save_in_activation(x)\n        return x\n    def _save_in_activation(self, x: paddle.Tensor) -> None:\n        assert self.dim_pad > 0\n        self.activation = paddle.to_tensor(x.numpy()[:, :, -self.dim_pad:,\n                                                     ...]).clone().detach()\n    def _setup_activation(self, input_shape: Tuple[float, ...]) -> None:\n        assert self.dim_pad > 0\n        self.activation = paddle.zeros(shape=[\n            *input_shape[:2],  # type: ignore\n            self.dim_pad,\n            *input_shape[3:]\n        ])\nclass TemporalCGAvgPool3D(CausalModule):\n    def __init__(self, ) -> None:"
        },
        {
            "comment": "The code defines a forward function for a CausalModule that performs cumulative sum operation on input tensor. It also includes methods to detach and reset the activation tensor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":269-295",
            "content": "        super().__init__()\n        self.n_cumulated_values = 0\n        self.register_forward_post_hook(self._detach_activation)\n    def forward(self, x: paddle.Tensor) -> paddle.Tensor:\n        input_shape = x.shape\n        cumulative_sum = paddle.cumsum(x, axis=2)\n        if self.activation is None:\n            self.activation = cumulative_sum[:, :, -1:].clone()\n        else:\n            cumulative_sum += self.activation\n            self.activation = cumulative_sum[:, :, -1:].clone()\n        noe = paddle.arange(1, input_shape[2] + 1)\n        axis = paddle.to_tensor([0, 1, 3, 4])\n        noe = paddle.unsqueeze(noe, axis=axis)\n        divisor = noe.expand(x.shape)\n        x = cumulative_sum / (self.n_cumulated_values + divisor)\n        self.n_cumulated_values += input_shape[2]\n        return x\n    @staticmethod\n    def _detach_activation(module: CausalModule, inputs: paddle.Tensor,\n                           output: paddle.Tensor) -> None:\n        module.activation.detach()\n    def reset_activation(self) -> None:"
        },
        {
            "comment": "This code defines a SqueezeExcitation layer class with input channels, activation functions, convolution type, causality flag, and squeeze factor as parameters. It initializes the layer by setting the causal flag's multiplier, dividing the input channel count by the squeeze factor, rounding up to 8 using make_divisible function, and adding temporal cumulative average pooling and convolution blocks with specified parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":296-321",
            "content": "        super().reset_activation()\n        self.n_cumulated_values = 0\nclass SqueezeExcitation(nn.Layer):\n    def __init__(self,\n                 input_channels: int,\n                 activation_2: nn.Layer,\n                 activation_1: nn.Layer,\n                 conv_type: str,\n                 causal: bool,\n                 squeeze_factor: int = 4,\n                 bias_attr: bool = True) -> None:\n        super().__init__()\n        self.causal = causal\n        se_multiplier = 2 if causal else 1\n        squeeze_channels = _make_divisible(\n            input_channels // squeeze_factor * se_multiplier, 8)\n        self.temporal_cumualtive_GAvg3D = TemporalCGAvgPool3D()\n        self.fc1 = ConvBlock3D(input_channels * se_multiplier,\n                               squeeze_channels,\n                               kernel_size=(1, 1, 1),\n                               padding=0,\n                               causal=causal,\n                               conv_type=conv_type,\n                               bias_attr=bias_attr)"
        },
        {
            "comment": "The code defines a class with two activation functions, and a _scale method that scales the input tensor based on temporal average or average pooling. The forward method applies the scale to the input for spatial pyramid pooling.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":322-346",
            "content": "        self.activation_1 = activation_1()\n        self.activation_2 = activation_2()\n        self.fc2 = ConvBlock3D(squeeze_channels,\n                               input_channels,\n                               kernel_size=(1, 1, 1),\n                               padding=0,\n                               causal=causal,\n                               conv_type=conv_type,\n                               bias_attr=bias_attr)\n    def _scale(self, inputs: paddle.Tensor) -> paddle.Tensor:\n        if self.causal:\n            x_space = paddle.mean(inputs, axis=[3, 4], keepdim=True)\n            scale = self.temporal_cumualtive_GAvg3D(x_space)\n            scale = paddle.concat((scale, x_space), axis=1)\n        else:\n            scale = F.adaptive_avg_pool3d(inputs, 1)\n        scale = self.fc1(scale)\n        scale = self.activation_1(scale)\n        scale = self.fc2(scale)\n        return self.activation_2(scale)\n    def forward(self, inputs: paddle.Tensor) -> paddle.Tensor:\n        scale = self._scale(inputs)\n        return scale * inputs"
        },
        {
            "comment": "This code defines the BasicBneck class which is a neural network layer. It has multiple parameters such as input_channels, out_channels, expanded_channels, kernel_size, stride, padding, padding_avg, causal, conv_type, norm_layer, and activation_layer. If expanded_channels is not equal to out_channels, it will first expand the channels using ConvBlock3D. The class also checks for illegal stride values to prevent unexpected behavior.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":349-381",
            "content": "class BasicBneck(nn.Layer):\n    def __init__(\n        self,\n        input_channels,\n        out_channels,\n        expanded_channels,\n        kernel_size,\n        stride,\n        padding,\n        padding_avg,\n        causal: bool,\n        conv_type: str,\n        norm_layer: Optional[Callable[..., nn.Layer]] = None,\n        activation_layer: Optional[Callable[..., nn.Layer]] = None,\n    ) -> None:\n        super().__init__()\n        assert type(stride) is tuple\n        if (not stride[0] == 1 or not (1 <= stride[1] <= 2)\n                or not (1 <= stride[2] <= 2)):\n            raise ValueError('illegal stride value')\n        self.res = None\n        layers = []\n        if expanded_channels != out_channels:\n            # expand\n            self.expand = ConvBlock3D(in_planes=input_channels,\n                                      out_planes=expanded_channels,\n                                      kernel_size=(1, 1, 1),\n                                      padding=(0, 0, 0),\n                                      causal=causal,"
        },
        {
            "comment": "This code defines a ConvBlock3D for MoviNet backbone, includes deepwise convolution and SE (Squeeze Excitation) layers. These components process 3D feature maps with various configurations depending on the input planes, kernel size, stride, padding, etc., applying different activation functions based on the conv_type.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":382-403",
            "content": "                                      conv_type=conv_type,\n                                      norm_layer=norm_layer,\n                                      activation_layer=activation_layer)\n        # deepwise\n        self.deep = ConvBlock3D(in_planes=expanded_channels,\n                                out_planes=expanded_channels,\n                                kernel_size=kernel_size,\n                                padding=padding,\n                                stride=stride,\n                                groups=expanded_channels,\n                                causal=causal,\n                                conv_type=conv_type,\n                                norm_layer=norm_layer,\n                                activation_layer=activation_layer)\n        # SE\n        self.se = SqueezeExcitation(\n            expanded_channels,\n            causal=causal,\n            activation_1=activation_layer,\n            activation_2=(nn.Sigmoid if conv_type == \"3d\" else nn.Hardsigmoid),\n            conv_type=conv_type)"
        },
        {
            "comment": "This code defines a ConvBlock3D for projecting the input channels to the desired output channels. If the stride is not (1, 1, 1) or input and output channels are different, it adds an average pooling layer and another ConvBlock3D with appropriate parameters. The causal parameter determines if causal convolution should be used, and Identity activation layer is applied without any transformation.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":404-426",
            "content": "        # project\n        self.project = ConvBlock3D(expanded_channels,\n                                   out_channels,\n                                   kernel_size=(1, 1, 1),\n                                   padding=(0, 0, 0),\n                                   causal=causal,\n                                   conv_type=conv_type,\n                                   norm_layer=norm_layer,\n                                   activation_layer=Identity)\n        if not (stride == (1, 1, 1) and input_channels == out_channels):\n            if stride != (1, 1, 1):\n                layers.append(\n                    nn.AvgPool3D((1, 3, 3), stride=stride, padding=padding_avg))\n            layers.append(\n                ConvBlock3D(\n                    in_planes=input_channels,\n                    out_planes=out_channels,\n                    kernel_size=(1, 1, 1),\n                    padding=(0, 0, 0),\n                    norm_layer=norm_layer,\n                    activation_layer=Identity,\n                    causal=causal,"
        },
        {
            "comment": "The code defines the MoViNet class, which is a backbone model for video analysis. It initializes layers based on input parameters and then performs feature extraction using the defined layers. The forward method applies residual connections and a scale factor to combine the extracted features with the input.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":427-463",
            "content": "                    conv_type=conv_type,\n                ))\n            self.res = nn.Sequential(*layers)\n        self.alpha = self.create_parameter(shape=[1], dtype=\"float32\")\n    def forward(self, inputs: paddle.Tensor) -> paddle.Tensor:\n        if self.res is not None:\n            residual = self.res(inputs)\n        else:\n            residual = inputs\n        if self.expand is not None:\n            x = self.expand(inputs)\n        else:\n            x = inputs\n        x = self.deep(x)\n        x = self.se(x)\n        x = self.project(x)\n        result = residual + self.alpha * x\n        return result\n@BACKBONES.register()\nclass MoViNet(nn.Layer):\n    def __init__(\n        self,\n        model_type: str = 'A0',\n        hidden_dim: int = 2048,\n        causal: bool = True,\n        num_classes: int = 400,\n        conv_type: str = \"3d\",\n    ) -> None:\n        super().__init__()\n        \"\"\"\n        causal: causal mode\n        num_classes: number of classes for classifcation\n        conv_type: type of convolution either 3d or 2plus1d"
        },
        {
            "comment": "The code defines a MOViNet model, which consists of a ConvBlock3D (conv1) and multiple BasicBneck blocks. It takes in parameters such as the number of input and output planes, kernel size, stride, padding, causal flag, conv type, norm layer, and activation layer. These parameters are extracted from the MODEL_CONFIG dictionary based on the model type. The blocks are organized in an OrderedDict called blocks_dic for future reference.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":464-486",
            "content": "        \"\"\"\n        blocks_dic = OrderedDict()\n        cfg = MODEL_CONFIG[model_type]\n        norm_layer = nn.BatchNorm3D if conv_type == \"3d\" else nn.BatchNorm2D\n        activation_layer = nn.Swish if conv_type == \"3d\" else nn.Hardswish\n        # conv1\n        self.conv1 = ConvBlock3D(in_planes=cfg['conv1'][0],\n                                 out_planes=cfg['conv1'][1],\n                                 kernel_size=cfg['conv1'][2],\n                                 stride=cfg['conv1'][3],\n                                 padding=cfg['conv1'][4],\n                                 causal=causal,\n                                 conv_type=conv_type,\n                                 norm_layer=norm_layer,\n                                 activation_layer=activation_layer)\n        # blocks\n        for i in range(2, len(cfg['block_num']) + 1):\n            for j in range(cfg['block_num'][i - 1]):\n                blocks_dic[f'b{i}_l{j}'] = BasicBneck(\n                    cfg[f'b{i}_l{j}'][0],\n                    cfg[f'b{i}_l{j}'][1],"
        },
        {
            "comment": "This code is defining a MOViNet model with specific configurations for blocks, convolutional layers, and pooling operations. It initializes the blocks as sequential layers and adds an additional 3D ConvBlock layer ('conv7') followed by a classifier.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":487-509",
            "content": "                    cfg[f'b{i}_l{j}'][2],\n                    cfg[f'b{i}_l{j}'][3],\n                    cfg[f'b{i}_l{j}'][4],\n                    cfg[f'b{i}_l{j}'][5],\n                    cfg[f'b{i}_l{j}'][6],\n                    causal=causal,\n                    conv_type=conv_type,\n                    norm_layer=norm_layer,\n                    activation_layer=activation_layer)\n        self.blocks = nn.Sequential(*(blocks_dic.values()))\n        # conv7\n        self.conv7 = ConvBlock3D(in_planes=cfg['conv7'][0],\n                                 out_planes=cfg['conv7'][1],\n                                 kernel_size=cfg['conv7'][2],\n                                 stride=cfg['conv7'][3],\n                                 padding=cfg['conv7'][4],\n                                 causal=causal,\n                                 conv_type=conv_type,\n                                 norm_layer=norm_layer,\n                                 activation_layer=activation_layer)\n        # pool\n        self.classifier = nn.Sequential("
        },
        {
            "comment": "This code defines a 3D Convolutional Neural Network (CNN) backbone for MoviNet. It includes dense layers, convolution blocks, and optional temporal pooling. The model architecture can be causal or non-causal depending on the `causal` parameter.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":510-538",
            "content": "            # dense9\n            ConvBlock3D(in_planes=cfg['conv7'][1],\n                        out_planes=hidden_dim,\n                        kernel_size=(1, 1, 1),\n                        causal=causal,\n                        conv_type=conv_type,\n                        bias_attr=True),\n            nn.Swish(),\n            nn.Dropout(p=0.2),\n            # dense10d\n            ConvBlock3D(in_planes=hidden_dim,\n                        out_planes=num_classes,\n                        kernel_size=(1, 1, 1),\n                        causal=causal,\n                        conv_type=conv_type,\n                        bias_attr=True),\n        )\n        if causal:\n            self.cgap = TemporalCGAvgPool3D()\n        self.apply(self._weight_init)\n        self.causal = causal\n    def avg(self, x: paddle.Tensor) -> paddle.Tensor:\n        if self.causal:\n            avg = F.adaptive_avg_pool3d(x, (x.shape[2], 1, 1))\n            avg = self.cgap(avg)[:, :, -1:]\n        else:\n            avg = F.adaptive_avg_pool3d(x, 1)\n        return avg"
        },
        {
            "comment": "The code defines a class for a MoviNet backbone, which performs convolutions and has block layers. The forward function passes the input through these layers and then flattens the result before returning it. A static method initializes the network weights based on the layer type. Another static method cleans activation buffers in CausalModule subclasses.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":540-571",
            "content": "    @staticmethod\n    def _weight_init(m):\n        if isinstance(m, nn.Conv3D):\n            nn.initializer.KaimingNormal(m.weight)\n            if m.bias is not None:\n                nn.initializer.Constant(0.0)(m.bias)\n        elif isinstance(m, (nn.BatchNorm3D, nn.BatchNorm2D, nn.GroupNorm)):\n            nn.initializer.Constant(1.0)(m.weight)\n            nn.initializer.Constant(0.0)(m.bias)\n        elif isinstance(m, nn.Linear):\n            nn.initializer.Normal(m.weight, 0, 0.01)\n            nn.initializer.Constant(0.0)(m.bias)\n    def forward(self, x: paddle.Tensor) -> paddle.Tensor:\n        x = self.conv1(x)\n        x = self.blocks(x)\n        x = self.conv7(x)\n        x = self.avg(x)\n        x = self.classifier(x)\n        x = x.flatten(1)\n        return x\n    @staticmethod\n    def _clean_activation_buffers(m):\n        if issubclass(type(m), CausalModule):\n            m.reset_activation()\n    def clean_activation_buffers(self) -> None:\n        self.apply(self._clean_activation_buffers)\nif __name__ == '__main__':"
        },
        {
            "comment": "Creating a MoViNet network instance with causal set to False and 3D convolution type, then generating summary using Paddle's summary function with input size (1, 3, 8, 224, 224).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/movinet.py\":572-573",
            "content": "    net = MoViNet(causal=False, conv_type='3d')\n    paddle.summary(net, input_size=(1, 3, 8, 224, 224))"
        }
    ]
}