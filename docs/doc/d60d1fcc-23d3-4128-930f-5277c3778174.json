{
    "summary": "The code constructs a PaddleVideo pipeline for preprocessing data and builds a data loader for distributed model training, handling variable batch sizes and using mix_collate_fn to collate data.",
    "details": [
        {
            "comment": "The code is building a pipeline for PaddleVideo. It imports necessary libraries and classes, utilizes function to build the pipeline, logs information using get_logger from paddlevideo.utils, and adheres to Apache License 2.0. The purpose of this code seems to be related to data preprocessing and possibly model training in a distributed environment.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/builder.py\":0-28",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport signal\nimport os\nimport paddle\nfrom paddle.io import DataLoader, DistributedBatchSampler\nfrom .registry import DATASETS, PIPELINES\nfrom ..utils.build_utils import build\nfrom .pipelines.compose import Compose\nfrom paddlevideo.utils import get_logger\nfrom paddlevideo.utils.multigrid import DistributedShortSampler\nimport numpy as np\nlogger = get_logger(\"paddlevideo\")\ndef build_pipeline(cfg):\n    \"\"\"Build pipeline."
        },
        {
            "comment": "build_dataset: Builds a dataset using provided config dictionary, building pipeline first.\nbuild_batch_pipeline: Constructs the batch pipeline using config from the PIPELINES module.\nbuild_dataloader: Creates Paddle Dataloader object using specified parameters and dataset.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/builder.py\":29-73",
            "content": "    Args:\n        cfg (dict): root config dict.\n    \"\"\"\n    if cfg == None:\n        return\n    return Compose(cfg)\ndef build_dataset(cfg):\n    \"\"\"Build dataset.\n    Args:\n        cfg (dict): root config dict.\n    Returns:\n        dataset: dataset.\n    \"\"\"\n    #XXX: ugly code here!\n    cfg_dataset, cfg_pipeline = cfg\n    cfg_dataset.pipeline = build_pipeline(cfg_pipeline)\n    dataset = build(cfg_dataset, DATASETS, key=\"format\")\n    return dataset\ndef build_batch_pipeline(cfg):\n    batch_pipeline = build(cfg, PIPELINES)\n    return batch_pipeline\ndef build_dataloader(dataset,\n                     batch_size,\n                     num_workers,\n                     places,\n                     shuffle=True,\n                     drop_last=True,\n                     multigrid=False,\n                     collate_fn_cfg=None,\n                     **kwargs):\n    \"\"\"Build Paddle Dataloader.\n    XXX explain how the dataloader work!\n    Args:\n        dataset (paddle.dataset): A PaddlePaddle dataset object.\n        batch_size (int): batch size on single card."
        },
        {
            "comment": "This code appears to be part of a data loading and processing function for a machine learning or deep learning model. It uses a sampler to manage the data, with options for shuffling and dropping the last batch if needed. The mix_collate_fn function is defined to collate the data in a specific way using a pipeline built from collate_fn_cfg.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/builder.py\":74-95",
            "content": "        num_worker (int): num_worker\n        shuffle(bool): whether to shuffle the data at every epoch.\n    \"\"\"\n    if multigrid:\n        sampler = DistributedShortSampler(dataset,\n                                          batch_sizes=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)\n    else:\n        sampler = DistributedBatchSampler(dataset,\n                                          batch_size=batch_size,\n                                          shuffle=shuffle,\n                                          drop_last=drop_last)\n    #NOTE(shipping): when switch the mix operator on, such as: mixup, cutmix.\n    # batch like: [[img, label, attibute, ...], [imgs, label, attribute, ...], ...] will recollate to:\n    # [[img, img, ...], [label, label, ...], [attribute, attribute, ...], ...] as using numpy.transpose.\n    def mix_collate_fn(batch):\n        pipeline = build_batch_pipeline(collate_fn_cfg)\n        batch = pipeline(batch)\n        slots = []"
        },
        {
            "comment": "This code appears to create a data loader that can handle batches of varying lengths. It iterates through each batch and organizes the items into slots based on their length, either creating a new slot for longer items or appending them to existing ones. The DataLoader class is then instantiated with this collate_fn for processing the dataset, using the provided parameters. Additionally, signal handlers are set up to handle SIGINT and SIGTERM signals to terminate the process group if needed.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/builder.py\":96-131",
            "content": "        for items in batch:\n            for i, item in enumerate(items):\n                if len(slots) < len(items):\n                    slots.append([item])\n                else:\n                    slots[i].append(item)\n        return [np.stack(slot, axis=0) for slot in slots]\n    #if collate_fn_cfg is not None:\n    #ugly code here. collate_fn is mix op config\n    #    collate_fn = mix_collate_fn(collate_fn_cfg)\n    data_loader = DataLoader(\n        dataset,\n        batch_sampler=sampler,\n        places=places,\n        num_workers=num_workers,\n        collate_fn=mix_collate_fn if collate_fn_cfg is not None else None,\n        return_list=True,\n        **kwargs)\n    return data_loader\ndef term_mp(sig_num, frame):\n    \"\"\" kill all child processes\n    \"\"\"\n    pid = os.getpid()\n    pgid = os.getpgid(os.getpid())\n    logger.info(\"main proc {} exit, kill process group \" \"{}\".format(pid, pgid))\n    os.killpg(pgid, signal.SIGKILL)\n    return\nsignal.signal(signal.SIGINT, term_mp)\nsignal.signal(signal.SIGTERM, term_mp)"
        }
    ]
}