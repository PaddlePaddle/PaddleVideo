{
    "summary": "The code defines an AttentionLSTM class for a video tagging model, extending ModelBase. It initializes properties, retrieves configurations and dimensions, builds the LSTM attention model, applies fully connected layers, and uses an optimizer with piecewise learning rate decay and L2 regularization.",
    "details": [
        {
            "comment": "The code is importing necessary modules and defining a class called AttentionLSTM. It extends the ModelBase class and has an __init__ method to initialize its properties such as name, configuration, mode, and is_videotag flag. The get_config method is also defined for retrieving configuration from a file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/models/attention_lstm/attention_lstm.py\":0-30",
            "content": "#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n#Licensed under the Apache License, Version 2.0 (the \"License\");\n#you may not use this file except in compliance with the License.\n#You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#Unless required by applicable law or agreed to in writing, software\n#distributed under the License is distributed on an \"AS IS\" BASIS,\n#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#See the License for the specific language governing permissions and\n#limitations under the License.\nfrom ..model import ModelBase\nfrom .lstm_attention import LSTMAttentionModel\nimport logging\nimport paddle\nimport paddle.static as static\nlogger = logging.getLogger(__name__)\n__all__ = [\"AttentionLSTM\"]\nclass AttentionLSTM(ModelBase):\n    def __init__(self, name, cfg, mode='train', is_videotag=False):\n        super(AttentionLSTM, self).__init__(name, cfg, mode)\n        self.is_videotag = is_videotag\n        self.get_config()"
        },
        {
            "comment": "The code defines a model's configuration method, retrieving feature names, dimensions, number of classes, embedding size, LSTM size, and drop rate. It also gets mode-specific configurations such as batch size, number of GPUs, learning rate, weight decay, total training samples, and epochs for learning rate decay.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/models/attention_lstm/attention_lstm.py\":32-53",
            "content": "    def get_config(self):\n        # get model configs\n        self.feature_names = self.cfg.MODEL.feature_names\n        self.feature_dims = self.cfg.MODEL.feature_dims\n        self.num_classes = self.cfg.MODEL.num_classes\n        self.embedding_size = self.cfg.MODEL.embedding_size\n        self.lstm_size = self.cfg.MODEL.lstm_size\n        self.drop_rate = self.cfg.MODEL.drop_rate\n        # get mode configs\n        self.batch_size = self.get_config_from_sec(self.mode, 'batch_size', 1)\n        self.num_gpus = self.get_config_from_sec(self.mode, 'num_gpus', 1)\n        if self.mode == 'train':\n            self.learning_rate = self.get_config_from_sec(\n                'train', 'learning_rate', 1e-3)\n            self.weight_decay = self.get_config_from_sec(\n                'train', 'weight_decay', 8e-4)\n            self.num_samples = self.get_config_from_sec('train', 'num_samples',\n                                                        5000000)\n            self.decay_epochs = self.get_config_from_sec(\n                'train', 'decay_epochs', [5])"
        },
        {
            "comment": "The code initializes feature and label inputs for the model, depending on the mode. It also builds a dataloader if use_dataloader is True, but not recommended in infer mode.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/models/attention_lstm/attention_lstm.py\":54-75",
            "content": "            self.decay_gamma = self.get_config_from_sec('train', 'decay_gamma',\n                                                        0.1)\n    def build_input(self, use_dataloader):\n        self.feature_input = []\n        for name, dim in zip(self.feature_names, self.feature_dims):\n            self.feature_input.append(\n                static.data(shape=[None, dim],\n                           lod_level=1,\n                           dtype='float32',\n                           name=name))\n        if self.mode != 'infer':\n            self.label_input = static.data(shape=[None, self.num_classes],\n                                          dtype='float32',\n                                          name='label')\n        else:\n            self.label_input = None\n        if use_dataloader:\n            assert self.mode != 'infer', \\\n                    'dataloader is not recommendated when infer, please set use_dataloader to be false.'\n            self.dataloader = paddle.io.DataLoader.from_generator(\n                feed_list=self.feature_input + [self.label_input],"
        },
        {
            "comment": "This code defines a LSTM attention model with multiple input features. It concatenates output of each feature, applies fully connected layers, and returns the result.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/models/attention_lstm/attention_lstm.py\":76-102",
            "content": "                capacity=8,\n                iterable=True)\n    def build_model(self):\n        att_outs = []\n        for i, (input_dim,\n                feature) in enumerate(zip(self.feature_dims,\n                                          self.feature_input)):\n            att = LSTMAttentionModel(input_dim, self.embedding_size,\n                                     self.lstm_size, self.drop_rate)\n            att_out = att.forward(feature, is_training=(self.mode == 'train'))\n            att_outs.append(att_out)\n        if len(att_outs) > 1:\n            out = paddle.concat(x=att_outs, axis=1)\n        else:\n            out = att_outs[0]  # video only, without audio in videoTag\n        fc1 = static.nn.fc(\n            x=out,\n            size=8192,\n            activation='relu',\n            bias_attr=paddle.ParamAttr(\n                regularizer=paddle.regularizer.L2Decay(coeff=0.0),\n                initializer=paddle.nn.initializer.Normal(std=0.0)),\n            name='fc1')\n        fc2 = static.nn.fc(\n            x=fc1,"
        },
        {
            "comment": "This code defines an attention LSTM model for video tagging. It uses a tanh activation function, L2 decay regularizer, and normal initializer for the fully connected layers. The logit layer applies sigmoid activation to output probabilities for each class. The optimizer function sets up a learning rate schedule using RMSProp optimizer with decay epochs and boundaries.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/models/attention_lstm/attention_lstm.py\":103-124",
            "content": "            size=4096,\n            activation='tanh',\n            bias_attr=paddle.ParamAttr(\n                regularizer=paddle.regularizer.L2Decay(coeff=0.0),\n                initializer=paddle.nn.initializer.Normal(std=0.0)),\n            name='fc2')\n        self.logit = static.nn.fc(x=fc2, size=self.num_classes, activation=None, \\\n                              bias_attr=paddle.ParamAttr(regularizer=paddle.regularizer.L2Decay(coeff=0.0),\n                                                  initializer=paddle.nn.initializer.Normal(std=0.0)), name='output')\n        self.output = paddle.nn.functional.sigmoid(self.logit)\n    def optimizer(self):\n        assert self.mode == 'train', \"optimizer only can be get in train mode\"\n        values = [\n            self.learning_rate * (self.decay_gamma**i)\n            for i in range(len(self.decay_epochs) + 1)\n        ]\n        iter_per_epoch = self.num_samples / self.batch_size\n        boundaries = [e * iter_per_epoch for e in self.decay_epochs]\n        return paddle.optimizer.RMSProp("
        },
        {
            "comment": "This code defines a model with an LSTM layer and attention mechanism. It uses piecewise learning rate decay, L2 weight decay regularization, calculates binary cross-entropy loss for classification tasks, and supports both training, validation, and inference modes.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/models/attention_lstm/attention_lstm.py\":125-150",
            "content": "            learning_rate=paddle.optimizer.lr.PiecewiseDecay(values=values,\n                                                       boundaries=boundaries),\n            centered=True,\n            weight_decay=paddle.regularizer.L2Decay(coeff=self.weight_decay))\n    def loss(self):\n        assert self.mode != 'infer', \"invalid loss calculationg in infer mode\"\n        cost = paddle.nn.functional.binary_cross_entropy(\n            input=self.logit, label=self.label_input, reduction=None)\n        cost = paddle.sum(x=cost, axis=-1)\n        sum_cost = paddle.sum(x=cost)\n        self.loss_ = paddle.scale(sum_cost,\n                                        scale=self.num_gpus,\n                                        bias_after_scale=False)\n        return self.loss_\n    def outputs(self):\n        return [self.output, self.logit]\n    def feeds(self):\n        return self.feature_input if self.mode == 'infer' else self.feature_input + [\n            self.label_input\n        ]\n    def fetches(self):\n        if self.mode == 'train' or self.mode == 'valid':"
        },
        {
            "comment": "This code defines a class with three methods. The first method, `fetch_list()`, returns the fetch list for different modes ('train', 'test', or 'infer'). In 'train' mode, it calculates losses and includes them in the fetch list. In 'test' mode, it does the same. In 'infer' mode, only the output is included in the fetch list. If an unrecognized mode is provided, a `NotImplementedError` is raised. The `weights_info()` method returns no information as it is not implemented yet. Lastly, the `load_pretrain_params()` method loads pretrained weights from a given file, excluding any \"fc_0\" layer parameters, and logs a message confirming this action.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/models/attention_lstm/attention_lstm.py\":151-179",
            "content": "            losses = self.loss()\n            fetch_list = [losses, self.output, self.label_input]\n        elif self.mode == 'test':\n            losses = self.loss()\n            fetch_list = [losses, self.output, self.label_input]\n        elif self.mode == 'infer':\n            fetch_list = [self.output]\n        else:\n            raise NotImplementedError('mode {} not implemented'.format(\n                self.mode))\n        return fetch_list\n    def weights_info(self):\n        return None, None\n    def load_pretrain_params(self, exe, pretrain, prog):\n        logger.info(\n            \"Load pretrain weights from {}, exclude fc layer.\".format(pretrain))\n        state_dict = paddle.static.load_program_state(pretrain)\n        dict_keys = list(state_dict.keys())\n        for name in dict_keys:\n            if \"fc_0\" in name:\n                del state_dict[name]\n                logger.info(\n                    'Delete {} from pretrained parameters. Do not load it'.\n                    format(name))\n        paddle.static.set_program_state(prog, state_dict)"
        }
    ]
}