{
    "summary": "The code initializes a ResNet-TSM backbone with convolutional layers and bottleneck blocks, but may be deprecated and needs data preparation changes for better compatibility.",
    "details": [
        {
            "comment": "This code snippet defines a ConvBNLayer class which combines a Conv2D and BatchNorm2D layer. It is imported from paddle.nn and will be used for creating convolutional neural network layers in the PaddlePaddle framework. The layer can be utilized to process image data or other types of spatial input data by applying convolution operations followed by batch normalization.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":0-29",
            "content": "# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport paddle\nimport paddle.nn as nn\nfrom paddle.nn import (Conv2D, BatchNorm2D, Linear, Dropout, MaxPool2D,\n                       AvgPool2D)\nfrom paddle import ParamAttr\nimport paddle.nn.functional as F\nfrom paddle.regularizer import L2Decay\nfrom ..registry import BACKBONES\nfrom ..weight_init import weight_init_\nfrom ...utils import load_ckpt\nclass ConvBNLayer(nn.Layer):\n    \"\"\"Conv2D and BatchNorm2D layer.\n    Args:"
        },
        {
            "comment": "This code defines a class called ConvBNLayer which inherits from an unspecified parent class. It takes in parameters such as number of input and output channels, kernel size, stride, groups, activation function, name, and data format for the Conv2D layer. The class initializes a Conv2D layer using these parameters and adds BatchNorm2D and ReLU layers after it. Weight and bias initialization values are named in the restore parameters, and they are explicitly declared in the init_weights method.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":30-52",
            "content": "        in_channels (int): Number of channels for the input.\n        out_channels (int): Number of channels for the output.\n        kernel_size (int): Kernel size.\n        stride (int): Stride in the Conv2D layer. Default: 1.\n        groups (int): Groups in the Conv2D, Default: 1.\n        act (str): Indicate activation after BatchNorm2D layer.\n        name (str): the name of an instance of ConvBNLayer.\n    Note: weight and bias initialization include initialize values and name the restored parameters, values initialization are explicit declared in the ```init_weights``` method.\n    \"\"\"\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 kernel_size,\n                 stride=1,\n                 groups=1,\n                 act=None,\n                 name=None,\n                 data_format=\"NCHW\"):\n        super(ConvBNLayer, self).__init__()\n        self._conv = Conv2D(in_channels=in_channels,\n                            out_channels=out_channels,\n                            kernel_size=kernel_size,"
        },
        {
            "comment": "This code defines a BottleneckBlock class with a convolution layer, batch normalization, and optional activation function. The forward pass applies the convolution, batch normalization, and activation if present.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":53-83",
            "content": "                            stride=stride,\n                            padding=(kernel_size - 1) // 2,\n                            groups=groups,\n                            weight_attr=ParamAttr(name=name + \"_weights\"),\n                            bias_attr=False,\n                            data_format=data_format)\n        if name == \"conv1\":\n            bn_name = \"bn_\" + name\n        else:\n            bn_name = \"bn\" + name[3:]\n        self._act = act\n        self._batch_norm = BatchNorm2D(\n            out_channels,\n            weight_attr=ParamAttr(name=bn_name + \"_scale\",\n                                  regularizer=L2Decay(0.0)),\n            bias_attr=ParamAttr(name=bn_name + \"_offset\",\n                                regularizer=L2Decay(0.0)),\n            data_format=data_format)\n    def forward(self, inputs):\n        y = self._conv(inputs)\n        y = self._batch_norm(y)\n        if self._act:\n            y = getattr(paddle.nn.functional, self._act)(y)\n        return y\nclass BottleneckBlock(nn.Layer):\n    def __init__(self,"
        },
        {
            "comment": "This code defines a class called BottleneckBlock, which is a part of a neural network model. It contains several ConvBNLayer objects for processing input data, with different parameters such as in_channels, out_channels, kernel_size, stride, and act (activation function). The class also has an attribute for data_format and initializes the ConvBNLayer objects with specific names.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":84-107",
            "content": "                 in_channels,\n                 out_channels,\n                 stride,\n                 shortcut=True,\n                 num_seg=8,\n                 name=None,\n                 data_format=\"NCHW\"):\n        super(BottleneckBlock, self).__init__()\n        self.data_format = data_format\n        self.conv0 = ConvBNLayer(in_channels=in_channels,\n                                 out_channels=out_channels,\n                                 kernel_size=1,\n                                 act=\"relu\",\n                                 name=name + \"_branch2a\",\n                                 data_format=data_format)\n        self.conv1 = ConvBNLayer(in_channels=out_channels,\n                                 out_channels=out_channels,\n                                 kernel_size=3,\n                                 stride=stride,\n                                 act=\"relu\",\n                                 name=name + \"_branch2b\",\n                                 data_format=data_format)\n        self.conv2 = ConvBNLayer(in_channels=out_channels,"
        },
        {
            "comment": "This code is initializing a ConvBNLayer and a shortcut connection for the TSM backbone. The layers have specific out_channels, kernel_size, stride, name, and data_format configurations. If a shortcut is not provided, it initializes another ConvBNLayer. The forward function reshapes input to have a shape of [N, T, C, H, W] for further processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":108-133",
            "content": "                                 out_channels=out_channels * 4,\n                                 kernel_size=1,\n                                 act=None,\n                                 name=name + \"_branch2c\",\n                                 data_format=data_format)\n        if not shortcut:\n            self.short = ConvBNLayer(in_channels=in_channels,\n                                     out_channels=out_channels * 4,\n                                     kernel_size=1,\n                                     stride=stride,\n                                     name=name + \"_branch1\",\n                                     data_format=data_format)\n        self.shortcut = shortcut\n        self.num_seg = num_seg\n    def forward(self, inputs):\n        if paddle.is_compiled_with_custom_device('npu'):\n            x = inputs\n            seg_num = self.num_seg\n            shift_ratio = 1.0 / self.num_seg\n            shape = x.shape  #[N*T, C, H, W]\n            reshape_x = x.reshape(\n                (-1, seg_num, shape[1], shape[2], shape[3]))  #[N, T, C, H, W]"
        },
        {
            "comment": "This code performs temporal shift operation on the input tensor. If a certain condition is met, it pads and concatenates slices of the input tensor before performing the reshape and temporal shift operations. The resulting output is then passed through several convolutional layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":134-163",
            "content": "            pad_x = F.pad(reshape_x, [\n                0,\n                0,\n                1,\n                1,\n                0,\n                0,\n                0,\n                0,\n                0,\n                0,\n            ])  #[N, T+2, C, H, W]\n            c1 = int(shape[1] * shift_ratio)\n            c2 = int(shape[1] * 2 * shift_ratio)\n            slice1 = pad_x[:, :seg_num, :c1, :, :]\n            slice2 = pad_x[:, 2:seg_num + 2, c1:c2, :, :]\n            slice3 = pad_x[:, 1:seg_num + 1, c2:, :, :]\n            concat_x = paddle.concat([slice1, slice2, slice3],\n                                     axis=2)  #[N, T, C, H, W]\n            shifts = concat_x.reshape(shape)\n        else:\n            shifts = F.temporal_shift(inputs,\n                                      self.num_seg,\n                                      1.0 / self.num_seg,\n                                      data_format=self.data_format)\n        y = self.conv0(shifts)\n        conv1 = self.conv1(y)\n        conv2 = self.conv2(conv1)\n        if self.shortcut:"
        },
        {
            "comment": "The code defines a BasicBlock class which is a residual block. It contains two 3x3 convolutional layers followed by BN and ReLU activations. If the shortcut connection is not used, it also includes an additional convolution layer for the shortcut path. The purpose of this residual block is to alleviate the problem of vanishing gradients in deeper networks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":164-201",
            "content": "            short = inputs\n        else:\n            short = self.short(inputs)\n        y = paddle.add(x=short, y=conv2)\n        return F.relu(y)\nclass BasicBlock(nn.Layer):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 stride,\n                 shortcut=True,\n                 name=None,\n                 data_format=\"NCHW\"):\n        super(BasicBlock, self).__init__()\n        self.stride = stride\n        self.conv0 = ConvBNLayer(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            filter_size=3,\n            stride=stride,\n            act=\"relu\",\n            name=name + \"_branch2a\",\n            data_format=data_format,\n        )\n        self.conv1 = ConvBNLayer(\n            in_channels=out_channels,\n            out_channels=out_channels,\n            filter_size=3,\n            act=None,\n            name=name + \"_branch2b\",\n            data_format=data_format,\n        )\n        if not shortcut:\n            self.short = ConvBNLayer(\n                in_channels=in_channels,"
        },
        {
            "comment": "The code defines a ResNet TSM backbone model with specified depth and data format. It consists of an initialization, a forward function for processing inputs, and the ability to be registered at BACKBONES. It also supports different layers like 18, 34, 50, 101, and 152.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":202-240",
            "content": "                out_channels=out_channels,\n                filter_size=1,\n                stride=stride,\n                name=name + \"_branch1\",\n                data_format=data_format,\n            )\n        self.shortcut = shortcut\n    def forward(self, inputs):\n        y = self.conv0(inputs)\n        conv1 = self.conv1(y)\n        if self.shortcut:\n            short = inputs\n        else:\n            short = self.short(inputs)\n        y = paddle.add(short, conv1)\n        y = F.relu(y)\n        return y\n@BACKBONES.register()\nclass ResNetTSM(nn.Layer):\n    \"\"\"ResNet TSM backbone.\n    Args:\n        depth (int): Depth of resnet model.\n        pretrained (str): pretrained model. Default: None.\n    \"\"\"\n    def __init__(self, depth, num_seg=8, data_format=\"NCHW\", pretrained=None):\n        super(ResNetTSM, self).__init__()\n        self.pretrained = pretrained\n        self.layers = depth\n        self.num_seg = num_seg\n        self.data_format = data_format\n        supported_layers = [18, 34, 50, 101, 152]\n        assert self.layers in supported_layers, \\"
        },
        {
            "comment": "This code initializes a ResNet-TSM backbone with different depth configurations based on the input layers. It includes a convolution layer, max pooling 2D layer, and a block list for deeper networks. The code checks if the layers are supported (18, 34, 50, 101, or 152) and assigns corresponding depth and number of channels accordingly.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":241-272",
            "content": "            \"supported layers are {} but input layer is {}\".format(\n                supported_layers, self.layers)\n        if self.layers == 18:\n            depth = [2, 2, 2, 2]\n        elif self.layers == 34 or self.layers == 50:\n            depth = [3, 4, 6, 3]\n        elif self.layers == 101:\n            depth = [3, 4, 23, 3]\n        elif self.layers == 152:\n            depth = [3, 8, 36, 3]\n        in_channels = 64\n        out_channels = [64, 128, 256, 512]\n        self.conv = ConvBNLayer(in_channels=3,\n                                out_channels=64,\n                                kernel_size=7,\n                                stride=2,\n                                act=\"relu\",\n                                name=\"conv1\",\n                                data_format=self.data_format)\n        self.pool2D_max = MaxPool2D(\n            kernel_size=3,\n            stride=2,\n            padding=1,\n            data_format=self.data_format,\n        )\n        self.block_list = []\n        if self.layers >= 50:\n            for block in range(len(depth)):"
        },
        {
            "comment": "Code creates bottleneck blocks for ResNet TSM architecture, varying the number of input channels based on layer index and configuration. It adds sublayers with specified parameters including number of segments and stride for each block.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":273-292",
            "content": "                shortcut = False\n                for i in range(depth[block]):\n                    if self.layers in [101, 152] and block == 2:\n                        if i == 0:\n                            conv_name = \"res\" + str(block + 2) + \"a\"\n                        else:\n                            conv_name = \"res\" + str(block + 2) + \"b\" + str(i)\n                    else:\n                        conv_name = \"res\" + str(block + 2) + chr(97 + i)\n                    bottleneck_block = self.add_sublayer(\n                        conv_name,\n                        BottleneckBlock(\n                            in_channels=in_channels\n                            if i == 0 else out_channels[block] * 4,\n                            out_channels=out_channels[block],\n                            stride=2 if i == 0 and block != 0 else 1,\n                            num_seg=self.num_seg,\n                            shortcut=shortcut,\n                            name=conv_name,\n                            data_format=self.data_format))"
        },
        {
            "comment": "Code initializes a ResNet TSM model backbone, with block-specific in_channels and adds either bottleneck or basic blocks depending on the depth configuration. Init_weights function is also defined to initialize weights for the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":293-315",
            "content": "                    in_channels = out_channels[block] * 4\n                    self.block_list.append(bottleneck_block)\n                    shortcut = True\n        else:\n            for block in range(len(depth)):\n                shortcut = False\n                for i in range(depth[block]):\n                    conv_name = \"res\" + str(block + 2) + chr(97 + i)\n                    basic_block = self.add_sublayer(\n                        conv_name,\n                        BasicBlock(\n                            in_channels=in_channels[block]\n                            if i == 0 else out_channels[block],\n                            out_channels=out_channels[block],\n                            stride=2 if i == 0 and block != 0 else 1,\n                            shortcut=shortcut,\n                            name=conv_name,\n                            data_format=self.data_format,\n                        ))\n                    self.block_list.append(basic_block)\n                    shortcut = True\n    def init_weights(self):"
        },
        {
            "comment": "This code initializes parameters for a ResNet TSM backbone. If a pretrained loading path is provided, it loads the weights from that path; otherwise, it uses specific initialization functions for Conv2D and BatchNorm2d layers. No bias is used in Conv2D layers.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":316-331",
            "content": "        \"\"\"Initiate the parameters.\n        Note:\n            1. when indicate pretrained loading path, will load it to initiate backbone.\n            2. when not indicating pretrained loading path, will follow specific initialization initiate backbone. Always, Conv2D layer will be initiated by KaimingNormal function, and BatchNorm2d will be initiated by Constant function.\n            Please refer to https://www.paddlepaddle.org.cn/documentation/docs/en/develop/api/paddle/nn/initializer/kaiming/KaimingNormal_en.html\n        \"\"\"\n        #XXX: check bias!!! check pretrained!!!\n        if isinstance(self.pretrained, str) and self.pretrained.strip() != \"\":\n            load_ckpt(self, self.pretrained)\n        elif self.pretrained is None or self.pretrained.strip() == \"\":\n            for layer in self.sublayers():\n                if isinstance(layer, nn.Conv2D):\n                    #XXX: no bias\n                    weight_init_(layer, 'KaimingNormal')\n                elif isinstance(layer, nn.BatchNorm2D):"
        },
        {
            "comment": "This code defines a forward function for a backbone model. It uses convolution and pooling layers to extract features from input data. The comments indicate that this implementation may be deprecated, and the data preparation should be modified according to recognizer2d.py for better compatibility with paddlepaddle's to_static method.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/resnet_tsm.py\":332-352",
            "content": "                    weight_init_(layer, 'Constant', value=1)\n    def forward(self, inputs):\n        \"\"\"Define how the backbone is going to run.\n        \"\"\"\n        #NOTE: (deprecated design) Already merge axis 0(batches) and axis 1(clips) before extracting feature phase,\n        # please refer to paddlevideo/modeling/framework/recognizers/recognizer2d.py#L27\n        #y = paddle.reshape(\n        #    inputs, [-1, inputs.shape[2], inputs.shape[3], inputs.shape[4]])\n        #NOTE: As paddlepaddle to_static method need a \"pure\" model to trim. It means from\n        #  1. the phase of generating data[images, label] from dataloader\n        #     to\n        #  2. last layer of a model, always is FC layer\n        y = self.conv(inputs)\n        y = self.pool2D_max(y)\n        for block in self.block_list:\n            y = block(y)\n        return y"
        }
    ]
}