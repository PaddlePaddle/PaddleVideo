{
    "summary": "This code defines Paddle Video's image preprocessing classes for resizing, aspect ratio adjustment, and custom cropping transforms. It performs horizontal flipping, object detection, and returns foreground/nocare masks from a scribble image.",
    "details": [
        {
            "comment": "This code defines a Paddle Video pipeline class, \"RandomScale\\_manet,\" which resizes the input image and its corresponding ground truth to random scales. The allowed scales are [0.75, 1, 1.25]. For elements like 'img1', 'img2', or 'ref\\_img,' it uses cv2's INTER_CUBIC interpolation. For other elements, it utilizes cv2's INTER_NEAREST interpolation. The pipeline is registered at PIPELINES for further usage.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py\":0-42",
            "content": "import os\nimport random\nimport cv2\nimport numpy as np\nimport paddle\nfrom PIL import Image\nfrom davisinteractive.utils.operations import bresenham\nfrom ..registry import PIPELINES\ncv2.setNumThreads(0)\nNEW_BRANCH = True\n@PIPELINES.register()\nclass RandomScale_manet(object):\n    \"\"\"Randomly resize the image and the ground truth to specified scales.\n    Args:\n        scales (list): the list of scales\n    \"\"\"\n    def __init__(self, scales=[0.75, 1, 1.25]):\n        self.scales = scales\n    def __call__(self, sample):\n        # Fixed range of scales\n        sc = self.scales[random.randint(0, len(self.scales) - 1)]\n        for elem in sample.keys():\n            if 'meta' in elem:\n                continue\n            tmp = sample[elem]\n            if elem == 'img1' or elem == 'img2' or elem == 'ref_img':\n                flagval = cv2.INTER_CUBIC\n            else:\n                flagval = cv2.INTER_NEAREST\n            tmp = cv2.resize(tmp, None, fx=sc, fy=sc, interpolation=flagval)\n            sample[elem] = tmp\n        return sample"
        },
        {
            "comment": "The code defines a Resize_manet class, which is a pipeline for resizing an image to a specified output size. The input could be either an integer or a tuple representing the desired output dimensions. If the input is an integer, it will use that as the smaller edge of the image and maintain aspect ratio. The code checks if the current image size matches the desired output size; if so, it returns the results without modification, otherwise it resizes the image to match the desired output size. This class is used in a computer vision context for preprocessing images.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py\":45-74",
            "content": "@PIPELINES.register()\nclass Resize_manet(object):\n    \"\"\"Rescale the image in a results to a given size.\n    Args:\n        output_size (tuple or int): Desired output size. If tuple, output is\n            matched to output_size. If int, smaller of image edges is matched\n            to output_size keeping aspect ratio the same.\n    \"\"\"\n    def __init__(self, output_size):\n        assert isinstance(output_size, (int, list))\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        else:\n            self.output_size = output_size\n    #        self.seg_interpolation = cv2.INTER_CUBIC if is_continuous else cv2.INTER_NEAREST\n    #        self.fix = fix\n    def __call__(self, results):\n        img1 = results['img1']\n        h, w = img1.shape[:2]\n        if self.output_size == (h, w):\n            return results\n        else:\n            new_h, new_w = self.output_size\n        new_h, new_w = int(new_h), int(new_w)\n        for elem in results.keys():\n            if 'meta' in elem:"
        },
        {
            "comment": "This code defines a custom transform for image processing, specifically random cropping. It takes an input image and crops it randomly to the specified output size. The interpolation method used during resizing is determined by the element type in the 'results' dictionary. If the element is 'img1', 'img2', or 'ref_img', cubic interpolation is used, otherwise nearest neighbor interpolation is used. The cropped image is then stored back into the results dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py\":75-108",
            "content": "                continue\n            tmp = results[elem]\n            if elem == 'img1' or elem == 'img2' or elem == 'ref_img':\n                flagval = cv2.INTER_CUBIC\n            else:\n                flagval = cv2.INTER_NEAREST\n            tmp = cv2.resize(tmp, dsize=(new_w, new_h), interpolation=flagval)\n            results[elem] = tmp\n        return results\n@PIPELINES.register()\nclass RandomCrop_manet(object):\n    \"\"\"Crop randomly the image in a results.\n    Args:\n        output_size (tuple or int): Desired output size. If int, square crop\n            is made.\n    \"\"\"\n    def __init__(self, output_size, step=None):\n        assert isinstance(output_size, (int, list))\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        else:\n            assert len(output_size) == 2\n            self.output_size = output_size\n        self.step = step\n    def __call__(self, results):\n        image = results['img1']\n        h, w = image.shape[:2]\n        new_h, new_w = self.output_size"
        },
        {
            "comment": "This code randomly crops an image and its associated labels to the specified new height and width. It checks if the cropped reference scribble label contains only one class label before updating other labels accordingly.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py\":110-133",
            "content": "        new_h = h if new_h >= h else new_h\n        new_w = w if new_w >= w else new_w\n        is_contain_obj = False\n        #        while (not is_contain_obj) and (step < 5):\n        if self.step is None:\n            while not is_contain_obj:\n                #                step += 1\n                top = np.random.randint(0, h - new_h + 1)\n                left = np.random.randint(0, w - new_w + 1)\n                ref_scribble_label = results['ref_scribble_label']\n                new_ref_scribble_label = ref_scribble_label[top:top + new_h,\n                                                            left:left + new_w]\n                if len(np.unique(new_ref_scribble_label)) == 1:\n                    continue\n                else:\n                    for elem in results.keys():\n                        if 'meta' in elem:\n                            continue\n                        tmp = results[elem]\n                        tmp = tmp[top:top + new_h, left:left + new_w]\n                        results[elem] = tmp"
        },
        {
            "comment": "This code randomly selects a region within the original image and applies random horizontal flipping to it. It checks if the selected region contains an object (by checking if the number of unique labels in ref_scribble_label is greater than 1) and continues flipping until either an object is found or the maximum allowed steps are reached. The function then returns the modified dictionary with the updated data for each key, except 'meta'. This custom transform is registered as a pipeline module for use in image processing tasks.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py\":134-162",
            "content": "                    break\n        else:\n            st = 0\n            while not is_contain_obj and st < self.step:\n                st += 1\n                top = np.random.randint(0, h - new_h + 1)\n                left = np.random.randint(0, w - new_w + 1)\n                ref_scribble_label = results['ref_scribble_label']\n                new_ref_scribble_label = ref_scribble_label[top:top + new_h,\n                                                            left:left + new_w]\n                if len(np.unique(\n                        new_ref_scribble_label)) == 1 or st < self.step - 1:\n                    continue\n                else:\n                    for elem in results.keys():\n                        if 'meta' in elem:\n                            continue\n                        tmp = results[elem]\n                        tmp = tmp[top:top + new_h, left:left + new_w]\n                        results[elem] = tmp\n                    break\n        return results\n@PIPELINES.register()\nclass RandomHorizontalFlip_manet(object):"
        },
        {
            "comment": "This code snippet contains two custom transforms for image processing. The first one, HorizontalFlip, randomly flips the given image and ground truth horizontally with a probability of 0.5. The second one, ToTensor_manet, converts ndarrays in results to Tensors by normalizing the images and reshaping them as required. Both transforms are added to the PADDLEPIPELINES registry for later use in image processing pipelines.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py\":163-197",
            "content": "    \"\"\"Horizontally flip the given image and ground truth randomly with a probability of 0.5.\"\"\"\n    def __init__(self, prob):\n        self.p = prob\n    def __call__(self, results):\n        if random.random() < self.p:\n            for elem in results.keys():\n                if 'meta' in elem:\n                    continue\n                tmp = results[elem]\n                tmp = cv2.flip(tmp, flipCode=1)\n                results[elem] = tmp\n        return results\n@PIPELINES.register()\nclass ToTensor_manet(object):\n    \"\"\"Convert ndarrays in results to Tensors.\"\"\"\n    def __call__(self, results):\n        for elem in results.keys():\n            if 'meta' in elem:\n                continue\n            tmp = results[elem]\n            if tmp.ndim == 2:\n                tmp = tmp[:, :, np.newaxis]\n            else:\n                tmp = tmp / 255.\n                tmp -= (0.485, 0.456, 0.406)\n                tmp /= (0.229, 0.224, 0.225)\n            tmp = tmp.transpose([2, 0, 1])\n            results[elem] = paddle.to_tensor(tmp)"
        },
        {
            "comment": "This function takes in a scribble image and optionally dilation and nocare area values. It returns the foreground mask and nocare mask. If the maximum value of the scribble is 1, it computes the foreground by dilating the scribble using an ellipse kernel. Else, it assigns the scribble as the foreground. Then, if a nocare area is given, it computes the nocare mask by dilating the foreground with another ellipse kernel and subtracting the original foreground.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py\":198-219",
            "content": "        return results\ndef gt_from_scribble(scr, dilation=11, nocare_area=21):\n    # Compute foreground\n    if scr.max() == 1:\n        kernel_fg = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,\n                                              (dilation, dilation))\n        fg = cv2.dilate(scr.astype(np.uint8),\n                        kernel=kernel_fg).astype(scr.dtype)\n    else:\n        fg = scr\n    # Compute nocare area\n    if nocare_area is None:\n        nocare = None\n    else:\n        kernel_nc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,\n                                              (nocare_area, nocare_area))\n        nocare = cv2.dilate(fg, kernel=kernel_nc) - fg\n    return fg, nocare"
        }
    ]
}