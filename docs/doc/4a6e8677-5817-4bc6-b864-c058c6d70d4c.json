{
    "summary": "The code imports necessary libraries, sets up a DALI reader, defines TSN_Dali_loader class, initializes parallel video preprocessing, handles potential import errors, and returns output and label using PaddleOps for normalization.",
    "details": [
        {
            "comment": "This code imports necessary libraries, sets up logger, and attempts to import DALI pipeline and related functions for creating a generic iterator for PaddlePaddle. If any of these imports fail, it falls back by setting the respective variable as an object.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":0-31",
            "content": "# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport random\nimport math\nimport paddle\nfrom paddle.distributed import ParallelEnv\nimport paddle.distributed as dist\nfrom paddlevideo.utils import get_logger\nlogger = get_logger(\"paddlevideo\")\ntry:\n    from nvidia.dali.pipeline import Pipeline\n    import nvidia.dali.ops as ops\n    import nvidia.dali.types as types\n    import tempfile\n    from nvidia.dali.plugin.paddle import DALIGenericIterator\nexcept:\n    Pipeline = object"
        },
        {
            "comment": "The code defines a class `TSN_Dali_loader` that initializes attributes related to batch size, file path, number of segments, segment length, input and target image sizes. It also sets variables for distributed training, data normalization, and builds a DALI reader for training data using shuffled full lines from the file path.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":34-64",
            "content": "def get_input_data(data):\n    return paddle.to_tensor(data[0]['image']), paddle.to_tensor(\n        data[0]['label'])\nclass TSN_Dali_loader(object):\n    def __init__(self, cfg):\n        self.batch_size = cfg.batch_size\n        self.file_path = cfg.file_path\n        self.num_seg = cfg.num_seg\n        self.seglen = cfg.seglen\n        self.short_size = cfg.short_size\n        self.target_size = cfg.target_size\n        # set num_shards and shard_id when distributed training is implemented\n        self.num_shards = dist.get_world_size()\n        self.shard_id = ParallelEnv().local_rank\n        self.dali_mean = cfg.mean * (self.num_seg * self.seglen)\n        self.dali_std = cfg.std * (self.num_seg * self.seglen)\n    def build_dali_reader(self):\n        \"\"\"\n        build dali training reader\n        \"\"\"\n        def reader_():\n            with open(self.file_path) as flist:\n                full_lines = [line for line in flist]\n                if (not hasattr(reader_, 'seed')):\n                    reader_.seed = 0\n                random.Random(reader_.seed).shuffle(full_lines)"
        },
        {
            "comment": "This code snippet initializes a reader and distributes the data evenly across multiple shards. It calculates the number of lines to be assigned to each shard based on the total number of lines and the number of shards. It then ensures that the full_lines list is an even multiple of the total_lines by appending additional items if necessary. The snippet asserts that the length of full_lines equals total_lines, assigns lines to trainers based on their shard ID, and logs information about the distribution of data among shards.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":65-87",
            "content": "                logger.info(f\"reader shuffle seed: {reader_.seed}.\")\n                if reader_.seed is not None:\n                    reader_.seed += 1\n                per_node_lines = int(\n                    math.ceil(len(full_lines) * 1.0 / self.num_shards))\n                total_lines = per_node_lines * self.num_shards\n                # aligned full_lines so that it can evenly divisible\n                full_lines += full_lines[:(total_lines - len(full_lines))]\n                assert len(full_lines) == total_lines\n                # trainer get own sample\n                lines = full_lines[self.shard_id:total_lines:self.num_shards]\n                assert len(lines) == per_node_lines\n                logger.info(\n                    f\"shard_id: {self.shard_id}, trainer_count: {self.num_shards}\"\n                )\n                logger.info(\n                    f\"read videos from {self.shard_id * per_node_lines}, \"\n                    f\"length: {per_node_lines}, \"\n                    f\"lines length: {len(lines)}, \""
        },
        {
            "comment": "This code initializes a PaddlePaddle VideoPipe instance, loading and preprocessing video files in parallel for training. It sets the batch size, number of threads, device ID, file list, sequence length, number of segments, segment length, resize shorter scale, crop target size, whether it's in training mode, and the number of shards and shard ID.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":88-110",
            "content": "                    f\"total: {len(full_lines)}\")\n            video_files = ''.join([item for item in lines])\n            tf = tempfile.NamedTemporaryFile()\n            tf.write(str.encode(video_files))\n            tf.flush()\n            video_files = tf.name\n            device_id = ParallelEnv().local_rank\n            logger.info(f'---------- device_id: {device_id} -----------')\n            pipe = VideoPipe(batch_size=self.batch_size,\n                             num_threads=1,\n                             device_id=device_id,\n                             file_list=video_files,\n                             sequence_length=self.num_seg * self.seglen,\n                             num_seg=self.num_seg,\n                             seg_length=self.seglen,\n                             resize_shorter_scale=self.short_size,\n                             crop_target_size=self.target_size,\n                             is_training=True,\n                             num_shards=self.num_shards,\n                             shard_id=self.shard_id,"
        },
        {
            "comment": "This code initializes a DALI (Data Augmentation Library for Images) generic iterator to load video data from a file list, and returns it. It uses a VideoPipe class to define the pipeline configuration, including parameters such as batch size, number of threads, device ID, sequence length, and more.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":111-141",
            "content": "                             dali_mean=self.dali_mean,\n                             dali_std=self.dali_std)\n            logger.info(\n                'initializing dataset, it will take several minutes if it is too large .... '\n            )\n            video_loader = DALIGenericIterator([pipe], ['image', 'label'],\n                                               len(lines),\n                                               dynamic_shape=True,\n                                               auto_reset=True)\n            return video_loader\n        dali_reader = reader_()\n        return dali_reader\nclass VideoPipe(Pipeline):\n    def __init__(self,\n                 batch_size,\n                 num_threads,\n                 device_id,\n                 file_list,\n                 sequence_length,\n                 num_seg,\n                 seg_length,\n                 resize_shorter_scale,\n                 crop_target_size,\n                 is_training=False,\n                 initial_prefetch_size=20,\n                 num_shards=1,"
        },
        {
            "comment": "This code initializes a VideoPipe object with the given parameters, including file list, sequence length, and number of segments. It uses ops.VideoReader to read video data from the file list in the specified format. Due to the limitations of resize function, it transposes and reshapes the data before performing resizing operation on the 2-D image.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":142-159",
            "content": "                 shard_id=0,\n                 dali_mean=0.,\n                 dali_std=1.0):\n        super(VideoPipe, self).__init__(batch_size, num_threads, device_id)\n        self.input = ops.VideoReader(device=\"gpu\",\n                                     file_list=file_list,\n                                     sequence_length=sequence_length,\n                                     num_seg=num_seg,\n                                     seg_length=seg_length,\n                                     is_training=is_training,\n                                     num_shards=num_shards,\n                                     shard_id=shard_id,\n                                     random_shuffle=is_training,\n                                     initial_fill=initial_prefetch_size)\n        # the sequece data read by ops.VideoReader is of shape [F, H, W, C]\n        # Because the ops.Resize does not support sequence data,\n        # it will be transposed into [H, W, F, C],\n        # then reshaped to [H, W, FC], and then resized like a 2-D image."
        },
        {
            "comment": "The code creates a DALI loader for image processing, with transpose, reshape, resize operations, and implements crop and mirror normalization. It also includes uniform distribution generators for position and mirror. The normalization will be implemented using PaddleOps due to the difficulty of dimension broadcasting in DALI.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":160-175",
            "content": "        self.transpose = ops.Transpose(device=\"gpu\", perm=[1, 2, 0, 3])\n        self.reshape = ops.Reshape(device=\"gpu\",\n                                   rel_shape=[1.0, 1.0, -1],\n                                   layout='HWC')\n        self.resize = ops.Resize(device=\"gpu\",\n                                 resize_shorter=resize_shorter_scale)\n        # crops and mirror are applied by ops.CropMirrorNormalize.\n        # Normalization will be implemented in paddle due to the difficulty of dimension broadcast,\n        # It is not sure whether dimension broadcast can be implemented correctly by dali, just take the Paddle Op instead.\n        self.pos_rng_x = ops.Uniform(range=(0.0, 1.0))\n        self.pos_rng_y = ops.Uniform(range=(0.0, 1.0))\n        self.mirror_generator = ops.Uniform(range=(0.0, 1.0))\n        self.cast_mirror = ops.Cast(dtype=types.DALIDataType.INT32)\n        self.crop_mirror_norm = ops.CropMirrorNormalize(\n            device=\"gpu\",\n            crop=[crop_target_size, crop_target_size],"
        },
        {
            "comment": "The code defines a DALI loader and its associated operations for image processing. It includes mean and std for normalization, reshaping, casting to int64, transpose, resize, normalization by dividing by 255, generating positional information, cropping with mirror flag, and finally reshaping the output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":176-201",
            "content": "            mean=dali_mean,\n            std=dali_std)\n        self.reshape_back = ops.Reshape(\n            device=\"gpu\",\n            shape=[num_seg, seg_length * 3, crop_target_size, crop_target_size],\n            layout='FCHW')\n        self.cast_label = ops.Cast(device=\"gpu\", dtype=types.DALIDataType.INT64)\n    def define_graph(self):\n        output, label = self.input(name=\"Reader\")\n        output = self.transpose(output)\n        output = self.reshape(output)\n        output = self.resize(output)\n        output = output / 255.\n        pos_x = self.pos_rng_x()\n        pos_y = self.pos_rng_y()\n        mirror_flag = self.mirror_generator()\n        mirror_flag = (mirror_flag > 0.5)\n        mirror_flag = self.cast_mirror(mirror_flag)\n        output = self.crop_mirror_norm(output,\n                                       crop_pos_x=pos_x,\n                                       crop_pos_y=pos_y,\n                                       mirror=mirror_flag)\n        output = self.reshape_back(output)\n        label = self.cast_label(label)"
        },
        {
            "comment": "The code defines a method that returns an output and label, and another method for determining the length of the loader.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/dali_loader.py\":202-205",
            "content": "        return output, label\n    def __len__(self):\n        return self.epoch_size()"
        }
    ]
}