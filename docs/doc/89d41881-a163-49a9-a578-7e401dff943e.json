{
    "summary": "This code initializes weights for a PaddlePaddle layer with options for customization and truncated normal distribution, offering proper initialization for deep learning models using normal distribution and PaddlePaddle's Normal initializer.",
    "details": [
        {
            "comment": "The code is a function for initializing the weights of a given layer using different functions. It supports in-place parameter initialization and can be used with PaddlePaddle framework. The function accepts various arguments to customize the weight initialization process.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py\":0-35",
            "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport math\nimport paddle\nimport paddle.nn.initializer as init\nimport numpy as np\nfrom scipy import special\ndef weight_init_(layer,\n                 func,\n                 weight_name=None,\n                 bias_name=None,\n                 bias_value=0.0,\n                 **kwargs):\n    \"\"\"\n    In-place params init function.\n    Usage:\n    .. code-block:: python\n        import paddle\n        import numpy as np\n        data = np.ones([3, 4], dtype='float32')"
        },
        {
            "comment": "Code initializes a linear layer, prints its weight, applies weight initialization with normal distribution, and prints the weight again. The _no_grad_trunc_normal_ function sets tensor values to be truncated normal with specified mean, std, a, and b parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py\":36-65",
            "content": "        linear = paddle.nn.Linear(4, 4)\n        input = paddle.to_tensor(data)\n        print(linear.weight)\n        linear(input)\n        weight_init_(linear, 'Normal', 'fc_w0', 'fc_b0', std=0.01, mean=0.1)\n        print(linear.weight)\n    \"\"\"\n    if hasattr(layer, 'weight') and layer.weight is not None:\n        getattr(init, func)(**kwargs)(layer.weight)\n        if weight_name is not None:\n            # override weight name\n            layer.weight.name = weight_name\n    if hasattr(layer, 'bias') and layer.bias is not None:\n        init.Constant(bias_value)(layer.bias)\n        if bias_name is not None:\n            # override bias name\n            layer.bias.name = bias_name\ndef _no_grad_trunc_normal_(tensor, mean, std, a, b):\n    def norm_cdf(x):\n        # Computes standard normal cumulative distribution function\n        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n    if (mean < a - 2 * std) or (mean > b + 2 * std):\n        print(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n              \"The distribution of values may be incorrect.\")"
        },
        {
            "comment": "This code initializes the weights of a tensor by generating values from a truncated normal distribution, with the lower and upper bounds defined by 'a' and 'b'. It then transforms these values to ensure they are within the desired range, mean, and standard deviation. The resulting tensor is set as the new value for the original tensor. This process ensures proper initialization for deep learning models.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py\":67-97",
            "content": "    with paddle.no_grad():\n        # Values are generated by using a truncated uniform distribution and\n        # then using the inverse CDF for the normal distribution.\n        # Get upper and lower cdf values\n        l = norm_cdf((a - mean) / std)\n        u = norm_cdf((b - mean) / std)\n        # Uniformly fill tensor with values from [l, u], then translate to [2l-1, 2u-1].\n        tmp = np.random.uniform(2 * l - 1, 2 * u - 1,\n                                size=list(tensor.shape)).astype(np.float32)\n        # Use inverse cdf transform for normal distribution to get truncated\n        # standard normal\n        tmp = special.erfinv(tmp)\n        # Transform to proper mean, std\n        tmp *= (std * math.sqrt(2.0))\n        tmp += mean\n        # Clamp to ensure it's in the proper range\n        tmp = np.clip(tmp, a, b)\n        tensor.set_value(paddle.to_tensor(tmp))\n        return tensor\ndef _calculate_fan_in_and_fan_out(tensor):\n    dimensions = tensor.dim()\n    if dimensions < 2:\n        raise ValueError(\n            \"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\""
        },
        {
            "comment": "The code defines a function for initializing the weight of a neural network. It first calculates the fan-in and fan-out based on the shape and dimensions of the tensor. Then, it provides options to initialize weights with truncated normal or Kaiming normal distributions. The trunc_normal_ and kaiming_normal_ functions are also defined to handle different initialization methods with optional parameters for mean, std, a, b, mode, and nonlinearity.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py\":98-129",
            "content": "        )\n    num_input_fmaps = tensor.shape[1]\n    num_output_fmaps = tensor.shape[0]\n    receptive_field_size = 1\n    if tensor.dim() > 2:\n        receptive_field_size = tensor[0][0].numel()\n    fan_in = num_input_fmaps * receptive_field_size\n    fan_out = num_output_fmaps * receptive_field_size\n    return fan_in, fan_out\ndef trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\ndef kaiming_normal_(tensor, a=0., mode='fan_in', nonlinearity='leaky_relu'):\n    def _calculate_correct_fan(tensor, mode):\n        mode = mode.lower()\n        valid_modes = ['fan_in', 'fan_out']\n        if mode not in valid_modes:\n            raise ValueError(\n                \"Mode {} not supported, please use one of {}\".format(\n                    mode, valid_modes))\n        fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n        return fan_in if mode == 'fan_in' else fan_out\n    def calculate_gain(nonlinearity, param=None):\n        linear_fns = [\n            'linear', 'conv1d', 'conv2d', 'conv3d', 'conv_transpose1d',"
        },
        {
            "comment": "This function initializes the weights of a tensor with a normal distribution. It checks the type of nonlinearity function and returns an appropriate gain factor, then calculates the standard deviation for weight initialization using fan inversion formula. The final step is to initialize the tensor with Normal initializer from PaddlePaddle library.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py\":130-156",
            "content": "            'conv_transpose2d', 'conv_transpose3d'\n        ]\n        if nonlinearity in linear_fns or nonlinearity == 'sigmoid':\n            return 1\n        elif nonlinearity == 'tanh':\n            return 5.0 / 3\n        elif nonlinearity == 'relu':\n            return math.sqrt(2.0)\n        elif nonlinearity == 'leaky_relu':\n            if param is None:\n                negative_slope = 0.01\n            elif not isinstance(param, bool) and isinstance(\n                    param, int) or isinstance(param, float):\n                negative_slope = param\n            else:\n                raise ValueError(\n                    \"negative_slope {} not a valid number\".format(param))\n            return math.sqrt(2.0 / (1 + negative_slope**2))\n        else:\n            raise ValueError(\n                \"Unsupported nonlinearity {}\".format(nonlinearity))\n    fan = _calculate_correct_fan(tensor, mode)\n    gain = calculate_gain(nonlinearity, a)\n    std = gain / math.sqrt(fan)\n    with paddle.no_grad():\n        paddle.nn.initializer.Normal(0, std)(tensor)"
        },
        {
            "comment": "Initializing weights for a neural network model.\nThis function returns the initialized tensor with random values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py\":157-157",
            "content": "        return tensor"
        }
    ]
}