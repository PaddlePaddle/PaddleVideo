{
    "summary": "This code converts a PaddlePaddle model to ONNX for inference using paddle2onnx and ONNXRuntime. The ONNX format enables similar usage to Paddle, with results matching Paddle predictions.",
    "details": [
        {
            "comment": "This code demonstrates the process of converting a PaddlePaddle model to an ONNX model for inference using Paddle2ONNX and ONNXRuntime. It first installs the necessary packages, downloads the PP-TSN inference model, and then uses paddle2onnx to convert the model to the ONNX format while specifying the opset version.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/paddle2onnx/readme.md\":0-47",
            "content": "# paddle2onnx \u6a21\u578b\u8f6c\u5316\u4e0e\u9884\u6d4b\n\u672c\u7ae0\u8282\u4ecb\u7ecd PP-TSN \u6a21\u578b\u5982\u4f55\u8f6c\u5316\u4e3a ONNX \u6a21\u578b\uff0c\u5e76\u57fa\u4e8e ONNX \u5f15\u64ce\u9884\u6d4b\u3002\n## 1. \u73af\u5883\u51c6\u5907\n\u9700\u8981\u51c6\u5907 Paddle2ONNX \u6a21\u578b\u8f6c\u5316\u73af\u5883\uff0c\u548c ONNX \u6a21\u578b\u9884\u6d4b\u73af\u5883\u3002\nPaddle2ONNX \u652f\u6301\u5c06 PaddlePaddle \u6a21\u578b\u683c\u5f0f\u8f6c\u5316\u5230 ONNX \u6a21\u578b\u683c\u5f0f\uff0c\u7b97\u5b50\u76ee\u524d\u7a33\u5b9a\u652f\u6301\u5bfc\u51fa ONNX Opset 9~11\uff0c\u90e8\u5206Paddle\u7b97\u5b50\u652f\u6301\u66f4\u4f4e\u7684ONNX Opset\u8f6c\u6362\u3002\n\u66f4\u591a\u7ec6\u8282\u53ef\u53c2\u8003 [Paddle2ONNX](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/README_zh.md)\n- \u5b89\u88c5 Paddle2ONNX\n```bash\npython3.7 -m pip install paddle2onnx\n```\n- \u5b89\u88c5 ONNXRuntime\n```bash\n# \u5efa\u8bae\u5b89\u88c5 1.9.0 \u7248\u672c\uff0c\u53ef\u6839\u636e\u73af\u5883\u66f4\u6362\u7248\u672c\u53f7\npython3.7 -m pip install onnxruntime==1.9.0\n```\n## 2. \u6a21\u578b\u8f6c\u6362\n- PP-TSN inference\u6a21\u578b\u4e0b\u8f7d\n    ```bash\n    # \u4e0b\u8f7dinference\u6a21\u578b\u5230PaddleVideo/inference/ppTSN/ \u76ee\u5f55\u4e0b\n    mkdir -p ./inference\n    wget -P ./inference/ https://videotag.bj.bcebos.com/PaddleVideo-release2.3/ppTSN.zip\n    # \u89e3\u538binference\u6a21\u578b\n    pushd ./inference\n    unzip ppTSN.zip\n    popd\n    ```\n- \u6a21\u578b\u8f6c\u6362\n    \u4f7f\u7528 Paddle2ONNX \u5c06 Paddle inference\u6a21\u578b\u8f6c\u6362\u4e3a ONNX \u683c\u5f0f\u6a21\u578b\uff1a\n    ```bash\n    paddle2onnx \\\n    --model_dir=./inference/ppTSN \\\n    --model_filename=ppTSN.pdmodel \\\n    --params_filename=ppTSN.pdiparams \\\n    --save_file=./inference/ppTSN/ppTSN.onnx \\\n    --opset_version=10 \\"
        },
        {
            "comment": "Enables ONNX checker to generate ONNX format model file for inference. Usage of ONNX model is similar to Paddle, and results match with Paddle inference predictions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/paddle2onnx/readme.md\":48-69",
            "content": "    --enable_onnx_checker=True\n    ```\n\u6267\u884c\u5b8c\u6bd5\u540e\uff0c\u53ef\u4ee5\u53d1\u73b0 `./inference/ppTSN` \u76ee\u5f55\u4e0b\u751f\u6210\u4e86\u4e00\u4e2a ONNX \u683c\u5f0f\u7684\u6a21\u578b\u6587\u4ef6 `ppTSN.onnx`\n## 3. onnx \u9884\u6d4b\n\u63a5\u4e0b\u6765\u5c31\u53ef\u4ee5\u7528 ONNX \u683c\u5f0f\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5176\u7528\u6cd5\u4e0epaddle \u9884\u6d4b\u6a21\u578b\u7c7b\u4f3c\n\u6267\u884c\u5982\u4e0b\u547d\u4ee4\uff1a\n```bash\npython3.7 deploy/paddle2onnx/predict_onnx.py \\\n--input_file data/example.avi \\\n--config configs/recognition/pptsn/pptsn_k400_videos.yaml \\\n--onnx_file=./inference/ppTSN/ppTSN.onnx\n```\n\u7ed3\u679c\u5982\u4e0b\uff1a\n```bash\nCurrent video file: data/example.avi\n        top-1 class: 5\n        top-1 score: 0.9998553991317749\n```\n\u53ef\u4ee5\u9a8c\u8bc1\u8be5\u7ed3\u679c\u4e0ePaddle inference\u7684\u9884\u6d4b\u7ed3\u679c\u5b8c\u5168\u4e00\u81f4"
        }
    ]
}