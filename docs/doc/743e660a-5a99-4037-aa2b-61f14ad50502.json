{
    "summary": "The script initializes a larger application, sets up logging and imports modules, predicts video tags using PaddleVideo's models, configures parameters, builds the model, prepares inputs/outputs, runs inference, checks file existence, retrieves infer reader, sets up data feeder, fetches model outputs, collects results with video IDs, logs/saves average processing time, and checks GPU availability and version compatibility before running.",
    "details": [
        {
            "comment": "This code appears to be an import and initialization script for a larger application. It sets up logging, imports various modules and libraries, checks the CUDA availability, and performs version checking. The code also includes licensing information and copyright notices.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/predict.py\":0-36",
            "content": "#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n#Licensed under the Apache License, Version 2.0 (the \"License\");\n#you may not use this file except in compliance with the License.\n#You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n#Unless required by applicable law or agreed to in writing, software\n#distributed under the License is distributed on an \"AS IS\" BASIS,\n#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#See the License for the specific language governing permissions and\n#limitations under the License.\nimport os\nimport sys\nimport time\nimport logging\nimport argparse\nimport ast\nimport numpy as np\nimport paddle\nimport paddle.static as static\ntry:\n    import cPickle as pickle\nexcept:\n    import pickle\nfrom utils.config_utils import *\nimport models\nfrom reader import get_reader\nfrom metrics import get_metrics\nfrom utils.utility import check_cuda\nfrom utils.utility import check_version\nlogging.root.handlers = []\nFORMAT = '[%(levelname)s: %(filename)s: %(lineno)4d]: %(message)s'"
        },
        {
            "comment": "The code imports logging, sets up a logger with debug level and configures the format. It then defines a function 'parse_args' that uses argparse to set default values for model name, config file path, whether to use GPU or not, weight path, and batch size for inference.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/predict.py\":37-63",
            "content": "logging.basicConfig(level=logging.DEBUG, format=FORMAT, stream=sys.stdout)\nlogger = logging.getLogger(__name__)\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--model_name',\n                        type=str,\n                        default='AttentionCluster',\n                        help='name of model to train.')\n    parser.add_argument('--config',\n                        type=str,\n                        default='configs/attention_cluster.txt',\n                        help='path to config file of model')\n    parser.add_argument('--use_gpu',\n                        type=ast.literal_eval,\n                        default=True,\n                        help='default use gpu.')\n    parser.add_argument(\n        '--weights',\n        type=str,\n        default='./data/checkpoints/AttentionLSTM_epoch9.pdparams',\n        help='weight path.')\n    parser.add_argument('--batch_size',\n                        type=int,\n                        default=1,\n                        help='sample number in a batch for inference.')"
        },
        {
            "comment": "This code snippet is part of a Python script for video tag prediction. It uses an argument parser to specify input files, log intervals, top k predictions and output directory. The default directories and paths are provided if no arguments are specified by the user.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/predict.py\":64-86",
            "content": "    parser.add_argument('--filelist',\n                        type=str,\n                        default=None,\n                        help='path to inferenece data file lists file.')\n    parser.add_argument('--log_interval',\n                        type=int,\n                        default=1,\n                        help='mini-batch interval to log.')\n    parser.add_argument('--infer_topk',\n                        type=int,\n                        default=20,\n                        help='topk predictions to restore.')\n    parser.add_argument('--save_dir',\n                        type=str,\n                        default=os.path.join('data', 'predict_results',\n                                             'attention_lstm'),\n                        help='directory to store results')\n    parser.add_argument('--video_path',\n                        type=str,\n                        default=None,\n                        help='directory to store results')\n    parser.add_argument('--label_file',\n                        type=str,"
        },
        {
            "comment": "The code defines a function that takes arguments, parses the config file, and builds an inference model using PaddleVideo's models. It then builds the inputs and outputs of the model, sets up the Executor based on GPU availability, and runs the startup program. Finally, it checks if the video or filelist path exists before proceeding with the inference process.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/predict.py\":87-114",
            "content": "                        default='label_3396.txt',\n                        help='chinese label file path')\n    args = parser.parse_args()\n    return args\ndef infer(args):\n    # parse config\n    config = parse_config(args.config)\n    infer_config = merge_configs(config, 'infer', vars(args))\n    print_configs(infer_config, \"Infer\")\n    infer_model = models.get_model(args.model_name, infer_config, mode='infer')\n    infer_model.build_input(use_dataloader=False)\n    infer_model.build_model()\n    infer_feeds = infer_model.feeds()\n    infer_outputs = infer_model.outputs()\n    place = paddle.CUDAPlace(0) if args.use_gpu else paddle.CPUPlace()\n    exe = static.Executor(place)\n    exe.run(static.default_startup_program())\n    filelist = args.filelist or infer_config.INFER.filelist\n    filepath = args.video_path or infer_config.INFER.get('filepath', '')\n    if filepath != '':\n        assert os.path.exists(filepath), \"{} not exist.\".format(filepath)\n    else:\n        assert os.path.exists(filelist), \"{} not exist.\".format(filelist)"
        },
        {
            "comment": "This code retrieves an infer reader, checks and loads weights for the model, sets up a data feeder, fetches outputs from the model, and collects results with video IDs.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/predict.py\":116-140",
            "content": "    # get infer reader\n    infer_reader = get_reader(args.model_name.upper(), 'infer', infer_config)\n    if args.weights:\n        assert os.path.exists(\n            args.weights), \"Given weight dir {} not exist.\".format(args.weights)\n    # if no weight files specified, download weights from paddle\n    weights = args.weights or infer_model.get_weights()\n    infer_model.load_test_weights(exe, weights, static.default_main_program())\n    infer_feeder = paddle.fluid.DataFeeder(place=place, feed_list=infer_feeds)\n    fetch_list = infer_model.fetches()\n    infer_metrics = get_metrics(args.model_name.upper(), 'infer', infer_config)\n    infer_metrics.reset()\n    periods = []\n    cur_time = time.time()\n    for infer_iter, data in enumerate(infer_reader()):\n        data_feed_in = [items[:-1] for items in data]\n        video_id = [items[-1] for items in data]\n        infer_outs = exe.run(fetch_list=fetch_list,\n                             feed=infer_feeder.feed(data_feed_in))\n        infer_result_list = [item for item in infer_outs] + [video_id]"
        },
        {
            "comment": "The code calculates the average processing time for each sample, logs the information, and saves the final output. It uses a log interval to report progress, and the `infer_metrics` object accumulates data for logging and saving. The code also checks for GPU availability and version compatibility before running.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoTag/predict.py\":142-170",
            "content": "        prev_time = cur_time\n        cur_time = time.time()\n        period = cur_time - prev_time\n        periods.append(period)\n        infer_metrics.accumulate(infer_result_list)\n        if args.log_interval > 0 and infer_iter % args.log_interval == 0:\n            logger.info('Processed {} samples'.format(\n                (infer_iter + 1) * len(video_id)))\n    logger.info('[INFER] infer finished. average time: {}'.format(\n        np.mean(periods)))\n    if not os.path.isdir(args.save_dir):\n        os.makedirs(args.save_dir)\n    infer_metrics.finalize_and_log_out(savedir=args.save_dir,\n                                       label_file=args.label_file)\nif __name__ == \"__main__\":\n    args = parse_args()\n    # check whether the installed paddle is compiled with GPU\n    check_cuda(args.use_gpu)\n    check_version()\n    logger.info(args)\n    infer(args)"
        }
    ]
}