{
    "summary": "This code utilizes PaddleVideo's TimeSformer model for video processing, including a VideoDecoder class to decode mp4 files and handle varying durations. The \"ActionFeatureDecoder\" class handles feature decoding, while the function prepares data for model input and normalizes inputs for PaddlePaddle's video pipeline.",
    "details": [
        {
            "comment": "This code snippet is part of the PaddleVideo library and it appears to import various packages, define a function \"get_start_end_idx\", and register something into the PIPELINES registry. It seems to handle video clip processing for TimeSformer and other models. The function calculates start and end indices for video clips based on video size, clip size, clip index, and the total number of clips.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":0-31",
            "content": "#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport numpy as np\ntry:\n    import av\nexcept ImportError as e:\n    print(\n        f\"Warning! {e}, [av] package and it's dependencies is required for TimeSformer and other models.\"\n    )\nimport cv2\nimport pickle\nimport decord as de\nimport math\nimport random\nfrom ..registry import PIPELINES\ndef get_start_end_idx(video_size, clip_size, clip_idx, num_clips):\n    delta = max(video_size - clip_size, 0)\n    if clip_idx == -1:  # here"
        },
        {
            "comment": "This code defines a VideoDecoder class for decoding mp4 files to frames. It takes the file path as input and has additional parameters for time-series applications like TimeSformer. The __call__ method performs the decoding operation, returning a list of numpy arrays representing the decoded frames.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":32-68",
            "content": "        # Random temporal sampling.\n        start_idx = random.uniform(0, delta)\n    else:  # ignore\n        # Uniformly sample the clip with the given index.\n        start_idx = delta * clip_idx / num_clips\n    end_idx = start_idx + clip_size - 1\n    return start_idx, end_idx\n@PIPELINES.register()\nclass VideoDecoder(object):\n    \"\"\"\n    Decode mp4 file to frames.\n    Args:\n        filepath: the file path of mp4 file\n    \"\"\"\n    def __init__(self,\n                 backend='cv2',\n                 mode='train',\n                 sampling_rate=32,\n                 num_seg=8,\n                 num_clips=1,\n                 target_fps=30):\n        self.backend = backend\n        # params below only for TimeSformer\n        self.mode = mode\n        self.sampling_rate = sampling_rate\n        self.num_seg = num_seg\n        self.num_clips = num_clips\n        self.target_fps = target_fps\n    def __call__(self, results):\n        \"\"\"\n        Perform mp4 decode operations.\n        return:\n            List where each item is a numpy array after decoder."
        },
        {
            "comment": "This code is part of a video decoding pipeline. It checks the backend and decodes videos using either cv2, decord or pyav depending on the backend specified. It reads frames from the video and stores them in 'results' dictionary for further processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":69-97",
            "content": "        \"\"\"\n        file_path = results['filename']\n        results['format'] = 'video'\n        results['backend'] = self.backend\n        if self.backend == 'cv2':\n            cap = cv2.VideoCapture(file_path)\n            videolen = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n            sampledFrames = []\n            for i in range(videolen):\n                ret, frame = cap.read()\n                # maybe first frame is empty\n                if ret == False:\n                    continue\n                img = frame[:, :, ::-1]\n                sampledFrames.append(img)\n            results['frames'] = sampledFrames\n            results['frames_len'] = len(sampledFrames)\n        elif self.backend == 'decord':\n            container = de.VideoReader(file_path)\n            frames_len = len(container)\n            results['frames'] = container\n            results['frames_len'] = frames_len\n        elif self.backend == 'pyav':  # for TimeSformer\n            if self.mode in [\"train\", \"valid\"]:\n                clip_idx = -1\n            elif self.mode in [\"test\"]:"
        },
        {
            "comment": "This code checks if the duration of a video file is None. If it is, it sets decode_all_video to True and calculates video_start_pts and video_end_pts as 0 and infinity respectively. If the duration is not None, it calculates start and end indices for decoding specific clips from the video file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":98-124",
            "content": "                clip_idx = 0\n            else:\n                raise NotImplementedError\n            container = av.open(file_path)\n            num_clips = 1  # always be 1\n            # decode process\n            fps = float(container.streams.video[0].average_rate)\n            frames_length = container.streams.video[0].frames\n            duration = container.streams.video[0].duration\n            if duration is None:\n                # If failed to fetch the decoding information, decode the entire video.\n                decode_all_video = True\n                video_start_pts, video_end_pts = 0, math.inf\n            else:\n                decode_all_video = False\n                start_idx, end_idx = get_start_end_idx(\n                    frames_length,\n                    self.sampling_rate * self.num_seg / self.target_fps * fps,\n                    clip_idx, num_clips)\n                timebase = duration / frames_length\n                video_start_pts = int(start_idx * timebase)\n                video_end_pts = int(end_idx * timebase)"
        },
        {
            "comment": "This code snippet is part of a video decoding pipeline in PaddleVideo. It seeks to a specific start time of the video stream, then decodes and filters frames based on their start and end points. Frames before the start point are skipped, while frames after the end point are buffered. Finally, it stores the relevant frames in the \"tmp\\_frames\" dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":126-149",
            "content": "            frames = None\n            # If video stream was found, fetch video frames from the video.\n            if container.streams.video:\n                margin = 1024\n                seek_offset = max(video_start_pts - margin, 0)\n                container.seek(seek_offset,\n                               any_frame=False,\n                               backward=True,\n                               stream=container.streams.video[0])\n                tmp_frames = {}\n                buffer_count = 0\n                max_pts = 0\n                for frame in container.decode(**{\"video\": 0}):\n                    max_pts = max(max_pts, frame.pts)\n                    if frame.pts < video_start_pts:\n                        continue\n                    if frame.pts <= video_end_pts:\n                        tmp_frames[frame.pts] = frame\n                    else:\n                        buffer_count += 1\n                        tmp_frames[frame.pts] = frame\n                        if buffer_count >= 0:\n                            break"
        },
        {
            "comment": "This code extracts video frames, sorts them by timestamp, and then converts the frames to RGB format. It calculates the start and end indices for a given clip size based on the number of frames and the selected clip size. The results are stored in a dictionary along with additional information such as frame length and indices. If no code is provided for the \"else\" condition, a NotImplementedError will be raised. This class is registered as a pipeline using @PIPELINES.register().",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":150-176",
            "content": "                video_frames = [tmp_frames[pts] for pts in sorted(tmp_frames)]\n                container.close()\n                frames = [frame.to_rgb().to_ndarray() for frame in video_frames]\n                clip_sz = self.sampling_rate * self.num_seg / self.target_fps * fps\n                start_idx, end_idx = get_start_end_idx(\n                    len(frames),  # frame_len\n                    clip_sz,\n                    clip_idx if decode_all_video else\n                    0,  # If decode all video, -1 in train and valid, 0 in test;\n                    # else, always 0 in train, valid and test, as we has selected clip size frames when decode.\n                    1)\n                results['frames'] = frames\n                results['frames_len'] = len(frames)\n                results['start_idx'] = start_idx\n                results['end_idx'] = end_idx\n        else:\n            raise NotImplementedError\n        return results\n@PIPELINES.register()\nclass FrameDecoder(object):\n    \"\"\"just parse results\n    \"\"\""
        },
        {
            "comment": "The code defines three pipeline classes for decoding different types of data. The MRIDecoder class sets the format to 'MRI'. The FeatureDecoder class initializes with parameters num_classes, max_len and has_label, then performs feature decode operations on loaded pkl files, parsing them into RGB/audio format, padding as necessary, and returning a list of numpy arrays.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":177-221",
            "content": "    def __init__(self):\n        pass\n    def __call__(self, results):\n        results['format'] = 'frame'\n        return results\n@PIPELINES.register()\nclass MRIDecoder(object):\n    \"\"\"just parse results\n    \"\"\"\n    def __init__(self):\n        pass\n    def __call__(self, results):\n        results['format'] = 'MRI'\n        return results\n@PIPELINES.register()\nclass FeatureDecoder(object):\n    \"\"\"\n        Perform feature decode operations.e.g.youtube8m\n    \"\"\"\n    def __init__(self, num_classes, max_len=512, has_label=True):\n        self.max_len = max_len\n        self.num_classes = num_classes\n        self.has_label = has_label\n    def __call__(self, results):\n        \"\"\"\n        Perform feature decode operations.\n        return:\n            List where each item is a numpy array after decoder.\n        \"\"\"\n        #1. load pkl\n        #2. parse to rgb/audio/\n        #3. padding\n        filepath = results['filename']\n        data = pickle.load(open(filepath, 'rb'), encoding='bytes')\n        record = data\n        nframes = record['nframes'] if 'nframes' in record else record["
        },
        {
            "comment": "This code is preparing data for a model. It loads the 'feature' and 'audio' from the record if available, converts them to float type, and cuts them up to the specified number of frames (nframes). If labels are present in the record, it makes one-hot encoding out of them. The data is then dequantized using a method, and results are stored into the 'labels' variable. Finally, three lists (feat_pad_list, feat_len_list, mask_list) are initialized for further data processing. The code handles two types of data: 'feature' and 'audio', iterating over them in a range loop.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":222-248",
            "content": "            b'nframes']\n        rgb = record['feature'].astype(\n            float) if 'feature' in record else record[b'feature'].astype(float)\n        audio = record['audio'].astype(\n            float) if 'audio' in record else record[b'audio'].astype(float)\n        if self.has_label:\n            label = record['label'] if 'label' in record else record[b'label']\n            one_hot_label = self.make_one_hot(label, self.num_classes)\n        rgb = rgb[0:nframes, :]\n        audio = audio[0:nframes, :]\n        rgb = self.dequantize(rgb,\n                              max_quantized_value=2.,\n                              min_quantized_value=-2.)\n        audio = self.dequantize(audio,\n                                max_quantized_value=2,\n                                min_quantized_value=-2)\n        if self.has_label:\n            results['labels'] = one_hot_label.astype(\"float32\")\n        feat_pad_list = []\n        feat_len_list = []\n        mask_list = []\n        vitem = [rgb, audio]\n        for vi in range(2):  #rgb and audio"
        },
        {
            "comment": "This function pads and dequantizes video features for model input. It first checks the type of feature (video or audio) and prepends 'rgb_' or 'audio_' to the result keys accordingly. Then it pads the feature with zeros to match the max length, creates a mask for the padded feature, and dequantizes the feature from byte format to float format.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":249-274",
            "content": "            if vi == 0:\n                prefix = \"rgb_\"\n            else:\n                prefix = \"audio_\"\n            feat = vitem[vi]\n            results[prefix + 'len'] = feat.shape[0]\n            #feat pad step 1. padding\n            feat_add = np.zeros((self.max_len - feat.shape[0], feat.shape[1]),\n                                dtype=np.float32)\n            feat_pad = np.concatenate((feat, feat_add), axis=0)\n            results[prefix + 'data'] = feat_pad.astype(\"float32\")\n            #feat pad step 2. mask\n            feat_mask_origin = np.ones(feat.shape, dtype=np.float32)\n            feat_mask_add = feat_add\n            feat_mask = np.concatenate((feat_mask_origin, feat_mask_add),\n                                       axis=0)\n            results[prefix + 'mask'] = feat_mask.astype(\"float32\")\n        return results\n    def dequantize(self,\n                   feat_vector,\n                   max_quantized_value=2.,\n                   min_quantized_value=-2.):\n        \"\"\"\n        Dequantize the feature from the byte format to the float format"
        },
        {
            "comment": "The code defines a class called \"ActionFeatureDecoder\" for feature decoding operations in football actions. It initializes with parameters for the maximum length, number of classes, and whether or not it should handle labels. The __call__ method performs the decoding operation on input results and returns a list of numpy arrays after decoding.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":275-309",
            "content": "        \"\"\"\n        assert max_quantized_value > min_quantized_value\n        quantized_range = max_quantized_value - min_quantized_value\n        scalar = quantized_range / 255.0\n        bias = (quantized_range / 512.0) + min_quantized_value\n        return feat_vector * scalar + bias\n    def make_one_hot(self, label, dim=3862):\n        one_hot_label = np.zeros(dim)\n        one_hot_label = one_hot_label.astype(float)\n        for ind in label:\n            one_hot_label[int(ind)] = 1\n        return one_hot_label\n@PIPELINES.register()\nclass ActionFeatureDecoder(object):\n    \"\"\"\n        Perform feature decode operations on footballaction\n    \"\"\"\n    def __init__(self, num_classes, max_len=512, has_label=True):\n        self.max_len = max_len\n        self.num_classes = num_classes\n        self.has_label = has_label\n    def __call__(self, results):\n        \"\"\"\n        Perform feature decode operations.\n        return:\n            List where each item is a numpy array after decoder.\n        \"\"\"\n        #1. load pkl\n        #2. parse to rgb/audio/"
        },
        {
            "comment": "The code is reading a pickle file, extracting the rgb image and audio features, label information, and performing some data manipulations. It sets the label to either 0 or 1 randomly if there's more than one in the data, normalizes iou values, and adds padding to the data for further processing. This is used in a video processing pipeline for PaddlePaddle.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":310-337",
            "content": "        #3. padding\n        filepath = results['filename']\n        data = pickle.load(open(filepath, 'rb'), encoding='bytes')\n        pkl_data = data\n        rgb = pkl_data['image_feature'].astype(float)\n        audio = pkl_data['audio_feature'].astype(float)\n        label_id_info = pkl_data['label_info']\n        label_cls = [label_id_info['label']]\n        label_one = int(label_cls[0])\n        if len(label_cls) > 1:\n            label_index = random.randint(0, 1)\n            label_one = int(label_cls[label_index])\n        iou_norm = float(label_id_info['norm_iou'])\n        results['labels'] = np.array([label_one])\n        results['iou_norm'] = float(iou_norm)\n        vitem = [rgb, audio]\n        for vi in range(2):  #rgb and audio\n            if vi == 0:\n                prefix = \"rgb_\"\n            else:\n                prefix = \"audio_\"\n            feat = vitem[vi]\n            results[prefix + 'len'] = feat.shape[0]\n            #feat pad step 1. padding\n            feat_add = np.zeros((self.max_len - feat.shape[0], feat.shape[1]),"
        },
        {
            "comment": "This code pads the feature data and its corresponding mask for a PaddleVideo pipeline, concatenating them and casting the results to float32 type before storing in the 'results' dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/loader/pipelines/decode.py\":338-346",
            "content": "                                dtype=np.float32)\n            feat_pad = np.concatenate((feat, feat_add), axis=0)\n            results[prefix + 'data'] = feat_pad.astype(\"float32\")\n            #feat pad step 2. mask\n            feat_mask_origin = np.ones(feat.shape, dtype=np.float32)\n            feat_mask = np.concatenate((feat_mask_origin, feat_add), axis=0)\n            results[prefix + 'mask'] = feat_mask.astype(\"float32\")\n        return results"
        }
    ]
}