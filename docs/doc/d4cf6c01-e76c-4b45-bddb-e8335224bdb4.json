{
    "summary": "The FeatureReader class, a DataReader subclass, reads video features using LSTM, attention cluster, and NextVlad models for YouTube-8M dataset. It handles multimodal data loading, exception handling, label manipulation, soft labels generation, and batch input feature creation. A function loads words and their indices from a file into a dictionary.",
    "details": [
        {
            "comment": "FeatureReader class is a subclass of DataReader, which reads video features from files using Pickle. It uses pandas and includes ExtractEmbeddingReader to read Ernie tasks and provides data reader functions for train/test splits.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":0-38",
            "content": "\"\"\"\nfeature reader\n\"\"\"\n#  Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport sys\ntry:\n    import cPickle as pickle\n    from cStringIO import StringIO\nexcept ImportError:\n    import pickle\n    from io import BytesIO\nimport numpy as np\nimport random\nimport os\nimport traceback\nimport pickle\npython_ver = sys.version_info\nfrom collections import defaultdict\nimport pandas as pd\nfrom .ernie_task_reader import ExtractEmbeddingReader\nfrom .reader_utils import DataReader\nclass FeatureReader(DataReader):"
        },
        {
            "comment": "The code initializes a data reader for YouTube-8M dataset, which contains features extracted by prior networks. It supports three models: LSTM, attention cluster, and NextVlad. The constructor takes the name, mode (train or test), and configuration parameters as inputs. It sets the batch size, file list, eigen_file (for NextVlad only), number of segments (num_seg), loss type, and initializes an ExtractEmbeddingReader using a vocab.txt file and maximum sequence length (text_max_len).",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":39-66",
            "content": "    \"\"\"\n    Data reader for youtube-8M dataset, which was stored as features extracted by prior networks\n    This is for the three models: lstm, attention cluster, nextvlad\n    dataset cfg: num_classes\n                 batch_size\n                 list\n                 NextVlad only: eigen_file\n    \"\"\"\n    def __init__(self, name, mode, cfg):\n        \"\"\"\n        init\n        \"\"\"\n        self.name = name\n        self.mode = mode\n        self.num_classes = cfg.MODEL.num_classes\n        # set batch size and file list\n        self.batch_size = cfg[mode.upper()]['batch_size']\n        self.filelist = cfg[mode.upper()]['filelist']\n        self.eigen_file = cfg.MODEL.get('eigen_file', None)\n        self.num_seg = cfg.MODEL.get('num_seg', None)\n        self.loss_type = cfg.TRAIN['loss_type']\n        vocab_file = os.path.join(cfg.TRAIN.ernie_pretrain_dict_path,\n                                  'vocab.txt')\n        self.ernie_reader = ExtractEmbeddingReader(\n            vocab_path=vocab_file,\n            max_seq_len=cfg.MODEL.text_max_len,"
        },
        {
            "comment": "The code loads a class dictionary and a video file information based on the given configuration. It then creates a reader function that iterates through the URLs, checks if a file exists for each URL, and skips if it doesn't. If the file exists, it loads the data (pickle format) using the appropriate pickle version for Python < 3.0 or >= 3.0.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":67-94",
            "content": "            do_lower_case=True)\n        url_title_label_file = cfg[mode.upper()]['url_title_label_file']\n        self.class_dict = load_class_file(cfg.MODEL.class_name_file)\n        self.url_title_info = load_video_file(url_title_label_file,\n                                              self.class_dict, mode)\n    def create_reader(self):\n        \"\"\"\n        create reader\n        \"\"\"\n        url_list = list(self.url_title_info.keys())\n        if self.mode == 'train':\n            random.shuffle(url_list)\n        def reader():\n            \"\"\"reader\n            \"\"\"\n            batch_out = []\n            for url in url_list:\n                try:\n                    filepath = os.path.join(\n                        self.filelist,\n                        url.split('/')[-1].split('.')[0] + '.pkl')\n                    if os.path.exists(filepath) is False:\n                        continue\n                    if python_ver < (3, 0):\n                        record = pickle.load(open(filepath, 'rb'))\n                    else:"
        },
        {
            "comment": "This code reads data from a file, prepares and processes it into various formats. It first loads the record from a file with pickle, then extracts text, RGB image data, and audio data (defaulting to zeroes if no audio is present). The code also generates one-hot encoding for the text using the ernie_reader. It obtains the video data and depending on the mode, assigns labels either as one-hot or softmax based on the loss type specified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":95-112",
            "content": "                        record = pickle.load(open(filepath, 'rb'),\n                                             encoding='iso-8859-1')\n                    text_raw = self.url_title_info[url]['title']\n                    rgb = record['feature']['image_pkl'].astype(float)\n                    if record['feature']['audio_pkl'].shape[0] == 0:\n                        audio_pkl = np.zeros((10, 128))\n                        audio = audio_pkl.astype(float)\n                    else:\n                        audio = record['feature']['audio_pkl'].astype(float)\n                    text_one_hot = self.ernie_reader.data_generate_from_text(\n                        str(text_raw))\n                    video = record['video']\n                    if self.mode != 'infer':\n                        label = self.url_title_info[url]['label']\n                        label = [int(w) for w in label]\n                        if self.loss_type == 'sigmoid':\n                            label = make_one_hot(label, self.num_classes)\n                        elif self.loss_type == 'softmax':"
        },
        {
            "comment": "This code is part of a data reader for multimodal video tagging. It reads in RGB images, audio clips, and text one-hot vectors, then appends them to a batch. If a label is available, it converts the label to a softmax output; otherwise, it yields the video itself. The code handles exceptions during data loading and allows for inferencing. Configuration values are retrieved using get_config_from_sec function.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":113-139",
            "content": "                            label = make_one_soft_hot(label, self.num_classes,\n                                                      False)\n                        batch_out.append((rgb, audio, text_one_hot, label))\n                    else:\n                        batch_out.append((rgb, audio, text_one_hot, video))\n                    if len(batch_out) == self.batch_size:\n                        yield batch_out\n                        batch_out = []\n                except Exception as e:\n                    print(\"warning: load data {} failed, {}\".format(\n                        filepath, str(e)))\n                    traceback.print_exc()\n                    continue\n# if self.mode == 'infer' and len(batch_out) > 0:\n            if len(batch_out) > 0:\n                yield batch_out\n        return reader\n    def get_config_from_sec(self, sec, item, default=None):\n        \"\"\"get_config_from_sec\n        \"\"\"\n        if sec.upper() not in self.cfg:\n            return default\n        return self.cfg[sec.upper()].get(item, default)"
        },
        {
            "comment": "This code defines a function load_video_file() that reads a label file in tab-separated format and stores the URLs, titles, and labels into a dictionary called url_info_dict. It also contains another function dequantize(), but this one is not used in the current code block. The load_video_file() function checks for NA values and splits the labels by comma before processing. If 'mode' is set to 'infer', it only stores title information; otherwise, it processes the labels. Finally, it prints the number of processed videos and returns the url_info_dict dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":142-172",
            "content": "def load_video_file(label_file, class_dict, mode='train'):\n    \"\"\"\n    labelfile formate: URL \\t title \\t label1,label2\n    return dict\n    \"\"\"\n    data = pd.read_csv(label_file, sep='\\t', header=None)\n    url_info_dict = defaultdict(dict)\n    for index, row in data.iterrows():\n        url = row[0]\n        if url in url_info_dict:\n            continue\n        if pd.isna(row[1]):\n            title = \"\"\n        else:\n            title = str(row[1])\n        if mode == 'infer':\n            url_info_dict[url] = {'title': title}\n        else:\n            if pd.isna(row[2]):\n                continue\n            labels = row[2].split(',')\n            labels_idx = [class_dict[w] for w in labels if w in class_dict]\n            if len(labels_idx) < 1:\n                continue\n            if url not in url_info_dict:\n                url_info_dict[url] = {'label': labels_idx, 'title': title}\n    print('load video %d' % (len(url_info_dict)))\n    return url_info_dict\ndef dequantize(feat_vector, max_quantized_value=2., min_quantized_value=-2.):"
        },
        {
            "comment": "This code contains a series of functions for handling and manipulating label data. The 'feature_reader' function dequantizes feature values, while the 'label_smmoth' function modifies a one-hot label vector by replacing zeros with a specific smoothness value. The 'make_one_soft_hot' function creates a one-hot soft label based on the input label and applies label smoothing if specified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":173-211",
            "content": "    \"\"\"\n    Dequantize the feature from the byte format to the float format\n    \"\"\"\n    assert max_quantized_value > min_quantized_value\n    quantized_range = max_quantized_value - min_quantized_value\n    scalar = quantized_range / 255.0\n    bias = (quantized_range / 512.0) + min_quantized_value\n    return feat_vector * scalar + bias\nepsilon = 0.1\nsmmoth_score = (1.0 / float(210)) * epsilon\ndef label_smmoth(label_one_hot_vector):\n    \"\"\"\n    label_smmoth\n    \"\"\"\n    global smmoth_score\n    for i in range(len(label_one_hot_vector)):\n        if label_one_hot_vector[i] == 0:\n            label_one_hot_vector[i] = smmoth_score\n    return label_one_hot_vector\ndef make_one_soft_hot(label, dim=15, label_smmoth=False):\n    \"\"\"\n    make_one_soft_hot\n    \"\"\"\n    one_hot_soft_label = np.zeros(dim)\n    one_hot_soft_label = one_hot_soft_label.astype(float)\n    # multi-labelis\n    # label smmoth\n    if label_smmoth:\n        one_hot_soft_label = label_smmoth(one_hot_soft_label)\n    label_len = len(label)\n    prob = (1 - np.sum(one_hot_soft_label)) / float(label_len)"
        },
        {
            "comment": "This code defines several functions for generating one-hot labels, creating random indices, and getting batch input features for a specific application. It uses numpy arrays for efficient operations and handling multidimensional data. The functions can be used in the context of multimodal video analysis, where labels, text inputs, and other data are processed for further processing or model training.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":212-250",
            "content": "    for ind in label:\n        one_hot_soft_label[ind] += prob\n    #one_hot_soft_label = label_smmoth(one_hot_soft_label)\n    return one_hot_soft_label\ndef make_one_hot(label, dim=15):\n    \"\"\"\n    make_one_hot\n    \"\"\"\n    one_hot_soft_label = np.zeros(dim)\n    one_hot_soft_label = one_hot_soft_label.astype(float)\n    for ind in label:\n        one_hot_soft_label[ind] = 1\n    return one_hot_soft_label\ndef generate_random_idx(feature_len, num_seg):\n    \"\"\"\n    generate_random_idx\n    \"\"\"\n    idxs = []\n    stride = float(feature_len) / num_seg\n    for i in range(num_seg):\n        pos = (i + np.random.random()) * stride\n        idxs.append(min(feature_len - 1, int(pos)))\n    return idxs\ndef get_batch_ernie_input_feature(reader, texts):\n    \"\"\"\n    get_batch_ernie_input_feature\n    \"\"\"\n    result_list = reader.data_generate_from_texts(texts)\n    result_trans = []\n    for i in range(len(texts)):\n        result_trans.append([result_list[0][i],\\\n                             result_list[1][i],\n                             result_list[2][i],"
        },
        {
            "comment": "The code contains a function that loads and returns a dictionary containing words and their corresponding indices from a class file. The function reads the lines of the file, removes any leading or trailing whitespace, splits the line based on tabs, assigns the first element as the word and the second element as the index (if available), then adds these key-value pairs to a dictionary. This dictionary is returned as the result.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py\":251-273",
            "content": "                             result_list[3][i],\n                             result_list[4][i]])\n    return np.array(result_trans)\ndef load_class_file(class_file):\n    \"\"\"\n    load_class_file\n    \"\"\"\n    class_lines = open(class_file, 'r', encoding='utf8').readlines()\n    class_dict = {}\n    for i, line in enumerate(class_lines):\n        tmp = line.strip().split('\\t')\n        word = tmp[0]\n        index = str(i)\n        if len(tmp) == 2:\n            index = tmp[1]\n        class_dict[word] = index\n    return class_dict\nif __name__ == '__main__':\n    pass"
        }
    ]
}