{
    "summary": "The code processes video frames, performs inference using an AI model and measures processing times. It preprocesses data in batches and utilizes TensorRT with GPU optimizations and MKLDNN support for efficiency.",
    "details": [
        {
            "comment": "The code initializes variables and performs batch size operations. It copies the batch of frames and resizes it to accommodate for multiple segments per frame batch. The times vector will store execution time values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":0-25",
            "content": "// Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n#include <include/video_rec.h>\nnamespace PaddleVideo\n{\n    void VideoRecognizer::Run(const std::vector<string> &frames_batch_path, const std::vector<std::vector<cv::Mat> > &frames_batch, std::vector<double> *times)\n    {\n        // Copy parameters to the function\n        int real_batch_num = frames_batch.size();\n        std::vector<cv::Mat> srcframes(real_batch_num * this->num_seg, cv::Mat());\n        for (int i = 0; i < real_batch_num; ++i)"
        },
        {
            "comment": "This code preprocesses video frames for model inference. It copies frames from source to destination, resizes them using a scale operation, and performs center cropping. The number of views is set to 1 if the model name is \"ppTSM\". The preprocessing steps include scaling and centering cropping to ensure the frames are properly formatted for inference.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":26-54",
            "content": "        {\n            for (int j = 0; j < this->num_seg; ++j)\n            {\n                frames_batch[i][j].copyTo(srcframes[i * this->num_seg + j]);\n            }\n        }\n        auto preprocess_start = std::chrono::steady_clock::now();\n        /* Preprocess */\n        std::vector<cv::Mat> resize_frames;\n        std::vector<cv::Mat> crop_frames;\n        std::vector<float> input;\n        int num_views = 1;\n        if (this->inference_model_name == \"ppTSM\")\n        {\n            num_views = 1;\n            // 1. Scale\n            resize_frames = std::vector<cv::Mat>(real_batch_num * this->num_seg, cv::Mat());\n            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    this->scale_op_.Run(srcframes[i * this->num_seg + j], resize_frames[i * this->num_seg + j], this->use_tensorrt_, 256);\n                }\n            }\n            // 2. CenterCrop\n            crop_frames = std::vector<cv::Mat>(real_batch_num * num_views * this->num_seg, cv::Mat());"
        },
        {
            "comment": "This code performs image preprocessing and conversion on video frames before feeding them into a neural network. It first resizes, centers, and crops the video frames using `centercrop_op_.Run()`. Then it normalizes the frames in an in-place operation using `normalize_op_.Run()`, with the mean and scale values provided. Finally, it converts the normalized frames into a single array using the dimensions from the first frame, and stores them in the 'input' vector.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":55-79",
            "content": "            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    this->centercrop_op_.Run(resize_frames[i * this->num_seg + j], crop_frames[i * this->num_seg + j], this->use_tensorrt_, 224);\n                }\n            }\n            // 3. Normalization(inplace operation)\n            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    for (int k = 0; k < num_views; ++k)\n                    {\n                        this->normalize_op_.Run(&crop_frames[i * num_views * this->num_seg + j * num_views + k], this->mean_, this->scale_, this->is_scale_);\n                    }\n                }\n            }\n            // 4. Image2Array\n            int rh = crop_frames[0].rows;\n            int rw = crop_frames[0].cols;\n            int rc = crop_frames[0].channels();\n            input = std::vector<float>(real_batch_num * num_views * this->num_seg *  crop_frames[0].rows * crop_frames[0].cols * rc, 0.0f);"
        },
        {
            "comment": "The code is iterating over real_batch_num number of batches and num_seg segments within each batch. For each segment, it's applying a set of operations (permute, scale, TenCrop) to a series of frames. These operations are used for data preprocessing before inputting into an inference model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":80-104",
            "content": "            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    for (int k = 0; k < num_views; ++k)\n                    {\n                        this->permute_op_.Run(&crop_frames[i * num_views * this->num_seg + j * num_views + k], input.data() + (i * num_views * this->num_seg + j * num_views + k) * (rh * rw * rc));\n                    }\n                }\n            }\n        }\n        else if(this->inference_model_name == \"ppTSN\")\n        {\n            num_views = 10;\n            // 1. Scale\n            resize_frames = std::vector<cv::Mat>(real_batch_num * this->num_seg, cv::Mat());\n            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    this->scale_op_.Run(srcframes[i * this->num_seg + j], resize_frames[i * this->num_seg + j], this->use_tensorrt_, 256);\n                }\n            }\n            // 2. TenCrop"
        },
        {
            "comment": "This code performs image preprocessing for video frames. It initializes a vector of crop_frames, iterates through real_batch_num and num_seg to run resizing and cropping operations on each frame using tencrop_op_. Next, it applies normalization inplace operation on each frame using normalize_op_. Finally, it converts the processed frames into an array by extracting rows and columns size from the first crop_frame.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":105-128",
            "content": "            crop_frames = std::vector<cv::Mat>(real_batch_num * this->num_seg * num_views, cv::Mat());\n            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    this->tencrop_op_.Run(resize_frames[i * this->num_seg + j], crop_frames, (i * this->num_seg  + j) * num_views, this->use_tensorrt_, 224);\n                }\n            }\n            // 3. Normalization(inplace operation)\n            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    for (int k = 0; k < num_views; ++k)\n                    {\n                        this->normalize_op_.Run(&crop_frames[i * this->num_seg * num_views + j * num_views + k], this->mean_, this->scale_, this->is_scale_);\n                    }\n                }\n            }\n            // 4. Image2Array\n            int rh = crop_frames[0].rows;\n            int rw = crop_frames[0].cols;"
        },
        {
            "comment": "The code initializes a vector with zeros based on the number of frames, segments, views, and channels. It then iterates over the real batch number, segments, and views to permute and populate the input vector. Finally, it performs inference by reshaping the input tensor for prediction.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":129-151",
            "content": "            int rc = crop_frames[0].channels();\n            input = std::vector<float>(real_batch_num * this->num_seg * num_views *  crop_frames[0].rows * crop_frames[0].cols * rc, 0.0f);\n            for (int i = 0; i < real_batch_num; ++i)\n            {\n                for (int j = 0; j < this->num_seg; ++j)\n                {\n                    for (int k = 0; k < num_views; ++k)\n                    {\n                        this->permute_op_.Run(&crop_frames[i * this->num_seg * num_views + j * num_views + k], input.data() + (i * this->num_seg * num_views + j * num_views + k) * (rh * rw * rc));\n                    }\n                }\n            }\n        }\n        else\n        {\n            throw \"[Error] Not implemented yet\";\n        }\n        auto preprocess_end = std::chrono::steady_clock::now();\n        /* Inference */\n        auto input_names = this->predictor_->GetInputNames();\n        auto input_t = this->predictor_->GetInputHandle(input_names[0]);\n        input_t->Reshape({real_batch_num * num_views * this->num_seg, 3, crop_frames[0].rows, crop_frames[0].cols});"
        },
        {
            "comment": "This code segment performs inference using an AI model, gathers the output probabilities, and applies softmax operation to convert logits into probabilities.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":152-174",
            "content": "        auto inference_start = std::chrono::steady_clock::now();\n        input_t->CopyFromCpu(input.data());\n        this->predictor_->Run(); // Use the inference library to predict\n        std::vector<float> predict_batch;\n        auto output_names = this->predictor_->GetOutputNames();\n        auto output_t = this->predictor_->GetOutputHandle(output_names[0]);\n        auto predict_shape = output_t->shape();\n        // Get the number of class\n        int class_num = predict_shape[1];\n        int out_numel = std::accumulate(predict_shape.begin(), predict_shape.end(), 1, std::multiplies<int>());\n        predict_batch.resize(out_numel); // NxC\n        output_t->CopyToCpu(predict_batch.data()); // Copy the model output to predict_batch\n        // Convert output (logits) into probabilities\n        for (int i = 0; i < real_batch_num; ++i)\n        {\n            this->softmax_op_.Inplace_Run(predict_batch.begin() + i * class_num, predict_batch.begin() + (i + 1) * class_num);\n        }\n        auto inference_end = std::chrono::steady_clock::now();"
        },
        {
            "comment": "This code snippet is responsible for post-processing the results of object detection after model inference. It calculates the class and score for each frame, outputs it, and stores the processing times.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":176-197",
            "content": "        // output decode\n        auto postprocess_start = std::chrono::steady_clock::now();\n        std::vector<std::string> str_res;\n        std::vector<float>scores;\n        for (int i = 0; i < real_batch_num; ++i)\n        {\n            int argmax_idx = int(Utility::argmax(predict_batch.begin() + i * class_num, predict_batch.begin() + (i + 1) * class_num));\n            float score = predict_batch[argmax_idx];\n            scores.push_back(score);\n            str_res.push_back(this->label_list_[argmax_idx]);\n        }\n        auto postprocess_end = std::chrono::steady_clock::now();\n        for (int i = 0; i < str_res.size(); i++)\n        {\n            std::cout << frames_batch_path[i] << \"\\tclass: \" << str_res[i] << \"\\tscore: \" << scores[i] << endl;\n        }\n        std::chrono::duration<float> preprocess_diff = preprocess_end - preprocess_start;\n        times->push_back(double(preprocess_diff.count() * 1000));\n        std::chrono::duration<float> inference_diff = inference_end - inference_start;\n        times->push_back(double(inference_diff.count() * 1000));"
        },
        {
            "comment": "This code initializes a Paddle Video recognizer by loading the model from a given directory. It also sets up GPU and TensorRT configurations if needed, and specifies precision based on the provided string value.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":198-222",
            "content": "        std::chrono::duration<float> postprocess_diff = postprocess_end - postprocess_start;\n        times->push_back(double(postprocess_diff.count() * 1000));\n    }\n    void VideoRecognizer::LoadModel(const std::string &model_dir)\n    {\n        //   AnalysisConfig config;\n        paddle_infer::Config config;\n        config.SetModel(model_dir + \"/\" + this->inference_model_name + \".pdmodel\",\n                        model_dir + \"/\" + this->inference_model_name + \".pdiparams\");\n        if (this->use_gpu_)\n        {\n            config.EnableUseGpu(this->gpu_mem_, this->gpu_id_);\n            if (this->use_tensorrt_)\n            {\n                auto precision = paddle_infer::Config::Precision::kFloat32;\n                if (this->precision_ == \"fp16\")\n                {\n                    precision = paddle_infer::Config::Precision::kHalf;\n                }\n                else if (this->precision_ == \"int8\")\n                {\n                    precision = paddle_infer::Config::Precision::kInt8;\n                }"
        },
        {
            "comment": "This code checks the inference model name and configures TensorRT engine accordingly for different models like ppTSM, TSM, ppTSN, or TSN. It sets workspace size to a large value, maxBatchSize based on number of segments, minSubgraphSize to 3, precision, and disables useStatic and useCalibMode.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":224-246",
            "content": "                if (this->inference_model_name == \"ppTSM\" || this->inference_model_name == \"TSM\")\n                {\n                    config.EnableTensorRtEngine(\n                        1 << 30, // workspaceSize\n                        this->rec_batch_num * this->num_seg * 1, // maxBatchSize\n                        3, // minSubgraphSize\n                        precision, // precision\n                        false,// useStatic\n                        false //useCalibMode\n                    );\n                }\n                else if(this->inference_model_name == \"ppTSN\" || this->inference_model_name == \"TSN\")\n                {\n                    config.EnableTensorRtEngine(\n                        1 << 30,\n                        this->rec_batch_num * this->num_seg * 10,\n                        3, // minSubgraphSize\n                        precision,// precision\n                        false,// useStatic\n                        false //useCalibMode\n                    );\n                }\n                else"
        },
        {
            "comment": "The code enables the TensorRT engine with specific parameters, such as workspace size, max batch size, minimum subgraph size, and precision. It checks if TensorRT is enabled and deactivates it by default for models that do not support dynamic shape. The code also defines input shape ranges (min, opt) for a particular key (\"data_batch_0\").",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":247-270",
            "content": "                {\n                    config.EnableTensorRtEngine(\n                        1 << 30, // workspaceSize\n                        this->rec_batch_num, // maxBatchSize\n                        3, // minSubgraphSize\n                        precision,// precision\n                        false,// useStatic\n                        false //useCalibMode\n                    );\n                }\n                std::cout << \"Enable TensorRT is: \" << config.tensorrt_engine_enabled() << std::endl;\n                /* some model dose not suppport dynamic shape with TRT, deactivate it by default */\n                // std::map<std::string, std::vector<int> > min_input_shape =\n                // {\n                //     {\"data_batch_0\", {1, this->num_seg, 3, 1, 1}}\n                // };\n                // std::map<std::string, std::vector<int> > max_input_shape =\n                // {\n                //     {\"data_batch_0\", {1, this->num_seg, 3, 256, 256}}\n                // };\n                // std::map<std::string, std::vector<int> > opt_input_shape ="
        },
        {
            "comment": "This code initializes a PaddleVideo predictor with TensorRT configuration options. It sets the GPU usage, enables MKLDNN (if needed), specifies input names and optimizations, disables INFO log messages, and creates the predictor.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/cpp_infer/src/video_rec.cpp\":271-303",
            "content": "                // {\n                //     {\"data_batch_0\", {this->rec_batch_num,  this->num_seg, 3, 224, 224}}\n                // };\n                // config.SetTRTDynamicShapeInfo(min_input_shape, max_input_shape,\n                //                               opt_input_shape);\n            }\n        }\n        else\n        {\n            config.DisableGpu();\n            if (this->use_mkldnn_)\n            {\n                config.EnableMKLDNN();\n                // cache 10 different shapes for mkldnn to avoid memory leak\n                config.SetMkldnnCacheCapacity(10);\n            }\n            config.SetCpuMathLibraryNumThreads(this->cpu_math_library_num_threads_);\n        }\n        config.SwitchUseFeedFetchOps(false);\n        // true for multiple input\n        config.SwitchSpecifyInputNames(true);\n        config.SwitchIrOptim(true);\n        config.EnableMemoryOptim();\n        config.DisableGlogInfo();\n        this->predictor_ = CreatePredictor(config);\n    }\n} // namespace PaddleVideo"
        }
    ]
}