{
    "summary": "This code sets up PaddleVideo, imports libraries, and defines preprocessing pipelines for image recognition web services using PaddlePaddle. It includes a `VideoOp` class for video operations and a \"VideoService\" class for preprocessing and post-processing methods.",
    "details": [
        {
            "comment": "This code is importing necessary libraries and modules, setting up the path for the PaddleVideo project, and defining several image processing pipelines including CenterCrop, Image2Array, Normalization, Sampler, and Scale. The purpose of this code is to provide a base for building an image recognition web service using PaddlePaddle.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/recognition_web_service.py\":0-27",
            "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport argparse\nimport base64\nimport os\nimport sys\nfrom typing import Callable, Dict, List\nimport numpy as np\n__dir__ = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.abspath(os.path.join(__dir__, '../../')))\nfrom paddle_serving_app.reader import Sequential\nfrom paddlevideo.loader.pipelines import (CenterCrop, Image2Array,\n                                          Normalization, Sampler, Scale,"
        },
        {
            "comment": "This code defines a function called get_preprocess_seq that returns a list of preprocessing operators based on the model name passed as an argument. The model names accepted are \"PPTSM\" and \"PPTSN\". The function checks the model name, and depending on its value, it constructs and returns a sequence of preprocess operators including Sampler, Scale, CenterCrop, Image2Array, and Normalization. These operations prepare the input data for a specific model before feeding into the model for prediction or inference.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/recognition_web_service.py\":28-61",
            "content": "                                          TenCrop)\ntry:\n    from paddle_serving_server_gpu.web_service import Op, WebService\nexcept ImportError:\n    from paddle_serving_server.web_service import Op, WebService\nVALID_MODELS = [\"PPTSM\", \"PPTSN\"]\ndef get_preprocess_seq(model_name: str) -> List[Callable]:\n    \"\"\"get preprocess sequence by model name\n    Args:\n        model_name (str): model name for web serving, such as 'PPTSM', 'PPTSN'\n    Returns:\n        List[Callable]: preprocess operators in list.\n    \"\"\"\n    if model_name == 'PPTSM':\n        preprocess_seq = [\n            Sampler(8, 1, valid_mode=True),\n            Scale(256),\n            CenterCrop(224),\n            Image2Array(),\n            Normalization([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]\n    elif model_name == 'PPTSN':\n        preprocess_seq = [\n            Sampler(25, 1, valid_mode=True, select_left=True),\n            Scale(256, fixed_ratio=True, do_round=True, backend='cv2'),\n            TenCrop(224),\n            Image2Array(),\n            Normalization([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
        },
        {
            "comment": "This code snippet defines a class `VideoOp` that initializes an object with a preprocessing sequence and a dictionary of labels. The `preprocess()` method takes input dictionaries, data ID, and log ID as arguments to perform some operation on video data. The `init_op()` method is responsible for setting up the preprocessing sequence and label dictionary.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/recognition_web_service.py\":62-101",
            "content": "        ]\n    else:\n        raise ValueError(\n            f\"model_name must in {VALID_MODELS}, but got {model_name}\")\n    return preprocess_seq\ndef np_softmax(x: np.ndarray, axis=0) -> np.ndarray:\n    \"\"\"softmax function\n    Args:\n        x (np.ndarray): logits.\n    Returns:\n        np.ndarray: probs.\n    \"\"\"\n    x -= np.max(x, axis=axis, keepdims=True)\n    x = np.exp(x) / np.sum(np.exp(x), axis=axis, keepdims=True)\n    return x\nclass VideoOp(Op):\n    def init_op(self):\n        \"\"\"init_op\n        \"\"\"\n        self.seq = Sequential(get_preprocess_seq(args.name))\n        self.label_dict = {}\n        with open(\"../../data/k400/Kinetics-400_label_list.txt\", \"r\") as fin:\n            for line in fin:\n                label_ind, label_name = line.strip().split(' ')\n                label_ind = int(label_ind)\n                self.label_dict[label_ind] = label_name.strip()\n    def preprocess(self, input_dicts: Dict, data_id: int, log_id: int):\n        \"\"\"preprocess\n        Args:\n            input_dicts (Dict): input_dicts.\n            data_id (int): data_id."
        },
        {
            "comment": "This code function takes input_dicts, decodes and reshapes the 'frames' data into numpy array, splits it based on frame length, then squeezes the dimensions and stores the result in results dictionary. It also handles unexpected keys by raising ValueError.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/recognition_web_service.py\":102-124",
            "content": "            log_id (int): log_id.\n        Returns:\n            output_data: data for process stage.\n            is_skip_process: skip process stage or not, False default\n            prod_errcode: None default, otherwise, product errores occured.\n                          It is handled in the same way as exception.\n            prod_errinfo: \"\" default.\n        \"\"\"\n        (_, input_dict), = input_dicts.items()\n        for key in input_dict.keys():\n            if key == \"frames\":\n                frame_data = base64.b64decode(input_dict[key].encode('utf8'))\n                frame_data = np.fromstring(frame_data, np.uint8)\n            elif key == 'frames_shape':\n                shape_data = eval(input_dict[key])\n            else:\n                raise ValueError(f\"unexpected key received: {key}\")\n        frame_data = frame_data.reshape(shape_data)\n        frame_len = frame_data.shape[0]\n        frame_data = np.split(frame_data, frame_len, axis=0)\n        frame_data = [frame.squeeze(0) for frame in frame_data]\n        results = {"
        },
        {
            "comment": "This code defines two methods: 'preprocess' and 'postprocess'. The 'preprocess' method takes input data in frames, sets the backend as cv2, expands dimensions for input to the network, and returns tmp_inp with a shape of [1,b,t,c,h,w]. The 'postprocess' method receives input_dicts from preprocess stage, fetch_dict from process stage, data_id, and log_id. It then returns the fetch result as a dictionary type.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/recognition_web_service.py\":125-148",
            "content": "            'frames': frame_data,\n            'frames_len': frame_len,\n            'format': 'video',\n            'backend': 'cv2'\n        }\n        results = self.seq(results)\n        tmp_inp = np.expand_dims(results['imgs'], axis=0)  # [b,t,c,h,w]\n        # The input for the network is input_data[0], so need to add 1 dimension at the beginning\n        tmp_inp = np.expand_dims(tmp_inp, axis=0).copy()  # [1,b,t,c,h,w]\n        return {\"data_batch_0\": tmp_inp}, False, None, \"\"\n    def postprocess(self, input_dicts: Dict, fetch_dict: Dict, data_id: int,\n                    log_id: int):\n        \"\"\"postprocess\n        Args:\n            input_dicts (Dict): data returned in preprocess stage, dict(for single predict) or list(for batch predict).\n            fetch_dict (Dict): data returned in process stage, dict(for single predict) or list(for batch predict).\n            data_id (int): inner unique id, increase auto.\n            log_id (int): logid, 0 default.\n        Returns:\n            fetch_dict: fetch result must be dict type."
        },
        {
            "comment": "This code defines a class and a function. The class, \"VideoService\", extends the \"WebService\" class and has a method called \"get_pipeline_response\". The method takes an input operation (read_op) as its argument and returns a VideoOp object with the given read_op as its input. The function \"parse_args\" is used to parse command line arguments. It seems that this code is related to video processing and handling inputs/outputs in some kind of pipeline or web service.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/recognition_web_service.py\":149-181",
            "content": "            prod_errcode: None default, otherwise, product errores occured.\n                          It is handled in the same way as exception.\n            prod_errinfo: \"\" default.\n        \"\"\"\n        score_list = fetch_dict[\"outputs\"]\n        result = {\"label\": [], \"prob\": []}\n        for score in score_list:\n            score = np_softmax(score)\n            score = score.tolist()\n            max_score = max(score)\n            max_index = score.index(max_score)\n            result[\"label\"].append(self.label_dict[max_index])\n            result[\"prob\"].append(max_score)\n        result[\"label\"] = str(result[\"label\"])\n        result[\"prob\"] = str(result[\"prob\"])\n        return result, None, \"\"\nclass VideoService(WebService):\n    def get_pipeline_response(self, read_op):\n        \"\"\"get_pipeline_response\n        Args:\n            read_op ([type]): [description]\n        Returns:\n            [type]: [description]\n        \"\"\"\n        video_op = VideoOp(name=\"video\", input_ops=[read_op])\n        return video_op\ndef parse_args():"
        },
        {
            "comment": "This code parses command-line arguments, initializes a PaddleVideo VideoService object with the provided configuration file and runs the service. The name of the model used in web serving is \"PPTSM\".",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/deploy/python_serving/recognition_web_service.py\":182-207",
            "content": "    # general params\n    parser = argparse.ArgumentParser(\"PaddleVideo Web Serving model script\")\n    parser.add_argument(\n        '-n',\n        '--name',\n        type=str,\n        default='PPTSM',\n        help='model name used in web serving, such as PPTSM, PPTSN...')\n    parser.add_argument('-c',\n                        '--config',\n                        type=str,\n                        default='configs/PP-TSM.yaml',\n                        help='serving config file path')\n    return parser.parse_args()\nif __name__ == '__main__':\n    # get args such as serving config yaml path.\n    args = parse_args()\n    # start serving\n    uci_service = VideoService(name=\"video\")\n    uci_service.prepare_pipeline_config(yaml_file=args.config)\n    uci_service.run_service()"
        }
    ]
}