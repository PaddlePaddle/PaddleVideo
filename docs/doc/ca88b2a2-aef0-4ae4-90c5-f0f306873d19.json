{
    "summary": "The code extracts audio features using MFCC and STFT for action detection in FootballAction. It includes spectrogram bins conversion, data normalization, and resampling with examples using a WAV file.",
    "details": [
        {
            "comment": "This code extracts audio features using the Mel-frequency cepstral coefficients (MFCC) method. It defines a function \"frame\" to slice data into frames, another function \"periodic_hann\" for windowing using periodic Hann window, and finally a function \"stft_magnitude\" for computing Short Time Fourier Transform (STFT) magnitude from signal. The code likely uses these functions in combination to extract MFCC features from audio data.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py\":0-37",
            "content": "\"\"\"\naudio feature extract\n\"\"\"\n# coding: utf-8\nimport os\nimport numpy as np\nimport pickle\nimport mfcc.vgg_params as vgg_params\ndef frame(data, window_length, hop_length):\n    \"\"\"\n    frame\n    \"\"\"\n    num_samples = data.shape[0]\n    #print(\"window_length , hop_length\", window_length, hop_length)\n    #print(\"num_sample = \", num_samples)\n    num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))\n    #print(\" num_frames = \", num_frames)\n    shape = (num_frames, window_length) + data.shape[1:]\n    #print(\" shape = \", shape)\n    strides = (data.strides[0] * hop_length, ) + data.strides\n    #print(\"data.strides = \", data.strides)\n    #print(\"strides = \", strides)\n    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\ndef periodic_hann(window_length):\n    \"\"\"\n    periodic_hann\n    \"\"\"\n    return 0.5 - (0.5 *\n                  np.cos(2 * np.pi / window_length * np.arange(window_length)))\ndef stft_magnitude(signal, fft_length, hop_length=None, window_length=None):\n    \"\"\"\n    stft_magnitude"
        },
        {
            "comment": "This code defines functions for converting frequencies from Hertz to Mel scale, and creating a mel spectrum matrix from a spectrogram. It also includes validation checks to ensure lower edge frequency is less than the upper edge frequency. The Mel scale is used in audio processing for approximating human auditory perception of sound.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py\":38-68",
            "content": "    \"\"\"\n    frames = frame(signal, window_length, hop_length)\n    window = periodic_hann(window_length)\n    windowed_frames = frames * window\n    return np.abs(np.fft.rfft(windowed_frames, int(fft_length)))\n_MEL_BREAK_FREQUENCY_HERTZ = 700.0\n_MEL_HIGH_FREQUENCY_Q = 1127.0\ndef hertz_to_mel(frequencies_hertz):\n    \"\"\"\n    hertz_to_mel\n    \"\"\"\n    return _MEL_HIGH_FREQUENCY_Q * np.log(1.0 + (frequencies_hertz /\n                                                 _MEL_BREAK_FREQUENCY_HERTZ))\ndef spectrogram_to_mel_matrix(num_mel_bins=20,\n                              num_spectrogram_bins=129,\n                              audio_sample_rate=8000,\n                              lower_edge_hertz=125.0,\n                              upper_edge_hertz=3800.0):\n    \"\"\"\n    spectrogram_to_mel_matrix\n    \"\"\"\n    nyquist_hertz = audio_sample_rate / 2.\n    if lower_edge_hertz >= upper_edge_hertz:\n        raise ValueError(\"lower_edge_hertz %.1f >= upper_edge_hertz %.1f\" %\n                         (lower_edge_hertz, upper_edge_hertz))"
        },
        {
            "comment": "This function calculates mel-frequency cepstral coefficients (MFCC) from speech audio data. It converts spectrogram bins to hertz and mel scales, creates band edges for mel analysis, computes mel weights matrix using triangular interpolation, and sets the first row of the matrix to zero.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py\":69-89",
            "content": "    spectrogram_bins_hertz = np.linspace(0.0, nyquist_hertz,\n                                         num_spectrogram_bins)\n    spectrogram_bins_mel = hertz_to_mel(spectrogram_bins_hertz)\n    band_edges_mel = np.linspace(hertz_to_mel(lower_edge_hertz),\n                                 hertz_to_mel(upper_edge_hertz),\n                                 num_mel_bins + 2)\n    mel_weights_matrix = np.empty((num_spectrogram_bins, num_mel_bins))\n    for i in range(num_mel_bins):\n        lower_edge_mel, center_mel, upper_edge_mel = band_edges_mel[i:i + 3]\n        lower_slope = ((spectrogram_bins_mel - lower_edge_mel) /\n                       (center_mel - lower_edge_mel))\n        upper_slope = ((upper_edge_mel - spectrogram_bins_mel) /\n                       (upper_edge_mel - center_mel))\n        mel_weights_matrix[:,\n                           i] = np.maximum(0.0,\n                                           np.minimum(lower_slope, upper_slope))\n    mel_weights_matrix[0, :] = 0.0\n    return mel_weights_matrix\ndef log_mel_spectrogram(data,"
        },
        {
            "comment": "This function takes in audio data and parameters such as audio sample rate, window length in seconds, hop length in seconds, and other optional keywords. It calculates the window length samples and hop length samples based on the provided audio sample rate. It then determines the FFT length by taking the next highest power of 2 from the window length samples. Finally, it computes the spectrogram using the STFT (Short-Time Fourier Transform) magnitude with the calculated parameters and returns the resulting spectrogram.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py\":90-110",
            "content": "                        audio_sample_rate=8000,\n                        log_offset=0.0,\n                        window_length_secs=0.025,\n                        hop_length_secs=0.010,\n                        **kwargs):\n    \"\"\"\n    log_mel_spectrogram\n    \"\"\"\n    window_length_samples = int(round(audio_sample_rate * window_length_secs))\n    #print(\"audio_sample_rate = \", audio_sample_rate)\n    #print(\"window_length_secs = \", window_length_secs)\n    #print(\"window_length_sample \", window_length_samples)\n    hop_length_samples = int(round(audio_sample_rate * hop_length_secs))\n    #print(\"hop_length_samples \", hop_length_samples)\n    fft_length = 2**int(np.ceil(np.log(window_length_samples) / np.log(2.0)))\n    #print(\" fft_lengt = \", fft_length)\n    spectrogram = stft_magnitude(data,\n                                 fft_length=fft_length,\n                                 hop_length=hop_length_samples,\n                                 window_length=window_length_samples)\n    #print(\" spectrogram.shape = \", spectrogram.shape)"
        },
        {
            "comment": "The code extracts audio features from a WAV file using short-time Fourier transform (STFT) and applies Mel-frequency cepstral coefficients (MFCCs). It reads the WAV file, pads zeros if necessary to match desired window length, scales the data to be between -1 and 1, and then calculates STFT. Finally, it computes MFCCs from the spectrogram and returns the log of the result plus a small offset for numerical stability.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py\":111-135",
            "content": "    mel_spectrogram = np.dot(\n        spectrogram,\n        spectrogram_to_mel_matrix(num_spectrogram_bins=spectrogram.shape[1],\n                                  audio_sample_rate=audio_sample_rate,\n                                  **kwargs))\n    return np.log(mel_spectrogram + log_offset)\ndef wav_to_example(wav_data, sample_rate):\n    \"\"\"\n    wav_to_example\n    \"\"\"\n    #sample_rate, wav_data = wavfile.read(wav_file)\n    assert wav_data.dtype == np.int16, 'Bad sample type: %r' % wav_data.dtype\n    #wav_data = wav_data[:16000*30]\n    #print(\" wav_data \", wav_data.shape)\n    #print(\" wav_data \", wav_data.shape)\n    pad_zero_num = int(sample_rate * (vgg_params.STFT_WINDOW_LENGTH_SECONDS -\n                                      vgg_params.STFT_HOP_LENGTH_SECONDS))\n    wav_data_extend = np.hstack((wav_data, np.zeros(pad_zero_num)))\n    wav_data = wav_data_extend\n    #print(\" wav_data \", wav_data.shape)\n    wav_data = wav_data / 32768.0  # Convert to [-1.0, +1.0]\n    #print(\" wav_data after convert to -1 1\", wav_data)"
        },
        {
            "comment": "This code performs feature extraction on audio data for action detection in the FootballAction application. It ensures that the audio data is within specified bounds, applies mean normalization if necessary, resamples to a fixed rate, and then generates log mel spectrogram features. These features are framed into examples at a specific sample rate and window length for use by VGG model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py\":136-156",
            "content": "    #if wav_data.shape[0] > max_second * sample_rate:\n    #    wav_data = wav_data[:max_second * sample_rate, :]\n    if len(wav_data.shape) > 1:\n        wav_data = np.mean(wav_data, axis=1)\n    #print(\" wav_data after mean\", wav_data.shape, len(wav_data.shape), wav_data)\n    # Resample to the rate assumed by vgg.\n    #if sample_rate != vgg_params.SAMPLE_RATE:\n    #    wav_data = resampy.resample(wav_data, sample_rate, vgg_params.SAMPLE_RATE)\n    log_mel = log_mel_spectrogram(\n        wav_data,\n        audio_sample_rate=vgg_params.SAMPLE_RATE,\n        log_offset=vgg_params.LOG_OFFSET,\n        window_length_secs=vgg_params.STFT_WINDOW_LENGTH_SECONDS,\n        hop_length_secs=vgg_params.STFT_HOP_LENGTH_SECONDS,\n        num_mel_bins=vgg_params.NUM_MEL_BINS,\n        lower_edge_hertz=vgg_params.MEL_MIN_HZ,\n        upper_edge_hertz=vgg_params.MEL_MAX_HZ)\n    # Frame features into examples.\n    features_sample_rate = 1.0 / vgg_params.STFT_HOP_LENGTH_SECONDS\n    example_window_length = int(\n        round(vgg_params.EXAMPLE_WINDOW_SECONDS * features_sample_rate))"
        },
        {
            "comment": "The code defines a function that extracts audio features from WAV files. It calculates the hop length based on the example window length and sample rate, and applies a log Mel spectrum to the audio data. It also includes a separate function for extracting examples from PCM files and converting them into examples at a given sample rate. The main part of the code demonstrates how to use the functions by reading a WAV file, printing its shape after processing with the feature extraction functions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py\":158-181",
            "content": "    example_hop_length = int(\n        round(vgg_params.EXAMPLE_HOP_SECONDS * features_sample_rate))\n    log_mel_examples = frame(log_mel,\n                             window_length=example_window_length,\n                             hop_length=example_hop_length)\n    return log_mel_examples\ndef extract_pcm(pcm_file, sample_rate):\n    with open(pcm_file, \"rb\") as f:\n        pcm_data = f.read()\n    audio_data = np.fromstring(pcm_data, dtype=np.int16)\n    examples = wav_to_example(audio_data, sample_rate)\n    return examples\nif __name__ == \"__main__\":\n    wav_file = sys.argv[1]\n    print(\"wav_file = \", wav_file)\n    with open(wav_file, \"rb\") as f:\n        pcm_data = f.read()\n    audio_data = np.fromstring(pcm_data, dtype = np.int16)\n    examples_batch = wav_to_example(audio_data, 16000)\n    print(\"examples_batch.shape\", examples_batch.shape)   "
        }
    ]
}