{
    "summary": "This code utilizes PaddleVideo library to train a video quality assessment model with GPU support, parallel processing, and distributed training. It includes data loaders, solvers, optimization, logging, and validation for efficient model training.",
    "details": [
        {
            "comment": "This code is part of the PaddleVideo library for video quality assessment. It imports necessary modules, and uses builders to construct data loaders, datasets, models, solvers, and metrics. It also includes utilities for logging and batch processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":0-27",
            "content": "\"\"\"\n# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"\nimport time\nimport os.path as osp\nimport paddle\nimport paddle.distributed.fleet as fleet\nfrom ..loader.builder import build_dataloader, build_dataset\nfrom ..modeling.builder import build_model\nfrom ..solver import build_lr, build_optimizer\nfrom ..metrics import build_metric\nfrom ..utils import do_preciseBN\nfrom paddlevideo.utils import get_logger, coloring\nfrom paddlevideo.utils import (AverageMeter, build_rec_record, log_batch,"
        },
        {
            "comment": "This function trains a model with specified configuration. It uses GPU for computation, and allows for parallel processing if multiple GPUs are available. Optionally, it performs validation during training and can also be used for fleet-based distributed training. The trained model's output directory is defined in the configuration file.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":28-60",
            "content": "                               log_epoch, save, load, mkdir)\n#from paddlevideo.metrics import QualityMetric\nimport numpy as np\nfrom scipy import stats\ndef train_model(cfg,\n                weights=None,\n                parallel=True,\n                validate=True,\n                amp=False,\n                fleet=False):\n    \"\"\"Train model entry\n    Args:\n    \tcfg (dict): configuration.\n        weights (str): weights path for finetuning.\n    \tparallel (bool): Whether multi-cards training. Default: True.\n        validate (bool): Whether to do evaluation. Default: False.\n    \"\"\"\n    if fleet:\n        fleet.init(is_collective=True)\n    logger = get_logger(\"paddlevideo\")\n    batch_size = cfg.DATASET.get('batch_size', 8)\n    valid_batch_size = cfg.DATASET.get('valid_batch_size', batch_size)\n    places = paddle.set_device('gpu')\n    # default num worker: 0, which means no subprocess will be created\n    num_workers = cfg.DATASET.get('num_workers', 0)\n    model_name = cfg.model_name\n    output_dir = cfg.get(\"output_dir\", \"./output/model_name/\")"
        },
        {
            "comment": "Code snippet creates a directory, builds the model based on configuration, and sets up data loaders for training and validation datasets. It also handles parallelization and distributed model usage if specified.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":61-88",
            "content": "    mkdir(output_dir)\n    # 1. Construct model\n    model = build_model(cfg.MODEL)\n    if parallel:\n        model = paddle.DataParallel(model)\n    if fleet:\n        model = paddle.distributed_model(model)\n    # 2. Construct dataset and dataloader\n    train_dataset = build_dataset((cfg.DATASET.train, cfg.PIPELINE.train))\n    train_dataloader_setting = dict(batch_size=batch_size,\n                                    num_workers=num_workers,\n                                    collate_fn_cfg=cfg.get('MIX', None),\n                                    places=places)\n    train_loader = build_dataloader(train_dataset, **train_dataloader_setting)\n    if validate:\n        valid_dataset = build_dataset((cfg.DATASET.valid, cfg.PIPELINE.valid))\n        validate_dataloader_setting = dict(\n            batch_size=valid_batch_size,\n            num_workers=num_workers,\n            places=places,\n            drop_last=False,\n            shuffle=cfg.DATASET.get(\n                'shuffle_valid',\n                False)  #NOTE: attention lstm need shuffle valid data."
        },
        {
            "comment": "Building a valid data loader, constructing a solver with specified optimizer and learning rate, resuming training from a previous epoch or finetuning the model.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":89-112",
            "content": "        )\n        valid_loader = build_dataloader(valid_dataset,\n                                        **validate_dataloader_setting)\n    # 3. Construct solver.\n    lr = build_lr(cfg.OPTIMIZER.learning_rate, len(train_loader))\n    optimizer = build_optimizer(cfg.OPTIMIZER,\n                                lr,\n                                parameter_list=model.parameters())\n    if fleet:\n        optimizer = fleet.distributed_optimizer(optimizer)\n    # Resume\n    resume_epoch = cfg.get(\"resume_epoch\", 0)\n    if resume_epoch:\n        filename = osp.join(output_dir,\n                            model_name + \"_epoch_{}\".format(resume_epoch))\n        resume_model_dict = load(filename + '.pdparams')\n        resume_opt_dict = load(filename + '.pdopt')\n        model.set_state_dict(resume_model_dict)\n        optimizer.set_state_dict(resume_opt_dict)\n    # Finetune:\n    if weights:\n        assert resume_epoch == 0, \"Conflict occurs when finetuning, please switch resume function off by setting resume_epoch to 0 or not indicating it.\""
        },
        {
            "comment": "The code loads a model and sets its state dict. Then, it proceeds to train the model if not in resume phase. It builds record_list for metrics calculation and iterates through data from train loader to forward pass and calculate metrics. If AMP is enabled, auto-casting is used during training steps.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":113-146",
            "content": "        model_dict = load(weights)\n        model.set_state_dict(model_dict)\n    # 4. Train Model\n    ###AMP###\n    if amp:\n        scaler = paddle.amp.GradScaler(init_loss_scaling=1024)\n    best = 0.\n    max_SROCC = 0\n    max_PLCC = 0\n    Metric = build_metric(cfg.METRIC)\n    for epoch in range(0, cfg.epochs):\n        if epoch < resume_epoch:\n            logger.info(\n                \"| epoch: [{epoch+1}] <= resume_epoch: [{ resume_epoch}], continue... \"\n            )\n            continue\n        model.train()\n        record_list = build_rec_record(cfg.MODEL)\n        tic = time.time()\n        train_output = []\n        train_label = []\n        for i, data in enumerate(train_loader):\n            record_list['reader_time'].update(time.time() - tic)\n            # 4.1 forward\n            ###AMP###\n            if amp:\n                with paddle.amp.auto_cast(\n                        custom_black_list={\"temporal_shift\", \"reduce_mean\"}):\n                    if parallel:\n                        outputs = model._layers.train_step(data)"
        },
        {
            "comment": "This code handles the model training step for video quality assessment. It uses the model's `train_step` function to calculate outputs and labels, then extends them to the train_output and train_label lists respectively. The average loss is calculated and scaled before its backward pass. Finally, it performs optimization by minimizing the scaler and clearing gradients.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":147-170",
            "content": "                        ## required for DataParallel, will remove in next version\n                        model._reducer.prepare_for_backward(\n                            list(model._find_varbase(outputs)))\n                    else:\n                        outputs = model.train_step(data)\n                train_output.extend(outputs['output'])\n                train_label.extend(outputs['label'])\n                avg_loss = outputs['loss']\n                scaled = scaler.scale(avg_loss)\n                scaled.backward()\n                # keep prior to 2.0 design\n                scaler.minimize(optimizer, scaled)\n                optimizer.clear_grad()\n            else:\n                if parallel:\n                    outputs = model._layers.train_step(data)\n                    ## required for DataParallel, will remove in next version\n                    model._reducer.prepare_for_backward(\n                        list(model._find_varbase(outputs)))\n                else:\n                    outputs = model.train_step(data)"
        },
        {
            "comment": "Code snippet performs backward propagation, optimizes model parameters, logs training progress and learning rate, updates metrics, and logs information at specified intervals.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":172-197",
            "content": "                train_output.extend(outputs['output'])\n                train_label.extend(outputs['label'])\n                # 4.2 backward\n                avg_loss = outputs['loss']\n                avg_loss.backward()\n                # 4.3 minimize\n                optimizer.step()\n                optimizer.clear_grad()\n            # log record\n            record_list['lr'].update(optimizer._global_learning_rate(),\n                                     batch_size)\n            for name, value in outputs.items():\n                if name == 'output' or name == 'label':\n                    continue\n                record_list[name].update(value, batch_size)\n            record_list['batch_time'].update(time.time() - tic)\n            tic = time.time()\n            if i % cfg.get(\"log_interval\", 10) == 0:\n                ips = \"ips: {:.5f} instance/sec.\".format(\n                    batch_size / record_list[\"batch_time\"].val)\n                log_batch(record_list, i, epoch + 1, cfg.epochs, \"train\", ips)\n            # learning rate iter step"
        },
        {
            "comment": "This code is part of a training process for a video quality assessment model. It checks if the learning rate should be updated by an iterative step, then updates it accordingly. The code calculates the train_SROCC and train_PLCC metrics to track progress, logs this information, and evaluates the model's performance on a separate validation dataset. A record of the training process is maintained to monitor batch time and other relevant statistics.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":198-228",
            "content": "            if cfg.OPTIMIZER.learning_rate.get(\"iter_step\"):\n                lr.step()\n        # learning rate epoch step\n        if not cfg.OPTIMIZER.learning_rate.get(\"iter_step\"):\n            lr.step()\n        train_PLCC, train_SROCC = Metric.accumulate_train(\n            train_output, train_label)\n        logger.info(\"train_SROCC={}\".format(train_SROCC))\n        logger.info(\"train_PLCC={}\".format(train_PLCC))\n        ips = \"ips: {:.5f} instance/sec.\".format(\n            batch_size * record_list[\"batch_time\"].count /\n            record_list[\"batch_time\"].sum)\n        log_epoch(record_list, epoch + 1, \"train\", ips)\n        eval_output = []\n        eval_label = []\n        def evaluate(best, max_SROCC, max_PLCC):\n            \"\"\"evaluate\"\"\"\n            model.eval()\n            record_list = build_rec_record(cfg.MODEL)\n            record_list.pop('lr')\n            tic = time.time()\n            for i, data in enumerate(valid_loader):\n                if parallel:\n                    outputs = model._layers.val_step(data)"
        },
        {
            "comment": "This code is part of a model's validation step during training. It collects outputs and labels from the model, updates logging records, and logs validation metrics such as SROCC and PLCC. If these metrics are greater than the previous maximum values, it updates the max values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":229-253",
            "content": "                else:\n                    outputs = model.val_step(data)\n                eval_output.extend(outputs['output'])\n                eval_label.extend(outputs['label'])\n                # log_record\n                for name, value in outputs.items():\n                    if name == 'output' or name == 'label':\n                        continue\n                    record_list[name].update(value, batch_size)\n                record_list['batch_time'].update(time.time() - tic)\n                tic = time.time()\n                if i % cfg.get(\"log_interval\", 10) == 0:\n                    ips = \"ips: {:.5f} instance/sec.\".format(\n                        batch_size / record_list[\"batch_time\"].val)\n                    log_batch(record_list, i, epoch + 1, cfg.epochs, \"val\", ips)\n            eval_PLCC, eval_SROCC = Metric.accumulate_train(\n                eval_output, eval_label)\n            logger.info(\"val_SROCC={}\".format(eval_SROCC))\n            logger.info(\"val_PLCC={}\".format(eval_PLCC))\n            if max_SROCC <= eval_SROCC and max_PLCC <= eval_PLCC:"
        },
        {
            "comment": "This code snippet is responsible for storing the best optimizer and model states, logging instance per second (ips) during validation phase, and optionally performing precise batch normalization if configuration allows. It returns the best parameters, maximum SROCC, and maximum PLCC values.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":254-275",
            "content": "                max_SROCC = eval_SROCC\n                max_PLCC = eval_PLCC\n                logger.info(\"max_SROCC={}\".format(max_SROCC))\n                logger.info(\"max_PLCC={}\".format(max_PLCC))\n                save(optimizer.state_dict(),\n                     osp.join(output_dir, model_name + \"_best.pdopt\"))\n                save(model.state_dict(),\n                     osp.join(output_dir, model_name + \"_best.pdparams\"))\n            ips = \"ips: {:.5f} instance/sec.\".format(\n                batch_size * record_list[\"batch_time\"].count /\n                record_list[\"batch_time\"].sum)\n            log_epoch(record_list, epoch + 1, \"val\", ips)\n            return best, max_SROCC, max_PLCC\n        # use precise bn to improve acc\n        if cfg.get(\"PRECISEBN\") and (epoch % cfg.PRECISEBN.preciseBN_interval\n                                     == 0 or epoch == cfg.epochs - 1):\n            do_preciseBN(\n                model, train_loader, parallel,\n                min(cfg.PRECISEBN.num_iters_preciseBN, len(train_loader)))"
        },
        {
            "comment": "This code block performs validation and model saving in a training process. It validates the model every 'val_interval' epochs or on the last epoch, and saves optimizer and model states every 'save_interval' epochs or on the last epoch. The logger then informs that training is finished.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/applications/VideoQualityAssessment/paddlevideo/tasks/train.py\":277-294",
            "content": "        # 5. Validation\n        if validate and (epoch % cfg.get(\"val_interval\", 1) == 0\n                         or epoch == cfg.epochs - 1):\n            with paddle.no_grad():\n                best, max_SROCC, max_PLCC = evaluate(best, max_SROCC, max_PLCC)\n        # 6. Save model\n        if epoch % cfg.get(\"save_interval\", 1) == 0 or epoch == cfg.epochs - 1:\n            save(\n                optimizer.state_dict(),\n                osp.join(output_dir,\n                         model_name + \"_epoch_{}.pdopt\".format(epoch)))\n            save(\n                model.state_dict(),\n                osp.join(output_dir,\n                         model_name + \"_epoch_{}.pdparams\".format(epoch)))\n    logger.info('training {model_name} finished')"
        }
    ]
}