{
    "summary": "The code reads a file for model details, extracts lines with common functions, sets up inference directories and parameters, enables ONNX checker, converts using paddle2onnx, saves logs, runs inference, and checks status for the \"func_paddle2onnx\" function.",
    "details": [
        {
            "comment": "Code is reading a file, parsing specific lines to extract model name, python path, and other parameters for paddle2onnx conversion. It's using common functions from \"common_func.sh\" and \"awk\" command for line extraction.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/test_tipc/test_paddle2onnx.sh\":0-31",
            "content": "#!/bin/bash\nsource test_tipc/common_func.sh\nFILENAME=$1\nMODE=$2\ndataline=$(cat ${FILENAME})\nlines=(${dataline})\n# common params\nmodel_name=$(func_parser_value \"${lines[1]}\")\npython=$(func_parser_value \"${lines[2]}\")\n# parser params\ndataline=$(awk 'NR==1, NR==14{print}'  $FILENAME)\nIFS=$'\\n'\nlines=(${dataline})\n# parser paddle2onnx\nmodel_name=$(func_parser_value \"${lines[1]}\")\npython=$(func_parser_value \"${lines[2]}\")\npadlle2onnx_cmd=$(func_parser_value \"${lines[3]}\")\ninfer_model_dir_key=$(func_parser_key \"${lines[4]}\")\ninfer_model_dir_value=$(func_parser_value \"${lines[4]}\")\nmodel_filename_key=$(func_parser_key \"${lines[5]}\")\nmodel_filename_value=$(func_parser_value \"${lines[5]}\")\nparams_filename_key=$(func_parser_key \"${lines[6]}\")\nparams_filename_value=$(func_parser_value \"${lines[6]}\")\nsave_file_key=$(func_parser_key \"${lines[7]}\")\nsave_file_value=$(func_parser_value \"${lines[7]}\")\nopset_version_key=$(func_parser_key \"${lines[8]}\")\nopset_version_value=$(func_parser_value \"${lines[8]}\")\nenable_onnx_checker_key=$(func_parser_key \"${lines[9]}\")"
        },
        {
            "comment": "Creating function \"func_paddle2onnx\" with arguments _script, setting up log path and directories for paddle2onnx inference. It then sets parameters such as infer_model_dir_key, model_filename_key, params_filename_key, save_file_key, and opset_version_key.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/test_tipc/test_paddle2onnx.sh\":32-57",
            "content": "enable_onnx_checker_value=$(func_parser_value \"${lines[9]}\")\n# parser onnx inference\ninference_py=$(func_parser_value \"${lines[10]}\")\nconfig_key=$(func_parser_key \"${lines[11]}\")\nconfig_value=$(func_parser_value \"${lines[11]}\")\nmodel_key=$(func_parser_key \"${lines[12]}\")\ninput_file_key=$(func_parser_key \"${lines[13]}\")\ninput_file_value=$(func_parser_value \"${lines[13]}\")\nLOG_PATH=\"./log/${model_name}/${MODE}\"\nmkdir -p ${LOG_PATH}\nstatus_log=\"${LOG_PATH}/results_paddle2onnx.log\"\nfunction func_paddle2onnx(){\n    IFS='|'\n    _script=$1\n    # paddle2onnx\n    _save_log_path=\"${LOG_PATH}/paddle2onnx_infer_cpu.log\"\n    set_dirname=$(func_set_params \"${infer_model_dir_key}\" \"${infer_model_dir_value}\")\n    set_model_filename=$(func_set_params \"${model_filename_key}\" \"${model_filename_value}\")\n    set_params_filename=$(func_set_params \"${params_filename_key}\" \"${params_filename_value}\")\n    set_save_model=$(func_set_params \"${save_file_key}\" \"${save_file_value}\")\n    set_opset_version=$(func_set_params \"${opset_version_key}\" \"${opset_version_value}\")"
        },
        {
            "comment": "The code sets enable_onnx_checker and uses it to execute paddle2onnx conversion, saves the log. Then, it runs inference using Python and saves the status check log.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/test_tipc/test_paddle2onnx.sh\":58-72",
            "content": "    set_enable_onnx_checker=$(func_set_params \"${enable_onnx_checker_key}\" \"${enable_onnx_checker_value}\")\n    trans_log=\"${LOG_PATH}/trans_model.log\"\n    trans_model_cmd=\"${padlle2onnx_cmd} ${set_dirname} ${set_model_filename} ${set_params_filename} ${set_save_model} ${set_opset_version} ${set_enable_onnx_checker} > ${trans_log} 2>&1 \"\n    eval $trans_model_cmd\n    last_status=${PIPESTATUS[0]}\n    status_check $last_status \"${trans_model_cmd}\" \"${status_log}\" \"${model_name}\"\n    # python inference\n    set_gpu=$(func_set_params \"${use_gpu_key}\" \"${use_gpu_value}\")\n    set_model_dir=$(func_set_params \"${model_key}\" \"${save_file_value}\")\n    set_input_file=$(func_set_params \"${input_file_key}\" \"${input_file_value}\")\n    set_config=$(func_set_params \"${config_key}\" \"${config_value}\")\n    infer_model_cmd=\"${python} ${inference_py} ${set_config} ${set_input_file} ${set_model_dir} > ${_save_log_path} 2>&1 \"\n    eval $infer_model_cmd\n    last_status=${PIPESTATUS[0]}\n    status_check $last_status \"${infer_model_cmd}\" \"${status_log}\" \"${model_name}\""
        },
        {
            "comment": "This code segment is running a test for the function \"func_paddle2onnx\" by exporting Count variable, setting IFS to \"|\", and echoing a message.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/test_tipc/test_paddle2onnx.sh\":73-80",
            "content": "}\necho \"################### run test ###################\"\nexport Count=0\nIFS=\"|\"\nfunc_paddle2onnx"
        }
    ]
}