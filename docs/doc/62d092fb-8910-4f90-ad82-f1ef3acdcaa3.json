{
    "summary": "The code introduces PPTSM-Mv3 backbone networks and MobileNetV3 models in PaddleVideo using PyTorch, with diverse parameters, weight initialization, pretrained model URLs, network configuration dictionaries. It also constructs CNN layers with Batch Normalization and builds the PPTSM-MV3 backbone model using temporal shifting, convolutions, SE modules, and implements Hardsigmoid function separately.",
    "details": [
        {
            "comment": "Copyright notice, license information, and reference to the associated research paper. The code imports necessary libraries and registers the backbone model within the PaddleVideo module registry. It also includes a function for weight initialization.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":0-27",
            "content": "# copyright (c) 2021 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# reference: https://arxiv.org/abs/1905.02244\nfrom __future__ import absolute_import, division, print_function\nimport paddle\nimport paddle.nn as nn\nimport paddle.nn.functional as F\nfrom paddle import ParamAttr\nfrom paddle.nn import AdaptiveAvgPool2D, BatchNorm, Conv2D, Dropout, Linear\nfrom paddle.regularizer import L2Decay\nfrom ..registry import BACKBONES\nfrom ..weight_init import weight_init_\nfrom ...utils import load_ckpt"
        },
        {
            "comment": "The code defines pretrained model URLs for MobileNetV3_small_x1_0 and MobileNetV3_large_x1_0, as well as lists of stages for each model. The MODEL_STAGES_PATTERN contains different depthwise blocks' parameters such as kernel size, channel numbers, activation function, and stride. NET_CONFIG is a dictionary containing configurations for specific network architectures with different parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":29-51",
            "content": "# Download URL of pretrained model\n# MODEL_URLS = {\n#     \"MobileNetV3_small_x1_0\":\n#     \"https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/legendary_models/MobileNetV3_small_x1_0_ssld_pretrained.pdparams\",\n#     \"MobileNetV3_large_x1_0\":\n#     \"https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/legendary_models/MobileNetV3_large_x1_0_ssld_pretrained.pdparams\",\n# }\nMODEL_STAGES_PATTERN = {\n    \"MobileNetV3_small\": [\"blocks[0]\", \"blocks[2]\", \"blocks[7]\", \"blocks[10]\"],\n    \"MobileNetV3_large\":\n    [\"blocks[0]\", \"blocks[2]\", \"blocks[5]\", \"blocks[11]\", \"blocks[14]\"]\n}\n# \"large\", \"small\" is just for MobinetV3_large, MobileNetV3_small respectively.\n# The type of \"large\" or \"small\" config is a list. Each element(list) represents a depthwise block, which is composed of k, exp, se, act, s.\n# k: kernel_size\n# exp: middle channel number in depthwise block\n# c: output channel number in depthwise block\n# se: whether to use SE block\n# act: which activation to use\n# s: stride in depthwise block\nNET_CONFIG = {"
        },
        {
            "comment": "This code defines two versions of the PPTSM-Mv3 backbone network architecture for the PaddleVideo library: \"large\" and \"small\". The backbone is a series of convolutional layers, with different configurations specified by parameters k (kernel size), exp (expansion factor), c (number of channels), se (if using squeeze-and-excitation), act (activation function), and s (strides). The large version has more layers and higher capacities for learning, while the small version is optimized for inference speed. Each layer's configuration is defined in a list of lists.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":52-78",
            "content": "    \"large\": [\n        # k, exp, c, se, act, s\n        [3, 16, 16, False, \"relu\", 1],\n        [3, 64, 24, False, \"relu\", 2],\n        [3, 72, 24, False, \"relu\", 1],\n        [5, 72, 40, True, \"relu\", 2],\n        [5, 120, 40, True, \"relu\", 1],\n        [5, 120, 40, True, \"relu\", 1],\n        [3, 240, 80, False, \"hardswish\", 2],\n        [3, 200, 80, False, \"hardswish\", 1],\n        [3, 184, 80, False, \"hardswish\", 1],\n        [3, 184, 80, False, \"hardswish\", 1],\n        [3, 480, 112, True, \"hardswish\", 1],\n        [3, 672, 112, True, \"hardswish\", 1],\n        [5, 672, 160, True, \"hardswish\", 2],\n        [5, 960, 160, True, \"hardswish\", 1],\n        [5, 960, 160, True, \"hardswish\", 1],\n    ],\n    \"small\": [\n        # k, exp, c, se, act, s\n        [3, 16, 16, True, \"relu\", 2],\n        [3, 72, 24, False, \"relu\", 2],\n        [3, 88, 24, False, \"relu\", 1],\n        [5, 96, 40, True, \"hardswish\", 2],\n        [5, 240, 40, True, \"hardswish\", 1],\n        [5, 240, 40, True, \"hardswish\", 1],\n        [5, 120, 48, True, \"hardswish\", 1],"
        },
        {
            "comment": "This code defines the MobileNetV3 model with various parameters such as channel numbers, activation functions, and division rules for each layer. The class \"MobileNetV3\" is a custom PyTorch Layer that represents the network architecture, utilizing convolutional layers and activation functions like Hardswish or ReLU. The function \"_make_divisible\" ensures proper alignment of channel numbers with hardware considerations, while \"_create_act\" creates instances of the specified activation functions.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":79-117",
            "content": "        [5, 144, 48, True, \"hardswish\", 1],\n        [5, 288, 96, True, \"hardswish\", 2],\n        [5, 576, 96, True, \"hardswish\", 1],\n        [5, 576, 96, True, \"hardswish\", 1],\n    ]\n}\n# first conv output channel number in MobileNetV3\nSTEM_CONV_NUMBER = 16\n# last second conv output channel for \"small\"\nLAST_SECOND_CONV_SMALL = 576\n# last second conv output channel for \"large\"\nLAST_SECOND_CONV_LARGE = 960\n# last conv output channel number for \"large\" and \"small\"\nLAST_CONV = 1280\ndef _make_divisible(v, divisor=8, min_value=None):\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\ndef _create_act(act):\n    if act == \"hardswish\":\n        return nn.Hardswish()\n    elif act == \"relu\":\n        return nn.ReLU()\n    elif act is None:\n        return None\n    else:\n        raise RuntimeError(\n            \"The activation function is not supported: {}\".format(act))\nclass MobileNetV3(nn.Layer):\n    \"\"\""
        },
        {
            "comment": "The function defines a MobileNetV3 model with configurable parameters like depthwise blocks, scale, class number, inplanes, class_squeeze, class_expand, dropout probability, and number of segments. It takes these parameters as inputs and returns the specific MobileNetV3 model based on the arguments provided.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":118-141",
            "content": "    MobileNetV3\n    Args:\n        config: list. MobileNetV3 depthwise blocks config.\n        scale: float=1.0. The coefficient that controls the size of network parameters.\n        class_num: int=1000. The number of classes.\n        inplanes: int=16. The output channel number of first convolution layer.\n        class_squeeze: int=960. The output channel number of penultimate convolution layer.\n        class_expand: int=1280. The output channel number of last convolution layer.\n        dropout_prob: float=0.2.  Probability of setting units to zero.\n    Returns:\n        model: nn.Layer. Specific MobileNetV3 model depends on args.\n    \"\"\"\n    def __init__(self,\n                 config,\n                 stages_pattern,\n                 scale=1.0,\n                 class_num=400,\n                 inplanes=STEM_CONV_NUMBER,\n                 class_squeeze=LAST_SECOND_CONV_LARGE,\n                 class_expand=LAST_CONV,\n                 dropout_prob=0.2,\n                 num_seg=8,\n                 pretrained=None,\n                 return_patterns=None,"
        },
        {
            "comment": "This code defines a PPTSM-MV3 backbone model with specified configurations, including input planes, scale factor, class parameters, and number of segments. It uses convolutional layers and residual units for feature extraction and processing.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":142-167",
            "content": "                 return_stages=None):\n        super().__init__()\n        self.cfg = config\n        self.scale = scale\n        self.inplanes = inplanes\n        self.class_squeeze = class_squeeze\n        self.class_expand = class_expand\n        self.class_num = class_num\n        self.num_seg = num_seg\n        self.pretrained = pretrained\n        self.conv = ConvBNLayer(in_c=3,\n                                out_c=_make_divisible(self.inplanes *\n                                                      self.scale),\n                                filter_size=3,\n                                stride=2,\n                                padding=1,\n                                num_groups=1,\n                                if_act=True,\n                                act=\"hardswish\")\n        self.blocks = nn.Sequential(*[\n            ResidualUnit(in_c=_make_divisible(self.inplanes * self.scale if i ==\n                                              0 else self.cfg[i - 1][2] *\n                                              self.scale),"
        },
        {
            "comment": "The code initializes a PPTSM-MV3 model, which consists of several convolutional blocks and a final classification layer. The convolutional blocks are defined by the `self.cfg` list, where each element contains the kernel size, expansion factor, output channels, whether to use SE module, and activation function, along with the stride. The last convolutional block is followed by an average pooling layer and a final convolution layer for classification.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":168-193",
            "content": "                         mid_c=_make_divisible(self.scale * exp),\n                         out_c=_make_divisible(self.scale * c),\n                         filter_size=k,\n                         stride=s,\n                         use_se=se,\n                         num_seg=self.num_seg,\n                         act=act)\n            for i, (k, exp, c, se, act, s) in enumerate(self.cfg)\n        ])\n        self.last_second_conv = ConvBNLayer(\n            in_c=_make_divisible(self.cfg[-1][2] * self.scale),\n            out_c=_make_divisible(self.scale * self.class_squeeze),\n            filter_size=1,\n            stride=1,\n            padding=0,\n            num_groups=1,\n            if_act=True,\n            act=\"hardswish\")\n        self.avg_pool = AdaptiveAvgPool2D(1)\n        self.last_conv = Conv2D(in_channels=_make_divisible(self.scale *\n                                                            self.class_squeeze),\n                                out_channels=self.class_expand,\n                                kernel_size=1,"
        },
        {
            "comment": "This code defines a neural network model for the PPTSM_MV3 backbone. It includes convolutional layers, blocks, a Hardswish activation function, optional dropout, and fully connected layers for classification. The `init_weights` method initializes the network's weights, and the `forward` method passes input through the model layers to generate output.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":194-221",
            "content": "                                stride=1,\n                                padding=0,\n                                bias_attr=False)\n        self.hardswish = nn.Hardswish()\n        if dropout_prob is not None:\n            self.dropout = Dropout(p=dropout_prob, mode=\"downscale_in_infer\")\n        else:\n            self.dropout = None\n        self.fc = Linear(self.class_expand, class_num)\n    def init_weights(self):\n        \"\"\"Initiate the parameters.\n        \"\"\"\n        if isinstance(self.pretrained, str) and self.pretrained.strip() != \"\":\n            load_ckpt(self, self.pretrained)\n        elif self.pretrained is None or self.pretrained.strip() == \"\":\n            for layer in self.sublayers():\n                if isinstance(layer, nn.Conv2D):\n                    #XXX: no bias\n                    weight_init_(layer, 'KaimingNormal')\n                elif isinstance(layer, nn.BatchNorm2D):\n                    weight_init_(layer, 'Constant', value=1)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.blocks(x)"
        },
        {
            "comment": "This code defines a ConvBNLayer class that takes input and output channels, filter size, stride, padding, number of groups, activation function flag, and activation type as parameters. It initializes the layers for convolutional neural network and applies Batch Normalization and activation functions if specified. The class also returns the last layer of the model after feature aggregation for video classification.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":222-257",
            "content": "        x = self.last_second_conv(x)\n        x = self.avg_pool(x)\n        x = self.last_conv(x)\n        x = self.hardswish(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        # feature aggregation for video\n        x = paddle.reshape(x, [-1, self.num_seg, x.shape[1]])\n        x = paddle.mean(x, axis=1)\n        x = paddle.reshape(x, shape=[-1, self.class_expand])\n        x = self.fc(x)\n        return x\nclass ConvBNLayer(nn.Layer):\n    def __init__(self,\n                 in_c,\n                 out_c,\n                 filter_size,\n                 stride,\n                 padding,\n                 num_groups=1,\n                 if_act=True,\n                 act=None):\n        super().__init__()\n        self.conv = Conv2D(in_channels=in_c,\n                           out_channels=out_c,\n                           kernel_size=filter_size,\n                           stride=stride,\n                           padding=padding,\n                           groups=num_groups,\n                           bias_attr=False)"
        },
        {
            "comment": "The code defines a ResidualUnit class with an expand_conv layer containing ConvBNLayer, used for building the residual unit in PPTSM-MV3 model. It also includes optional BatchNorm (bn) and activation (act) layers based on provided parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":258-291",
            "content": "        self.bn = BatchNorm(num_channels=out_c,\n                            act=None,\n                            param_attr=ParamAttr(regularizer=L2Decay(0.0)),\n                            bias_attr=ParamAttr(regularizer=L2Decay(0.0)))\n        self.if_act = if_act\n        self.act = _create_act(act)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        if self.if_act:\n            x = self.act(x)\n        return x\nclass ResidualUnit(nn.Layer):\n    def __init__(self,\n                 in_c,\n                 mid_c,\n                 out_c,\n                 filter_size,\n                 stride,\n                 use_se,\n                 num_seg=8,\n                 act=None):\n        super().__init__()\n        self.if_shortcut = stride == 1 and in_c == out_c\n        self.if_se = use_se\n        self.num_seg = num_seg\n        self.expand_conv = ConvBNLayer(in_c=in_c,\n                                       out_c=mid_c,\n                                       filter_size=1,\n                                       stride=1,"
        },
        {
            "comment": "Defines a PPTSM_MV3 block with ConvBNLayer, bottleneck convolution layer, optional SEModule for spatial attention, and a linear convolution layer.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":292-311",
            "content": "                                       padding=0,\n                                       if_act=True,\n                                       act=act)\n        self.bottleneck_conv = ConvBNLayer(in_c=mid_c,\n                                           out_c=mid_c,\n                                           filter_size=filter_size,\n                                           stride=stride,\n                                           padding=int((filter_size - 1) // 2),\n                                           num_groups=mid_c,\n                                           if_act=True,\n                                           act=act)\n        if self.if_se:\n            self.mid_se = SEModule(mid_c)\n        self.linear_conv = ConvBNLayer(in_c=mid_c,\n                                       out_c=out_c,\n                                       filter_size=1,\n                                       stride=1,\n                                       padding=0,\n                                       if_act=False,\n                                       act=None)"
        },
        {
            "comment": "This code defines a PPTSM-MV3 backbone model for video analysis. It uses temporal shifting, convolutions, and SE module (if specified) in its forward pass. The Hardsigmoid function is implemented as a separate class to apply hard sigmoid activation with customizable slope and offset parameters.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":313-347",
            "content": "    def forward(self, x):\n        identity = x\n        if self.if_shortcut:\n            x = F.temporal_shift(x, self.num_seg, 1.0 / self.num_seg)\n        x = self.expand_conv(x)\n        x = self.bottleneck_conv(x)\n        if self.if_se:\n            x = self.mid_se(x)\n        x = self.linear_conv(x)\n        if self.if_shortcut:\n            x = paddle.add(identity, x)\n        return x\n# nn.Hardsigmoid can't transfer \"slope\" and \"offset\" in nn.functional.hardsigmoid\nclass Hardsigmoid(nn.Layer):\n    def __init__(self, slope=0.2, offset=0.5):\n        super().__init__()\n        self.slope = slope\n        self.offset = offset\n    def forward(self, x):\n        return nn.functional.hardsigmoid(x,\n                                         slope=self.slope,\n                                         offset=self.offset)\nclass SEModule(nn.Layer):\n    def __init__(self, channel, reduction=4):\n        super().__init__()\n        self.avg_pool = AdaptiveAvgPool2D(1)\n        self.conv1 = Conv2D(in_channels=channel,\n                            out_channels=channel // reduction,"
        },
        {
            "comment": "The code defines a Convolutional Neural Network layer for the PPTSM-MobileNetV3_small_x1_0 model. It consists of an average pooling layer, two 1x1 convolution layers with ReLU and hard sigmoid activations. The forward function performs element-wise multiplication between input and output to implement residual learning.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":348-375",
            "content": "                            kernel_size=1,\n                            stride=1,\n                            padding=0)\n        self.relu = nn.ReLU()\n        self.conv2 = Conv2D(in_channels=channel // reduction,\n                            out_channels=channel,\n                            kernel_size=1,\n                            stride=1,\n                            padding=0)\n        self.hardsigmoid = Hardsigmoid(slope=0.2, offset=0.5)\n    def forward(self, x):\n        identity = x\n        x = self.avg_pool(x)\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.hardsigmoid(x)\n        return paddle.multiply(x=identity, y=x)\ndef PPTSM_MobileNetV3_small_x1_0(pretrained=None, **kwargs):\n    \"\"\"\n    MobileNetV3_small_x1_0\n    Args:\n        pretrained: bool=False or str. If `True` load pretrained parameters, `False` otherwise.\n                    If str, means the path of the pretrained model.\n        use_ssld: bool=False. Whether using distillation pretrained model when pretrained=True."
        },
        {
            "comment": "This code defines a function that returns specific MobileNetV3 models based on given arguments. The \"MobileNetV3\" class is used to create the models, and parameters such as config, scale, stages_pattern, class_squeeze, pretrained, and other optional keyword arguments are passed to the constructor of the class. The function is then registered with BACKBONES for future use.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":376-404",
            "content": "    Returns:\n        model: nn.Layer. Specific `MobileNetV3_small_x1_0` model depends on args.\n    \"\"\"\n    model = MobileNetV3(\n        config=NET_CONFIG[\"small\"],\n        scale=1.0,\n        stages_pattern=MODEL_STAGES_PATTERN[\"MobileNetV3_small\"],\n        class_squeeze=LAST_SECOND_CONV_SMALL,\n        pretrained=pretrained,\n        **kwargs)\n    return model\n@BACKBONES.register()\ndef PPTSM_MobileNetV3(pretrained=None, **kwargs):\n    \"\"\"\n    MobileNetV3_large_x1_0\n    Args:\n        pretrained: bool=False or str. If `True` load pretrained parameters, `False` otherwise.\n                    If str, means the path of the pretrained model.\n        use_ssld: bool=False. Whether using distillation pretrained model when pretrained=True.\n    Returns:\n        model: nn.Layer. Specific `MobileNetV3_large_x1_0` model depends on args.\n    \"\"\"\n    model = MobileNetV3(\n        config=NET_CONFIG[\"large\"],\n        scale=1.0,\n        stages_pattern=MODEL_STAGES_PATTERN[\"MobileNetV3_large\"],\n        class_squeeze=LAST_SECOND_CONV_LARGE,"
        },
        {
            "comment": "This code is creating an instance of the PPTSM-MV3 backbone model with specified pretrained weights and returning it.",
            "location": "\"/media/root/Prima/works/PaddleVideo/docs/src/paddlevideo/modeling/backbones/pptsm_mv3.py\":405-407",
            "content": "        pretrained=pretrained,\n        **kwargs)\n    return model"
        }
    ]
}