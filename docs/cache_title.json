{"_default": {"1": {"path": "/MANIFEST.in", "hash": "51011ab5248241a5342dc66d29b0bf6c", "title": "PaddleVideo Manifest Configuration"}, "2": {"path": "/README.md", "hash": "040580f5fc094937e3f2bd7a44398a10", "title": "Advanced Video Processing with PaddleVideo"}, "3": {"path": "/README.md:1-22", "hash": "4cce85ce5aeb1ebec74d5433ea057d60", "title": "Advanced Video Processing with PaddleVideo"}, "4": {"path": "/README.md:25-58", "hash": "d0104ca49a4e7ce35bafadac28a1ecfe", "title": "PaddleVideo: Comprehensive Video Tech Course and Code"}, "5": {"path": "/README.md:59-75", "hash": "723dc73199205226f2a5a204daa701ba", "title": "PaddleVideo Documentation Table of Contents"}, "6": {"path": "/README_en.md", "hash": "cd6ede8dea665e0f1dcd30634becb920", "title": "PaddleVideo: Deep Learning for Video Processing"}, "7": {"path": "/README_en.md:1-20", "hash": "f4c779b72ae4186b05ebe61b0229730d", "title": "PaddleVideo: Industrial and Academic Video Toolset"}, "8": {"path": "/README_en.md:20-43", "hash": "ec8d741392534965bd155d28e9ea8af1", "title": "PaddleVideo: Comprehensive Video AI Platform"}, "9": {"path": "/README_en.md:44-65", "hash": "b4dee3c3b64c767cc12188c0c2880ccf", "title": "PaddleVideo: Video Processing Deep Learning Library"}, "10": {"path": "/__init__.py", "hash": "9325bc821164e2318951b0ab91c9b9fe", "title": "Licensed Python Module: PaddleVideo"}, "11": {"path": "/applications/AbnormalActionDetection/README.md", "hash": "b2f28c4e5f6643c1d50ddafb259efa9b", "title": "Abnormal Action Detection with PaddleVideo"}, "12": {"path": "/applications/AbnormalActionDetection/README.md:1-40", "hash": "5bc59ef806ab6332c42acf44c432a03c", "title": "Abnormal Action Detection with PaddleVideo"}, "13": {"path": "/applications/AbnormalActionDetection/README.md:42-114", "hash": "4288c9cd07ccecde5ff1aca2746a9c3b", "title": "Abnormal Action Detection Pipeline"}, "14": {"path": "/applications/AbnormalActionDetection/README.md:115-153", "hash": "8034e08ba6e24d19f74caadca666bec8", "title": "Video Action Detection with PaddleVideo"}, "15": {"path": "/applications/Anti-UAV/README.md", "hash": "ce453c9978f837a13c37ada1f9784f80", "title": "Detect UAVs in Restricted Areas with PaddleDetection"}, "16": {"path": "/applications/Anti-UAV/README.md:1-21", "hash": "699916c39e2a29a77ff52a24ac3189e3", "title": "Paddle-Anti-UAV: Detecting Flying UAVs"}, "17": {"path": "/applications/Anti-UAV/README.md:23-36", "hash": "ccd88661848474b9ed00c415219e426d", "title": "UAV Detection with PP-YOLO and PaddleDetection"}, "18": {"path": "/applications/Anti-UAV/README.md:36-39", "hash": "94b3f624e802a25496b9bfb6c14c76d2", "title": "Customize Anti-UAV Demo with PaddleVideo"}, "19": {"path": "/applications/Anti-UAV/get_image_label.py", "hash": "a2df3de2513796ad42402ee9f6be0aa9", "title": "Object Detection and Labeling Tool"}, "20": {"path": "/applications/Anti-UAV/get_image_label.py:1-53", "hash": "976acbc2829be2e0dfc8046bf2565066", "title": "Initialize Directories and Info"}, "21": {"path": "/applications/Anti-UAV/get_image_label.py:54-77", "hash": "fff3d7e205c46314804d2e3183d6e8d0", "title": "Object Detection and Labeling in Images"}, "22": {"path": "/applications/Anti-UAV/get_image_label.py:78-101", "hash": "1eba698bbbe52fa7c2d2a7d81b515944", "title": "Write and Annotate Image Data"}, "23": {"path": "/applications/Anti-UAV/get_image_label.py:102-128", "hash": "733ce5e6560513c1676d018c7b205448", "title": "Labeling Frames by Object Presence"}, "24": {"path": "/applications/Anti-UAV/get_image_label.py:129-151", "hash": "a7481af59d716db456669816b284cd65", "title": "Bounding Box Image Labelling"}, "25": {"path": "/applications/Anti-UAV/get_image_label.py:152-164", "hash": "d75223f8ccfc29c5333252bf2fad9128", "title": "Writing Annotation and Image Data to JSON Files"}, "26": {"path": "/applications/BasketballAction/README.md", "hash": "298e57a8dda588bd5f7692888b7b25f8", "title": "Basketball Action Detection App"}, "27": {"path": "/applications/BasketballAction/README.md:1-69", "hash": "5de11621443af81d7f77c148ddf30c5c", "title": "Basketball Action Detection with PaddlePaddle"}, "28": {"path": "/applications/BasketballAction/README.md:70-99", "hash": "0a285dc09212a0b6113e705a09e1d6b5", "title": "Basketball Action Dataset Structure"}, "29": {"path": "/applications/BasketballAction/README.md:100-135", "hash": "d0516eff0898001d285536de4988c1ca", "title": "Prepare, Train, and Convert ppTSM Model"}, "30": {"path": "/applications/BasketballAction/README.md:136-163", "hash": "e66eaaba6b5ff7b41f97784bdf2562f3", "title": "BasketballAction: Feature Extraction & BMN Training"}, "31": {"path": "/applications/BasketballAction/README.md:165-206", "hash": "6d8e8045f3ca8765af0355bc67fb6c16", "title": "Preparing and Training BMN Model for Basketball Action Dataset"}, "32": {"path": "/applications/BasketballAction/README.md:207-243", "hash": "2791f6b95d3da3618adc0a29cd5290ec", "title": "BMN-Based Basketball Action Predictions"}, "33": {"path": "/applications/BasketballAction/README.md:244-284", "hash": "68e1ebbdfeb4bc12cfdb9fc38dfa3f6a", "title": "BasketballAction LSTM Training Data Structure"}, "34": {"path": "/applications/BasketballAction/README.md:285-319", "hash": "f04b42a03e28bee26fdabea4b8c24b69", "title": "PaddleVideo BasketballAction: LSTM Data Formats"}, "35": {"path": "/applications/BasketballAction/README.md:320-365", "hash": "06261df6b09b5953989109041bd5f907", "title": "LSTM Model Inference and Evaluation"}, "36": {"path": "/applications/BasketballAction/README.md:366-389", "hash": "f4bef9f4d37cd85e3f802451c5422a72", "title": "Optimized Action Detection with TSM and BMN"}, "37": {"path": "/applications/BasketballAction/README.md:389-389", "hash": "7cc294d6dd9b283df95dd8e5dd5a235f", "title": "Author List"}, "38": {"path": "/applications/BasketballAction/predict/action_detect/action.py", "hash": "bfe70b60b0dba3fbb7a78e5f6024c08d", "title": "Basketball Action Detector"}, "39": {"path": "/applications/BasketballAction/predict/action_detect/action.py:1-44", "hash": "0f87161ac0577d2c3b140f8fa5cabec8", "title": "Basketball Action Detection with Python"}, "40": {"path": "/applications/BasketballAction/predict/action_detect/action.py:45-71", "hash": "5673b8ef127cb63650d8f5eaba451585", "title": "ModelPredict Class Initialization and Configuration"}, "41": {"path": "/applications/BasketballAction/predict/action_detect/action.py:72-104", "hash": "6900a7da0667e5df7bd1772e412c031d", "title": "InferModel for Action Prediction"}, "42": {"path": "/applications/BasketballAction/predict/action_detect/action.py:105-133", "hash": "4209a678258f4434b3ea59029447301d", "title": "Video Action Detection and Feature Extraction"}, "43": {"path": "/applications/BasketballAction/predict/action_detect/action.py:134-152", "hash": "6fee7518e5cba95c22618bcfa0012713", "title": "Feature Extraction and Storage"}, "44": {"path": "/applications/BasketballAction/predict/action_detect/action.py:153-174", "hash": "a5e48f1341b9641f32b4e5b590935744", "title": "Video Feature Inference and Storage"}, "45": {"path": "/applications/BasketballAction/predict/action_detect/logger.py", "hash": "96e8f1f7751ef922ea41922fca4c9f7b", "title": "Custom Logger for News Stripper"}, "46": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/feature_extractor.py", "hash": "51936031fa85e7a0694a404fcc023694", "title": "Audio Feature Extraction and Processing"}, "47": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/feature_extractor.py:1-41", "hash": "6abfda1f3582b909d81361b265777f50", "title": "Audio Feature Extraction Functions"}, "48": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/feature_extractor.py:44-68", "hash": "904984a133fe6004aa422875b0c855b3", "title": "Mel Spectrogram Matrix Creation"}, "49": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/feature_extractor.py:69-93", "hash": "a75e021411d82ab3b84628a9161cc6b3", "title": "Calculate MFCC for Audio Data"}, "50": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/feature_extractor.py:94-116", "hash": "1dc192beafb2315543d04c680691b5b3", "title": "Mel Spectrogram Feature Extraction"}, "51": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/feature_extractor.py:117-139", "hash": "8c1574afd1ade70f6da96610979c7224", "title": "Audio Feature Extraction and Preprocessing"}, "52": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/feature_extractor.py:140-158", "hash": "ba681cd41370584a1277047c80023dab", "title": "Extract Audio Features for Wav File"}, "53": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/model_config.py", "hash": "574c1392fd9221b3a4d9820af61e3c18", "title": "Model-Based Audio Feature Extraction"}, "54": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/model_config.py:1-42", "hash": "d62bdfd06cac9bd81c9723dd16f88c72", "title": "Audio Feature Extraction Model"}, "55": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/model_config.py:43-51", "hash": "f6b4f7a1dcb2fbc9a190fcd8c8269de4", "title": "Audio Feature List Generator"}, "56": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/vgg_params.py", "hash": "48665dcb4614e556d4cc94b8dcd68918", "title": "VGGish Parameters for Basketball Action Detection"}, "57": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/vgg_params.py:1-29", "hash": "35f25d08141da44ecc7dc8129f8bf6e4", "title": "Global VGGish Parameters"}, "58": {"path": "/applications/BasketballAction/predict/action_detect/mfcc/vgg_params.py:30-37", "hash": "7c78a76b29a405198566b746a0d741c3", "title": "Adam Optimizer with Epsilon Value"}, "59": {"path": "/applications/BasketballAction/predict/action_detect/models/audio_infer.py", "hash": "2bbeef0ddfde34d58b47dfeebfdec54c", "title": "Audio Inference with InferModel"}, "60": {"path": "/applications/BasketballAction/predict/action_detect/models/audio_infer.py:1-37", "hash": "5f64d83960167a63c7691d9850260085", "title": "Audio Inference Model Initialization"}, "61": {"path": "/applications/BasketballAction/predict/action_detect/models/audio_infer.py:39-69", "hash": "a6cb67c793098f417ae4702531184a7c", "title": "Audio Inference Model"}, "62": {"path": "/applications/BasketballAction/predict/action_detect/models/audio_infer.py:71-80", "hash": "90a686d19257837b37d04597974a7d57", "title": "Audio Infer: Model Prediction and Time Calculation"}, "63": {"path": "/applications/BasketballAction/predict/action_detect/models/bmn_infer.py", "hash": "877aa64dab8aed20ed74a43d4669c362", "title": "Basketball Action BMN Inferencing"}, "64": {"path": "/applications/BasketballAction/predict/action_detect/models/bmn_infer.py:1-37", "hash": "0a929815b326e5689ec7babe9f8f0c0e", "title": "BMN Inferencing Class Initialization"}, "65": {"path": "/applications/BasketballAction/predict/action_detect/models/bmn_infer.py:38-63", "hash": "ddd597a350b5209e89a85b7ba2af591a", "title": "Basketball Action Detection Model"}, "66": {"path": "/applications/BasketballAction/predict/action_detect/models/bmn_infer.py:64-86", "hash": "dc77f169a448096e17822bd24b321db0", "title": "Action Detection Model"}, "67": {"path": "/applications/BasketballAction/predict/action_detect/models/bmn_infer.py:87-111", "hash": "eb3cf523601a71513ae00edcab0ff096", "title": "Boundary Mask Prediction"}, "68": {"path": "/applications/BasketballAction/predict/action_detect/models/bmn_infer.py:112-131", "hash": "422c29a3915399549ee7e19a2e97e59a", "title": "Average Model Predictions for Action Detection"}, "69": {"path": "/applications/BasketballAction/predict/action_detect/models/bmn_infer.py:133-155", "hash": "f66e6c5e4778e544bca1c3baa24321e6", "title": "Inference Time for Action Detection"}, "70": {"path": "/applications/BasketballAction/predict/action_detect/models/lstm_infer.py", "hash": "e6de4f579cb00c2b268658f7a78d8c62", "title": "LSTM-based Basketball Action Detection"}, "71": {"path": "/applications/BasketballAction/predict/action_detect/models/lstm_infer.py:1-36", "hash": "7e669227e352f2fe805e0ff493a7681e", "title": "LSTM Inferencing Model in BasketballAction"}, "72": {"path": "/applications/BasketballAction/predict/action_detect/models/lstm_infer.py:37-61", "hash": "0a0c313f9fe364e41a6f5d606d566f9f", "title": "GPU-Optimized LSTM Action Detector"}, "73": {"path": "/applications/BasketballAction/predict/action_detect/models/lstm_infer.py:62-90", "hash": "2c30772601f48d2661cde36676eded46", "title": "LSTM Basketball Action Detection"}, "74": {"path": "/applications/BasketballAction/predict/action_detect/models/lstm_infer.py:91-112", "hash": "dade7c6b9a6350b55333c6af38108ea8", "title": "LSTM-Based Action Detection"}, "75": {"path": "/applications/BasketballAction/predict/action_detect/models/lstm_infer.py:113-141", "hash": "aca733d36668ffcd496f1b1f305e2c03", "title": "LSTM Model for Action Detection"}, "76": {"path": "/applications/BasketballAction/predict/action_detect/models/lstm_infer.py:142-145", "hash": "ae0a2ebd517d97b94a9970dea5f72552", "title": "JSON Data Logging and Time Tracking"}, "77": {"path": "/applications/BasketballAction/predict/action_detect/models/pptsm_infer.py", "hash": "ce44f5f726303ddcb82a1d40262c84d7", "title": "PPTSM Action Detection Infer Model"}, "78": {"path": "/applications/BasketballAction/predict/action_detect/models/pptsm_infer.py:1-38", "hash": "ef25e41fffbf103bf8a7e69da1d303fe", "title": "PPTSM Action Detection Model Inference"}, "79": {"path": "/applications/BasketballAction/predict/action_detect/models/pptsm_infer.py:40-69", "hash": "64fc9ae8dac66f205e5db46a93eca091", "title": "PaddleVideo Action Prediction"}, "80": {"path": "/applications/BasketballAction/predict/action_detect/models/pptsm_infer.py:70-83", "hash": "099116356100c8134fe29569ce4a1a0e", "title": "Python Model Prediction with Timing"}, "81": {"path": "/applications/BasketballAction/predict/action_detect/reader/__init__.py", "hash": "2e9ec402585026301d4b3692fdd50115", "title": "Alphabetical Action Readers"}, "82": {"path": "/applications/BasketballAction/predict/action_detect/reader/audio_reader.py", "hash": "0e3ba10a6e651c7cbe1d69febd61976f", "title": "Audio Reader for YouTube-8M Dataset"}, "83": {"path": "/applications/BasketballAction/predict/action_detect/reader/audio_reader.py:1-37", "hash": "3711b62cae432d7e6f17732977e00689", "title": "AudioReader Class for YouTube-8M Dataset"}, "84": {"path": "/applications/BasketballAction/predict/action_detect/reader/audio_reader.py:38-70", "hash": "57909ba726c505de60d0f5557fa2d537", "title": "Audio Reader for Multiple Models"}, "85": {"path": "/applications/BasketballAction/predict/action_detect/reader/audio_reader.py:71-78", "hash": "5c8185ee6f26bcf580be40fbd4ccfc05", "title": "Audio Batch Manager"}, "86": {"path": "/applications/BasketballAction/predict/action_detect/reader/bmninf_reader.py", "hash": "7b99e067cd9126596237aa7df6f2b720", "title": "BMNINF Reader for Basketball Action Prediction"}, "87": {"path": "/applications/BasketballAction/predict/action_detect/reader/bmninf_reader.py:1-49", "hash": "1344cb1e63f2cf510ad1280cbb3e97a5", "title": "BMNINF Reader: Generating Proposals for BMN Models"}, "88": {"path": "/applications/BasketballAction/predict/action_detect/reader/bmninf_reader.py:50-73", "hash": "47c77ed4c5d02db7028ec5b1a4006230", "title": "BMNINF Reader Initialization"}, "89": {"path": "/applications/BasketballAction/predict/action_detect/reader/bmninf_reader.py:74-105", "hash": "fc054050240a1ea5a9416d76b7c55c38", "title": "BMNInf Reader Class"}, "90": {"path": "/applications/BasketballAction/predict/action_detect/reader/bmninf_reader.py:106-141", "hash": "ad9fa762a095f81076785f3f53d29d1d", "title": "BMNINF Reader Functionality"}, "91": {"path": "/applications/BasketballAction/predict/action_detect/reader/bmninf_reader.py:142-151", "hash": "a131cef54b9a68f0fc643b956b8dc4a0", "title": "Video Data Reader Class"}, "92": {"path": "/applications/BasketballAction/predict/action_detect/reader/feature_reader.py", "hash": "85e2610aca5d5eb085194701e10ba993", "title": "FeatureReader: YouTube-8M Dataset Reader and Model Support"}, "93": {"path": "/applications/BasketballAction/predict/action_detect/reader/feature_reader.py:1-33", "hash": "313ba89d6f29e5e156bdc16baba45d54", "title": "FeatureReader: Efficient YouTube-8M Data Reader"}, "94": {"path": "/applications/BasketballAction/predict/action_detect/reader/feature_reader.py:35-71", "hash": "489bda0b8e0e14bf07e56ba4f0c6b514", "title": "Feature Reader: Data Batches for Basketball"}, "95": {"path": "/applications/BasketballAction/predict/action_detect/reader/feature_reader.py:72-86", "hash": "dcbff9500e88d488875d63bca732ed2b", "title": "Batching Action Features Reader"}, "96": {"path": "/applications/BasketballAction/predict/action_detect/reader/reader_utils.py", "hash": "ccf03df124e3510d96b3843769ada5b9", "title": "Video Reader Utils"}, "97": {"path": "/applications/BasketballAction/predict/action_detect/reader/reader_utils.py:1-34", "hash": "2d7e71819e9cc679872d392193085df1", "title": "Customizable Reader Not Found Error Handling"}, "98": {"path": "/applications/BasketballAction/predict/action_detect/reader/reader_utils.py:35-83", "hash": "55bd23bae418a6b6869d19bfc6c6896c", "title": "Video Data Reader Zoo"}, "99": {"path": "/applications/BasketballAction/predict/action_detect/reader/reader_utils.py:84-109", "hash": "5704627a68b275ca50c91a745697dfb3", "title": "Singleton Reader Registry"}, "100": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py", "hash": "2d29f888005a3975a0f029209d51a224", "title": "TSMINF Image Reader"}, "101": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:1-37", "hash": "bc05d07b103f62d5f0de9759c9eab625", "title": "TSMINF Reader: Efficient JPG Video Dataset Reader"}, "102": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:38-66", "hash": "c7dfaf3de58d548bda5db38558a700ea", "title": "Configuring TSN Inference Reader"}, "103": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:67-97", "hash": "e2560c1a53f5cf8387484d1c17a43b43", "title": "BasketballAction Video Reader"}, "104": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:98-120", "hash": "8a50fdcce8ea7693f60867d86e70c44f", "title": "Multithreaded Video Frame to Image Conversion"}, "105": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:122-144", "hash": "08e2401bcb21b55ee4983161845fcfde", "title": "Fault-Tolerant Image Reader"}, "106": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:145-172", "hash": "a3ce1a2779ecfa11978e5eed5a9e4031", "title": "Transformative Image Reader: Applied Action Detection"}, "107": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:173-203", "hash": "068ee2441b734a10d40772d187320110", "title": "Image Transformation Function"}, "108": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:204-239", "hash": "8e5a5f1a63cd3d7de61b18717d455148", "title": "Random Crop Size Generator"}, "109": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:240-262", "hash": "aeeb79d6174f4ae7efeaf4a20147f3cc", "title": "Crop Position Calculator"}, "110": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:263-298", "hash": "b4018286865661e1212b59ccdfe1b8d7", "title": "Random Cropped Image Group"}, "111": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:300-338", "hash": "23e6ba369e55e2163e0db095831e8238", "title": "Image Preprocessing for ML Models"}, "112": {"path": "/applications/BasketballAction/predict/action_detect/reader/tsminf_reader.py:339-366", "hash": "614e89003e6673c0c635f1bc4e6b7af3", "title": "Image Cropper and Resizer"}, "113": {"path": "/applications/BasketballAction/predict/action_detect/utils/config_utils.py", "hash": "68c51c32b69a155437b9003c02f6ba68", "title": "BasketballAction Config Utils"}, "114": {"path": "/applications/BasketballAction/predict/action_detect/utils/config_utils.py:1-46", "hash": "c46afb8f771fae69f34040f56b550828", "title": "PaddleVideo BasketballAction Config Utils"}, "115": {"path": "/applications/BasketballAction/predict/action_detect/utils/config_utils.py:47-79", "hash": "09cfac2e9709615fe65250db7409611a", "title": "Config Parser and Printer"}, "116": {"path": "/applications/BasketballAction/predict/action_detect/utils/config_utils.py:80-80", "hash": "c9ab799842bd7e51591e67ac336ac1c7", "title": "Logger for Code Separation"}, "117": {"path": "/applications/BasketballAction/predict/action_detect/utils/preprocess.py", "hash": "43307e52ad097b996f3fbd921f6362c7", "title": "FFmpeg Functions for Video Processing"}, "118": {"path": "/applications/BasketballAction/predict/action_detect/utils/process_result.py", "hash": "65fe1acf9920ac04515c18bdff134a95", "title": "Action Detection with NMS Filtration"}, "119": {"path": "/applications/BasketballAction/predict/action_detect/utils/process_result.py:1-39", "hash": "5a93568b8d58788695fb70eb8711ee83", "title": "Non-Maximum Suppression Algorithm for Bounding Boxes"}, "120": {"path": "/applications/BasketballAction/predict/action_detect/utils/process_result.py:40-76", "hash": "faed7797f1ad7c66ae518c29f6b9be93", "title": "Non-Maximal Suppression for Bounding Boxes"}, "121": {"path": "/applications/BasketballAction/predict/action_detect/utils/process_result.py:77-107", "hash": "39aef6bea8c50f6fa7fcfb461bc43c82", "title": "Video Detection Filtering and Sorting"}, "122": {"path": "/applications/BasketballAction/predict/action_detect/utils/process_result.py:108-129", "hash": "9f95b1aa88d6bbf303b67bd591c7ad57", "title": "Action Detection Processing"}, "123": {"path": "/applications/BasketballAction/predict/action_detect/utils/process_result.py:130-144", "hash": "ac7d8b3a54886185736b3323db968d5f", "title": "NMS Action Result Processor"}, "124": {"path": "/applications/BasketballAction/predict/eval.py", "hash": "9cfd165da96fde629d77425d33c84851", "title": "Optimal IOU Threshold for Basketball"}, "125": {"path": "/applications/BasketballAction/predict/eval.py:1-36", "hash": "c0cabbcb0a70178df5f04b65e256bfca", "title": "Load Ground Truth Annotations (gts)"}, "126": {"path": "/applications/BasketballAction/predict/eval.py:37-67", "hash": "ad0e31650fbefcd882c02b50b3449bef", "title": "Evaluating Basketball Action Predictions"}, "127": {"path": "/applications/BasketballAction/predict/eval.py:68-93", "hash": "6849b1ee3990bbc7466275cfe159afce", "title": "Box Sorting and Conversion Function"}, "128": {"path": "/applications/BasketballAction/predict/eval.py:94-120", "hash": "66c9448c5b431533f9ca853e504c8cc6", "title": "Box Evaluation Metrics Calculator"}, "129": {"path": "/applications/BasketballAction/predict/eval.py:121-144", "hash": "924865ac8627ea81aa8ff4b729dc2168", "title": "IoU-based Metric Calculation for Object Detection"}, "130": {"path": "/applications/BasketballAction/predict/eval.py:146-161", "hash": "33e7b507025d2a53cab3a371674a6fcd", "title": "Precision and Recall Calculator"}, "131": {"path": "/applications/BasketballAction/predict/eval.py:162-189", "hash": "4a0fa77f91eadfbf2111c16cecb05a46", "title": "Calculate F1 Score from Predictions"}, "132": {"path": "/applications/BasketballAction/predict/eval.py:190-218", "hash": "020665e02edcc60d1f7c78c465e4f7c2", "title": "Video Action Detection Model Evaluation"}, "133": {"path": "/applications/BasketballAction/predict/eval.py:219-237", "hash": "8e323e84cdd16739b5bd0a5471758526", "title": "Optimal IOU Threshold for Basketball"}, "134": {"path": "/applications/BasketballAction/predict/predict.py", "hash": "89bee6a3470af3d39c7d7724e3af9d21", "title": "Basketball Action Prediction"}, "135": {"path": "/applications/BasketballAction/predict/predict.py:2-33", "hash": "07b4e3bff1ff99d956db9b4d1e3ff04a", "title": "Basketball Action Predictor"}, "136": {"path": "/applications/BasketballAction/predict/predict.py:34-35", "hash": "9dfa6e92926308d7f1b7eb838cfd619f", "title": "Write Indented JSON to File"}, "137": {"path": "/applications/EIVideo/EIVideo/README.MD", "hash": "c249ee3417abad3260afe53069107481", "title": "CLI Guide for EIVideo Annotation Tool"}, "138": {"path": "/applications/EIVideo/EIVideo/__init__.py", "hash": "e4c73450a57bed7e75139a54ff57178b", "title": "EIVideo __init__.py: Root Paths and Constants"}, "139": {"path": "/applications/EIVideo/EIVideo/api.py", "hash": "3cdcbb684d9486ef38a1d8aaa780b782", "title": "JSON Video Annotation Tool"}, "140": {"path": "/applications/EIVideo/EIVideo/api.py:1-39", "hash": "651801941194611bf24bd479affb8632", "title": "Image Handling Functions"}, "141": {"path": "/applications/EIVideo/EIVideo/api.py:40-67", "hash": "51a9b17bb0bb1ab96e5650f5c0003aac", "title": "PNG to JSON Image Parsing"}, "142": {"path": "/applications/EIVideo/EIVideo/api.py:68-101", "hash": "6431255103bffa93af337d68e240a2b2", "title": "Video Processing: Save, Load, and Annotate JSON"}, "143": {"path": "/applications/EIVideo/EIVideo/api.py:102-130", "hash": "9a9dd34d09c03ea945b60a44df989c20", "title": "Image Resizing and Processing"}, "144": {"path": "/applications/EIVideo/EIVideo/api.py:131-134", "hash": "f745fbcba7410d454e4bcb18e78b92b3", "title": "JSON Overlay Dictionary Saving"}, "145": {"path": "/applications/EIVideo/EIVideo/main.py", "hash": "fb60ad789571033efcc60ddc6a17702d", "title": "PaddleVideo Training with Distributed Support"}, "146": {"path": "/applications/EIVideo/EIVideo/main.py:1-29", "hash": "dce623c65f692d573aa52c1ceb357f84", "title": "PaddleVideo Training Script"}, "147": {"path": "/applications/EIVideo/EIVideo/main.py:30-53", "hash": "26cc4a22923fb4f65e062c19d5a792d2", "title": "Command Line Arguments for EIVideo"}, "148": {"path": "/applications/EIVideo/EIVideo/main.py:54-82", "hash": "a19895013e9c9b35e644ab520dbd9e4a", "title": "Command-Line Arguments for Training Control"}, "149": {"path": "/applications/EIVideo/EIVideo/main.py:83-116", "hash": "2e05bbfb49231625cfbb30d227a85e83", "title": "Command-line Arguments Parser for Video Testing"}, "150": {"path": "/applications/EIVideo/EIVideo/paddlevideo/__init__.py", "hash": "ffb301b1e71c7ebff0b2564fb855f2ef", "title": "PaddleVideo Library Initialization"}, "151": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/__init__.py", "hash": "4ebcf1008359584b24d9b2520e58df22", "title": "Loading EIVideo Modules"}, "152": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/builder.py", "hash": "45c2b084d9ffc77311307a568807bf1f", "title": "Graceful Termination PaddleVideo Dataset Loader"}, "153": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/builder.py:1-31", "hash": "65c2dd69710bb2b3a3151a4df9fec52e", "title": "Building Pipeline with PaddleVideo"}, "154": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/builder.py:32-80", "hash": "7fbd939985907168261514f93306245e", "title": "Dataset Loader Builder"}, "155": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/builder.py:81-106", "hash": "2282479a3c3711e0e4e4d225731bbd6d", "title": "Paddle Dataloader Builder"}, "156": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/builder.py:107-134", "hash": "0e5d1fca24ce0ae0bd4f146e6ccc9cbc", "title": "Mix Collate Function for Stacked Batches"}, "157": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/builder.py:135-151", "hash": "8b4b38eaf330a0b23dd5b4f5a1151fff", "title": "Signal Handler Setup for Process and Group"}, "158": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/__init__.py", "hash": "8d0df7baee32e8ec9ef98eff1f677943", "title": "EIVideo Image Preprocessing Pipeline"}, "159": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/compose.py", "hash": "d1dff462d80b23d18ca4ae63aba9e2fb", "title": "Flexible Pipeline Transformation with Compose"}, "160": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/compose.py:1-31", "hash": "9a6f31ff7974f3a0c693a344b565babb", "title": "Compose Class for Pipeline Composition"}, "161": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/compose.py:32-59", "hash": "a63d62c298c795ae2288cfc27b2b97c5", "title": "Compose Class Sequential Transform Composition"}, "162": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/compose.py:60-76", "hash": "7015aad7ed7341310f7f5ddfc150b3e2", "title": "Compose Pipeline Class"}, "163": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py", "hash": "785a5df685fabdb35e62a85bb1002868", "title": "Paddle Video Image Preprocessing"}, "164": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py:1-43", "hash": "8512a9e42e06788632c0474e040559bc", "title": "RandomScale\\_manet Pipeline"}, "165": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py:46-75", "hash": "4f62fae17c491927716ceb70dfc20653", "title": "Resize Image Pipeline"}, "166": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py:76-109", "hash": "7372a66c2074bf55837712edf43978bc", "title": "Custom Image Crop Transform"}, "167": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py:111-134", "hash": "70cfbea7f349494ff56dd75582c8822d", "title": "Cropped Labels from Image"}, "168": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py:135-163", "hash": "e1c6cd400c53d0f7c86d7733b4b584fb", "title": "Random Region Flipping Transform"}, "169": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py:164-198", "hash": "89110683aeef66e7952aa6d9436b66ee", "title": "Custom Image Transforms for PaddlePipelines"}, "170": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/pipelines/custom_transforms_f.py:199-220", "hash": "d1a9edc111f4e09940b6a3c9e1f6851d", "title": "Scribble Image to Foreground Mask"}, "171": {"path": "/applications/EIVideo/EIVideo/paddlevideo/loader/registry.py", "hash": "78c9d0502880b135c5db97193284a2cc", "title": "Organizing PaddleVideo Functionalities with Registries"}, "172": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/__init__.py", "hash": "516462c31e2b5e4b352e764efea6f1ac", "title": "PaddleVideo Metrics Initialization"}, "173": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/base.py", "hash": "f4da35e3aaa5401e0d447e0131ea5688", "title": "Abstract Base Metric Class for PaddleVideo's EIVideo"}, "174": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/build.py", "hash": "a358e2f5d18276139017e2df56bf08cb", "title": "Apache-Licensed EIVideo Metric Builder"}, "175": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/registry.py", "hash": "df96b61f43a6063fd36b4ec66ff63de9", "title": "Registry-Based Metric Management"}, "176": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py", "hash": "62dcda21329f7886c0d8a7a372604ec5", "title": "VOS Metric: Video Object Segmentation"}, "177": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:1-38", "hash": "6a68e47a1ca076a2e3068161531324ae", "title": "VOS Metric Class Registration"}, "178": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:39-67", "hash": "cf8c1cee298b86eb554a8556e65b6374", "title": "Video Processing Class Initialization"}, "179": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:68-90", "hash": "f79f68194752f243d50c38181f93d7fe", "title": "VOS Metric Initialization"}, "180": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:91-114", "hash": "09e845612c40f1769ca916bd13705e39", "title": "Embedding Preparation for EIVideo"}, "181": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:115-131", "hash": "c922f954c7c1acd863a6ec8ddcb3292b", "title": "Video Object Segmentation Metric"}, "182": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:133-148", "hash": "44e53fd8bc3cf01d49a7bc7b6d7b8eec", "title": "Data Augmentation and Label Averaging"}, "183": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:149-168", "hash": "174caf3bed1bfb67c2bc36ddec45c3cc", "title": "Frame-wise Flipped Label Generation"}, "184": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:169-192", "hash": "da6ed58d873c3ae8610df9d0f6d488d2", "title": "Average Time per Frame Calculation"}, "185": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:193-211", "hash": "bb1764a4c4f000224a34a4af7ec5fde6", "title": "Frame Rate Metrics and Tensor Manipulation"}, "186": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:212-224", "hash": "21e77dfe5e52d4837273361606aa5a11", "title": "Tracking Sequence Numbers"}, "187": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:225-238", "hash": "8f288883006a6e658f97591683c11c2e", "title": "Range of Indices in Code"}, "188": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:239-252", "hash": "6378be9aa104498965cbd64fd4bd5741", "title": "VOS Metric Sequence"}, "189": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:253-271", "hash": "c15e836d9e071c29ebb94944abd0bf30", "title": "Zip Folder and Image Mask Functions"}, "190": {"path": "/applications/EIVideo/EIVideo/paddlevideo/metrics/vos_metric.py:272-279", "hash": "b0f4f52ac7a38bdbac83e7369cade775", "title": "Zipping Metrics and Saving Results"}, "191": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/__init__.py", "hash": "ffd80bfd08d264631a624a591f36e615", "title": "PaddleVideo Model Registry"}, "192": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/__init__.py:1-23", "hash": "5c09503793e169a95918ff6c5c45afb3", "title": "PaddleVideo Import Script"}, "193": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/__init__.py:24-27", "hash": "49e69f1a883d66144a4aaaa195ebf87b", "title": "PaddleVideo Library Variables and Functions"}, "194": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/__init__.py", "hash": "cf637cb33c9d0ea5110ad7599e702a77", "title": "DeepLab Import Statement"}, "195": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/aspp_manet.py", "hash": "020a8ea6f19d5e871821e10bcd5f7ee2", "title": "ASPP-MANET Backbone Initialization"}, "196": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/aspp_manet.py:1-32", "hash": "215affe762795bcb4153aad9960f04e0", "title": "ASPP Layer Implementation in ASV Model"}, "197": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/aspp_manet.py:33-62", "hash": "ec12485f5700e7393c6ddc3d9be3f1a8", "title": "ASPP Network Initialization"}, "198": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/aspp_manet.py:63-85", "hash": "6489e4ce6abd019da706b6724fcab3f3", "title": "ASPP Module with Dilation and Pooling"}, "199": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/aspp_manet.py:86-117", "hash": "dd3bac8cd9a3f1a72b595e530bd0500a", "title": "ASPP-MANET Backbone Class Definition"}, "200": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/aspp_manet.py:118-124", "hash": "ef53c6756a5e432d1849d7b47e3a3575", "title": "ASPP Model Initialization"}, "201": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/decoder_manet.py", "hash": "23d81ac43b4ebc4669ea756037277ede", "title": "Manet Decoder Layer with Conv, BatchNorm, ReLU"}, "202": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/decoder_manet.py:1-30", "hash": "8807ee20e797145bd7582bdb79f7122a", "title": "Manet Decoder Class"}, "203": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/decoder_manet.py:31-59", "hash": "a0f8db291f8aa7a572dba15aee914c3f", "title": "Manet Decoder Block: Conv-BN-ReLU"}, "204": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/decoder_manet.py:60-65", "hash": "c60e3eb59c4cdf59b8af6860e061bd78", "title": "Manet Decoder Initialization"}, "205": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/deeplab_manet.py", "hash": "ad98ab7bf1cf9c5e01e7d225a36920f7", "title": "Static BatchNorm2d and DeepLab Backbone"}, "206": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/deeplab_manet.py:1-26", "hash": "6956c81df30e45b7b9d34cf696f94856", "title": "Frozen Batch Normalization Layer"}, "207": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/deeplab_manet.py:27-61", "hash": "4e00ece5c7a75b92e72b6542b9c8a9f7", "title": "DeepLab Network Backbone"}, "208": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/deeplab_manet.py:62-90", "hash": "02ba98d8872a5d88a6616d235983e375", "title": "DeepLab Model Creation and Evaluation"}, "209": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py", "hash": "2fd940a37b0e19796967ef1f0dd5c23c", "title": "ResNet-MANET Model Coding"}, "210": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:1-31", "hash": "4930d38db40addb55e2577b378384a34", "title": "Bottleneck ResNet Definition"}, "211": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:32-75", "hash": "77f63308da0931d690168c2bf6114002", "title": "ResNet: Efficient Video Backbone"}, "212": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:76-101", "hash": "a4fedbdd2098d2e79de7ce0dd0c9dbbf", "title": "ResNet-MANET Backbone Builder"}, "213": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:102-127", "hash": "c8ee43bc82bc0e431108a10e23fbd77e", "title": "ResNet-MANET Model Creation"}, "214": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:128-159", "hash": "3e35b076cb903ec57aded1d2d247d516", "title": "Create ResNet Residual Block with Downsampling"}, "215": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:160-191", "hash": "dac728ef971c1267451033ad5225373a", "title": "ResNet-MANET Backbone Model"}, "216": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:192-227", "hash": "aa1c038347f37edeb02901a96fad6f28", "title": "ResNet101 BatchNorm Backbone"}, "217": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/backbones/resnet_manet.py:230-245", "hash": "9365cf397dffe20a78f9d09390084de1", "title": "ResNet101 Model JSONizer"}, "218": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/builder.py", "hash": "6484cd728db6c3ad1eb4cde915904350", "title": "PaddleVideo Model Builder"}, "219": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/builder.py:1-19", "hash": "3f28547d2593019bda500421c35206f4", "title": "Model Registration and Building Utilities"}, "220": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/builder.py:22-73", "hash": "ae8878431be6d7f8f0c0bbe264d17d83", "title": "Video Processing Model Components Builder"}, "221": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/builder.py:74-116", "hash": "486070a3ec2d9f1c0fe3cd45f7048c20", "title": "Model Builder: Configurable PaddleVideo Models"}, "222": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/builder.py:117-125", "hash": "845ba5ea66799e49ec06d1aed9671c90", "title": "Video Analysis Framework Builder"}, "223": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/__init__.py", "hash": "93d6eabc081961b16616c604d109e1c0", "title": "PaddleVideo Framework: BaseSegment & Manet Definitions"}, "224": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/__init__.py", "hash": "469f38214046adb09e27eff05d53ad55", "title": "Python Segment Framework Initialization"}, "225": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/base.py", "hash": "354fdf8f91d2fa8007de829cd0191786", "title": "Semi-Video Segmentation Base Class"}, "226": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/base.py:2-30", "hash": "fe8d57aabde833feeb62136aace75c59", "title": "Semi-Video Object Segmentation Base Class"}, "227": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/base.py:31-59", "hash": "041299b867e83dab32004120d922ea41", "title": "Model Initialization and Processing"}, "228": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/base.py:60-95", "hash": "c272b24ad1e2d135142ca72f34c73803", "title": "Abstract Step Methods for Video Modeling"}, "229": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py", "hash": "45a463c8c3984f6fd5f579ccd4094117", "title": "Manet Stage 1 Video Segmentation"}, "230": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:1-26", "hash": "5304a7106dd7fa0313e6103e18d63a0c", "title": "MANET Model Imports for Video Tasks"}, "231": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:27-61", "hash": "7dc12a73f21500373208efcba2c40335", "title": "Manet Model Definition and Implementation Plan"}, "232": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:62-87", "hash": "eedad2bdf260ee0330b98d79be716dfc", "title": "Model Initialization and Evaluation"}, "233": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:88-109", "hash": "383c740343028c1a7aacbd0cbc77428f", "title": "Model State Check and Segmentation"}, "234": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:110-134", "hash": "074a8d4685584e9cc05e90251a4b1fcc", "title": "Manet Stage 1: Initialization and Embeddings"}, "235": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:136-157", "hash": "cd9e1220a8883718fb0649ee6066b7e4", "title": "Manet Stage1: Batch Image Transformation"}, "236": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:158-176", "hash": "843a3046ef9550ac0f9c46705d37bdd8", "title": "Reference Frame Embedding Initialization"}, "237": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:177-195", "hash": "0f375f84649cae1ae171474f7c3eb410", "title": "Save Interactive Scribble Image"}, "238": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:196-216", "hash": "68680f69440f52eba8c5429840a078a1", "title": "Scribble-Based Mask Generation"}, "239": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:217-234", "hash": "6621b5a22a8aab519c13e54638e84bda", "title": "Manet Stage 1 Segmentation Model Iteration"}, "240": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:235-254", "hash": "eb20d50d6d7beaf812a45300bc6f6e8b", "title": "Temp Dictionary Creation for Labels"}, "241": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:255-274", "hash": "82ed835a8f0886180da16ecbb10e69da", "title": "Scribble-based Labeling for Video Annotation"}, "242": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:275-292", "hash": "b8a8c50a8affe5dd51e84500736d3106", "title": "Local and Global Map Calculation for Segmentation"}, "243": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:293-310", "hash": "f71102a3e2fd745d4161cfb515cbda0c", "title": "Manet Segment Annotation Check"}, "244": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:311-327", "hash": "f7055dfa985b962b1f00ae5cb982932d", "title": "Mask Creation and Storage in Video Model"}, "245": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:328-347", "hash": "467318252178981a7af640411f5708a1", "title": "Save and Propagate Frames"}, "246": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:348-365", "hash": "df088f05b73f0ac969be5487cef15581", "title": "Manet Segmentation Model Function"}, "247": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:366-383", "hash": "fe68a13b229ef859c45ec7f2f77c5c05", "title": "Dynamic SegHead Model for Video Prediction"}, "248": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:384-402", "hash": "ab8d80ac78b7f38775954d72f95844f5", "title": "Image Segmentation Model Predictions"}, "249": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/framework/segment/manet_stage1.py:403-417", "hash": "2557459f19de9c0adc4903fe9cc33e91", "title": "Auto-Segmentation Framework"}, "250": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py", "hash": "63f9ec9ad178a824297ef6910763054c", "title": "IntVOS: Nearest Neighbor Attention for Video Segmentation"}, "251": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:1-37", "hash": "fe5f2d73afd9f3feaf2ae047c8990c8c", "title": "Pairwise Squared L2 Distance Calculation"}, "252": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:38-60", "hash": "b19bbb7424dbc4c223855bf45d486e82", "title": "Pairwise Distance Calculation for Nearest Neighbor Attention"}, "253": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:61-83", "hash": "174b9e65f2ea8b4b1330e42dcbda2061", "title": "Nearest Neighbor Distance Calculator"}, "254": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:84-113", "hash": "44da1add36d4c314a5c5ea49aaea37b3", "title": "Nearest Neighbor Features Calculation"}, "255": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:114-134", "hash": "31f821243bdc03815587b66602695d3d", "title": "Nearest Neighbor Feature Calculation"}, "256": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:135-158", "hash": "6e734d047c8337fbb44d4bffebeb520b", "title": "Split and Apply Chunks"}, "257": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:159-181", "hash": "0912c9485c3d3c7020ad4966950b7f3f", "title": "Nearest Neighbor Features Calculation"}, "258": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:182-201", "hash": "113c348be6d7b9f08055e50f978969b5", "title": "Nearest Neighbor Calculator"}, "259": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:202-224", "hash": "c4fec2ae2220c95feb98633467cee77a", "title": "Nearest Neighbor Tensor Reshaping"}, "260": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:225-252", "hash": "b40dd6b8de6eb3702a355245af35f782", "title": "Squared L2 Distance Calculator"}, "261": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:253-278", "hash": "1593fba60a0eceaec6c9904688064baf", "title": "Nearest Neighbor Features for Video Matching"}, "262": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:279-298", "hash": "4a6709ccc8871206281f9683cbf4bbec", "title": "Nearest Neighbor Feature Extraction"}, "263": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:300-325", "hash": "3fbeb58dddf4412d9630a99ef8c9dd9f", "title": "Local Distance and Offset Masks Calculation"}, "264": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:326-358", "hash": "7fea14a5369b05db4fc897bee1996165", "title": "Feature Extraction and Masking for IntVOS"}, "265": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:359-390", "hash": "8332282b008f261e1a1f1f33f8658713", "title": "Convolutional Neural Network Architecture for Image Processing"}, "266": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:391-418", "hash": "a3f95a70ffe0d39bb5b5f073475f21ef", "title": "Custom CNN Layer for Image Feature Extraction"}, "267": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:421-442", "hash": "8d6aaec9bccc2a59f5cb877523bad8c6", "title": "Split Separable Conv2D Layer"}, "268": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:443-488", "hash": "0d3594cf1c2a61351f58df200e68b73a", "title": "Dynamic Segmentation Architecture"}, "269": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:489-506", "hash": "3f0f26394c24a83c58bcc8927929e5b1", "title": "IntVOS Class Definition"}, "270": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:507-530", "hash": "a5879d4d7149c4e8deccdcc9508d9d03", "title": "Dynamic Semantic Segmentation Network Initialization"}, "271": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:531-559", "hash": "5a2ac31e57ec590da2322a5d0cb2ceae", "title": "IntVOS Model Head: Loss Calculation"}, "272": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:560-588", "hash": "092c55599b43ba142d6d259ee0047b62", "title": "Split-Apply-Combine: Prop SegHead Function"}, "273": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:589-622", "hash": "64e6525c02f6fe1b7140c5a47ebeb5dc", "title": "IntVOS: Prop Segmentation Head"}, "274": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:623-646", "hash": "33865b1737edcf85537c3d0fcc165f28", "title": "IntVOS: Feature Embedding Function"}, "275": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:647-665", "hash": "6fcb74f3b0c3d782942da7962b53616f", "title": "Nearest Neighbor Features Calculation"}, "276": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:667-687", "hash": "ecead76d5a97fcafa37a8496d9901fe4", "title": "Sequence Name Check and Update"}, "277": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:688-707", "hash": "903a562eaa23c9efd24a0cf653e193f9", "title": "Nearest Neighbor Features for Previous Frame"}, "278": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:708-724", "hash": "35526a5cf5e6f0235192be7f70df09f9", "title": "Map Dictionaries Check"}, "279": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:725-741", "hash": "4356022621b4baba29436d4882a56ebc", "title": "InterVOS Frame Processing"}, "280": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:742-763", "hash": "9ffe670a0764b558fac8a8ed6147f0f5", "title": "Video Modeling: Local Maps and Interaction Numbers"}, "281": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:764-787", "hash": "75b7dcd36835680270d0e37b3792ee9e", "title": "Defining Int_seghead Function"}, "282": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:788-813", "hash": "6eae7debd6a853926d4909baec28aa3b", "title": "Local Distance Map Calculation in IntVOS"}, "283": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:814-832", "hash": "aaaa59f8477814ab68155f304f10aecb", "title": "Update Global Map with Nearest Neighbors"}, "284": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:833-854", "hash": "bfac055d1154d5560d9b73d870d80362", "title": "Updating Global and Local Maps in Video Model"}, "285": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:856-878", "hash": "85d74f002ae6ee30aee39c5745a86ed5", "title": "Dynamic Object Scene Embeddings"}, "286": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/IntVOS.py:879-893", "hash": "990b3813da0effae564e4ab5037f5ec5", "title": "Segmentation Prediction in IntVOS"}, "287": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/heads/__init__.py", "hash": "f5d9e4c0f75f98e9bd5aa84e302ca02a", "title": "Copyright and Imports in PaddleVideo Heads"}, "288": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/registry.py", "hash": "dcff2e36669adb0046ec39b94682799c", "title": "Registry Management in PaddleVideo's EIVideo"}, "289": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/registry.py:1-27", "hash": "41d34bca0fd20493c29c23c9e82558b4", "title": "Video Component Registry in PaddleVideo's EIVideo"}, "290": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/registry.py:28-31", "hash": "9edd7c0fadd8d524fbe4ce151e8019a9", "title": "Four Model Registries for Efficient Video Processing"}, "291": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py", "hash": "f836414d6e4487d7a53064cee688f43b", "title": "Customizable PaddlePaddle Weight Initialization"}, "292": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py:1-36", "hash": "a4e39816683d02d3875550fa3302d901", "title": "Weight Initialization Functions"}, "293": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py:37-66", "hash": "730facfd4a8dc6061fe7c9ac0aaa9afc", "title": "Truncated Normal Weight Initialization"}, "294": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py:68-98", "hash": "8e42ab32c1bd99bb5836c8ef7e10e8a0", "title": "Truncated Normal Weight Initialization"}, "295": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py:99-130", "hash": "25cc197bad1d611e6b82038e4fc9e86b", "title": "Truncated and Kaiming Normal Weight Init"}, "296": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py:131-157", "hash": "eb485f578e2d8c3c7ef45a63f8eb17d0", "title": "Initialize Weights with Normal Distribution"}, "297": {"path": "/applications/EIVideo/EIVideo/paddlevideo/modeling/weight_init.py:158-158", "hash": "48e0b144a4073fff150af40e868b946e", "title": "Random Weight Initialization"}, "298": {"path": "/applications/EIVideo/EIVideo/paddlevideo/tasks/__init__.py", "hash": "ad4ef0535e4944a400a4949a7ab1ae4e", "title": "Importing Test Model Function"}, "299": {"path": "/applications/EIVideo/EIVideo/paddlevideo/tasks/test.py", "hash": "17623cd1b341c0d84c2cc7b1a8422b92", "title": "Multi-Card Model Testing"}, "300": {"path": "/applications/EIVideo/EIVideo/paddlevideo/tasks/test.py:1-31", "hash": "c059a19cb2a640db4a273bde3d346912", "title": "Model Testing without Gradient"}, "301": {"path": "/applications/EIVideo/EIVideo/paddlevideo/tasks/test.py:32-39", "hash": "9ceac2080fd741ddd93c503a39ea5820", "title": "Multi-card Test Configuration"}, "302": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/__init__.py", "hash": "11a097247079a44b22b703aec2640924", "title": "PaddleVideo Library Utilities"}, "303": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/build_utils.py", "hash": "f83a439f771717559e12a420144707b5", "title": "Building Objects with Config and Registry"}, "304": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/build_utils.py:1-31", "hash": "a54bbce1587d9d975c033d691a75cf89", "title": "Build Object Function"}, "305": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/build_utils.py:32-35", "hash": "01e0be5913d2e7da16af7e0dfe5327fc", "title": "Build and Validate Object Class"}, "306": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/config.py", "hash": "4de317a6037cb5b11bc599ffe7dfb554", "title": "Config Parser and Checker"}, "307": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/config.py:1-34", "hash": "9723ad71e3e4ac1d7587388959b7a5fc", "title": "Config Utilities Setup"}, "308": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/config.py:35-67", "hash": "b4449b3ecf2be557c0f8fa3cfdaca297", "title": "Config Parser and Printer"}, "309": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/config.py:68-109", "hash": "6c9628430b2be05dc6492df3dcac1287", "title": "Config Utilities and Visualization Functions"}, "310": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/config.py:110-139", "hash": "3517e871e60bffc4faea99c5cc4322af", "title": "Config Override Function"}, "311": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/config.py:140-170", "hash": "e8f88ba30cc39aa0b6d9a1bcca98d88a", "title": "Dynamic Config Overrides"}, "312": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/config.py:171-174", "hash": "c3c7fc8e31bd05056f4dd79d92cd7ed9", "title": "Check and Print Config"}, "313": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/dist_utils.py", "hash": "e0dab607c4f876623c7a502c5b5bdf99", "title": "Distributed Computing Utilities"}, "314": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/logger.py", "hash": "60ca93f2ed075ed2c8be2ee2f0a09be9", "title": "Customizing PaddleVideo Logging"}, "315": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/logger.py:1-38", "hash": "9e67c4508db20e6a05edf853dc6e7f9c", "title": "Colorful Logger: Setting Up Colors for Logging Messages in PaddleVideo"}, "316": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/logger.py:39-71", "hash": "493b6a787bc8f720911dc12b6349e726", "title": "PaddleVideo Logger Initialization"}, "317": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/logger.py:72-100", "hash": "ded062c3eabbf41a0248b763aa23a846", "title": "Custom Logger Configuration for Python"}, "318": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/logger.py:101-113", "hash": "bb1b5be6ba13385164d9cc43e870bcf5", "title": "Initialize and Set Logger Level"}, "319": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py", "hash": "89c2984099194a5f8a8befc04a6faa79", "title": "OpenCV-Powered PyTorch Image Processing"}, "320": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1-28", "hash": "84c086b6951787f99f43791353ca023b", "title": "Define Paddle Tensor Type Hints"}, "321": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:29-41", "hash": "067c3de0ccdead594bcf7f03b8068247", "title": "Unstructured Numeric Sequence"}, "322": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:42-54", "hash": "af346b41d910ecd01b05a97645762eee", "title": "Extract Integer List"}, "323": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:55-67", "hash": "1fae030b1c57e734544d077daf7d9553", "title": "List of Integers: Purpose Unclear"}, "324": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:68-105", "hash": "3c23a278c93fb20cd4a5394755404229", "title": "Masked Damager Function"}, "325": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:106-146", "hash": "ea6b1fcff32d44c2f036d051ad194b4f", "title": "Morphology-Based Mask Overlay"}, "326": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:147-172", "hash": "a44999afd8755e746139631009514576", "title": "Generate Overlay Images and JSON List"}, "327": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:173-206", "hash": "e79842394b9d78efd3be1d9cbb068cd0", "title": "Video Frame Loading and Labeling Utility"}, "328": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:207-236", "hash": "be809b41a60f162610642b72e22011ac", "title": "Efficient Scribble Label Processing Functions"}, "329": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:239-272", "hash": "756d573d733e1c6b88bb23ef952f6ef2", "title": "Load and Save Pretrained Model Function"}, "330": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:273-304", "hash": "8be8fd71fbc9379dc02033e7314cf5a0", "title": "Damage Masks Generator"}, "331": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:305-330", "hash": "afc567bb06bf1d200ccd8a8577134fbe", "title": "Mask Damage Utility"}, "332": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:331-361", "hash": "effc9d297128678dc65b16885b3d18d0", "title": "Randomly Shifting Numpy Mask"}, "333": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:362-388", "hash": "a5dc85e260c5dcfbed6e3544cc78a669", "title": "Randomly Manipulating Binary Masks for AI Robustness"}, "334": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:389-422", "hash": "22a77b0c9e808307d7e89d5a7858946e", "title": "Binary Mask Rotation and Scaling"}, "335": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:423-466", "hash": "f5a66f73e685909f6046c3eac2241b63", "title": "PaddleVideo Utilities"}, "336": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:467-500", "hash": "bfb27ee7844c02eaba13a425bfb06447", "title": "Tensor to PIL Image Conversion"}, "337": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:501-529", "hash": "6d06f64fe8487a0883e9fd8af67bd048", "title": "Adjusting Image Format for Compatibility"}, "338": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:530-553", "hash": "b844eeadcc338703047f71233c0b6ac0", "title": "Image Mode Validator"}, "339": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:554-578", "hash": "330bcd4eaf9cde0e1b5bda54e7c653e5", "title": "Compatibility Checker"}, "340": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:580-615", "hash": "5ac6ec9ad185d337bab304c1eabb8a3d", "title": "Paddle-Torch Dictionary Converter"}, "341": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:616-640", "hash": "1de600f73d0f8a801e173ea575f9e4c1", "title": "Gradient Norm Clipping Function"}, "342": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:641-666", "hash": "e70a2f4ad62f683ad26fcfd728cafabc", "title": "Total Norm of Parameters Calculation"}, "343": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:667-682", "hash": "0f949c9d2e6cbe47e6aab46e7eb28f2d", "title": "Manet Gradient Scaling"}, "344": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:683-716", "hash": "a263c38a887649c375b9cebd06c7e9f8", "title": "Max Index Gathering with PaddlePaddle"}, "345": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:717-745", "hash": "7da9dd40be0406375200ea1606c0ac00", "title": "Tensor Sampling and Reshaping"}, "346": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:746-774", "hash": "d770ababc2c9e2ecd028eebea080afa7", "title": "Tensor Initialization Functions"}, "347": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:775-806", "hash": "d779d361752a0d50c7bf33164fd573ab", "title": "Normalizing Tensor with PyTorch's Paddle"}, "348": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:807-833", "hash": "cc16f945d925b55f8676c606b48ea0de", "title": "Recommended Gain for Nonlinearity Functions"}, "349": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:834-859", "hash": "0704f9e7d8481e6b27450ccf9372e88d", "title": "Nonlinearity Mapping Function"}, "350": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:862-895", "hash": "3ee61d2991fef01bc0f04808da1d53ee", "title": "Uniform and Normal Tensor Initialization Functions"}, "351": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:896-923", "hash": "2284ce5b27cc865ee67caa70945bdbd5", "title": "Truncated Normal and Constant Tensor Filling"}, "352": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:924-966", "hash": "015866c38564ccb2e1fff4bc2a7202ce", "title": "Tensor Filling Methods: Constant, Ones, Zeros, and Identity Matrix"}, "353": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:968-998", "hash": "4277b09ab5b2d456bd064af325b543e0", "title": "Dirac and Identity Tensor Initializers"}, "354": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1000-1028", "hash": "aadc8e5150623c24e76eb31f45f8d1fa", "title": "Manet Initializer Function"}, "355": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1029-1060", "hash": "eb4d50bbe59ce8dc54450c19a202438d", "title": "Xavier Uniform Initialization for Tensors"}, "356": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1062-1089", "hash": "768307d5b90ee8090fe3a948eaf6384f", "title": "Xavier Initialization for Tensors"}, "357": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1091-1120", "hash": "a4da7ac460ce0dc3653a22448eb8e516", "title": "Xavier Normal Distribution Initialization in PyTorch"}, "358": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1121-1145", "hash": "e292484189cbb0b886de494daa70b2bb", "title": "Kaiming Uniform Initialization Function"}, "359": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1146-1170", "hash": "8c26d6c18b08dd94967ccb5172d2266d", "title": "Kaiming Normal Tensor Initialization"}, "360": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1171-1196", "hash": "4d1f70de3c85a86606ead61137c1144b", "title": "Orthogonal Matrix and Kaiming Initialization Functions"}, "361": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1197-1233", "hash": "d96ccb4aca33c0d517f946d3408f23a0", "title": "Sparsity-Ensured Normal Tensor Initialization"}, "362": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1234-1268", "hash": "e20c00acc63771d2b04b582bafdf00a9", "title": "Sparsity-Init Torch Tensor\n(or)\nSparse Torch Tensor Init\n(or)\nTorch Tensor Sparse Initializer"}, "363": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/manet_utils.py:1269-1295", "hash": "bae353059469eba47a1a041eb6f62010", "title": "Deprecating Init Methods: Torch.nn to PaddleVideo"}, "364": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/precise_bn.py", "hash": "0e0bbc2243536eb2347f16a7e1e1ef70", "title": "Precise Batch Normalization Improvement"}, "365": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/precise_bn.py:1-30", "hash": "273850870b51f1af31409be82f67a1da", "title": "Improved Batch Norm in EIVideo"}, "366": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/precise_bn.py:31-54", "hash": "39e98cb71eca93d4e4662969871e1cf1", "title": "Precise Batch Normalization Statistics"}, "367": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/precise_bn.py:55-80", "hash": "051d0a84e53d52d28eec3ee62653a616", "title": "Precise BN Training Algorithm"}, "368": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/precise_bn.py:81-84", "hash": "73667949d3794383b4f20e2cbabf0e8b", "title": "Updating BatchNorm Layers in Model Training"}, "369": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/profiler.py", "hash": "71fc94521b41663a468987ce6b4a9145", "title": "PaddlePaddle Profiler Initialization"}, "370": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/profiler.py:1-29", "hash": "915c6c3127eea51d9f94940df9dbf54d", "title": "Global Variables and Profiler Options"}, "371": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/profiler.py:30-52", "hash": "4a7ecf8be729828011fcf69a35f68557", "title": "Profiler Options Class"}, "372": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/profiler.py:53-76", "hash": "cd6b0eae761d553604279f6dad567c15", "title": "Profile Parser from String"}, "373": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/profiler.py:77-104", "hash": "a1ed4afe806c1caeccd30e95a1e2b959", "title": "Operator-Level Profiling with PaddlePaddle's Profiler"}, "374": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/profiler.py:105-110", "hash": "6bb5b0511e51ed77273e28c6dcf01f41", "title": "Profiler Step Incrementer"}, "375": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/record.py", "hash": "d6b97603e44f68a1d21cc0199c573139", "title": "PaddleVideo Record: Metrics Tracking and Logging"}, "376": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/record.py:1-32", "hash": "dfc55d3bc42eafac4e2aa3aee2cc8fce", "title": "Metrics Logger for Paddle Video"}, "377": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/record.py:33-49", "hash": "2ccf6902b0407acf7394eb15df6580a0", "title": "Framework-Specific Metric Recording"}, "378": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/record.py:50-72", "hash": "366b74e95ee7e7e1e51fcbf8387e5538", "title": "Average Meter for Metrics Tracking"}, "379": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/record.py:73-113", "hash": "2283f2f8e7867260af5f8aa64b77f42a", "title": "Tracking Metrics Class"}, "380": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/record.py:114-141", "hash": "7942a73e9fcc7a588c964f560b579a16", "title": "Epoch Metrics Logger"}, "381": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/record.py:142-157", "hash": "dcb099329731cb2a183018a4c50493ec", "title": "Epoch Metrics Logger"}, "382": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/registry.py", "hash": "37f5a552289064dfc46330490dcf80ac", "title": "Registry: Name-to-Object Mapping and Registration"}, "383": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/registry.py:1-34", "hash": "aa7f2ff72d1c3cea9b0e8c8444bff553", "title": "Registry Class for Custom Modules"}, "384": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/registry.py:36-70", "hash": "78cbec2e7904bafb22083914eb1e0021", "title": "Object Registry Manager"}, "385": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/registry.py:71-96", "hash": "496426f6a6b3d703db5356ef28669ea3", "title": "Registry Class and Methods"}, "386": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py", "hash": "6f5248104cb247195c807157bb34f54e", "title": "ViT Adaptor with PaddlePaddle Compatibility"}, "387": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py:1-28", "hash": "a509f5b63a5e89a093c3dda01edc9a09", "title": "ViT Model Adaptation for Existing Architecture"}, "388": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py:29-49", "hash": "41565172e7e51dfb5528faba907974bf", "title": "Maintaining 'pos_embed' Tensor Consistency"}, "389": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py:51-71", "hash": "ae609013da632e5f85398ef43b461d63", "title": "Adjusting Time Embedding Shape"}, "390": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py:72-96", "hash": "a550518360b4b02499bf023190ab4205", "title": "Temporal State Dictionary Merge"}, "391": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py:97-127", "hash": "8931e5ead2a81e57e80edcef255e88d3", "title": "Loading Pre-trained Model Parameters"}, "392": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py:128-152", "hash": "cbcb83a36e3b60ae73cf37c412902c32", "title": "Resnet and Vision Transformer Weights Loader"}, "393": {"path": "/applications/EIVideo/EIVideo/paddlevideo/utils/save_load.py:153-182", "hash": "4c723f63a295950c383f592b9405f5ec", "title": "Load and Save PaddlePaddle Models"}, "394": {"path": "/applications/EIVideo/EIVideo/paddlevideo/version.py", "hash": "6ca7d799557f98e977461c1e4bfd1c3e", "title": "PaddleVideo Version Info"}, "395": {"path": "/applications/EIVideo/EIVideo/setup.py", "hash": "98b861269945162787fe1380d6b7bf23", "title": "Code Credits and Sources"}, "396": {"path": "/applications/EIVideo/EIVideo/version.py", "hash": "c3ef742ac9b372ae98f46762a5d5bfaa", "title": "EIVideo Version Information"}, "397": {"path": "/applications/EIVideo/QEIVideo/__init__.py", "hash": "5f4b93320e7872df3b7e77431453b36c", "title": "QEIVideo Path and Version"}, "398": {"path": "/applications/EIVideo/QEIVideo/build_gui.py", "hash": "00684c73f9f566bd8f7ffe7cc244020c", "title": "Video GUI with PyQt5: Functionality Overview"}, "399": {"path": "/applications/EIVideo/QEIVideo/build_gui.py:1-36", "hash": "48c48fd458f46770f674bda16f62f949", "title": "PyQt5 GUI Builder Script"}, "400": {"path": "/applications/EIVideo/QEIVideo/build_gui.py:37-59", "hash": "eee56dd45a8c45b92e8bb1960135b56c", "title": "Progress Bar and Play Button Functionality"}, "401": {"path": "/applications/EIVideo/QEIVideo/build_gui.py:60-78", "hash": "a44569ae83612ec209d03680621c4aa0", "title": "Interactive Video Controls: Stop, Start, Select"}, "402": {"path": "/applications/EIVideo/QEIVideo/build_gui.py:79-107", "hash": "f41c84412ea14706d9084c968b465fe2", "title": "Video Processing GUI with Eraser Mode"}, "403": {"path": "/applications/EIVideo/QEIVideo/build_gui.py:109-135", "hash": "445598738d9bcefcc61e489a80102739", "title": "GUI Application Functions"}, "404": {"path": "/applications/EIVideo/QEIVideo/build_gui.py:136-151", "hash": "ae00c1caa32d5e5b7919d3936b1ba2a0", "title": "Update Frame in QEIVideo GUI"}, "405": {"path": "/applications/EIVideo/QEIVideo/gui/__init__.py", "hash": "6831e707cecf1216f8844622dabebd22", "title": "PaddleVideo's EIVideo Copyright Comment Block"}, "406": {"path": "/applications/EIVideo/QEIVideo/gui/demo.py", "hash": "e83f89f70bfd6ac0373ff859d725ce3f", "title": "DrawFrame Class for QT UI"}, "407": {"path": "/applications/EIVideo/QEIVideo/gui/demo.py:1-36", "hash": "6bfff55c5eb106142912c168eca1c19e", "title": "Interactive QWidget Drawing Class"}, "408": {"path": "/applications/EIVideo/QEIVideo/gui/demo.py:39-62", "hash": "aa90ac03139d916aad9f9e72744ddfce", "title": "DemoUI Frame Drawing Initialization"}, "409": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py", "hash": "11bc888ac07e07c627b3160c123671c7", "title": "EIVideo App UI Initialization"}, "410": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:1-32", "hash": "30a2b419d3cf245f2702990ee052c891", "title": "Video Application Main Window Initialization"}, "411": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:33-56", "hash": "bb594f045fd060b4ac44a64d10d6dc2d", "title": "UI Initialization in Video App"}, "412": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:57-77", "hash": "3b5a064653cf561771fa2858e242482f", "title": "GUI Setup for EIVideo"}, "413": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:78-101", "hash": "a423dc2749669e38522b1227b55a2df0", "title": "Painting App UI Setup"}, "414": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:102-122", "hash": "b2407957451ba06bad7962b10c53c150", "title": "Video Player UI Creation and Interaction"}, "415": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:123-142", "hash": "46cde7caac9308835de20c51955d34c8", "title": "Initializing Push Buttons and Layouts"}, "416": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:143-164", "hash": "9362f62f3802f3d7a2d779ce61be235d", "title": "Creating App's Main UI"}, "417": {"path": "/applications/EIVideo/QEIVideo/gui/ui_main_window.py:165-167", "hash": "30e1c17013b9c31648e8b7f7bb4831b2", "title": "GUI Element Updates in MainWindow"}, "418": {"path": "/applications/EIVideo/QEIVideo/start.py", "hash": "e687d4712aa6e455cabdaed11537d3b5", "title": "Launch QEIVideo GUI with Python"}, "419": {"path": "/applications/EIVideo/QEIVideo/tools/__init__.py", "hash": "6831e707cecf1216f8844622dabebd22", "title": "PaddleVideo QEIVideo Comment Block"}, "420": {"path": "/applications/EIVideo/QEIVideo/ui/__init__.py", "hash": "6831e707cecf1216f8844622dabebd22", "title": "EIVideo UI Init File Comment"}, "421": {"path": "/applications/EIVideo/QEIVideo/ui/demo.py", "hash": "56f03d75cd32f0ab7c93c1268f7fb427", "title": "Interactive PyQt5 Video Player UI"}, "422": {"path": "/applications/EIVideo/QEIVideo/ui/demo.py:1-25", "hash": "830d99ce02e389ffb5bcb57ae0290a3c", "title": "PyQt5 UI Generated Main Window Code"}, "423": {"path": "/applications/EIVideo/QEIVideo/ui/demo.py:26-41", "hash": "cd09b65720b1dc03b19afcb112b22f64", "title": "Video Player Interface Setup"}, "424": {"path": "/applications/EIVideo/QEIVideo/ui/demo.py:42-58", "hash": "054ea23803da10b934a7f0d8e0440391", "title": "Creating Video Player Buttons and Slider"}, "425": {"path": "/applications/EIVideo/QEIVideo/ui/demo.py:59-77", "hash": "43c473f9758b6783385a4e21a73d5e6a", "title": "GUI Layout for Video Player Application"}, "426": {"path": "/applications/EIVideo/QEIVideo/ui/demo.py:78-97", "hash": "87067f3a2d7be44ad96aa7c913928b8d", "title": "Creating Tab Widget with QProgressBar and QLabel"}, "427": {"path": "/applications/EIVideo/QEIVideo/ui/demo.py:98-113", "hash": "af10d2288e5e37fb6d942722e84b7577", "title": "QEIVideo UI Configuration"}, "428": {"path": "/applications/EIVideo/QEIVideo/version.py", "hash": "c3ef742ac9b372ae98f46762a5d5bfaa", "title": "EIVideo Version Info"}, "429": {"path": "/applications/EIVideo/QEIVideo/widget/PaintBoard.py", "hash": "f9cc390ff6dbc8c7cf3c9af4f6067161", "title": "PaintBoard: QWidget for Drawing & Erasing"}, "430": {"path": "/applications/EIVideo/QEIVideo/widget/PaintBoard.py:1-40", "hash": "e5f09b215fbcaf3472f0bc1640686abf", "title": "PaintBoard: Custom QWidget for Graphic Editing"}, "431": {"path": "/applications/EIVideo/QEIVideo/widget/PaintBoard.py:42-78", "hash": "123033653bd622694ec539a253e7558a", "title": "PaintBoard Class Functions"}, "432": {"path": "/applications/EIVideo/QEIVideo/widget/PaintBoard.py:80-106", "hash": "fbdbbac9c603805e7dc328483ecbb104", "title": "Mouse Event Handler for PaintBoard Drawing"}, "433": {"path": "/applications/EIVideo/README.md", "hash": "5e2d267957cba8b3187c707c9a03060c", "title": "EIVideo: Windows Video Annotation Tool"}, "434": {"path": "/applications/EIVideo/README.md:1-15", "hash": "2963f34fa2cd3f8181f58f6112fe815f", "title": "Interactive Intelligent Video Annotation Tool"}, "435": {"path": "/applications/EIVideo/README.md:16-49", "hash": "dbbb009fad1bcdbcf5b67cac14f76a1d", "title": "Interactive Video Annotation Toolbox"}, "436": {"path": "/applications/EIVideo/README.md:51-85", "hash": "89512fef8bcba4baa9953a5aa0d7de69", "title": "Introducing EIVideo: Customizable Interactive Video Annotation"}, "437": {"path": "/applications/EIVideo/README.md:86-119", "hash": "60b97b9b0a09e9132954a3f7c2d249b2", "title": "QEIVideo Installation and Roadmap Guide"}, "438": {"path": "/applications/EIVideo/README.md:121-123", "hash": "dc2ec17af962645ebebd6b3dac27a7c7", "title": "Emoji and Resource Sources"}, "439": {"path": "/applications/EIVideo/resources/QT/demo.ui", "hash": "c649ed8a427a19065c1bb208b25d4ecf", "title": "Qt Video Demo UI Designer"}, "440": {"path": "/applications/EIVideo/resources/QT/demo.ui:1-44", "hash": "48ab41836da16236cc9a0f01704de954", "title": "Main Window Interface Design"}, "441": {"path": "/applications/EIVideo/resources/QT/demo.ui:45-86", "hash": "939f60dd38274c323cdcacfd2afc8a4b", "title": "UI Design: Video Open Button"}, "442": {"path": "/applications/EIVideo/resources/QT/demo.ui:87-125", "hash": "59f536818ad234ae52bfdf19a2155a0a", "title": "UI Design with Chinese Buttons"}, "443": {"path": "/applications/EIVideo/resources/QT/demo.ui:126-169", "hash": "87751b7fd3fc4aced3c99b8bc9a71ef4", "title": "User Interface Layout Design"}, "444": {"path": "/applications/EIVideo/resources/QT/demo.ui:170-212", "hash": "39a464653554e6400b28e8a819640b2f", "title": "Qt UI Layout Design"}, "445": {"path": "/applications/EIVideo/resources/QT/demo.ui:213-236", "hash": "e9315496ed6101196c778bc94239ba30", "title": "Qt Application User Interface Layout: Demo.ui"}, "446": {"path": "/applications/EIVideo/resources/cmd", "hash": "4af3a4b1d3b5ce1aec92d53c162cd0a7", "title": "Updating EIVideo: PaddleGit Operations"}, "447": {"path": "/applications/FightRecognition/README.md", "hash": "b7f747cf2e8e66bc7a64caad15ace628", "title": "Fight Recognition Model Guide"}, "448": {"path": "/applications/FightRecognition/README.md:1-29", "hash": "70f11f26315c9ea863a4bbbd71006d53", "title": "Fight Recognition with PaddleVideo PP-TSM"}, "449": {"path": "/applications/FightRecognition/README.md:31-55", "hash": "4f185ea312cf5058453d876a2666fd17", "title": "Python Script Executes Fight Prediction Model"}, "450": {"path": "/applications/FightRecognition/README.md:56-75", "hash": "3c7fe054238e8ea9701da3da147d3db7", "title": "Fight Detection Datasets and Training Approach"}, "451": {"path": "/applications/FightRecognition/README.md:77-118", "hash": "ceb2c29db31d118a0f436eaa56b92daf", "title": "Multi-Dataset Fight Recognition Tool"}, "452": {"path": "/applications/FightRecognition/README.md:119-160", "hash": "cfbd5ddf01fda2c9b09e39951e2d9702", "title": "Train and Validate Video Lists Generation"}, "453": {"path": "/applications/FightRecognition/README.md:162-192", "hash": "c46763cd7c3857df49e8f41ad143894f", "title": "Cut Video Function"}, "454": {"path": "/applications/FightRecognition/README.md:193-245", "hash": "7a33e0716c574ae47602c35ae1e3b3bf", "title": "End of Model Training Code Snippet"}, "455": {"path": "/applications/FightRecognition/README.md:246-248", "hash": "91f2eabd399491fc9ce76f1c922e6dae", "title": "Loading and Saving Pre-Trained Model"}, "456": {"path": "/applications/FigureSkating/README.md", "hash": "58966ed550525814944169eab59d1b92", "title": "OpenPose for Figure Skating Analysis"}, "457": {"path": "/applications/FigureSkating/README.md:1-46", "hash": "267f4428f0be8a76f31123b36d99942b", "title": "Figure Skating Action Data Processing with OpenPose"}, "458": {"path": "/applications/FigureSkating/README.md:48-92", "hash": "ca42421616fc509bf9c68ebf0a4973ee", "title": "Training Figure Skating Models with Video Data"}, "459": {"path": "/applications/FootballAction/README.md", "hash": "dfa03f2f666c738847d5fdecaaa310b1", "title": "FootballAction Model Improvements in PaddleVideo"}, "460": {"path": "/applications/FootballAction/README.md:1-54", "hash": "3e1ba8bf8c9ddcb64386df8608c9578c", "title": "Soccer Action Detection Algorithm in PaddleVideo"}, "461": {"path": "/applications/FootballAction/README.md:55-118", "hash": "d3e635a0cc79854c81384e651a2b557e", "title": "Football Action Dataset Preprocessing"}, "462": {"path": "/applications/FootballAction/README.md:119-141", "hash": "84bb11d8bd91cd2a118ae1c953fde66d", "title": "Comprehensive FootballAction Dataset Directory"}, "463": {"path": "/applications/FootballAction/README.md:142-201", "hash": "87c3e876cb82a17755d38f3fdc05b447", "title": "Download, Run and Train PP-TSM for FootballAction"}, "464": {"path": "/applications/FootballAction/README.md:202-230", "hash": "2bd47e1415b0ee84f45918f994e1106a", "title": "Updating Recognizer2D and Exporting PP-TSM Model"}, "465": {"path": "/applications/FootballAction/README.md:231-275", "hash": "beee241493fb3ece4c38a1e7fa488541", "title": "Replacing Output Tensor and Extracting Features"}, "466": {"path": "/applications/FootballAction/README.md:276-320", "hash": "3c59f210914e9b1459b0d59a9209dfb1", "title": "BMN Dataset Creation Script"}, "467": {"path": "/applications/FootballAction/README.md:321-362", "hash": "68dcee7efc686721d592d16dfc9ee134", "title": "BMN Model Export and Prediction"}, "468": {"path": "/applications/FootballAction/README.md:363-408", "hash": "a1be3b1503171ddb62c0852563f7031e", "title": "Attention LSTM Improvements in FootballAction"}, "469": {"path": "/applications/FootballAction/README.md:409-441", "hash": "20025ecbb6c6ea36f2f756261ec85329", "title": "LSTM Training Data Snippet"}, "470": {"path": "/applications/FootballAction/README.md:442-493", "hash": "1b25f87fedfbb4824e0184244d2b70a8", "title": "LSTM Training and Prediction Code"}, "471": {"path": "/applications/FootballAction/README.md:494-513", "hash": "940a57a86453088cd9f26023bd4f9bb2", "title": "Improved PP-TSM Model for Football Action Detection"}, "472": {"path": "/applications/FootballAction/checkpoints/download.sh", "hash": "f940b6f312bfef7732b66fb298859b40", "title": "FootballAction Checkpoints Download Script"}, "473": {"path": "/applications/FootballAction/datasets/EuroCup2016/dataset_url.list", "hash": "92a97efd512e27af6ed85783bfd54b05", "title": "EuroCup2016 Video Dataset URLs"}, "474": {"path": "/applications/FootballAction/datasets/EuroCup2016/dataset_url.list:1-11", "hash": "6ccd57fe5b4cde5925c2ba638027b46a", "title": "EuroCup2016 Dataset URLs"}, "475": {"path": "/applications/FootballAction/datasets/EuroCup2016/dataset_url.list:12-22", "hash": "6eee21af04fda99d7411b063974efda7", "title": "EuroCup2016 Dataset Download URLs"}, "476": {"path": "/applications/FootballAction/datasets/EuroCup2016/dataset_url.list:23-33", "hash": "4094f2600859cbf9997e683aef122ed5", "title": "EuroCup2016 Video URLs List"}, "477": {"path": "/applications/FootballAction/datasets/EuroCup2016/dataset_url.list:34-44", "hash": "ee004d61db334d703792070c4422cc06", "title": "EuroCup2016 Dataset URL Listing"}, "478": {"path": "/applications/FootballAction/datasets/EuroCup2016/dataset_url.list:45-49", "hash": "a34eb5dd74b8ed1a7953245e47aa72f1", "title": "EuroCup2016 Video URLs"}, "479": {"path": "/applications/FootballAction/datasets/EuroCup2016/download_dataset.sh", "hash": "65ab339aaae79826021b462771787af7", "title": "Download EuroCup2016 Videos"}, "480": {"path": "/applications/FootballAction/datasets/EuroCup2016/download_dataset.sh:1-13", "hash": "ca093fbbbd4d014f931342d0ca2a05c0", "title": "Download EuroCup2016 Videos"}, "481": {"path": "/applications/FootballAction/datasets/EuroCup2016/download_dataset.sh:14-24", "hash": "07a3d517280a30bf980d8c81077b0c42", "title": "EuroCup2016 Video Download Script"}, "482": {"path": "/applications/FootballAction/datasets/EuroCup2016/download_dataset.sh:25-35", "hash": "ebd09658ff8b95ae18de7c93e0f260bd", "title": "EuroCup2016 Video Download"}, "483": {"path": "/applications/FootballAction/datasets/EuroCup2016/download_dataset.sh:36-46", "hash": "495201e0218b78ab0a5e0b25eba4e88c", "title": "EuroCup2016 Video Download Script"}, "484": {"path": "/applications/FootballAction/datasets/EuroCup2016/download_dataset.sh:47-51", "hash": "f9fa392aa2eb9b762689268e36d7fcd8", "title": "Download EuroCup2016 Mp4 Files"}, "485": {"path": "/applications/FootballAction/datasets/EuroCup2016/url.list", "hash": "bb1facd61a3eb4355dd3d6337d4bb197", "title": "EuroCup2016 Video URLs"}, "486": {"path": "/applications/FootballAction/datasets/EuroCup2016/url.list:1-26", "hash": "e1be6b544ab601d7aa8905297b4700cc", "title": "FootballAction EuroCup2016 URL List"}, "487": {"path": "/applications/FootballAction/datasets/EuroCup2016/url.list:27-49", "hash": "9d36cb5bff5983fb8952bf3dd2d4015a", "title": "EuroCup2016: FootballAction URLs List"}, "488": {"path": "/applications/FootballAction/datasets/EuroCup2016/url_val.list", "hash": "f1d7e89584a2e3a4285416d8c451c3ac", "title": "Video URL List for EuroCup2016"}, "489": {"path": "/applications/FootballAction/datasets/script/get_frames_pcm.py", "hash": "6e0b648179bcd5e7381f6bc305dedeab", "title": "Parallel FFmpeg Frame and Audio Extraction"}, "490": {"path": "/applications/FootballAction/datasets/script/get_frames_pcm.py:1-37", "hash": "ae54f2492860b747b9e17fb1bd1bf41b", "title": "Extract Frames and PCM Audio from Videos"}, "491": {"path": "/applications/FootballAction/datasets/script/get_frames_pcm.py:38-54", "hash": "275d0148743fcd72733b248616d9d1d8", "title": "Multithreaded MP4 Parser"}, "492": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py", "hash": "d174cb10d11499853563d28f6f1461a5", "title": "BMN Instance Extraction Script"}, "493": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:1-42", "hash": "25a57faf4608a8eb4125a7e0c6d50799", "title": "BMN GT Data Processor Script"}, "494": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:43-69", "hash": "2527b815b98622d054660c79e1fd7e52", "title": "Filtering Actions by Duration"}, "495": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:70-102", "hash": "214a140b0cbfd131b40e760ca9e14b93", "title": "BMN Window GT Data Combination"}, "496": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:103-128", "hash": "40cc973185c3ace062f3791567482d27", "title": "Segmenting Actions with Before/After IDs"}, "497": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:129-147", "hash": "a5c44e165a0ba3c6bd04871066d90bce", "title": "Random Video Segment Selection and Annotation"}, "498": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:148-178", "hash": "471f28b72af5cc3c050cae4feb510e8b", "title": "Saving Features with get_instance_for_bmn"}, "499": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:180-205", "hash": "6cd433831e2d5ad7626b8f3cfa9c2527", "title": "Reshaping and Concatenating Feature Arrays"}, "500": {"path": "/applications/FootballAction/datasets/script/get_instance_for_bmn.py:206-216", "hash": "2c63d989df57d4f379f7017a3ba75cd6", "title": "BMN Data Processing Pipeline"}, "501": {"path": "/applications/FootballAction/datasets/script/get_instance_for_lstm.py", "hash": "9140430e67a018e62064e227f7e4bbdd", "title": "Python Script for Football Dataset Preparation"}, "502": {"path": "/applications/FootballAction/datasets/script/get_instance_for_lstm.py:1-44", "hash": "f0f822dbeefed5e1e973c5a36ae30b52", "title": "IoU/IOA Calculator for LSTM Models"}, "503": {"path": "/applications/FootballAction/datasets/script/get_instance_for_lstm.py:45-80", "hash": "eff5b98fa2a65c44cc1b52ca4a77d508", "title": "IoU and IOA Comparison Tool"}, "504": {"path": "/applications/FootballAction/datasets/script/get_instance_for_lstm.py:82-110", "hash": "c2bbcc3f0afca6a0a249fd40696c8b40", "title": "Evaluate Proposals with IoU Threshold"}, "505": {"path": "/applications/FootballAction/datasets/script/get_instance_for_lstm.py:111-130", "hash": "0617a4ade66a624a118fd92581972ac0", "title": "Splitting Datasets for Football Actions"}, "506": {"path": "/applications/FootballAction/datasets/script/get_instance_for_lstm.py:132-161", "hash": "65c502aa005d81df362a28b825cb1c2f", "title": "Save Video Features and Labels to Files"}, "507": {"path": "/applications/FootballAction/datasets/script/get_instance_for_lstm.py:162-172", "hash": "bc9d48111b50eaae4fbf7c4494d5af78", "title": "Label File Processing Script"}, "508": {"path": "/applications/FootballAction/datasets/script/get_instance_for_pptsm.py", "hash": "3d65c4c69e88ce5f4c898ff7a2b2a46b", "title": "Action Detection and Dataset Generation"}, "509": {"path": "/applications/FootballAction/datasets/script/get_instance_for_pptsm.py:1-38", "hash": "4a9682074e74e7e5b021dd3c15161c38", "title": "Action Instance Extractor"}, "510": {"path": "/applications/FootballAction/datasets/script/get_instance_for_pptsm.py:39-65", "hash": "5f9d63cf2e91deedba14d0ad18fa52ae", "title": "Generating Positive and Negative Action Instances"}, "511": {"path": "/applications/FootballAction/datasets/script/get_instance_for_pptsm.py:66-96", "hash": "7333c072491a2d6941e30bc022cdbfb2", "title": "Multiprocessing Dataset Instantiation and Saving"}, "512": {"path": "/applications/FootballAction/datasets/script/get_instance_for_pptsm.py:97-97", "hash": "a87ca59399a789be7fae7271eb403868", "title": "File Path for Validation List"}, "513": {"path": "/applications/FootballAction/extractor/extract_bmn.py", "hash": "1421dd6382d6576937e8817889a9fd01", "title": "Video Classification and Detection Script"}, "514": {"path": "/applications/FootballAction/extractor/extract_bmn.py:1-49", "hash": "32e16eb189525a8d15d6f382e45421e6", "title": "Video Classification Model with Baidu Cloud"}, "515": {"path": "/applications/FootballAction/extractor/extract_bmn.py:50-83", "hash": "379b349eca67273b8c5964e8d856441f", "title": "Video Feature Extraction and Proposal Prediction"}, "516": {"path": "/applications/FootballAction/extractor/extract_bmn.py:84-91", "hash": "9d7290753ea6dcf51c1dd547e516b221", "title": "JSON Proposal Saver"}, "517": {"path": "/applications/FootballAction/extractor/extract_feat.py", "hash": "7096dd6c857c10e67372da641f4deaa0", "title": "Baidu Cloud Model-based Video Classifier"}, "518": {"path": "/applications/FootballAction/extractor/extract_feat.py:1-50", "hash": "bbc23420dd38f741873595c954b3a2e1", "title": "Baidu Cloud Action Video Classifier"}, "519": {"path": "/applications/FootballAction/extractor/extract_feat.py:51-74", "hash": "3bf9e1c01cc935f95769c1636dd1aaaa", "title": "Video Feature Extraction and Conversion"}, "520": {"path": "/applications/FootballAction/extractor/extract_feat.py:75-100", "hash": "8a55605be9cda3c773f63f21f15c324e", "title": "Video Feature Extractor and Classifier"}, "521": {"path": "/applications/FootballAction/predict/action_detect/action.py", "hash": "da861500873f28133b4919691e06c839", "title": "Baidu Cloud Action Detection System using ML"}, "522": {"path": "/applications/FootballAction/predict/action_detect/action.py:1-44", "hash": "984eb62574574c129b35906e19149c52", "title": "Baidu Action Detection System"}, "523": {"path": "/applications/FootballAction/predict/action_detect/action.py:45-71", "hash": "072be86a09859c2accef331de0cfd1f3", "title": "Initialize ModelPredict Object"}, "524": {"path": "/applications/FootballAction/predict/action_detect/action.py:72-103", "hash": "70424839176ad576523e3d3bb96bf50d", "title": "Action Detection Model Initialization"}, "525": {"path": "/applications/FootballAction/predict/action_detect/action.py:104-132", "hash": "a322a71fb862149c692c3bdab4277bfb", "title": "Action Detection Methods and Tracking in Football"}, "526": {"path": "/applications/FootballAction/predict/action_detect/action.py:133-151", "hash": "d9e9fcee7351dbb147a1057a1d4a8fdb", "title": "Configure PPTSM Model and Predict Features"}, "527": {"path": "/applications/FootballAction/predict/action_detect/action.py:152-173", "hash": "06d3df5b0b2de41d2a2af2e14ae95c95", "title": "Video Feature Processing for Action Detection"}, "528": {"path": "/applications/FootballAction/predict/action_detect/logger.py", "hash": "96e8f1f7751ef922ea41922fca4c9f7b", "title": "Custom Logger for News Stripper"}, "529": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py", "hash": "a94bb4e20910e72134245d0b879cca1e", "title": "MFCC-based Action Detection in Football"}, "530": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py:1-38", "hash": "4702f0e8cf47583759f7482a6880437b", "title": "MFCC Feature Extraction Algorithm"}, "531": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py:39-69", "hash": "6f7f7d0d1b6a1c9e5432fb1212bf4421", "title": "Mel Scale Audio Feature Extraction"}, "532": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py:70-90", "hash": "3c30d5a8da69931833fc303f42f83b82", "title": "Extract MFCC Features from Speech Audio"}, "533": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py:91-111", "hash": "11ef8eb43f7eacbcd98e306593d4f1fb", "title": "Spectrogram Calculator Function"}, "534": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py:112-136", "hash": "125f6bdd50fa4941414901088de62bbf", "title": "MFCC-based Audio Feature Extraction"}, "535": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py:137-157", "hash": "ae10f74ac4269ca100f43f95778f849b", "title": "Audio Feature Extraction for Action Detection"}, "536": {"path": "/applications/FootballAction/predict/action_detect/mfcc/feature_extractor.py:159-182", "hash": "e5b7e273b3abb97ee7e0e6036cf0e7e4", "title": "Audio Feature Extraction from WAV Files"}, "537": {"path": "/applications/FootballAction/predict/action_detect/mfcc/model_config.py", "hash": "574c1392fd9221b3a4d9820af61e3c18", "title": "ModelAudio: Extract, Slice, Predict"}, "538": {"path": "/applications/FootballAction/predict/action_detect/mfcc/vgg_params.py", "hash": "48665dcb4614e556d4cc94b8dcd68918", "title": "VGGish Model Parameters and Configurations"}, "539": {"path": "/applications/FootballAction/predict/action_detect/models/audio_infer.py", "hash": "2bbeef0ddfde34d58b47dfeebfdec54c", "title": "Audio Inference with InferModel"}, "540": {"path": "/applications/FootballAction/predict/action_detect/models/bmn_infer.py", "hash": "074abbe2fbc626716f1de15c2a5a001c", "title": "BMN Infer Action Detection"}, "541": {"path": "/applications/FootballAction/predict/action_detect/models/bmn_infer.py:1-37", "hash": "93533251d93f9f2f9e570a281ef3305f", "title": "BMN Infer App Class Definition"}, "542": {"path": "/applications/FootballAction/predict/action_detect/models/bmn_infer.py:38-63", "hash": "e02d14513a02c9dfaadacc2737e827dd", "title": "BMN Inference Process"}, "543": {"path": "/applications/FootballAction/predict/action_detect/models/bmn_infer.py:64-86", "hash": "ca5814796e1ddd927c31d010d057d788", "title": "Boundary Score Calculator"}, "544": {"path": "/applications/FootballAction/predict/action_detect/models/bmn_infer.py:87-111", "hash": "3f94668e726f5bed6178e98f4dc56b2c", "title": "Boundary-Based Mask Selection"}, "545": {"path": "/applications/FootballAction/predict/action_detect/models/bmn_infer.py:112-131", "hash": "4fd27d7157428a1de80d44e9195c8aad", "title": "Average-Window Action Detection"}, "546": {"path": "/applications/FootballAction/predict/action_detect/models/bmn_infer.py:133-156", "hash": "30f8f60b188935444a6f41d26bf9abdb", "title": "BMN Inference & JSON Saving"}, "547": {"path": "/applications/FootballAction/predict/action_detect/models/lstm_infer.py", "hash": "fbacdaaf91a8cebc44fc38186c2d0a40", "title": "Efficient LSTM Football Action Prediction"}, "548": {"path": "/applications/FootballAction/predict/action_detect/models/lstm_infer.py:1-36", "hash": "37088191473f81e93a65076cf01be2f0", "title": "Football Action Inference with PaddlePaddle"}, "549": {"path": "/applications/FootballAction/predict/action_detect/models/lstm_infer.py:37-61", "hash": "df8f39306fb9a87cd744036be49f9d0b", "title": "LSTM Model for Video Action Detection"}, "550": {"path": "/applications/FootballAction/predict/action_detect/models/lstm_infer.py:62-91", "hash": "68f29a4db96714d062cab1d209d769cf", "title": "LSTM Data Processing and Prediction"}, "551": {"path": "/applications/FootballAction/predict/action_detect/models/lstm_infer.py:92-110", "hash": "d8ff49c3b7d4385715b5bde4c2dc8c1a", "title": "LSTM Inferencing for Action Detection"}, "552": {"path": "/applications/FootballAction/predict/action_detect/models/lstm_infer.py:111-137", "hash": "df1360af774442a97192ef01f3f42c30", "title": "Initialize InferModel and Load Data"}, "553": {"path": "/applications/FootballAction/predict/action_detect/models/lstm_infer.py:138-152", "hash": "4d1e3028252b2a7bc95356cae7d7bed7", "title": "Efficient Action Detection"}, "554": {"path": "/applications/FootballAction/predict/action_detect/models/pptsm_infer.py", "hash": "fe973f7c13dbb8712f0ed8dfdfd0a49f", "title": "PPTSM Inference for Football Actions"}, "555": {"path": "/applications/FootballAction/predict/action_detect/models/pptsm_infer.py:1-38", "hash": "3941d738fe47213a7847b236734ad5ef", "title": "PPTSM Model Inference Class"}, "556": {"path": "/applications/FootballAction/predict/action_detect/models/pptsm_infer.py:40-67", "hash": "201ea3bf16089c38227c0c806604b558", "title": "PPTSM Inference Script"}, "557": {"path": "/applications/FootballAction/predict/action_detect/models/pptsm_infer.py:69-78", "hash": "3e11a570095628a2f08feca8617dfed7", "title": "Football Action Prediction Model"}, "558": {"path": "/applications/FootballAction/predict/action_detect/reader/__init__.py", "hash": "2e9ec402585026301d4b3692fdd50115", "title": "Alphabetical Action Readers"}, "559": {"path": "/applications/FootballAction/predict/action_detect/reader/audio_reader.py", "hash": "0e3ba10a6e651c7cbe1d69febd61976f", "title": "AudioReader for YouTube-8M Dataset"}, "560": {"path": "/applications/FootballAction/predict/action_detect/reader/bmninf_reader.py", "hash": "94990484dcd22cd9fa9a1800fbd8510b", "title": "BMNINF Reader for Football Action Detection"}, "561": {"path": "/applications/FootballAction/predict/action_detect/reader/bmninf_reader.py:1-49", "hash": "1a3d2a196ebcaca92af9ec63fe6b406e", "title": "BMNINF Reader: FootballAction Data Reader"}, "562": {"path": "/applications/FootballAction/predict/action_detect/reader/bmninf_reader.py:50-73", "hash": "5c43cf56ba560576ffa4050c6838946a", "title": "Bmninf Reader Initialization"}, "563": {"path": "/applications/FootballAction/predict/action_detect/reader/bmninf_reader.py:74-105", "hash": "e66ec537f47dffe9fdb075285b22a99e", "title": "Football Action Detection Reader"}, "564": {"path": "/applications/FootballAction/predict/action_detect/reader/bmninf_reader.py:106-138", "hash": "10fb330de77f6bb66b7fd73a7832f810", "title": "BMNINF Reader Function"}, "565": {"path": "/applications/FootballAction/predict/action_detect/reader/bmninf_reader.py:139-155", "hash": "c35c1c7c108fd1aa616343b4316302cd", "title": "Video Batch Reader for Football Action Detection"}, "566": {"path": "/applications/FootballAction/predict/action_detect/reader/feature_reader.py", "hash": "c2f3c29ec55adda10774455c82248fcd", "title": "Attention-Based LSTM Feature Reader"}, "567": {"path": "/applications/FootballAction/predict/action_detect/reader/feature_reader.py:1-33", "hash": "35c4c2542af117ce89f91cdce150b3f1", "title": "Attention-Based LSTM Feature Reader"}, "568": {"path": "/applications/FootballAction/predict/action_detect/reader/feature_reader.py:35-71", "hash": "973807570f9f8f9b17ff0b08418255be", "title": "Feature Reader Initialization"}, "569": {"path": "/applications/FootballAction/predict/action_detect/reader/feature_reader.py:72-86", "hash": "cbae92eefcffc03da619a285959bff2a", "title": "Multi-Feature Reader"}, "570": {"path": "/applications/FootballAction/predict/action_detect/reader/reader_utils.py", "hash": "ccf03df124e3510d96b3843769ada5b9", "title": "Video Reader Utils"}, "571": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py", "hash": "18ba7580b69661263367fe31df6e5fab", "title": "Threaded TSMINF Reader for Football Action Detection"}, "572": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:1-38", "hash": "4950e12ccb918c5ab75fc7fbd61a11c3", "title": "TSMINF Video Reader Class"}, "573": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:39-64", "hash": "e18d87ba3b935cf217f111f9a1235482", "title": "TSN Video Reader Initialization"}, "574": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:65-97", "hash": "b1cae6f53bc63019d79612de6dcc0396", "title": "Video Image Batch Reader for Inference"}, "575": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:98-119", "hash": "d4451cae9992a1e798a333db51ba8e0d", "title": "Multithreaded Video Image Reader"}, "576": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:120-141", "hash": "43d1ef51e6f44af23ca3edb01890f8f4", "title": "Image Data Inference and Transformation"}, "577": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:143-180", "hash": "d7e15106eb6f6907852b266d62166029", "title": "Image Transformation Function"}, "578": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:181-212", "hash": "e5364ca93e2129bd700f6464651526b3", "title": "Image Preprocessing for Football Action Detection"}, "579": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:213-242", "hash": "76b6b9384a581dc488f52b35fd8954cd", "title": "Random Crop with Offset Adjustment"}, "580": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:243-267", "hash": "aa4895f28ce2e1c239791459c6b535be", "title": "Random Crop Sizes for Action Detection"}, "581": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:268-307", "hash": "c4ee2e9e162fcfc049a99e74c38c0e2c", "title": "Image Processing Functions"}, "582": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:308-349", "hash": "75ae96c497211c416c7fe36f380f93cc", "title": "Image Group Manipulation Techniques"}, "583": {"path": "/applications/FootballAction/predict/action_detect/reader/tsminf_reader.py:350-357", "hash": "7aef93cb28b42c72e85fc57a303271f1", "title": "Adaptive Image Resizer"}, "584": {"path": "/applications/FootballAction/predict/action_detect/utils/config_utils.py", "hash": "68c51c32b69a155437b9003c02f6ba68", "title": "Config Utils for Basketball Action"}, "585": {"path": "/applications/FootballAction/predict/action_detect/utils/preprocess.py", "hash": "43307e52ad097b996f3fbd921f6362c7", "title": "FFmpeg Tools for Video Processing"}, "586": {"path": "/applications/FootballAction/predict/action_detect/utils/process_result.py", "hash": "65fe1acf9920ac04515c18bdff134a95", "title": "Action Detection with NMS Filtering"}, "587": {"path": "/applications/FootballAction/predict/eval.py", "hash": "b9872952f5e2c00ca322fafd868bd2a0", "title": "Evaluating Model Performance with F1 Scores"}, "588": {"path": "/applications/FootballAction/predict/eval.py:1-36", "hash": "0b162a0b85b76a232c7b693f5996ed1a", "title": "Initializing Ground Truth Data"}, "589": {"path": "/applications/FootballAction/predict/eval.py:37-67", "hash": "98a3561696ac97ae087ab1e41b0e8e55", "title": "IoU and Proposal Conversion Functions"}, "590": {"path": "/applications/FootballAction/predict/eval.py:68-93", "hash": "dc773e8134c36b6970c18ab9859a4ee0", "title": "Filtered Boxes and Ground Truth Conversion"}, "591": {"path": "/applications/FootballAction/predict/eval.py:94-120", "hash": "807d0d5b53780df588c1d4b2aa9c2f26", "title": "Intersection over Union Evaluation Functions"}, "592": {"path": "/applications/FootballAction/predict/eval.py:121-144", "hash": "a380ce3a5d2738fae8c3785d6e702c9f", "title": "Box IOU Evaluator"}, "593": {"path": "/applications/FootballAction/predict/eval.py:146-161", "hash": "19a874157d39640795ab03fe57f09ebc", "title": "Subtask Precision and Recall Calculator"}, "594": {"path": "/applications/FootballAction/predict/eval.py:162-189", "hash": "66b59a8ce7170653b7d82a2cbc40df5d", "title": "FootballAction Prediction Evaluation"}, "595": {"path": "/applications/FootballAction/predict/eval.py:190-218", "hash": "f1c73de3f672b56e952d485317c4400c", "title": "Football Action Prediction Evaluation"}, "596": {"path": "/applications/FootballAction/predict/eval.py:219-237", "hash": "c6ca29857b7ff4eec2eebd96d02a7ef0", "title": "Optimal Threshold Selection"}, "597": {"path": "/applications/FootballAction/predict/predict.py", "hash": "539db312ace0ff2bbfbb0194db289e3f", "title": "Football Action Detection Model Prediction"}, "598": {"path": "/applications/FootballAction/predict/predict.py:1-33", "hash": "8deae072592ee40b516d571f03592666", "title": "Video Action Detection Script"}, "599": {"path": "/applications/FootballAction/predict/predict.py:35-37", "hash": "a9de60b87f9374cf2472d46b2790060d", "title": "JSON Data Output in FootballAction App"}, "600": {"path": "/applications/Ma-Net/README.md", "hash": "0dc4dc4d62f327af9afaf9aa6660ea52", "title": "MA-Net Model for PaddleVideo: DAVIS Dataset Training & Testing"}, "601": {"path": "/applications/Ma-Net/README.md:1-35", "hash": "22b1caf0f175e1d57e9bcadcbf86e85d", "title": "Ma-Net: PaddleVideo's CVPR2020 Implementation"}, "602": {"path": "/applications/Ma-Net/README.md:36-47", "hash": "a5bd787f8fe9f67d7cb41587a222a019", "title": "Run Local Environment Script"}, "603": {"path": "/applications/Ma-Net/README_cn.md", "hash": "4c89171284b6d939068c7b29bc254be7", "title": "Ma-Net\u89c6\u9891\u5206\u5272\u5b9e\u73b0README\uff08\u4e2d\u6587\uff09"}, "604": {"path": "/applications/Ma-Net/config.py", "hash": "63a2c4750a344716b5ed6aa8b7ded441", "title": "Ma-Net Training Setup"}, "605": {"path": "/applications/Ma-Net/config.py:1-32", "hash": "8ed0e8a910135fa0f36f713144080335", "title": "Configuring Ma-Net Parameters"}, "606": {"path": "/applications/Ma-Net/config.py:33-53", "hash": "ae8a0dcb0a3418ddb210c1c67ec12449", "title": "Ma-Net App Config: CLI Arguments"}, "607": {"path": "/applications/Ma-Net/config.py:54-70", "hash": "b028e9662b9f3807ab6db495ead83ba7", "title": "Ma-Net Model Configuration"}, "608": {"path": "/applications/Ma-Net/config.py:71-88", "hash": "a1e34cdaf0e229a7825e04cbcdbaa43c", "title": "Ma-Net Configuration Arguments"}, "609": {"path": "/applications/Ma-Net/config.py:90-96", "hash": "6608ff432d1c0f6939611ff392b2caad", "title": "Default Initialization and Epoch Calculation"}, "610": {"path": "/applications/Ma-Net/dataloaders/DAVIS2017.md", "hash": "fcb159f0202407b0caf3aad997120a17", "title": "DAVIS2017 Dataset Download and Setup"}, "611": {"path": "/applications/Ma-Net/dataloaders/DAVIS2017_cn.md", "hash": "d598ccf7846d8f4583261e89ae6cb9b9", "title": "DAVIS2017 Dataset for Ma-Net"}, "612": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py", "hash": "939e5106072b53132c7bf7ecf67ae3e7", "title": "Data Augmentation for Video Object Detection"}, "613": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:1-35", "hash": "5c2918cc3f6bcb44d728123acd889c34", "title": "Uniform Image Rescaling Class"}, "614": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:36-69", "hash": "379e1036aa45e9ec94f812a0baace987", "title": "Custom Image Resizer Transform"}, "615": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:70-98", "hash": "7b17a7865d7dce72a15ad74ebb0f12c1", "title": "Random Crop with Sufficient Scribble Elements"}, "616": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:99-124", "hash": "35daee6d99f89f9b098f29306a606cf2", "title": "Adaptive Image Crop and Resize"}, "617": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:125-154", "hash": "bb49e55ef2af5a38574bf039345ad703", "title": "ScaleNRotate Class for Image Transformations"}, "618": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:155-189", "hash": "d2ca0a7a4f7f9e8d9ae01eae9dbfae1b", "title": "Random Scaling, Rotation, and Warping Transform"}, "619": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:191-229", "hash": "b5d77348b56c539d96ff2e7bf34d46b4", "title": "Data Augmentation Techniques in Ma-Net"}, "620": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:230-261", "hash": "806db4bdd000d17dbc4c29d8260cdd54", "title": "Normalizing and Initializing Custom Scribble Interaction"}, "621": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:262-288", "hash": "6c4f6c5b6a987aa5c54e91d2f02cf115", "title": "Scribble Segmentation with Bresenham"}, "622": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:289-310", "hash": "00e83f9c9497142282bb26a4258fee51", "title": "Generating GT Masks from Scribbles"}, "623": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:312-330", "hash": "1de53d16668d5c5fd856128f624a1e57", "title": "Dilated Mask Annotation Rounds Computation"}, "624": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:331-366", "hash": "88fa76756e9b32749797bda75d7c8d7b", "title": "Ma-Net Data Loader: Video OD Transform"}, "625": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:369-405", "hash": "9aaa44844bc81136e43bb0aa6f2235c3", "title": "Edge Mask Generation in Ma-Net Dataloader"}, "626": {"path": "/applications/Ma-Net/dataloaders/custom_transforms_f.py:406-416", "hash": "8a32cb59d81252860b49b25fff0f3711", "title": "Edge Mask Creation with Parsing Mask"}, "627": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py", "hash": "48b31ebafce84da9d9ffb2870aff5a31", "title": "DAVIS 2017 Dataset Preprocessing for Ma-Net"}, "628": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:1-40", "hash": "2962f6f6efe372f67df5d84bed63c3c2", "title": "DAVIS 2017 Test Data Manager"}, "629": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:41-73", "hash": "6f8d0b1031a2844e08d76017cfcac629", "title": "DAVIS2017 Dataset Initialization and Loading"}, "630": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:74-109", "hash": "1c72174a11406b3de332e071743dc269", "title": "DAVIS 2017 Semantic Segmentation Dataset Loader"}, "631": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:110-135", "hash": "cd9c32e99664a5ab42737662ee90f19d", "title": "File Sequence Extension and Preprocessing"}, "632": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:136-161", "hash": "7aa24bf7b8c447885a9404ce7a084d11", "title": "DAVIS 2017 Dataset Loader Code"}, "633": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:162-186", "hash": "ba43d8c73440ab039025d8bae5115593", "title": "Load Images and Labels from Path"}, "634": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:187-219", "hash": "1213e21ca52bd8e79310e97131be7976", "title": "DAVIS 2017 Video Object Detection Data Loader"}, "635": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:220-244", "hash": "175629ca418f24b5d3ccfa222cae2347", "title": "DAVIS2017 Mask Reader and Dictionary Creation"}, "636": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:246-273", "hash": "72769adb701783caf462b01550f83010", "title": "DAVIS 2017 Data Loader Initiation"}, "637": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:274-299", "hash": "e92da0b53cb83095d5488c826eb42c2e", "title": "DAVIS 2017 Dataset Loader"}, "638": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:300-320", "hash": "8acf622ba48e80bdf1174f76c06fbd06", "title": "Davis Frame Processing: Loader"}, "639": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:322-344", "hash": "1c53d5272ad02591be7da5f9c751c6dc", "title": "Random Scribble Label Assigner"}, "640": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:345-374", "hash": "155e6e5b88e9797468d5789be8085ab1", "title": "Image Dataloader and Transform"}, "641": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:375-400", "hash": "059d8b0fbc6d1046d33aff4d6a6b3998", "title": "Data Loading Function for Sequence Lists"}, "642": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:401-431", "hash": "ade6c45bc1f2a7a0dfba94599cc552cf", "title": "DAVIS 2017 Dataset Class Definition"}, "643": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:432-456", "hash": "768628968a8ae2f6393b1364886cb057", "title": "DAVIS Dataset Custom Dataloader"}, "644": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:457-485", "hash": "6eda4f5bd481ee22cb071feb3638195b", "title": "Custom Dataloader for Adjacent Frames"}, "645": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:486-506", "hash": "8f48daf95ff5f389b75c3d7aef200969", "title": "Loading Data for Video Sequences"}, "646": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:507-531", "hash": "e4f039961d76f8399995d5a22abb3f8b", "title": "Preparing DAVIS Dataset for Model"}, "647": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:532-562", "hash": "24549bff32e80e6a9673e2f5f8db6569", "title": "Ma-Net Dataset Creator"}, "648": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:563-585", "hash": "dc9bfcab1edfa0fbc926c593cb12bae9", "title": "Update Frame and Scribble Masks in Dataset"}, "649": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:586-610", "hash": "f5bffd0bcd7d3db3ea126d17260facad", "title": "Random JSON Label Dataset Initialization"}, "650": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:611-633", "hash": "fc65f22d21c6992414fe2ed126c01a03", "title": "JSON Parsing and Image Loading"}, "651": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:634-662", "hash": "7928ed8111a86cc9efc8b92d97daf7b0", "title": "Validate Sequence Existence and Preprocess Data"}, "652": {"path": "/applications/Ma-Net/dataloaders/davis_2017_f.py:664-672", "hash": "ddcc60af1aedbea8a052627351b8b66e", "title": "JSON Dataset Preprocessing"}, "653": {"path": "/applications/Ma-Net/dataloaders/helpers.py", "hash": "38ab4b8ec523d174f97e52db60013d3e", "title": "Functions for Tensor to Image Conversion and Model Naming"}, "654": {"path": "/applications/Ma-Net/dataloaders/helpers.py:1-46", "hash": "142ec8018b50a2a1ca6498f5badfcb75", "title": "Image Processing Helpers"}, "655": {"path": "/applications/Ma-Net/dataloaders/helpers.py:47-78", "hash": "6c6dc5678e52ee34c03d2a4c0686fbb5", "title": "Model Name Construction and Image Computation Functions"}, "656": {"path": "/applications/Ma-Net/dataloaders/helpers.py:79-81", "hash": "2fc384721c1d4a164aa142cf0a7c30c3", "title": "Enhancing Background with Dilation"}, "657": {"path": "/applications/Ma-Net/dataloaders/samplers.py", "hash": "36c2d97eb1924090f6b087bd256b1a52", "title": "Random Identity Sampler"}, "658": {"path": "/applications/Ma-Net/dataloaders/samplers.py:1-31", "hash": "d1c35953495bdfe7d9abe8395bcfc4b5", "title": "RandomIdentitySampler Class"}, "659": {"path": "/applications/Ma-Net/dataloaders/samplers.py:32-42", "hash": "7c529cae4f9478f861aefcdf8b4a4e4d", "title": "Random Identity Sampler"}, "660": {"path": "/applications/Ma-Net/networks/IntVOS.py", "hash": "3a31fc79235278686ae17f80b652acf8", "title": "Ma-Net: IntVOS Video Segmentation"}, "661": {"path": "/applications/Ma-Net/networks/IntVOS.py:1-42", "hash": "43a41ad08d57a9b71fc51a97e1929912", "title": "Pairwise Distance Calculation in PaddlePaddle Video OD"}, "662": {"path": "/applications/Ma-Net/networks/IntVOS.py:43-65", "hash": "9a08b50b2a3e2d7e98575a60ae8bb983", "title": "Pairwise Distance Calculator"}, "663": {"path": "/applications/Ma-Net/networks/IntVOS.py:66-88", "hash": "3d4f55183bea542fc232c920ac012f48", "title": "K-Nearest Neighbor Search with Padding Distance"}, "664": {"path": "/applications/Ma-Net/networks/IntVOS.py:89-118", "hash": "aaa3908937c802deec5790c9388258bc", "title": "Nearest Neighbor Feature Calculation"}, "665": {"path": "/applications/Ma-Net/networks/IntVOS.py:119-141", "hash": "eaec7f06570612fd5504d7403809dff8", "title": "KNN Search with Chunking"}, "666": {"path": "/applications/Ma-Net/networks/IntVOS.py:142-169", "hash": "c10b8548627d50bc5b987075c012d2a0", "title": "Nearest Neighbor Feature Computation"}, "667": {"path": "/applications/Ma-Net/networks/IntVOS.py:170-186", "hash": "d4ce4ef70dbbb7481d270e5d88ce437c", "title": "Nearest Neighbor Distance Calculation"}, "668": {"path": "/applications/Ma-Net/networks/IntVOS.py:187-211", "hash": "9c9c4e9c1c247396611bf6fd11145c8d", "title": "Nearest Neighbor Features Calculation"}, "669": {"path": "/applications/Ma-Net/networks/IntVOS.py:212-235", "hash": "2fdde311dff5841bbec258b2416f2370", "title": "Local Neighbor Feature Extraction"}, "670": {"path": "/applications/Ma-Net/networks/IntVOS.py:236-261", "hash": "a2d854d9b7142f88923ae93e07c94c4f", "title": "Boundary-Cross Correlation Sigmoid Transpose"}, "671": {"path": "/applications/Ma-Net/networks/IntVOS.py:262-287", "hash": "21e18da7422427208eb1be0a5807bef1", "title": "Pairwise L2 Distances Calculator"}, "672": {"path": "/applications/Ma-Net/networks/IntVOS.py:288-312", "hash": "09fdc574d2599aff4cbd641e0e440697", "title": "Local Downsampling in IntVOS Network"}, "673": {"path": "/applications/Ma-Net/networks/IntVOS.py:313-336", "hash": "a98d7ac77d2a9f0f16f9066ec914cde7", "title": "Sliding Window Distance Calculator"}, "674": {"path": "/applications/Ma-Net/networks/IntVOS.py:337-365", "hash": "4373b023efc7bf4ded4b24f80cb97289", "title": "Spatial Cross-Correlation Sampler"}, "675": {"path": "/applications/Ma-Net/networks/IntVOS.py:366-392", "hash": "651c7ccc6205fa488216a61f9895a3d2", "title": "IntVOS Nearest Neighbor Compute Function"}, "676": {"path": "/applications/Ma-Net/networks/IntVOS.py:393-421", "hash": "fab803b3c9bdd07c41bdcef419551c1c", "title": "Nearest Neighbor Feature Calculation"}, "677": {"path": "/applications/Ma-Net/networks/IntVOS.py:422-454", "hash": "3ff95cae963d0bb52b6a9cebb3fcef16", "title": "Offset Masks and Distance Tensor Calculation"}, "678": {"path": "/applications/Ma-Net/networks/IntVOS.py:455-486", "hash": "e4ad751bbdd23af02a04997f8124aef9", "title": "Residual Block and Segmentation Head for Ma-Net"}, "679": {"path": "/applications/Ma-Net/networks/IntVOS.py:487-513", "hash": "2964406da926ef7a3ad02f9dba987195", "title": "IntSegHead: Segmentation Neural Network"}, "680": {"path": "/applications/Ma-Net/networks/IntVOS.py:516-537", "hash": "41c3ec80601615667bd9a089a4c0cd40", "title": "Separable Conv Layer with BatchNorm"}, "681": {"path": "/applications/Ma-Net/networks/IntVOS.py:538-571", "hash": "96ce05d3220f3a23049e21f1cb5f57ab", "title": "Dynamic Segmentation Heads"}, "682": {"path": "/applications/Ma-Net/networks/IntVOS.py:572-589", "hash": "977f598e2315daa24449b19fc755040e", "title": "Initializing Network Architecture Components"}, "683": {"path": "/applications/Ma-Net/networks/IntVOS.py:590-616", "hash": "eb7c95488e93f7f93abfb0fc9471fce9", "title": "Dynamic Segmentation Network Forward Pass"}, "684": {"path": "/applications/Ma-Net/networks/IntVOS.py:617-640", "hash": "f32679e2da61875580ef48fc3a350c45", "title": "Splitting Input, Calling prop_seghead"}, "685": {"path": "/applications/Ma-Net/networks/IntVOS.py:641-664", "hash": "4a37273d727f36170a5612b93cc5b34e", "title": "IntVOS Feature Extraction"}, "686": {"path": "/applications/Ma-Net/networks/IntVOS.py:665-685", "hash": "5b6e12ed617174d762b12991c88d48da", "title": "Interpolated Feature Embedding Extraction"}, "687": {"path": "/applications/Ma-Net/networks/IntVOS.py:686-704", "hash": "f41da18327a4abfe5e54d326106cabb2", "title": "Extracting Nearest Neighbors per Object"}, "688": {"path": "/applications/Ma-Net/networks/IntVOS.py:705-725", "hash": "75a88d4e83697897913e29c9c73c2767", "title": "Check and Update Global Map Embedding"}, "689": {"path": "/applications/Ma-Net/networks/IntVOS.py:726-745", "hash": "8657707ed963d6421016b34d4681f12d", "title": "Nearest Neighbor Feature Extraction for Video Sequences"}, "690": {"path": "/applications/Ma-Net/networks/IntVOS.py:746-764", "hash": "bef6e06e1da1c905345291b8877e5f40", "title": "Sequence Map Initialization and Updating"}, "691": {"path": "/applications/Ma-Net/networks/IntVOS.py:765-781", "hash": "1d06721b43c607a7d85dd68c35012246", "title": "Updating Previous Frame Features"}, "692": {"path": "/applications/Ma-Net/networks/IntVOS.py:782-803", "hash": "e6c8e1590f63d521fcee2dd2c7d222f3", "title": "Frame Feature Handling and Concatenation"}, "693": {"path": "/applications/Ma-Net/networks/IntVOS.py:804-829", "hash": "f3a882a1a72e0d2e791f555e2ffe718a", "title": "int_seghead Function Overview"}, "694": {"path": "/applications/Ma-Net/networks/IntVOS.py:830-853", "hash": "8f7d19c24c8283958d083a056d5c93cf", "title": "Interpolating Ma-Net Scribble Labels"}, "695": {"path": "/applications/Ma-Net/networks/IntVOS.py:854-877", "hash": "321cee970fec50aed86d8f36aea7cb93", "title": "Updating Global and Local Maps: IntVOS.py:854-877"}, "696": {"path": "/applications/Ma-Net/networks/IntVOS.py:878-897", "hash": "81298636241d5f2c0eba48c75425be79", "title": "Updating Distance and Temporary Dictionaries"}, "697": {"path": "/applications/Ma-Net/networks/IntVOS.py:898-921", "hash": "69fb417002a72eaf96d503fca7abf356", "title": "Tensor Operations for Segmentation Model"}, "698": {"path": "/applications/Ma-Net/networks/IntVOS.py:922-927", "hash": "f9305043d0784e17c5cf7c2836e8a5b1", "title": "Transposing Tensor and Storing in Dictionary"}, "699": {"path": "/applications/Ma-Net/networks/aspp.py", "hash": "9622cd5ecf9845613b8a6820a5167685", "title": "ASPP Module: ASPP Pyramid Pooling in Ma-Net"}, "700": {"path": "/applications/Ma-Net/networks/aspp.py:1-34", "hash": "f18da07329fb0ddd3c0da8930ec49c18", "title": "ASPP Module: Hierarchical Atrous Spatial Pooling"}, "701": {"path": "/applications/Ma-Net/networks/aspp.py:35-66", "hash": "fe91812a5d883b336acf9fd0d82502c4", "title": "ASPP Class: Building ASPP Network Modules"}, "702": {"path": "/applications/Ma-Net/networks/aspp.py:67-89", "hash": "af51ba4f90eb39433ca8ebf426f40689", "title": "ASPP Modules and Global Average Pooling Layer"}, "703": {"path": "/applications/Ma-Net/networks/aspp.py:90-123", "hash": "48cf61350c8f02a6a57d8e1742239263", "title": "ASPP Module in Ma-Net's CNN"}, "704": {"path": "/applications/Ma-Net/networks/backbone/__init__.py", "hash": "a7d7a1afe9ec012da61c08865efe6a9c", "title": "Build Backbone Networks"}, "705": {"path": "/applications/Ma-Net/networks/backbone/drn.py", "hash": "f32cbebd4a86d78e14dfa736f20cf3c4", "title": "Deep Residual Networks in PaddlePaddle"}, "706": {"path": "/applications/Ma-Net/networks/backbone/drn.py:1-29", "hash": "89b8d61ba199725a4d03988187bf968b", "title": "BasicBlock Class in DRN Network"}, "707": {"path": "/applications/Ma-Net/networks/backbone/drn.py:30-65", "hash": "2d2a04112254cf6396ea28649f0f04cd", "title": "Residual Bottleneck Block"}, "708": {"path": "/applications/Ma-Net/networks/backbone/drn.py:66-103", "hash": "26c397b15152e9ada951da5051411a6e", "title": "Deep Residual Network Model"}, "709": {"path": "/applications/Ma-Net/networks/backbone/drn.py:104-130", "hash": "6690a3c70872b867edd2139e9ad9d043", "title": "DRN Network: Convolutional and Pooling Architecture"}, "710": {"path": "/applications/Ma-Net/networks/backbone/drn.py:131-147", "hash": "d9cdf9306ef9b0e0bf9dba34b29459dc", "title": "DRN Network Architecture"}, "711": {"path": "/applications/Ma-Net/networks/backbone/drn.py:148-170", "hash": "dad11caae23d12f51595b63b7cdad987", "title": "Defining MA-Net Backbone Layers"}, "712": {"path": "/applications/Ma-Net/networks/backbone/drn.py:171-193", "hash": "8dd84cf2b79d8d1ee3d5b52271bddccc", "title": "DRN Network Layer Construction"}, "713": {"path": "/applications/Ma-Net/networks/backbone/drn.py:194-234", "hash": "25dc28a76fee2ba8f0434b17cac0fcbc", "title": "Deep Residual Network Backbone Architecture"}, "714": {"path": "/applications/Ma-Net/networks/backbone/drn.py:236-257", "hash": "1d2eb445bf7f2169482e257ae9f5b328", "title": "DRN_A Class in Ma-Net Backbone"}, "715": {"path": "/applications/Ma-Net/networks/backbone/drn.py:258-279", "hash": "be9ef2810371f8b6061b22ea67b90345", "title": "Creating Layers with _make_layer"}, "716": {"path": "/applications/Ma-Net/networks/backbone/drn.py:281-318", "hash": "d1540d45bbe54885fe7d03045e6b30c9", "title": "DRN Model Functions in Ma-Net Backbone"}, "717": {"path": "/applications/Ma-Net/networks/backbone/drn.py:319-349", "hash": "bb2ece4f4af3fcf7b183b162cddb07ea", "title": "Initializing DRN Models with Pre-Trained Weights"}, "718": {"path": "/applications/Ma-Net/networks/backbone/drn.py:350-380", "hash": "2a868812d7c9d580e1c6e715c6ea7afe", "title": "DRN Model Functions with Configurations"}, "719": {"path": "/applications/Ma-Net/networks/backbone/drn.py:381-400", "hash": "da54ad7145df89ecee74435fe836448b", "title": "DRN Model Definition and Pretrained Weights Loading"}, "720": {"path": "/applications/Ma-Net/networks/backbone/mobilenet.py", "hash": "b606be608209605b950c4f7951683a7e", "title": "Ma-Net: MobileNetV2 Backbone Initialization"}, "721": {"path": "/applications/Ma-Net/networks/backbone/mobilenet.py:1-33", "hash": "f62d8a613ef221fc319bbb8d24f8374a", "title": "MobileNet Network Layer Definition"}, "722": {"path": "/applications/Ma-Net/networks/backbone/mobilenet.py:34-63", "hash": "122b5ec131a8e897234696b8684a4728", "title": "MobileNet Layer Creation: Convolutional Neural Network"}, "723": {"path": "/applications/Ma-Net/networks/backbone/mobilenet.py:64-99", "hash": "94186a29945773d9163836a4459a2c10", "title": "MobileNetV2 Model Definition"}, "724": {"path": "/applications/Ma-Net/networks/backbone/mobilenet.py:100-127", "hash": "f35590688a5cbc54028f96b3ba8ba9d3", "title": "MobileNet Backbone for Ma-Net Application"}, "725": {"path": "/applications/Ma-Net/networks/backbone/mobilenet.py:128-157", "hash": "8c0d376cb63e8adc7786392ce73d4c43", "title": "Preparing MobileNet Backbone for Feature Extraction"}, "726": {"path": "/applications/Ma-Net/networks/backbone/mobilenet.py:158-163", "hash": "25d0aeadb7074681a6660d6b001f7966", "title": "Kaiming Normal Init and Batch Norm for Mobilenet"}, "727": {"path": "/applications/Ma-Net/networks/backbone/resnet.py", "hash": "f6e7c78b6ad96a9082e078d9e6eb972b", "title": "ResNet Architecture with Batch Normalization"}, "728": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:1-33", "hash": "1c02f22c10061ae7cdd2962741d64578", "title": "Bottleneck ResNet Backbone Definition"}, "729": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:34-77", "hash": "f1c356add7fb708d4e2ab157793d7b55", "title": "ResNet Architecture Design: BatchNorm, ReLU, Downsample"}, "730": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:78-103", "hash": "033fa26cc28140fa405df14f9ba8ddb0", "title": "Initializing ResNet Backbone: Conv, BN, Pool and Residual Blocks"}, "731": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:104-126", "hash": "418fe45f6c6e672e7999b23dc5b694d8", "title": "ResNet Network with Batch Normalization"}, "732": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:127-157", "hash": "4374b62e3deab7486c5b2d17237e43cc", "title": "ResNet Block Builder Function"}, "733": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:158-186", "hash": "d90194e7e7bc9f1d9a7ea1ae45c82de3", "title": "ResNet Residual Block Builder"}, "734": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:187-220", "hash": "bcb684d0feb36f5e7a4b280363fae55d", "title": "ResNet Network Definition"}, "735": {"path": "/applications/Ma-Net/networks/backbone/resnet.py:221-239", "hash": "c48ee841adb570a9769ad9afac171cf8", "title": "ResNet-101 Model Function"}, "736": {"path": "/applications/Ma-Net/networks/backbone/xception.py", "hash": "ae099b01b6bdebe8213abd6f3bda9559", "title": "AlignedXception Backbone for Image Classification"}, "737": {"path": "/applications/Ma-Net/networks/backbone/xception.py:1-34", "hash": "3eedc32a8db453647da523049e6e6cf1", "title": "Separable Conv Layer with BatchNorm"}, "738": {"path": "/applications/Ma-Net/networks/backbone/xception.py:35-67", "hash": "31dac4fba0728fd3ff28d1bb1af111c2", "title": "Xception Block Layer Initialization and Forward"}, "739": {"path": "/applications/Ma-Net/networks/backbone/xception.py:68-102", "hash": "08373364db83049baaadf56b5e24fa20", "title": "Xception Backbone Network Creation"}, "740": {"path": "/applications/Ma-Net/networks/backbone/xception.py:103-144", "hash": "ee651b0a058221818dc6a37059179db1", "title": "AlignedXception Network Code"}, "741": {"path": "/applications/Ma-Net/networks/backbone/xception.py:145-175", "hash": "25816d18822d3d183d508fc3a648df8c", "title": "AlignedXception Initialization Code"}, "742": {"path": "/applications/Ma-Net/networks/backbone/xception.py:176-201", "hash": "ce6159c58644571350d2f6f4918c6731", "title": "Xception Backbone: Block Architecture"}, "743": {"path": "/applications/Ma-Net/networks/backbone/xception.py:202-225", "hash": "52c3834ac3320265499f871b63282c13", "title": "Xception Block Creation and Implementation"}, "744": {"path": "/applications/Ma-Net/networks/backbone/xception.py:226-249", "hash": "db6251f7273f955033b2d03cc360fc89", "title": "Repeated Convolutions and Batch Normalization in Xception"}, "745": {"path": "/applications/Ma-Net/networks/backbone/xception.py:250-273", "hash": "2ab2edf28a83e785b91046b8a5971ca1", "title": "Xception Convolutions and Block Initialization"}, "746": {"path": "/applications/Ma-Net/networks/backbone/xception.py:274-297", "hash": "2d9a36f922db7206c9130a3278fa65bc", "title": "Xception Blocks in Ma-Net's Image Classification"}, "747": {"path": "/applications/Ma-Net/networks/backbone/xception.py:298-323", "hash": "fb992dacdfa26e5d8dccd6f666f470ed", "title": "Xception Block Configurations"}, "748": {"path": "/applications/Ma-Net/networks/backbone/xception.py:324-348", "hash": "255f0eea67b6e6a94acc67c95e7320c3", "title": "Xception: Separable Conv Layers"}, "749": {"path": "/applications/Ma-Net/networks/backbone/xception.py:349-390", "hash": "5dc5096965651dfbbecae6e11743f4ac", "title": "Xception Network Architecture"}, "750": {"path": "/applications/Ma-Net/networks/backbone/xception.py:391-427", "hash": "4d5f6796cba8273ef56c252d9bb03e5a", "title": "Xception Model: Neural Network for Image Classification"}, "751": {"path": "/applications/Ma-Net/networks/backbone/xception.py:429-447", "hash": "5f6f126f4ea0557a37ee9345fcb6f748", "title": "Updating Pre-trained Xception Model Weights"}, "752": {"path": "/applications/Ma-Net/networks/backbone/xception.py:448-455", "hash": "a68680e7662b63dd2bfcb6910b148b71", "title": "Renaming Conv and BN Parameters"}, "753": {"path": "/applications/Ma-Net/networks/decoder.py", "hash": "ed74fcfb39997669136e6a4fcc6cb011", "title": "Decoder Network Construction"}, "754": {"path": "/applications/Ma-Net/networks/decoder.py:1-32", "hash": "2526014e4bbe8e9cf34cca4db5ed423e", "title": "Decoder Layer for Feature Classification"}, "755": {"path": "/applications/Ma-Net/networks/decoder.py:33-62", "hash": "0aa76fd43ce935081179c02c1125296b", "title": "Decoder Network Architecture"}, "756": {"path": "/applications/Ma-Net/networks/decoder.py:65-66", "hash": "809d980da27ef420a28de0b2a333e562", "title": "Build Decoder Network Function"}, "757": {"path": "/applications/Ma-Net/networks/deeplab.py", "hash": "090bd2225f11dfb59b1ecbb10813584f", "title": "Freezing Batch Norm Layers in DeepLab"}, "758": {"path": "/applications/Ma-Net/networks/deeplab.py:1-31", "hash": "7312d7a1473d01731f9e93b6f4d10719", "title": "Frozen Batch Normalization for DeepLab"}, "759": {"path": "/applications/Ma-Net/networks/deeplab.py:32-64", "hash": "d87dce98aab0fd2a15106b799bc2eec0", "title": "DeepLab Class Definition"}, "760": {"path": "/applications/Ma-Net/networks/deeplab.py:65-81", "hash": "5d0904b985eedaa44fac5025f51325b3", "title": "Get ConvBN Layers' Parameters"}, "761": {"path": "/applications/Ma-Net/networks/loss.py", "hash": "5e764f7f30349f69e97ddddaeb510ab6", "title": "Custom Loss Function for Image Classification"}, "762": {"path": "/applications/Ma-Net/networks/loss.py:1-28", "hash": "a6af1f58c3f795a5deb42b0a0259332f", "title": "Custom BCE Loss Function"}, "763": {"path": "/applications/Ma-Net/networks/loss.py:29-44", "hash": "e2267a59e232d140e4a09a175c69c270", "title": "Hard Example Mining Loss"}, "764": {"path": "/applications/Ma-Net/networks/loss.py:45-67", "hash": "a7985ae7ed98f2cda5cc94ce40573178", "title": "Custom Loss Function with Hard Example Mining"}, "765": {"path": "/applications/Ma-Net/networks/loss.py:68-87", "hash": "c470740a5dcca8412174f31a44b72a5d", "title": "Top K Percent Pixel Loss"}, "766": {"path": "/applications/Ma-Net/networks/loss.py:88-109", "hash": "21eba121c08cd7c5b215bc08b72076d9", "title": "Hard Example Mining and Top-k Pixel Selection Loss"}, "767": {"path": "/applications/Ma-Net/networks/loss.py:110-130", "hash": "d22de70faaaaa0d5e529f77272da0503", "title": "Hard Example Mining Loss Function"}, "768": {"path": "/applications/Ma-Net/networks/loss.py:131-148", "hash": "83467e50f3b63063c1ccef61691dc894", "title": "Weighted Hard Example Mining Loss"}, "769": {"path": "/applications/Ma-Net/networks/loss.py:149-153", "hash": "80d4bf09d5ca72bab028ed1336a34c06", "title": "Top-k Mean Loss Calculation"}, "770": {"path": "/applications/Ma-Net/run.sh", "hash": "d896f29116237312216d0c2af4601d57", "title": "DeeplabV3_coco DAVIS Dataset Training and Testing"}, "771": {"path": "/applications/Ma-Net/run.sh:1-13", "hash": "830372ab50d564c65554c83ce06cd5e3", "title": "Train DeeplabV3 on DAVIS Dataset"}, "772": {"path": "/applications/Ma-Net/run.sh:13-15", "hash": "7aab5abd7565a5cc51c4949b811d8cc3", "title": "Testing Video Object Segmentation"}, "773": {"path": "/applications/Ma-Net/test.py", "hash": "79f21711edb5a2f29b2d2d96eb55bafb", "title": "DAVIS2017 Video Object Detection with PaddlePaddle"}, "774": {"path": "/applications/Ma-Net/test.py:1-39", "hash": "aa4dbd01451c8217220d30d942fd09bc", "title": "Data Preprocessing for DAVIS2017"}, "775": {"path": "/applications/Ma-Net/test.py:40-62", "hash": "383f1173c5275b320794e2dfef1d8ea3", "title": "Video Analysis Configuration Loading"}, "776": {"path": "/applications/Ma-Net/test.py:63-87", "hash": "85d5244dda8169a7e0310dd4a6bed25c", "title": "Preparing Image Dictionary for Model Training"}, "777": {"path": "/applications/Ma-Net/test.py:88-113", "hash": "62b3bc7b623e37e5a16214bceaf6c386", "title": "Interactive Session Initialization"}, "778": {"path": "/applications/Ma-Net/test.py:115-139", "hash": "e60eb8bf957da6439833d2a15896e802", "title": "Scribble Sequence Retrieval and Memory Initialization"}, "779": {"path": "/applications/Ma-Net/test.py:140-163", "hash": "7c5760d6139559b74c5eb8db6f0c93c6", "title": "Interaction Detection Code: File Writing and Embedding"}, "780": {"path": "/applications/Ma-Net/test.py:164-182", "hash": "4d38126eae4403bbc6e1a9296497d686", "title": "Extracting and Concatenating Embeddings"}, "781": {"path": "/applications/Ma-Net/test.py:183-203", "hash": "01607597a7091320343ec7f1dab4cd12", "title": "Scribble Labeling in Ma-Net"}, "782": {"path": "/applications/Ma-Net/test.py:204-224", "hash": "625512be4ba6a34b1ae3a496b0fb3d6f", "title": "Save Scribble Image with Palette"}, "783": {"path": "/applications/Ma-Net/test.py:226-244", "hash": "6f14c868166de4ea3c4740cca07e69a3", "title": "Segmentation Model Initialization"}, "784": {"path": "/applications/Ma-Net/test.py:245-262", "hash": "70d19b1a40b1357fe1295cd2ee8dff9e", "title": "Ma-Net Labeling: Predict, Resize, Max"}, "785": {"path": "/applications/Ma-Net/test.py:263-279", "hash": "61b781a174007c9b054f6887d9edf944", "title": "Save Interactive Video Frame as Labeled Image"}, "786": {"path": "/applications/Ma-Net/test.py:280-298", "hash": "1e1671ece6195a63531eb1d755338df8", "title": "Video Object Segmentation Algorithm with Pre-trained Model"}, "787": {"path": "/applications/Ma-Net/test.py:299-318", "hash": "0d94c1b01ac659a2961c61750ad36e7c", "title": "Function Call with Multiple Args and Interpolation"}, "788": {"path": "/applications/Ma-Net/test.py:320-338", "hash": "7916a5777a454aae04120c4964f50064", "title": "Image Saving for Prediction Labels"}, "789": {"path": "/applications/Ma-Net/test.py:339-356", "hash": "9f67ff3fceb3b70b64dd6a701c147435", "title": "Folder and Image Saving Reset"}, "790": {"path": "/applications/Ma-Net/test.py:357-374", "hash": "6db24a5477d228a0e04c052a83a85bb0", "title": "Video Object Detection with PaddlePaddle's Prop Seghead"}, "791": {"path": "/applications/Ma-Net/test.py:375-394", "hash": "88c4b123c89d6ab2042a8ae1fd822c38", "title": "Dynamic Object Detection and Classification"}, "792": {"path": "/applications/Ma-Net/test.py:395-412", "hash": "7ecac88445c657900bd596f92720427c", "title": "Save Image in Directory Structure"}, "793": {"path": "/applications/Ma-Net/test.py:413-436", "hash": "9b80fe136b13a7293e6badcce9ba8f11", "title": "Interactive Image Classification System"}, "794": {"path": "/applications/Ma-Net/test.py:437-468", "hash": "f047dc5e22660bc663428f6be5f62eed", "title": "Filtering Scribble Labels in Ma-Net"}, "795": {"path": "/applications/Ma-Net/test.py:469-485", "hash": "ef4d65471a715ff115ef66990e722a43", "title": "75 Colors Palette Definition"}, "796": {"path": "/applications/Ma-Net/test.py:486-498", "hash": "fc33b83bdb94e2fb6969714e718f495f", "title": "List of Sequential Numbers"}, "797": {"path": "/applications/Ma-Net/test.py:499-511", "hash": "d33358abf28d0dc4a17b550a87da627a", "title": "Incrementing Loop"}, "798": {"path": "/applications/Ma-Net/test.py:512-525", "hash": "74c6c8636dc7d7ea6c21babe96dd4dd2", "title": "Enigmatic Numerical Sequence"}, "799": {"path": "/applications/Ma-Net/train_stage1.py", "hash": "02f4513405043b84bf5ac11a7b50a2c0", "title": "Ma-Net Video Detection Training"}, "800": {"path": "/applications/Ma-Net/train_stage1.py:1-34", "hash": "247114078616f3fb855af0d5fd5abc21", "title": "Train Stage 1: Ma-Net Setup"}, "801": {"path": "/applications/Ma-Net/train_stage1.py:35-59", "hash": "9ef7d1dfd1f77f9a81fb13d9b890050b", "title": "Training Ma-Net in Stage 1"}, "802": {"path": "/applications/Ma-Net/train_stage1.py:61-87", "hash": "2cce2ce93f41cfc6f23def0c96299fbd", "title": "Training Stage: Ma-Net Model Initiation"}, "803": {"path": "/applications/Ma-Net/train_stage1.py:88-114", "hash": "1d1b997f0390ba977cdcf94303a63567", "title": "Dataset Preparation and Training Setup"}, "804": {"path": "/applications/Ma-Net/train_stage1.py:116-144", "hash": "0f3f418ffa2a924249e8b48e17757f0d", "title": "Model Resumption and Training"}, "805": {"path": "/applications/Ma-Net/train_stage1.py:145-172", "hash": "e24d908dc68f182b2e855c07a6efb442", "title": "Preparing Input Data for Model Training"}, "806": {"path": "/applications/Ma-Net/train_stage1.py:173-194", "hash": "5a213989a60f4ef86ec99a1d9c6db99c", "title": "Initialize Label and Object Dictionaries"}, "807": {"path": "/applications/Ma-Net/train_stage1.py:195-217", "hash": "0ca59bc15db8371176d79b2ad7fc11f1", "title": "Video Object Detection Model Training: Stages and Loss Functions"}, "808": {"path": "/applications/Ma-Net/train_stage1.py:218-240", "hash": "b6454ffdeed21b49e831cf50be43ba9b", "title": "Image Comparison and Normalization"}, "809": {"path": "/applications/Ma-Net/train_stage1.py:241-266", "hash": "e6c37541807ba0f4ef378ada2244559b", "title": "Sigmoid Binary Cross-Entropy Masks"}, "810": {"path": "/applications/Ma-Net/train_stage1.py:267-286", "hash": "53c43969a258dadfd0e57bd98979c4a8", "title": "Loading and Preparing Test Datasets"}, "811": {"path": "/applications/Ma-Net/train_stage1.py:287-306", "hash": "e7bdcc71c2124d8600cfb83a94bc7ced", "title": "Paddle Data Loader for Test Samples"}, "812": {"path": "/applications/Ma-Net/train_stage1.py:307-326", "hash": "25b14b6bc5aa619326e7a225e95a8ca7", "title": "Feature Extraction and Model Prediction"}, "813": {"path": "/applications/Ma-Net/train_stage1.py:327-348", "hash": "b414e0ad5a3711337abbe88e7d98a8c4", "title": "Frame-by-frame Prediction Saving Function"}, "814": {"path": "/applications/Ma-Net/train_stage1.py:349-378", "hash": "1e1036cc47f0d30e8d8884d1092499e8", "title": "Training Ma-Net with Adaptive Learning Rate"}, "815": {"path": "/applications/Ma-Net/train_stage1.py:379-391", "hash": "845a6c121c94382c0dfc8204cb625294", "title": "RGB Object Values List"}, "816": {"path": "/applications/Ma-Net/train_stage1.py:392-404", "hash": "5889eb2ff5f53af9ca89333e7212004e", "title": "Sequence Numbers in Ma-Net's train_stage1.py"}, "817": {"path": "/applications/Ma-Net/train_stage1.py:405-417", "hash": "f7363eaafbbe04bfd4136665bcf6e71b", "title": "Image Sequence Codes"}, "818": {"path": "/applications/Ma-Net/train_stage1.py:418-429", "hash": "b8946d12ee630a54a3990949fbb1ace7", "title": "Training Manager's Code and Function Call"}, "819": {"path": "/applications/Ma-Net/train_stage2.py", "hash": "bfa00ca6ce8dadc0fdc22c9cab75f6b9", "title": "Training Ma-Net Stage 2 with Learning Rates"}, "820": {"path": "/applications/Ma-Net/train_stage2.py:1-34", "hash": "fba0118827c25bc1d7fe94334898e948", "title": "Initialize Environment for Training"}, "821": {"path": "/applications/Ma-Net/train_stage2.py:35-61", "hash": "26bfa3c523b3335a07359e5826d788f2", "title": "DataLoader Initialization and Configuration"}, "822": {"path": "/applications/Ma-Net/train_stage2.py:62-89", "hash": "021462bd8cd2a4010fa57426b6e7b01a", "title": "Initialize Manager Object for VOS Training"}, "823": {"path": "/applications/Ma-Net/train_stage2.py:91-119", "hash": "415ce0c868fb23602d898da0323e4cad", "title": "Train Stage 2: Ma-Net Model Init & Optimization"}, "824": {"path": "/applications/Ma-Net/train_stage2.py:120-145", "hash": "d8a3eff369d68eabda88552b7c5b957a", "title": "Ma-Net: Training Stage 2"}, "825": {"path": "/applications/Ma-Net/train_stage2.py:146-170", "hash": "62e960b6bd8a2c039b5ed9d7005a4b28", "title": "Model Resuming and Training Loop"}, "826": {"path": "/applications/Ma-Net/train_stage2.py:171-191", "hash": "f4c1de6e229928461bdbbc284406a020", "title": "Dataset Initialization and Training Loop"}, "827": {"path": "/applications/Ma-Net/train_stage2.py:192-212", "hash": "4ad9e3547275c23894cc91ee3088addb", "title": "Training Stage 2: Setting Up Model and Feature Extraction"}, "828": {"path": "/applications/Ma-Net/train_stage2.py:213-229", "hash": "7853cbb365be2042e0838f2eac9cabd7", "title": "Image Classification Code Snippet Initialization"}, "829": {"path": "/applications/Ma-Net/train_stage2.py:230-247", "hash": "9ef7ccc8b052be36dfd8c0e57780eb48", "title": "Initialize and Process Sequences"}, "830": {"path": "/applications/Ma-Net/train_stage2.py:248-265", "hash": "dbf9c6e11afd0f3a79b19b7908929550", "title": "Label and Object Dictionary Handling"}, "831": {"path": "/applications/Ma-Net/train_stage2.py:266-287", "hash": "73978bc0d5faf2f96743dfa138403939", "title": "Training Stage 2: Updates and Visualizations"}, "832": {"path": "/applications/Ma-Net/train_stage2.py:288-306", "hash": "e0e17970d910cf4ca5f419985ca5adf7", "title": "Label and Prediction Visualization"}, "833": {"path": "/applications/Ma-Net/train_stage2.py:307-324", "hash": "db0adacc207e055a7e9d0b99dc154c22", "title": "Segmenting Image with Binary Cross-Entropy"}, "834": {"path": "/applications/Ma-Net/train_stage2.py:325-350", "hash": "c3ab7317d6329d02b4b8b9791f984487", "title": "Save Network at Intervals During Training"}, "835": {"path": "/applications/Ma-Net/train_stage2.py:351-367", "hash": "1caf4b6a98c64089422ad313e55d368c", "title": "Training Stage 2: Data Loader Setup"}, "836": {"path": "/applications/Ma-Net/train_stage2.py:368-386", "hash": "381382c1f40623e0ba23874016b6c3f1", "title": "Scribble Labeling and Image Processing in Stage 2"}, "837": {"path": "/applications/Ma-Net/train_stage2.py:387-406", "hash": "24d645c5f8201b471908bbe721a15c12", "title": "Model Training: Concatenating Labels and GPU Check"}, "838": {"path": "/applications/Ma-Net/train_stage2.py:407-423", "hash": "f910388fb870b0f6704fd7bc2b5a8f2b", "title": "Interpolated Image Classification with Interactor"}, "839": {"path": "/applications/Ma-Net/train_stage2.py:424-439", "hash": "3a298bfdd82751fdcffc8dd6d58b3504", "title": "Resizing and Updating Image Labels"}, "840": {"path": "/applications/Ma-Net/train_stage2.py:441-462", "hash": "1e5e55fa6b9ece8f565453254034fb28", "title": "Round-Based Video Model Training"}, "841": {"path": "/applications/Ma-Net/train_stage2.py:464-481", "hash": "e411b67fbad1027af723f881045e195b", "title": "Training Stage 2: Ma-Net Data Preparation"}, "842": {"path": "/applications/Ma-Net/train_stage2.py:482-500", "hash": "839e54dc602dcaee200ca6844aa3e8ae", "title": "Train Dataset Update and Model Training Progress"}, "843": {"path": "/applications/Ma-Net/train_stage2.py:501-525", "hash": "4692c0ff8d2935bcd8f05497d2b48c45", "title": "Efficient ROI Operation for Scribble Labels"}, "844": {"path": "/applications/Ma-Net/train_stage2.py:526-556", "hash": "7d6bd9b417cb91972ceb4cfed7ede998", "title": "Training Stage 2: Load, Train, Save Network"}, "845": {"path": "/applications/Ma-Net/train_stage2.py:557-573", "hash": "742f3f55103f9d2589c0171a6cbe72da", "title": "RGB Palette Generation Code"}, "846": {"path": "/applications/Ma-Net/train_stage2.py:574-586", "hash": "7fabf8081bd1e069a8086cee3e8fb32c", "title": "List of Numbers (81-150)"}, "847": {"path": "/applications/Ma-Net/train_stage2.py:587-599", "hash": "16d7a66846811affbcc0c9013c3e7c6f", "title": "Code Purpose Unclear"}, "848": {"path": "/applications/Ma-Net/train_stage2.py:600-612", "hash": "19fa6b33ff43e48d16ee92d6e98f5d40", "title": "Manager Training with Image Dimensions"}, "849": {"path": "/applications/Ma-Net/utils/api.py", "hash": "79c6bc610759cd63f9246845d88f1c04", "title": "Universal Tensor Utility API"}, "850": {"path": "/applications/Ma-Net/utils/api.py:1-49", "hash": "10fdd858fa5544f91dfb6e86f8dc9e62", "title": "Utility Functions for PyTorch-Paddle Conversion"}, "851": {"path": "/applications/Ma-Net/utils/api.py:50-83", "hash": "7b8d696a42772fe37b6ce4a485b1dd00", "title": "Tensor and Image Conversion Utilities"}, "852": {"path": "/applications/Ma-Net/utils/api.py:84-112", "hash": "0ce2ee51c32d331c5a10a1c3c5ae05b9", "title": "Compatibility Check: Adjust and Convert Image Data Types"}, "853": {"path": "/applications/Ma-Net/utils/api.py:113-136", "hash": "84e871b0f587545503de4a1b2c9c6b07", "title": "Mode Validator for Image Data Types"}, "854": {"path": "/applications/Ma-Net/utils/api.py:137-161", "hash": "95f3964351457a0b14835412a2a0939a", "title": "Verify Image Mode and Data Type"}, "855": {"path": "/applications/Ma-Net/utils/api.py:163-198", "hash": "6ed4298200728c9841a9a8b8972ba12e", "title": "Identity Class and Data Conversion Function"}, "856": {"path": "/applications/Ma-Net/utils/api.py:199-223", "hash": "3cc5269478864e350956e187182a308c", "title": "Gradient Norm Clipping Function"}, "857": {"path": "/applications/Ma-Net/utils/api.py:224-250", "hash": "b47d79e16e4bc0461c3741892db6b979", "title": "Max Absolute Value Finder"}, "858": {"path": "/applications/Ma-Net/utils/api.py:251-274", "hash": "fb07933157997624b1be215cd2a5f5d0", "title": "Ma-Net: Non-finite Parameter Clipping"}, "859": {"path": "/applications/Ma-Net/utils/api.py:275-307", "hash": "897024f9f654e8599d86fe40602cb42a", "title": "Maximum Value and Index Extractor"}, "860": {"path": "/applications/Ma-Net/utils/api.py:308-338", "hash": "005d904add4218a73915be62110ede07", "title": "Weight Initialization without Gradient Calculation"}, "861": {"path": "/applications/Ma-Net/utils/api.py:339-364", "hash": "f47c67e34ba7aceebe5d809a1294f60e", "title": "Truncated Normal Initialization"}, "862": {"path": "/applications/Ma-Net/utils/api.py:366-398", "hash": "2a37231df861e96e489f18bc0c773bf0", "title": "Tensor Transformations and Nonlinearity Gains"}, "863": {"path": "/applications/Ma-Net/utils/api.py:399-425", "hash": "8f99984a592e6a5e24adc839a90ddf74", "title": "Gain Calculator for Non-linear Functions"}, "864": {"path": "/applications/Ma-Net/utils/api.py:426-454", "hash": "4492313731135deb8e6215e19123f981", "title": "Initializing Tensor Distributions"}, "865": {"path": "/applications/Ma-Net/utils/api.py:455-483", "hash": "bef1fb328872f8bc266f409aad4cbfc5", "title": "Truncated Normal Tensor Initialization"}, "866": {"path": "/applications/Ma-Net/utils/api.py:484-526", "hash": "c1ccfbb813f0a00d2768522a62f6e97f", "title": "Initializing Tensor Functions in PyTorch"}, "867": {"path": "/applications/Ma-Net/utils/api.py:528-562", "hash": "4adbc7f9986c16394ae5e9065245f680", "title": "Preserving Identity in Linear and Conv Layers: Functions"}, "868": {"path": "/applications/Ma-Net/utils/api.py:563-592", "hash": "d90bf167683790f36ad98a43c0adc44c", "title": "Convolutional Layer Weights Init with Dirac Delta"}, "869": {"path": "/applications/Ma-Net/utils/api.py:593-627", "hash": "4312f41468cbe365ee37424254567b15", "title": "PaddlePaddle Tensor Utilities"}, "870": {"path": "/applications/Ma-Net/utils/api.py:628-655", "hash": "174d309192f6eb1088f7dbb3b4f3283a", "title": "Glorot Initialization in Ma-Net API"}, "871": {"path": "/applications/Ma-Net/utils/api.py:656-687", "hash": "920387d05af528640d87af0dc8b8a15a", "title": "Xavier/Glorot Tensor Initialization"}, "872": {"path": "/applications/Ma-Net/utils/api.py:688-709", "hash": "3cb27420b9a233bb332139c853e174e0", "title": "Uniform Tensor Filler"}, "873": {"path": "/applications/Ma-Net/utils/api.py:710-732", "hash": "56fff455f052e13471843b333c663e34", "title": "Kaiming Uniform Initialization in PyTorch"}, "874": {"path": "/applications/Ma-Net/utils/api.py:733-758", "hash": "0f9cf0839acf33cf4eef4fa65727619d", "title": "Kaiming Weight Initialization"}, "875": {"path": "/applications/Ma-Net/utils/api.py:759-789", "hash": "e50e1c1ae4e2273d450dfab0661b9767", "title": "QR Factorization of Tensors"}, "876": {"path": "/applications/Ma-Net/utils/api.py:790-822", "hash": "32e967cd7c19ec86b95825c181ab8264", "title": "QR Decomposition and Scaling"}, "877": {"path": "/applications/Ma-Net/utils/api.py:824-857", "hash": "133edd935d14c2e04d1e18b6363dadb2", "title": "Kaiming Normal Initializer Function"}, "878": {"path": "/applications/Ma-Net/utils/mask_damaging.py", "hash": "83ca8c2ef29bd52648f71310f469bd96", "title": "Mask Damager: Rotation and Translation in PaddleVideo"}, "879": {"path": "/applications/Ma-Net/utils/mask_damaging.py:1-36", "hash": "86b0b04daf039faea79a6540bb08ff2d", "title": "Mask Damager: Random Transformations for Labels"}, "880": {"path": "/applications/Ma-Net/utils/mask_damaging.py:37-73", "hash": "c8cb33c5ee71c1dbbde6e1bf052dc032", "title": "Mask Damaging Functions"}, "881": {"path": "/applications/Ma-Net/utils/mask_damaging.py:74-98", "hash": "af71abbffa022d66390ab221e0963fad", "title": "Mask Damaging Function"}, "882": {"path": "/applications/Ma-Net/utils/mask_damaging.py:99-129", "hash": "9b9eb601cd6f5c50a10e4333432ba641", "title": "Mask Damaging in PaddleVideo Library"}, "883": {"path": "/applications/Ma-Net/utils/mask_damaging.py:130-155", "hash": "bc5619fcddbf27ac17c5aa849d2fb0a6", "title": "Random Mask Damage Functions"}, "884": {"path": "/applications/Ma-Net/utils/mask_damaging.py:156-170", "hash": "141407f14329c81583ec22fb395324ac", "title": "Rotated and Translated Masks"}, "885": {"path": "/applications/Ma-Net/utils/meters.py", "hash": "1fc138c51bf4ad7354035da8e89092e5", "title": "AverageMeter Class: Compute and Store Average"}, "886": {"path": "/applications/Ma-Net/utils/utils.py", "hash": "3c65bff3639def5c6cf194533c382d2e", "title": "Label to RGB Conversion"}, "887": {"path": "/applications/MultimodalVideoTag/README.md", "hash": "dc9e6c63a62375d533b88595cf303329", "title": "Multimodal Video Tagging with PaddlePaddle 2.0"}, "888": {"path": "/applications/MultimodalVideoTag/README.md:1-37", "hash": "93df97124e57baf08804a15c6a5a3943", "title": "Multimodal Video Classification with PaddlePaddle"}, "889": {"path": "/applications/MultimodalVideoTag/README.md:38-65", "hash": "eecce3612f229191908898dab4f29464", "title": "Training, Evaluation, and Inference with Multimodal Video Tagging"}, "890": {"path": "/applications/MultimodalVideoTag/README.md:67-77", "hash": "366919cf2079d291a1d1c8d3fee4a4f6", "title": "Multimodal Video Tagging with Attention Clusters"}, "891": {"path": "/applications/MultimodalVideoTag/download.sh", "hash": "6ffef4fe898b05c0862258caaa93d6b5", "title": "Download ErnIE Model and Dataset"}, "892": {"path": "/applications/MultimodalVideoTag/eval_and_save_model.sh", "hash": "4ad940035aa0714d2e2c793c8d788cc5", "title": "Env Var Set, Eval & Save Model Script"}, "893": {"path": "/applications/MultimodalVideoTag/inference.sh", "hash": "3804f7c7b5fa40c0b0987fa7f5b5ab8f", "title": "GPU-Based Inference Script"}, "894": {"path": "/applications/MultimodalVideoTag/scenario_lib/accuracy_metrics.py", "hash": "d8b4d5257a229c3c486323c4b5dc5c4f", "title": "Multimodal Video Accuracy Metrics Calculator"}, "895": {"path": "/applications/MultimodalVideoTag/scenario_lib/accuracy_metrics.py:1-35", "hash": "76dc56a7cce457931b7c6c14fe743635", "title": "Accuracy Metrics Calculator"}, "896": {"path": "/applications/MultimodalVideoTag/scenario_lib/accuracy_metrics.py:36-68", "hash": "165d5a278783147bc6b78c6041d5591a", "title": "Multimodal Video Tag Accuracy Metrics"}, "897": {"path": "/applications/MultimodalVideoTag/scenario_lib/accuracy_metrics.py:69-95", "hash": "eb0870e6c86af0b28f918b4be7cfa0df", "title": "Video Tagging Metrics Computation"}, "898": {"path": "/applications/MultimodalVideoTag/scenario_lib/accuracy_metrics.py:96-125", "hash": "a3a976e167b5f65dc07d3f3b36866abd", "title": "Multilabel Top-K Accuracy"}, "899": {"path": "/applications/MultimodalVideoTag/scenario_lib/accuracy_metrics.py:126-158", "hash": "65dc6f414e16725c41d47053fd93f3bd", "title": "Top-K Accuracy Calculation"}, "900": {"path": "/applications/MultimodalVideoTag/scenario_lib/accuracy_metrics.py:159-160", "hash": "3b4f0b960dd797ab68cd3f0cabe2e3ec", "title": "Top-K Hits for Multilabel Prediction"}, "901": {"path": "/applications/MultimodalVideoTag/scenario_lib/config.py", "hash": "d520811dd6af9d3e55d58aab8308e85a", "title": "Config Parser and Merger for Multimodal Video Tag"}, "902": {"path": "/applications/MultimodalVideoTag/scenario_lib/config.py:1-52", "hash": "059dc711a63f7d52479c8d0fcdd564eb", "title": "Config Parser and Merger Function"}, "903": {"path": "/applications/MultimodalVideoTag/scenario_lib/config.py:53-71", "hash": "0dab57ea9258e8f9985d9bc31afb7c63", "title": "Config Updater and Printer"}, "904": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/__init__.py", "hash": "e87ac39072a18f0298ef132f5724f294", "title": "Multimodal Video Tag Datareader"}, "905": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py", "hash": "d11e619fb37cbb06a3751fa1e668b548", "title": "ERNIE Reader for Multimodal Video Tagging"}, "906": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:1-35", "hash": "5d6750408f1ae81edbfd48877703d080", "title": "Ernie Reader: MultimodalVideoTag's Python Component"}, "907": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:37-74", "hash": "c607f39fcfde13dc2471b8a1e51f18b2", "title": "CSV Reader: BaseReader Class"}, "908": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:75-102", "hash": "5eff42f11ab17064359390b02290636f", "title": "Initializing and Configuring ERNIE Task Reader"}, "909": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:103-131", "hash": "9120fe518947ae8abb22889c782fdddc", "title": "Record Creation from Text Tokenization"}, "910": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:132-151", "hash": "c59f01e47038fa7b9219b00a3140abaf", "title": "Ensuring Correct BERT/ERNIE Sequences"}, "911": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:152-179", "hash": "4dd77272a165f142f1d6707a7e44bb33", "title": "ERNIE Input Preparation"}, "912": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:180-207", "hash": "25528878999a9c3f8afa0b6f4b026ebe", "title": "ERNIE Batch Record Generation"}, "913": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:208-235", "hash": "d5846fa3e3c738878cc9864aab7f0f6c", "title": "Padding Ernie Batch Reader"}, "914": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:236-257", "hash": "fb2139030507e552e5a6cccb504103c5", "title": "ERNIE Task Data Processing"}, "915": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:258-289", "hash": "2b71edad180a73f0d3df8a9f8355297f", "title": "ERNIE Text Data Generation"}, "916": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:290-317", "hash": "795b05428b5c2e4255311c954ab0deb0", "title": "Pad Instances to Max Sequence Length"}, "917": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/ernie_task_reader.py:318-334", "hash": "a30af4131efc068507855c8dae77d55f", "title": "Preparing Return List in ERNIE Task Reader"}, "918": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py", "hash": "45b67f724640f7a0f3d922b51b811bb2", "title": "Multimodal Video Feature Reader"}, "919": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:1-39", "hash": "22bd62387b8faf5f2161f77d492b2bd0", "title": "FeatureReader: Multimodal Video Feature Data Reader"}, "920": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:40-67", "hash": "dc4061e08c6b21719d3c4c3cad604786", "title": "YouTube-8M Data Reader: LSTM, Attention Cluster, NextVlad"}, "921": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:68-95", "hash": "43275c5b97880e360981f79455adf8e9", "title": "Multimodal Data Reader Algorithm"}, "922": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:96-113", "hash": "9b9b9776739d23696d3fbdaa42dc1d56", "title": "Multi-Modal Dataset Feature Reader"}, "923": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:114-140", "hash": "ed33317741dd84edc2b1f4051197bb23", "title": "Multimodal Video Data Reader"}, "924": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:143-173", "hash": "0873755e1e902920a7052eef28870def", "title": "Function for Loading Video Files and Labels"}, "925": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:174-212", "hash": "fe419213819fd161ff91819c50970bfa", "title": "Label Data Manipulation Functions"}, "926": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:213-251", "hash": "39a4e9553ce276904d59ca2a3d796c7c", "title": "Efficient Data Reader for Multimodal Video Analysis"}, "927": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/feature_reader.py:252-274", "hash": "d76e7fe7e9a3b1a79a1424652f043c29", "title": "Load and Return Dictionary of Words and Indices"}, "928": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/reader_utils.py", "hash": "4129231bc35b3f4234236327a042d738", "title": "Reader Manager: Custom Exceptions and Singleton Design"}, "929": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/reader_utils.py:1-30", "hash": "c918e29733b2aec77e0f340f7a6901d0", "title": "Custom Exception for Missing Reader"}, "930": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/reader_utils.py:31-73", "hash": "7fdb3313376721e31c58987b8f929ecf", "title": "Video Data Reader Utilities"}, "931": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/reader_utils.py:74-91", "hash": "62bb80195ea21201f642dd9a773d0089", "title": "Reader Manager: Singleton for Registering and Retrieving Readers"}, "932": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py", "hash": "3b5f09da8c8f5637bca41c2f02f0aae8", "title": "Text Tokenization for Multimodal Video Tagging"}, "933": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:1-32", "hash": "1c505a4dbf637d772011564a7c434cea", "title": "Python Unicode Converter Function"}, "934": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:33-61", "hash": "508a3584082d1af33731748fc63aceb4", "title": "Universal Printable Text Encoder"}, "935": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:62-96", "hash": "a4272074431412da762bc6b766de1dc1", "title": "Vocabulary File Handler"}, "936": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:97-133", "hash": "2f8085c953d0dad7396afb381b4b63e2", "title": "FullTokenizer: Efficient Tokenization Class"}, "937": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:134-168", "hash": "ed7267011f946f9c4e08acee6679476e", "title": "End-to-End Tokenization with CharTokenizer"}, "938": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:169-197", "hash": "a85a06e3e42a6ddafa97403453198ef5", "title": "Basic Tokenizer for Text Tokenization"}, "939": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:198-229", "hash": "1ab54ef916786856448bd885b0150392", "title": "Chinese Text Tokenization and Processing"}, "940": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:230-259", "hash": "62ca54d06e5bd8358acacb7beb41046f", "title": "Text Tokenization Functions"}, "941": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:260-282", "hash": "97a32078cbb4b69c1f8a3fe8cacdac22", "title": "CJK Unicode Checker"}, "942": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:283-315", "hash": "51b2079033eb44b2f827872fc68a9502", "title": "Greedy Wordpiece Tokenizer"}, "943": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:316-348", "hash": "5e159469a794e6e13da4bf8e787ef11f", "title": "Tokenization and Unknown Word Handling"}, "944": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:349-382", "hash": "82860a8f2a0edb7f4d3e0719270a1f62", "title": "Tokenizing String Functions"}, "945": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:383-405", "hash": "ca61b02bd0fb82471f35f013be82b63a", "title": "Detect Punctuation and Chinese Characters"}, "946": {"path": "/applications/MultimodalVideoTag/scenario_lib/datareader/tokenization.py:406-441", "hash": "cbb0af8c222cf56a9b793c09e02c1582", "title": "Chinese Text Tokenizer"}, "947": {"path": "/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py", "hash": "b095b5967fcec00d5d91f913eff1da0e", "title": "Multimodal Video Tagging with PaddlePaddle"}, "948": {"path": "/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py:1-37", "hash": "4248451b6c2825a8c9b48211a63cc462", "title": "Multimodal Video Tag Evaluation Code"}, "949": {"path": "/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py:38-64", "hash": "86b7ba8afb398a6770407e6e3e78bbf8", "title": "Paddle Video Eval Argument Parser"}, "950": {"path": "/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py:65-94", "hash": "ea6d4e7c1c84f5fd3a5f6337aa609298", "title": "Evaluate and Save Inference Model"}, "951": {"path": "/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py:95-123", "hash": "08e58f6bd9ef368290c8c0d7721666b7", "title": "Save and Evaluate Model"}, "952": {"path": "/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py:124-145", "hash": "5e5af0bb56da2166ea4cb9b6560a823e", "title": "Evaluate and Save Multimodal Video Model"}, "953": {"path": "/applications/MultimodalVideoTag/scenario_lib/eval_and_save_model.py:146-159", "hash": "a68fd37f65742e2c4b8e83781ef7846c", "title": "Save Inference Model with Parameters"}, "954": {"path": "/applications/MultimodalVideoTag/scenario_lib/inference.py", "hash": "ac9ac700d564de16cea421936f9c79ff", "title": "Multimodal Video Tagging Inference"}, "955": {"path": "/applications/MultimodalVideoTag/scenario_lib/inference.py:1-38", "hash": "384870ad371612a27bea3acc6b9ef16a", "title": "Paddle Video Inference Script"}, "956": {"path": "/applications/MultimodalVideoTag/scenario_lib/inference.py:39-69", "hash": "f192c0566ed1150ef1bfc121c7332ca6", "title": "InferModel Class and Load Inference Model Function"}, "957": {"path": "/applications/MultimodalVideoTag/scenario_lib/inference.py:70-98", "hash": "eee08777cc6ce2bf7a071c405e4e1ebb", "title": "Multimodal Video Tagging Initialization"}, "958": {"path": "/applications/MultimodalVideoTag/scenario_lib/inference.py:100-122", "hash": "f3696b5182d838d7b29814b7feb42bc6", "title": "Multimodal Inference Function"}, "959": {"path": "/applications/MultimodalVideoTag/scenario_lib/inference.py:124-161", "hash": "dd0c8b573d1f7c7879a38ee1deb4f10f", "title": "Video Label Inference Function"}, "960": {"path": "/applications/MultimodalVideoTag/scenario_lib/inference.py:162-173", "hash": "275ec9c9be59c77cbc3e0d4e1de41437", "title": "MultimodalVideoTag Inference Function"}, "961": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py", "hash": "ed104a63b4db88e53211403a885d9939", "title": "Multi-modal Video Tagging with ERNIE"}, "962": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:1-34", "hash": "118b35b506e5858a01de73c7ee1ba019", "title": "AttentionLstmErnie: Combining Scenario-Classify and ERNIE"}, "963": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:35-59", "hash": "89fd33b9138e0779bce9887f6959d655", "title": "Attention LSTM ERNIE Model Initialization"}, "964": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:60-85", "hash": "2df31eaf55440b8b70acbc167c41fe73", "title": "AttentionLSTMERNIE Model Config Init"}, "965": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:86-108", "hash": "39a32a98e0cb9d660caa042152abef63", "title": "Ernie Model Data Feeding and Feature Extraction"}, "966": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:109-131", "hash": "1b310e9f4cab4e1829517ec430af91d0", "title": "ERNIE Model Initialization and Freeze"}, "967": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:132-154", "hash": "df64531a140203e5a6d7d9f8a82f1aa8", "title": "Attention-based LSTM Model for Video Tagging"}, "968": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:155-172", "hash": "0df5307c647d48f894e5bae40be30e12", "title": "Dynamic LSTM for Image Features with Attention"}, "969": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:173-194", "hash": "3e652879e60b3fb946f2c63d91480470", "title": "Multimodal LSTM with Audio and Visual Inputs"}, "970": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:195-214", "hash": "b2d62bd932b680d3643f74bc8f993404", "title": "Attention LSTM for Audio Reversal"}, "971": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:215-235", "hash": "196196a55416c090e0297c345ff4d3b0", "title": "Multimodal Video Tagging with LSTM-Attention and ERNIE"}, "972": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:236-260", "hash": "295becbb876034d62f000fe6e5fc9da7", "title": "Attention-based Neural Feature Sequence Calculation"}, "973": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:261-285", "hash": "294ab97e7b51a8a4f060aee2e3900779", "title": "Dropout and Batch Normalization for LSTM"}, "974": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:286-312", "hash": "04c6ba8fc591fcf6d8f1140bc7318c2e", "title": "Attention LSTM Ernie Model with Dropout"}, "975": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:313-334", "hash": "08218daf624cf9606b8f36c301b40a17", "title": "Loss Calculation with Piecewise Decay Optimizer"}, "976": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:336-365", "hash": "37d112e68c29ed1e4c65aed6ad870d2c", "title": "Sigmoid Loss Function in Attention LSTM"}, "977": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/attention_lstm_ernie.py:366-400", "hash": "7ddc59c33ec27e951ae05fd810c27b4e", "title": "Attention LSTM ERNIE Model Functions"}, "978": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py", "hash": "fbf0f763cd99593d0760f28eef0b1357", "title": "ERNIE Multimodal Video Tagging Model"}, "979": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:1-33", "hash": "61ed68bdc7783f20e76104c78ae085de", "title": "Ernie Model Configuration"}, "980": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:34-73", "hash": "c07f9ed7c17d22660aeccf557bc4b0bb", "title": "Ernie Model Configuration Class"}, "981": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:76-106", "hash": "672ef9fc4da4171a973d876350c00ae4", "title": "ERNIE Model Class Definition"}, "982": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:107-132", "hash": "0dca3aa617960bc4ac96a30affa72b0b", "title": "ERNIE Model Initialization and Building"}, "983": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:133-158", "hash": "6c42d01e5d7e89ed996d426fff5a250b", "title": "Multimodal Video Tagging Embedding Combination"}, "984": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:159-184", "hash": "27a4e4c9f5f9904f4056806bd00ae691", "title": "Embedding Layer Initialization and Encoding"}, "985": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:185-215", "hash": "00756883f901f7281a45ebbc58b202c9", "title": "Encoder Layer Initialization"}, "986": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:216-243", "hash": "7bc8befe6db0c2717eb2d1e5ef9eb4d0", "title": "TextCNN Model for Sequence Feature Extraction"}, "987": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/ernie.py:244-250", "hash": "2cf28dc5c4f70fbb00dac721f647e7a6", "title": "1D Convolutional Layer Creation"}, "988": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py", "hash": "e0a57c540decf204518f97995c6b065c", "title": "Transformer Encoder for NLP"}, "989": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:1-32", "hash": "04a7b094a61c702dba2c38bf2b4a5392", "title": "Multi-Head Attention Function"}, "990": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:33-57", "hash": "9b4722ff69e5c96d02a150a98dd265df", "title": "Multi-Head Attention Layer Code"}, "991": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:58-80", "hash": "bc4daf6c9c28c45e8efeea3713e6de09", "title": "Transformer Encoder Layer Function"}, "992": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:81-104", "hash": "cd3e7f332ac2c1f786c9e78a09fe5644", "title": "Split and Combine Attention Heads in Transformer Encoder"}, "993": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:105-128", "hash": "beaae361b8cfc412a8f5bc03bac70014", "title": "Scaled Dot-Product Attention in Transformer Encoder"}, "994": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:129-154", "hash": "d66b77ac33de6e58a8f43b523a68692f", "title": "Transformer Encoder Attention Mechanism"}, "995": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:155-182", "hash": "25b564fa21badc8540d0b295d5b6e8f5", "title": "Position-wise Feed-Forward Network in Transformer Encoder"}, "996": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:183-208", "hash": "299ba686e968c7cd045578c6b979b84a", "title": "Transformer Encoder Layer for Multimodal Video Tagging"}, "997": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:209-236", "hash": "cc887da84ce7f6dc465e8b3dad62a1e8", "title": "Transformer Encoder Layer Implementation"}, "998": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:237-268", "hash": "21a7c876423f24df6cdae9e174ef8de4", "title": "Transformer Encoder Layer with MH Attention"}, "999": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:269-308", "hash": "292e20ce365289ffa4c1f32d9028ae9f", "title": "Transformer Encoder Model Definition"}, "1000": {"path": "/applications/MultimodalVideoTag/scenario_lib/models/transformer_encoder.py:309-338", "hash": "29ec03a1932ac97acf7ee995e5e3410e", "title": "Transformer Encoder Function"}, "1001": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py", "hash": "91c724073b255af8239badcebab36cf5", "title": "Video Model Training with PaddlePaddle"}, "1002": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:1-34", "hash": "d168d694d2d41a4960c00fa63fd43f3d", "title": "Train Model Using AttentionLstmErnie"}, "1003": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:37-71", "hash": "67849f982f0f9b000afbd1a7370f8932", "title": "Command-Line Logging for Paddle Video"}, "1004": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:72-105", "hash": "494674d4d265dc681c7a8b55b7d836ab", "title": "Training Options in MultimodalVideoTag"}, "1005": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:106-136", "hash": "f494b27ac9ff4497aa2263145d241515", "title": "Command-Line Arguments for Model Training"}, "1006": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:137-160", "hash": "daba0e4010e4d0437e54ae63f32a385e", "title": "Training Model Setup"}, "1007": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:161-190", "hash": "0a42532e6f2941ddc2b5c37a634c2d19", "title": "Model Building and Execution Setup"}, "1008": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:191-213", "hash": "a14e4f9ed35d2be0ea5e69dcae5f093a", "title": "Data Parallelism with Pre-Trained Weights"}, "1009": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:214-231", "hash": "41f032a10121e5a1a412ecc7bc920521", "title": "Batch Size Setting in Multimodal Video Tagging"}, "1010": {"path": "/applications/MultimodalVideoTag/scenario_lib/train.py:232-263", "hash": "d914443fbd55a211a4df35db74552d96", "title": "Train Model with Custom Arguments"}, "1011": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py", "hash": "cfe7511073519932952e8f728ef76d92", "title": "Multi-Task Framework for Video Tagging"}, "1012": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:1-39", "hash": "ce980ba0c5e74d8bd9e8444e9dbc4ea3", "title": "Testing with PyReader Function"}, "1013": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:40-67", "hash": "ab85ec1cf0e5e542017e072072a51721", "title": "PaddleVideo Test Suite"}, "1014": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:68-96", "hash": "0159a8d28f558b07c9d04b24e6b9ba1c", "title": "Train Model with PyReader: Epochs, Testing, and Early Stopping"}, "1015": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:97-119", "hash": "68abdff3526c14ae9a28f5ac68d10e05", "title": "ML Training Loop Metrics Tracker"}, "1016": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:120-141", "hash": "4adb302a7622825a9c64e1f4067f2d93", "title": "Epoch Training Metrics and Testing"}, "1017": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:142-169", "hash": "3daeb3924d0495b005d2a16fb8dc007f", "title": "Save and Stop Training Model Function"}, "1018": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:170-201", "hash": "8323bb03408550644c7c0ea1650b5b30", "title": "Load Pretrained Parameters"}, "1019": {"path": "/applications/MultimodalVideoTag/scenario_lib/utils.py:204-218", "hash": "57de18fbfc82b0bb51f91f4bac58614f", "title": "AttrDict: Dictionary as Class Attributes"}, "1020": {"path": "/applications/MultimodalVideoTag/train.sh", "hash": "147849fa34b9c08eea4e80b766b3dd24", "title": "Efficient GPU Training of Attention LSTM Ernie"}, "1021": {"path": "/applications/PP-Care/Readme.md", "hash": "4fc2571c043db8eb87627ccde079f014", "title": "Pre-Trained PP-Care Model for Video Understanding"}, "1022": {"path": "/applications/PP-Care/Readme.md:1-55", "hash": "472d42b6f93b63e94221071c9ffe17c4", "title": "3DMRI Classification with PaddleVideo"}, "1023": {"path": "/applications/PP-Care/Readme.md:55-81", "hash": "8a5c79acee01d6c39c6761095fe23717", "title": "Initializing PP-Care Model for MRI Data"}, "1024": {"path": "/applications/PP-Care/Readme.md:81-106", "hash": "63252fde99ded8cb3cc40a70854bdb67", "title": "Optimized PP-Care Model Testing with ResNet50"}, "1025": {"path": "/applications/PP-Care/Readme.md:107-110", "hash": "839af0aa07f474148ee9c2fa6e9fdb5d", "title": "Efficient Video Neural Networks: A Comprehensive Guide"}, "1026": {"path": "/applications/PPHuman/README.md", "hash": "f58cf75f57adac219b6168226c50b904", "title": "PaddleVideo to PP-Human Model Conversion Script"}, "1027": {"path": "/applications/PPHuman/README.md:1-21", "hash": "8c0322585be1cef77d1d301c56035349", "title": "Training Behavior Model with PaddleVideo"}, "1028": {"path": "/applications/PPHuman/README.md:22-42", "hash": "eb786632af2f98a16dcd06ee0828a341", "title": "Data Preparation for PP-Human"}, "1029": {"path": "/applications/PPHuman/README.md:44-60", "hash": "6039b7950ceaf6144fcffa546ff1845b", "title": "Keypoint Detection with Pretrained Models"}, "1030": {"path": "/applications/PPHuman/README.md:62-83", "hash": "66d12f8544e9f3a158b830a25dea899f", "title": "PPHuman: Human Keypoint Detection in Videos"}, "1031": {"path": "/applications/PPHuman/README.md:84-114", "hash": "08d371118f168dda7b7b1ccce79b0dad", "title": "PPHuman JSON to Training Data Conversion"}, "1032": {"path": "/applications/PPHuman/README.md:115-143", "hash": "77ada94e9d1ee7edbc549ceda24ca4a9", "title": "Exporting PaddleVideo Model for PP-Human"}, "1033": {"path": "/applications/PPHuman/datasets/prepare_dataset.py", "hash": "3abf30e919497b8fc6e5db86eea5ee18", "title": "Preparing Datasets for PaddleVideo and PPHuman"}, "1034": {"path": "/applications/PPHuman/datasets/prepare_dataset.py:1-34", "hash": "a78472dcaa92a9c7313151a56fde206c", "title": "UR Fall Dataset Conversion for PaddleVideo"}, "1035": {"path": "/applications/PPHuman/datasets/prepare_dataset.py:35-69", "hash": "65ae4f5621c96b2ce7a69988aa11f35f", "title": "Consistent Dataset Preparation"}, "1036": {"path": "/applications/PPHuman/datasets/prepare_dataset.py:70-98", "hash": "d8b70b9c5e334311e0ef354344d87eef", "title": "Prepare Dataset for PaddleVideo's PPHuman"}, "1037": {"path": "/applications/README.md", "hash": "7e18c6626b0c3a07ff2a999ea12180c9", "title": "PaddleVideo: Versatile Application Cases"}, "1038": {"path": "/applications/T2VLAD/README.md", "hash": "3849f659e32eb8c04d4f412682a590b7", "title": "Introducing T2VLAD: Video Retrieval Model in PaddleVideo"}, "1039": {"path": "/applications/T2VLAD/README.md:1-60", "hash": "566dc671aea41b12017b8e0f34ae7c90", "title": "T2VLAD: Text Video Retrieval Model Introduction"}, "1040": {"path": "/applications/T2VLAD/README.md:61-75", "hash": "8a595511a98a24d6ac7baa0e0878f9d1", "title": "T2VLAD Performance Metrics"}, "1041": {"path": "/applications/T2VLAD/README_en.md", "hash": "101f1ae3f446b1add2cb4ab69f7810d0", "title": "T2VLAD: Text-Video Retrieval with PaddleNLP"}, "1042": {"path": "/applications/T2VLAD/README_en.md:1-31", "hash": "524237b07590972558a480528f540a35", "title": "Install PaddleNLP Dependency"}, "1043": {"path": "/applications/T2VLAD/README_en.md:32-59", "hash": "82292cfe2b02d7334d6263ddc65dcdcc", "title": "Train and Test T2VLAD on MSRVTT Dataset"}, "1044": {"path": "/applications/T2VLAD/README_en.md:61-69", "hash": "aa33c5b9d4ae8a3cd942c5d5a6435aab", "title": "Text-Video Retrieval Model Metrics: R@1, R@5, R@10"}, "1045": {"path": "/applications/T2VLAD/base/__init__.py", "hash": "1b4a0ac909e171afe00dd51ca0ada2cd", "title": "Importing Base Modules"}, "1046": {"path": "/applications/T2VLAD/base/base_dataset.py", "hash": "7b6f97ab8a29984a473b2339c0e848e6", "title": "Video Dataset Base Class"}, "1047": {"path": "/applications/T2VLAD/base/base_dataset.py:1-36", "hash": "e1f4d0204fab8e7c8a4d38cb6046ac84", "title": "Copyright, Libraries, and Type Guarding in Python"}, "1048": {"path": "/applications/T2VLAD/base/base_dataset.py:37-76", "hash": "2ca0d6de0d48225c86115ed287c3445f", "title": "Base Dataset Class for Video Features"}, "1049": {"path": "/applications/T2VLAD/base/base_dataset.py:77-101", "hash": "6cb0eee53ac36e371ea9014b348c953f", "title": "Dataset Class Initialization"}, "1050": {"path": "/applications/T2VLAD/base/base_dataset.py:102-125", "hash": "967bfc944fc077327f973dc61c97309f", "title": "Dataset Initialization"}, "1051": {"path": "/applications/T2VLAD/base/base_dataset.py:127-152", "hash": "359f4212b3d3da8f1dc809dec31a5597", "title": "Default Video Retrieval Paths"}, "1052": {"path": "/applications/T2VLAD/base/base_dataset.py:154-175", "hash": "6a037afe95f4f1ac035c0a0ae2226122", "title": "Experts Configuration Initialization"}, "1053": {"path": "/applications/T2VLAD/base/base_dataset.py:176-197", "hash": "d34809cc07fc13e7cfd3a4e053b5a374", "title": "Initializing Arrays for Model Evaluation"}, "1054": {"path": "/applications/T2VLAD/base/base_dataset.py:199-217", "hash": "c641dfd807e10dc28a3881e701b56738", "title": "Expert Index Initialization"}, "1055": {"path": "/applications/T2VLAD/base/base_dataset.py:218-237", "hash": "f0c4233f28e6e7c05f61da1422033a33", "title": "Video Feature Preparation and Test Captioning"}, "1056": {"path": "/applications/T2VLAD/base/base_dataset.py:238-257", "hash": "8ad3394bc98adedfc3be7534d5adb32e", "title": "Token Masking and Encoding in T2VLAD"}, "1057": {"path": "/applications/T2VLAD/base/base_dataset.py:258-280", "hash": "c52eb2d091262e330f1bfb28af5cfe54", "title": "Text Feature Creation and Split Configuration"}, "1058": {"path": "/applications/T2VLAD/base/base_dataset.py:281-304", "hash": "2c634d94e2d7f6f677fe7951902aeb91", "title": "Loading and Initializing Data for PaddleVideo"}, "1059": {"path": "/applications/T2VLAD/base/base_dataset.py:305-327", "hash": "717281a518d06e255fd8e531715ac2d5", "title": "Batch Tensor Initialization"}, "1060": {"path": "/applications/T2VLAD/base/base_dataset.py:329-350", "hash": "87b064fe99f7a062fe27abe7ed02269f", "title": "Data Preparation for Experts"}, "1061": {"path": "/applications/T2VLAD/base/base_dataset.py:351-372", "hash": "14e6def564d3ca5494b54ff7ae0b7b0d", "title": "Minibatch Creation for Video and Text Features"}, "1062": {"path": "/applications/T2VLAD/base/base_dataset.py:373-397", "hash": "f2d1caccb551babf9de76909efe1087a", "title": "Video Dataset Class for Text-to-Video Retrieval"}, "1063": {"path": "/applications/T2VLAD/base/base_dataset.py:398-413", "hash": "a89da377cd6edd2ff858400377848d48", "title": "Video Frame Feature Segmentation"}, "1064": {"path": "/applications/T2VLAD/base/base_dataset.py:414-437", "hash": "c7689cc6b19066cfd8929a136572b8e4", "title": "Random Captioning with Tokenization"}, "1065": {"path": "/applications/T2VLAD/base/base_dataset.py:438-463", "hash": "def7e73aca09c3d9f9e42f85c7f342da", "title": "Video Dataset Initialization"}, "1066": {"path": "/applications/T2VLAD/base/base_dataset.py:464-492", "hash": "7c3b8f048896d0fabe64f173d64d40ca", "title": "Defining Retrieval Data and Meta Dictionary"}, "1067": {"path": "/applications/T2VLAD/base/base_dataset.py:493-516", "hash": "d573b3980cc5d4b163610e7e38d3a50c", "title": "Feature Path Generator"}, "1068": {"path": "/applications/T2VLAD/base/base_dataset.py:517-539", "hash": "3deeb6f496fb8441463c4212d365f96e", "title": "Assertion Function and Summary Stats in T2VLAD Base Dataset"}, "1069": {"path": "/applications/T2VLAD/base/base_dataset.py:540-562", "hash": "357b803d8ebdf74287c3a9a9eb110834", "title": "Partition and Analyze Datasets"}, "1070": {"path": "/applications/T2VLAD/base/base_model.py", "hash": "4e2ed14cecfb69374e41aa7a4b79a205", "title": "Base Model Abstract Class"}, "1071": {"path": "/applications/T2VLAD/base/base_model.py:1-36", "hash": "a4657a7599ddf9a939c19f998b77bdaa", "title": "Abstract Base Model for PaddleVideo"}, "1072": {"path": "/applications/T2VLAD/base/base_model.py:37-37", "hash": "cee94c8bbc8174ddaf66a348db2a4731", "title": "Trainable Parameters Counter"}, "1073": {"path": "/applications/T2VLAD/base/base_trainer.py", "hash": "efcfc8558a644c92183bb1ab07082eb1", "title": "T2VLAD Trainer: Multi-Epoch Management and Checkpoints"}, "1074": {"path": "/applications/T2VLAD/base/base_trainer.py:1-33", "hash": "75dd3069c92c832e16efeba07a66a2d5", "title": "Base Trainer Class Setup"}, "1075": {"path": "/applications/T2VLAD/base/base_trainer.py:34-60", "hash": "abdc99eb5ffc7c3e735191c17cd2f232", "title": "Initializing Base Trainer Object"}, "1076": {"path": "/applications/T2VLAD/base/base_trainer.py:62-89", "hash": "b6864c225be7b03a748791bbbd4e202e", "title": "Training Trainer Class"}, "1077": {"path": "/applications/T2VLAD/base/base_trainer.py:90-110", "hash": "6082e1869b9c23ee1de221732ee6e63e", "title": "Metrics Logging and Monitoring Enhancements"}, "1078": {"path": "/applications/T2VLAD/base/base_trainer.py:111-128", "hash": "5a451e42fca434ea0640f7b729899c28", "title": "Improved Performance Check"}, "1079": {"path": "/applications/T2VLAD/base/base_trainer.py:129-151", "hash": "52bb13751df0938c3b859af195e4a566", "title": "Early Stopping and Best Model Saving"}, "1080": {"path": "/applications/T2VLAD/base/base_trainer.py:153-170", "hash": "eb9ddec6678bd8aa9b59d976eca088c2", "title": "Flexible Model Saving Conditions"}, "1081": {"path": "/applications/T2VLAD/base/base_trainer.py:171-186", "hash": "76358c417df6ca1e15d82da3e8f8520a", "title": "Video Prediction Saving and Logging"}, "1082": {"path": "/applications/T2VLAD/base/base_trainer.py:187-210", "hash": "204ed61b521dd73ce5d434ba4bb3404f", "title": "Model Checkpoint Management & Purge"}, "1083": {"path": "/applications/T2VLAD/base/base_trainer.py:211-238", "hash": "3c69a804c3073d3edcde947b54837178", "title": "Stale Model Pruning"}, "1084": {"path": "/applications/T2VLAD/base/base_trainer.py:239-258", "hash": "3cab6a7325c5e046cad866dc1426b985", "title": "AutoSave Best Model During Training"}, "1085": {"path": "/applications/T2VLAD/data/download_features.sh", "hash": "da0fbbd4dcbada209bc9ac584cd53d14", "title": "Remote Dataset Download & Extraction"}, "1086": {"path": "/applications/T2VLAD/data_loader/MSRVTT_dataset.py", "hash": "d1469bbafe8c7ebedafc34c01d16f6d0", "title": "MSRVTT Dataset Loader"}, "1087": {"path": "/applications/T2VLAD/data_loader/MSRVTT_dataset.py:1-29", "hash": "61e3996a11b1c0d0e946eb1842c15c83", "title": "MSRVTT Dataset Loader"}, "1088": {"path": "/applications/T2VLAD/data_loader/MSRVTT_dataset.py:30-46", "hash": "e5b8247f42069a627e9c1ed58adb34b7", "title": "Data Split Paths for MSRVTT Dataset"}, "1089": {"path": "/applications/T2VLAD/data_loader/MSRVTT_dataset.py:47-71", "hash": "61a41deb2347e5106a8fb562dc9f21c1", "title": "MSRVTT Dataset Feature Loading"}, "1090": {"path": "/applications/T2VLAD/data_loader/MSRVTT_dataset.py:72-89", "hash": "b450fe27b54972888c3c645306d9a7a9", "title": "Feature Aggregation for Expert in MSRVTT Dataset"}, "1091": {"path": "/applications/T2VLAD/data_loader/MSRVTT_dataset.py:90-108", "hash": "17e0e46213f3281272a5a8c9576b26f1", "title": "Checking and Validating Text Features"}, "1092": {"path": "/applications/T2VLAD/data_loader/MSRVTT_dataset.py:110-126", "hash": "245d5e6955adf0459a883b25acead1bb", "title": "Validating Test Sets and Missing Queries"}, "1093": {"path": "/applications/T2VLAD/data_loader/data_loaders.py", "hash": "116c8e9be1eba6fb215434a80ba92a17", "title": "Efficient Data Loader with LRU Caching"}, "1094": {"path": "/applications/T2VLAD/data_loader/data_loaders.py:1-36", "hash": "fb65577c7b0d741961a56ac0af525df4", "title": "Paddle Dataset Loader Function"}, "1095": {"path": "/applications/T2VLAD/data_loader/data_loaders.py:37-69", "hash": "58fbe1a58bb7f34ab75a1a9597fe6ff1", "title": "Create Dataset Function"}, "1096": {"path": "/applications/T2VLAD/data_loader/data_loaders.py:71-101", "hash": "9019005107fa8bac8496fc82aca062f6", "title": "Data Loader Constructor"}, "1097": {"path": "/applications/T2VLAD/data_loader/data_loaders.py:102-127", "hash": "79fc41ecd14341f2fe721d1a44d147f8", "title": "Flush and Create Dataset Loader"}, "1098": {"path": "/applications/T2VLAD/data_loader/data_loaders.py:129-145", "hash": "64f9e3dec133b4c4a709bb036b9f6b2e", "title": "Training DataLoader Creator"}, "1099": {"path": "/applications/T2VLAD/logger/__init__.py", "hash": "646f9b3b9079bdb7dfbcef7e80b9ddca", "title": "Importing T2VLAD Logger and Parser Functions"}, "1100": {"path": "/applications/T2VLAD/logger/log_parser.py", "hash": "737dbb861e20a89b4856ded9e83f25fb", "title": "Log Summary: Epoch Performance Stats"}, "1101": {"path": "/applications/T2VLAD/logger/log_parser.py:1-24", "hash": "34e4793dc42e594c30d32c6ce71430f6", "title": "Log Performance Stats with log_summary"}, "1102": {"path": "/applications/T2VLAD/logger/log_parser.py:26-56", "hash": "9502420928aa4a8aafec9d9531ba284e", "title": "Log Parser: Identifying Seeds and Metrics in T2VLAD"}, "1103": {"path": "/applications/T2VLAD/logger/log_parser.py:57-78", "hash": "cfa2ff83518c050bd72e392522b3d58e", "title": "Log Parser: Extracting Scores for Seeds"}, "1104": {"path": "/applications/T2VLAD/logger/log_parser.py:79-99", "hash": "de6ea38285328fde62d5a4afd4ce9909", "title": "Geometric Mean Seed Selection"}, "1105": {"path": "/applications/T2VLAD/logger/log_parser.py:101-104", "hash": "1fa5f166bd216bb91746ebb9b68bca14", "title": "Fixed Epoch Logging"}, "1106": {"path": "/applications/T2VLAD/logger/logger.py", "hash": "203ee422eb15db7d15596729cacac43f", "title": "Configure Logging from JSON File"}, "1107": {"path": "/applications/T2VLAD/model/loss.py", "hash": "0424c3c8c55cdebb12473c049cc71a6a", "title": "Contrastive Loss for T2VLAD"}, "1108": {"path": "/applications/T2VLAD/model/loss.py:1-28", "hash": "84a6c5d4a968bc42a0477a40a3271486", "title": "Max Margin Ranking Loss for T2VLAD"}, "1109": {"path": "/applications/T2VLAD/model/loss.py:29-61", "hash": "3ddf35108e91c86e7dddc14e8be824d9", "title": "Contrastive Loss for Image-Sentence Pairs"}, "1110": {"path": "/applications/T2VLAD/model/loss.py:62-85", "hash": "833b8e85a400388ed2a3f73dbf48b83d", "title": "Contrastive Learning Cost Calculation"}, "1111": {"path": "/applications/T2VLAD/model/loss.py:86-102", "hash": "0fb6698b9c64b82eaee1be46ef7ff3b1", "title": "Video-Level Loss Calculation in T2VLAD"}, "1112": {"path": "/applications/T2VLAD/model/metric.py", "hash": "fbef2cc5cacca04b4a62731bceb7183a", "title": "Retrieval Metrics and Visualization Tool"}, "1113": {"path": "/applications/T2VLAD/model/metric.py:1-30", "hash": "5566a45867d88d0492fa8ec1ce515ce5", "title": "Retrieval Metrics Computation"}, "1114": {"path": "/applications/T2VLAD/model/metric.py:31-58", "hash": "d20666d1e010673c6ad88478778d6b7e", "title": "Retrieval Metrics Calculation"}, "1115": {"path": "/applications/T2VLAD/model/metric.py:59-75", "hash": "d330aaa8fea39a5a300a4171bc6ec4f2", "title": "Averaging Tie-Breaking in Similarity Matrix"}, "1116": {"path": "/applications/T2VLAD/model/metric.py:76-98", "hash": "99801bdb113e341bbbc79aa93cd58d4c", "title": "Efficient Tied Scores Handling"}, "1117": {"path": "/applications/T2VLAD/model/metric.py:100-122", "hash": "277200653294fa8d74157379a249fa69", "title": "Average Rank Calculator"}, "1118": {"path": "/applications/T2VLAD/model/metric.py:124-148", "hash": "b963497b1b1a1011827a42ac7d9ed145", "title": "Retrieval Metric Computation and Validity Checks"}, "1119": {"path": "/applications/T2VLAD/model/metric.py:150-180", "hash": "1ffcf50b2a36772b85d52a3ebb4955ad", "title": "Closest Caption Retrieval Metrics"}, "1120": {"path": "/applications/T2VLAD/model/metric.py:181-199", "hash": "5877b48d9e1543f1eb98539dcf4c3a20", "title": "Optimistic or Averaging Caption Ranking"}, "1121": {"path": "/applications/T2VLAD/model/metric.py:200-224", "hash": "bceabb5196d91fe819f29e35b597ecdb", "title": "Matrix Rank Checker: Sanity-checking Code"}, "1122": {"path": "/applications/T2VLAD/model/metric.py:225-243", "hash": "8db44c7c3e25611d6c717ad4e25bc8be", "title": "Ranking Metrics Computation with Matplotlib and Numpy"}, "1123": {"path": "/applications/T2VLAD/model/model.py", "hash": "42cba9bda61cb17077852c1cbc8eb2f6", "title": "Enhanced Video Analysis with CENet"}, "1124": {"path": "/applications/T2VLAD/model/model.py:1-34", "hash": "fcce8d49221e6e380b72b839c8e02f12", "title": "Importing Libraries for T2VLAD Model"}, "1125": {"path": "/applications/T2VLAD/model/model.py:35-66", "hash": "95c5575b95e0937de32feb0f2524901d", "title": "Implementing Mish, Kronecker Product, and NaN Removal Functions"}, "1126": {"path": "/applications/T2VLAD/model/model.py:67-98", "hash": "8ee3d7bad815a14c02b4afe7b284a86a", "title": "NaN Handling in CENet Model"}, "1127": {"path": "/applications/T2VLAD/model/model.py:99-130", "hash": "de205933b09b5428e7249fd5cfbedab2", "title": "Model Initialization and Time Estimation"}, "1128": {"path": "/applications/T2VLAD/model/model.py:131-148", "hash": "b13ffc4cc0f7ec328f28202391ebaea9", "title": "Text Pooling in T2VLAD"}, "1129": {"path": "/applications/T2VLAD/model/model.py:149-179", "hash": "1c92a3009684de03e0ff16a115100ddc", "title": "Transformer Layer Implementation"}, "1130": {"path": "/applications/T2VLAD/model/model.py:180-207", "hash": "033dde6d904e463baf53ffcf6f1527af", "title": "Attention Functions in T2VLAD Model"}, "1131": {"path": "/applications/T2VLAD/model/model.py:208-237", "hash": "41f7deec50601fb0bce7c419f4da9b87", "title": "Transformer Class with Multi-Head Attention"}, "1132": {"path": "/applications/T2VLAD/model/model.py:238-275", "hash": "a4437f3c04314fe58a45bf3ac3a42238", "title": "CEModule Class Definition"}, "1133": {"path": "/applications/T2VLAD/model/model.py:277-297", "hash": "0e7adfb519d98ef147f91cf71373c661", "title": "MOE Model Initialization"}, "1134": {"path": "/applications/T2VLAD/model/model.py:298-323", "hash": "21287acf63eda84bac705ae8ccd7d36d", "title": "Model Initialization and Preparation"}, "1135": {"path": "/applications/T2VLAD/model/model.py:325-350", "hash": "c4dd759345348f0d1d5988abd6cf24aa", "title": "Gated Embedding Units for MOE Computation"}, "1136": {"path": "/applications/T2VLAD/model/model.py:351-374", "hash": "7df3eb6125c455c00f61db1efee64c3f", "title": "Gated Text Embeddings in Model.py"}, "1137": {"path": "/applications/T2VLAD/model/model.py:376-397", "hash": "1bffcb436b9ab9ba91abedf45503d15e", "title": "Multi-Modal MOE Weights and Feature Extraction"}, "1138": {"path": "/applications/T2VLAD/model/model.py:398-422", "hash": "ed733ed50a8841042c5e220f73ddc01a", "title": "Cross-View Video Localization via VLAD and MOE"}, "1139": {"path": "/applications/T2VLAD/model/model.py:423-456", "hash": "08cb18dc82ddd6b9799557e0e0d46d22", "title": "T2VLAD Model Layers Explained"}, "1140": {"path": "/applications/T2VLAD/model/model.py:458-485", "hash": "2475a2c25f51224c92b9b98b2822e2d4", "title": "Sharded Embedding Similarity Matrix Function"}, "1141": {"path": "/applications/T2VLAD/model/model.py:486-507", "hash": "8e0f4f45ca24070970b79970b7be9dd3", "title": "Video-Text Similarity Calculator"}, "1142": {"path": "/applications/T2VLAD/model/model.py:508-526", "hash": "cc2a91311246f737b390ff0daa439bec", "title": "Tensor Weights Combination and Normalization"}, "1143": {"path": "/applications/T2VLAD/model/model.py:527-533", "hash": "344603c015a05c4f4a5ae7700e76cddb", "title": "Video-Text Similarity Calculator"}, "1144": {"path": "/applications/T2VLAD/model/net_vlad.py", "hash": "54e0bfe1fe925a0ce5f69ab84914fef5", "title": "NetVLAD in T2VLAD Model Initialization"}, "1145": {"path": "/applications/T2VLAD/model/net_vlad.py:1-33", "hash": "ecf6a3fd8aea9c01b36339616c2ab86d", "title": "NetVLAD Algorithm: Implementation and Parameters"}, "1146": {"path": "/applications/T2VLAD/model/net_vlad.py:34-44", "hash": "5c73a86010505b33e78759e6f757b12f", "title": "Initializing VLAD Model Parameters"}, "1147": {"path": "/applications/T2VLAD/model/net_vlad.py:46-76", "hash": "4976b5e8ab63fc2ef9f5e25da85cea10", "title": "T2VLAD: Sanity Checks and Forward Pass"}, "1148": {"path": "/applications/T2VLAD/model/net_vlad.py:77-99", "hash": "5367835f76c5a2019477364f6ac95b89", "title": "Batch Normalized VLAD Representation Generation"}, "1149": {"path": "/applications/T2VLAD/model/net_vlad.py:100-100", "hash": "5c472512456723e03051d1652085aefe", "title": "VLAD Feature Extraction in NetVLAD Model"}, "1150": {"path": "/applications/T2VLAD/model/text.py", "hash": "c4ed57127843a9ce600cde4d9f04f4e9", "title": "Text Embedding for Video Descriptions"}, "1151": {"path": "/applications/T2VLAD/model/text.py:1-37", "hash": "3d23f4cfed112068bcfed0080a41d53c", "title": "Text Embedding Interface"}, "1152": {"path": "/applications/T2VLAD/model/text.py:38-73", "hash": "65a32dd97eec0d4f6d6025adde87d310", "title": "W2VEmbedding: Text Embedding with Word2Vec"}, "1153": {"path": "/applications/T2VLAD/model/text.py:74-101", "hash": "70295451fc0d1eaa9b29b0c79472ca0a", "title": "Initializing Text2Vec Model Class"}, "1154": {"path": "/applications/T2VLAD/model/text.py:103-130", "hash": "6a208229a744b406ba470a801880a558", "title": "Text Embedding Class"}, "1155": {"path": "/applications/T2VLAD/model/text.py:131-146", "hash": "da2e351839f2974b4f189c00c2401f16", "title": "OpenAI GPT Embedding Tokenizer"}, "1156": {"path": "/applications/T2VLAD/parse_config.py", "hash": "b24109bfd057e2ff10982c0f22ae8dee", "title": "ConfigParser: Config Management & Parsing"}, "1157": {"path": "/applications/T2VLAD/parse_config.py:1-35", "hash": "b94143530daea5c7915afca2d107c9ce", "title": "ConfigParser Class Overview"}, "1158": {"path": "/applications/T2VLAD/parse_config.py:36-62", "hash": "32bb9e8659207b2fe79c03c5cde498e7", "title": "Initializing Argument Parser and Config Loading"}, "1159": {"path": "/applications/T2VLAD/parse_config.py:63-88", "hash": "d82ffa88fadfc1025d7f0021dc066093", "title": "Config-Based Model Saving and Logging"}, "1160": {"path": "/applications/T2VLAD/parse_config.py:89-112", "hash": "4d87b71dd7ebc471ced40c12b84a90f1", "title": "Directory Purging and Recreation in parse_config.py"}, "1161": {"path": "/applications/T2VLAD/parse_config.py:113-134", "hash": "d5439cf2ee4750d25b5437a0fda08c67", "title": "Config Parser and Custom Arguments"}, "1162": {"path": "/applications/T2VLAD/parse_config.py:135-159", "hash": "a8549e62c61961420a2b39acff2b8470", "title": "Config File Processing and Class Initialization"}, "1163": {"path": "/applications/T2VLAD/parse_config.py:160-190", "hash": "0f6bb97e5acda21d3169d38fd75510f9", "title": "Overwriting Check and Config Updates"}, "1164": {"path": "/applications/T2VLAD/parse_config.py:191-232", "hash": "e98c75b3d6965101966c20abf237f4de", "title": "Parse Config Class"}, "1165": {"path": "/applications/T2VLAD/parse_config.py:233-239", "hash": "ecb06be395ee5ae6c58125859eacacdc", "title": "Nested Object Access and Modify Functions"}, "1166": {"path": "/applications/T2VLAD/test.py", "hash": "18006b0a05be55a1e15ad4cd6984f0b7", "title": "PaddleVideo: Prediction Compression and Evaluation"}, "1167": {"path": "/applications/T2VLAD/test.py:1-33", "hash": "16b8ca6f84323d52a6c012eda680726b", "title": "Compress Predictions in PaddleVideo Library"}, "1168": {"path": "/applications/T2VLAD/test.py:34-51", "hash": "a143d73ed677a788a078d3e5de025463", "title": "Input Shape Validation: Ensuring Compatibility"}, "1169": {"path": "/applications/T2VLAD/test.py:52-84", "hash": "53adf989c25f81e54493e0bba509a317", "title": "Function for Initializing Paddle.js Model and Data Loader"}, "1170": {"path": "/applications/T2VLAD/test.py:85-116", "hash": "8609245fece6d9bf89accbee9737caf9", "title": "Model Evaluation Initialization"}, "1171": {"path": "/applications/T2VLAD/test.py:117-146", "hash": "77444e194749f905b645d5365fdfc32b", "title": "Paddle Model Initialization and Dataset Preparation"}, "1172": {"path": "/applications/T2VLAD/test.py:147-167", "hash": "d07a45f3ceb68b36d17087b89359451b", "title": "Video Sub-Sample Processing with T2VLAD"}, "1173": {"path": "/applications/T2VLAD/test.py:168-190", "hash": "7e8808123797696ea0cf83137ee4f317", "title": "Metrics Calculation and Logging"}, "1174": {"path": "/applications/T2VLAD/test.py:193-206", "hash": "276d15915986d9010f3c39ede431abe7", "title": "Argument Parsing and Configuration Loading"}, "1175": {"path": "/applications/T2VLAD/train.py", "hash": "a3120c278e9d7b3d5939224cf6dfd3a0", "title": "Video Analysis Model Training Script"}, "1176": {"path": "/applications/T2VLAD/train.py:1-35", "hash": "8db8945237493c7db228dd5837094c24", "title": "PaddleVideo: Training Framework Setup"}, "1177": {"path": "/applications/T2VLAD/train.py:37-67", "hash": "0f4bfc6d1b543597ae301a0da91b6836", "title": "Experiment Initialization Function"}, "1178": {"path": "/applications/T2VLAD/train.py:68-92", "hash": "f69d4415d788ae2499ce103ab9a71956", "title": "Model Initialization and Training Setup"}, "1179": {"path": "/applications/T2VLAD/train.py:93-115", "hash": "30e2f37a5bc795646eec61288a01e928", "title": "Train Model and Save Best"}, "1180": {"path": "/applications/T2VLAD/train.py:116-133", "hash": "bfd8c84e064c4362f6cf7e95f5b332da", "title": "Command-line Arguments for Video Analysis Training"}, "1181": {"path": "/applications/T2VLAD/train.py:135-151", "hash": "9c375171540e27616724573ed68b16ca", "title": "Command-Line Training Setup"}, "1182": {"path": "/applications/T2VLAD/trainer/__init__.py", "hash": "da7ae981fc6fb2eef2419c801abd22c1", "title": "Importing Trainer Functions"}, "1183": {"path": "/applications/T2VLAD/trainer/trainer.py", "hash": "229f18465d70534598724ecbeda53feb", "title": "Memory-Efficient Video Retrieval Trainer"}, "1184": {"path": "/applications/T2VLAD/trainer/trainer.py:1-31", "hash": "08ea4dff6b4c5527ecdb14e08d992200", "title": "PaddlePaddle Video Retrieval Trainer"}, "1185": {"path": "/applications/T2VLAD/trainer/trainer.py:32-66", "hash": "ef9ea08309f0ef2e20a9f3a1b7b7aee5", "title": "Evaluation Samples Duplication and Yielding"}, "1186": {"path": "/applications/T2VLAD/trainer/trainer.py:67-89", "hash": "99b573ec80c06313cc5c9da4683549a1", "title": "Epoch-based Model Trainer Class"}, "1187": {"path": "/applications/T2VLAD/trainer/trainer.py:91-117", "hash": "b0c87ef73d9d4046c96ed8659907257d", "title": "Batch Training with Model Loss Computation"}, "1188": {"path": "/applications/T2VLAD/trainer/trainer.py:119-150", "hash": "d10e9a20b23c1a662db0f0e9970d0361", "title": "ML Model Training Loop and Scheduler"}, "1189": {"path": "/applications/T2VLAD/trainer/trainer.py:151-171", "hash": "0636827e35b10fb5925a74961e460c80", "title": "Model Evaluation Initialization"}, "1190": {"path": "/applications/T2VLAD/trainer/trainer.py:172-190", "hash": "5a994262203ec3f306cca838e348d9dd", "title": "Batch Subsampling for Video ML Model"}, "1191": {"path": "/applications/T2VLAD/trainer/trainer.py:191-209", "hash": "6c07277224137a33996b07d0b77dc550", "title": "PaddlePaddle-based Similarity Calculation for T2VLAD Training"}, "1192": {"path": "/applications/T2VLAD/trainer/trainer.py:210-228", "hash": "70d193535e44a1dd50c3ed429ed2f406", "title": "Epoch Metrics Tracking and Visualization"}, "1193": {"path": "/applications/T2VLAD/trainer/trainer.py:229-249", "hash": "c8b7f708b8c2963b2e3cfa08b70aff1a", "title": "Batch-wise Validation Metrics Calculation and Logging"}, "1194": {"path": "/applications/T2VLAD/trainer/trainer.py:250-267", "hash": "784ca49b2b1c8d7fa6904770d13a0bba", "title": "Top-K Metric Implementation"}, "1195": {"path": "/applications/T2VLAD/trainer/trainer.py:268-280", "hash": "913b6f78b9225805d1565e4cd2519378", "title": "Nested Predictions and Progress Functions"}, "1196": {"path": "/applications/T2VLAD/utils/__init__.py", "hash": "9292304a452b87320ec116ec6f752fb0", "title": "Import All from Util Module"}, "1197": {"path": "/applications/T2VLAD/utils/util.py", "hash": "b2d65261df2454c06003d12c73c1584a", "title": "Utility Functions for T2VLAD"}, "1198": {"path": "/applications/T2VLAD/utils/util.py:1-50", "hash": "47d19c0a9ce3a6f7e8aeaf19f6a4a61a", "title": "Utility Functions"}, "1199": {"path": "/applications/T2VLAD/utils/util.py:51-76", "hash": "4157dab36f990f94771495be9fd53dc5", "title": "Multifunctional Memory, Dictionary, and Expert Categorization"}, "1200": {"path": "/applications/T2VLAD/utils/util.py:77-103", "hash": "ca69c723d947979b04c7ff46a5fe6140", "title": "Temporal Expert Management and Utilities"}, "1201": {"path": "/applications/T2VLAD/utils/util.py:106-143", "hash": "6ae12a3e2a362f7a973c68cd163d4159", "title": "JSON, Hashable Dictionaries & Configuration Utilities"}, "1202": {"path": "/applications/T2VLAD/utils/util.py:144-165", "hash": "7728b39610ad75e5f408030d8f41aa00", "title": "Modality Dimensional Organization"}, "1203": {"path": "/applications/T2VLAD/utils/util.py:166-181", "hash": "91d9fb6cf4ee419c35239861fbc14f64", "title": "Determining Input-Output Dimensions for Expert Types and Temporal Methods"}, "1204": {"path": "/applications/T2VLAD/utils/util.py:182-202", "hash": "518a73dee0f02c52f839c291123dfa17", "title": "Dimensional Assignment for Experts: Util.py 182-202"}, "1205": {"path": "/applications/T2VLAD/utils/util.py:203-226", "hash": "9b0c7e05efea445108ab712d359aedf3", "title": "Configuring Expert Dimensions for T2VLAD"}, "1206": {"path": "/applications/T2VLAD/utils/util.py:227-258", "hash": "6a49751c6c2a14e7a10febcdf7810f30", "title": "Dimensionality Adjustment and Tensor Utilities"}, "1207": {"path": "/applications/T2VLAD/utils/util.py:260-284", "hash": "1b5d4df782c5547818ea1c4415abeee8", "title": "Normalize and Convert Image Tensors to Numpy Array"}, "1208": {"path": "/applications/T2VLAD/utils/util.py:285-321", "hash": "7887416340db91a8c1fafbbb27089dbe", "title": "Utility Functions in util.py"}, "1209": {"path": "/applications/T2VLAD/utils/util.py:323-327", "hash": "184145183310aff57127478922574983", "title": "Create Directory If Non-Existent"}, "1210": {"path": "/applications/TableTennis/ActionRecognition/README.md", "hash": "acec7b82be7a6a0e6833e2ad9b101678", "title": "Table Tennis Action Recognition with VideoSwinTransformer"}, "1211": {"path": "/applications/TableTennis/ActionRecognition/README.md:1-43", "hash": "5046c43b1f5295d394c19dea0cada764", "title": "Table Tennis Action Recognition with VideoSwinTransformer"}, "1212": {"path": "/applications/TableTennis/ActionRecognition/README.md:44-66", "hash": "859a7d2e62b99e34645ca5ce3a9ba6b8", "title": "TableTennis Action Recognition with VideoSwin"}, "1213": {"path": "/applications/TableTennis/ActionRecognition/README.md:68-98", "hash": "8376fff90e0c0cccdc774b748e3eed39", "title": "Visualizing Predictions in Table Tennis Action Recognition"}, "1214": {"path": "/applications/TableTennis/datasets/script/submission_format_transfer.py", "hash": "c4c132d8a8c380e7727f2761df26779e", "title": "JSON Table Tennis Data Formatter"}, "1215": {"path": "/applications/TableTennis/datasets/script/submission_format_transfer.py:1-49", "hash": "d4f37053be471762b18b4e8b62e8010a", "title": "JSON Frame Rate Conversion and Formatting"}, "1216": {"path": "/applications/TableTennis/datasets/script/submission_format_transfer.py:50-64", "hash": "c854d313ef3f90d2727c759dd43e3fa5", "title": "Table Tennis Submission Format"}, "1217": {"path": "/applications/TableTennis/extractor/extract_bmn_for_tabletennis.py", "hash": "afc581309dc64fabf5059cfaa5370a2d", "title": "TableTennis Video Inferencer"}, "1218": {"path": "/applications/TableTennis/extractor/extract_bmn_for_tabletennis.py:1-50", "hash": "1e6233115751e8e41f2dfbdeb1e75153", "title": "BMN Model Loader for Baidu Cloud"}, "1219": {"path": "/applications/TableTennis/extractor/extract_bmn_for_tabletennis.py:52-84", "hash": "34aa80592ae1ba2eed2ad3d98123ebed", "title": "Video Feature Extraction and Bmn Prediction"}, "1220": {"path": "/applications/TableTennis/extractor/extract_bmn_for_tabletennis.py:85-93", "hash": "2b51d4e59a36a396b51f9cdb3f9f78c1", "title": "JSON Inference Results Writer"}, "1221": {"path": "/applications/TableTennis/fix_bad_label.py", "hash": "0309e8c6d47d313de7be4a642e9e06b8", "title": "Fix Labels in Table Tennis App"}, "1222": {"path": "/applications/TableTennis/get_instance_for_bmn.py", "hash": "7b499546380e721a79c3620ebf76789b", "title": "BMN Model Ground Truth Data for Table Tennis"}, "1223": {"path": "/applications/TableTennis/get_instance_for_bmn.py:1-48", "hash": "c1e41c7d9acd82ee1c583fed15e8c41c", "title": "BMN Model Ground Truth Generation"}, "1224": {"path": "/applications/TableTennis/get_instance_for_bmn.py:49-74", "hash": "92264ebe973fc45565c7758c52c31207", "title": "Video Action Extraction Algorithm"}, "1225": {"path": "/applications/TableTennis/get_instance_for_bmn.py:75-108", "hash": "67ec69769c223cdebe4f673fafb6babf", "title": "Combile GTS Segments"}, "1226": {"path": "/applications/TableTennis/get_instance_for_bmn.py:109-134", "hash": "7628ac5c2ebcb66ad16e3487df3c9cfc", "title": "Segmenting and Processing Actions List for BMN"}, "1227": {"path": "/applications/TableTennis/get_instance_for_bmn.py:135-154", "hash": "efd58fae9bb839413dcb3104abddbb48", "title": "Randomized Video Segment Selection"}, "1228": {"path": "/applications/TableTennis/get_instance_for_bmn.py:155-182", "hash": "a4a6a8259138cf35e1c1e6785566682e", "title": "Video Data Segmentation and Annotation"}, "1229": {"path": "/applications/TableTennis/get_instance_for_bmn.py:183-207", "hash": "11f578b7757c6022d2210e76f91df01c", "title": "Video Feature Extraction and Parsing"}, "1230": {"path": "/applications/TableTennis/get_instance_for_bmn.py:208-227", "hash": "4dbf9651b6afdecc1d447172804151c6", "title": "Table Tennis Dataset Processing and Saving"}, "1231": {"path": "/applications/TableTennis/gts_format_transfer.py", "hash": "d284f5cd9cd43d6f9bdaa2869faa2955", "title": "JSON Format Converter"}, "1232": {"path": "/applications/TableTennis/predict/action_detect/action.py", "hash": "93465fa04de2e7291f1cf9d1bbda094d", "title": "Baidu Cloud Action Detection Script"}, "1233": {"path": "/applications/TableTennis/predict/action_detect/action.py:1-48", "hash": "d9e4552daba842f008fbe6a423bfb410", "title": "Python Action Detection with Baidu Cloud"}, "1234": {"path": "/applications/TableTennis/predict/action_detect/action.py:49-76", "hash": "65a9cc84afce4896e4ecf15787ffef9f", "title": "ModelPredict Class Initialization and Configuration"}, "1235": {"path": "/applications/TableTennis/predict/action_detect/action.py:77-108", "hash": "118e088f07486f7fa21306061319f564", "title": "Action Detection via Multimodal Feature Extraction"}, "1236": {"path": "/applications/TableTennis/predict/action_detect/action.py:109-136", "hash": "20b7553647d253f3effe82939a5e308e", "title": "Video Classification and Feature Extraction Model"}, "1237": {"path": "/applications/TableTennis/predict/action_detect/action.py:137-158", "hash": "4bd0f8600b9a8680c03f6dd73f9f6d0e", "title": "Extracting Image and Audio Features"}, "1238": {"path": "/applications/TableTennis/predict/action_detect/action.py:159-185", "hash": "33e0d6084e94c1b550b07b6c721e2bf7", "title": "Action Detection Model Inference"}, "1239": {"path": "/applications/TableTennis/predict/action_detect/action.py:186-186", "hash": "3c46aa928a7adc5786614f1a19a3914d", "title": "File Data Writing"}, "1240": {"path": "/applications/TableTennis/predict/action_detect/logger.py", "hash": "53f5b3637c8c9c3a071f142122407137", "title": "Custom Logger for Action Detection"}, "1241": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py", "hash": "44df9225891de16d0f36afef6b29ca58", "title": "Audio Features for Table Tennis Prediction"}, "1242": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py:1-39", "hash": "b6d9a0e222451c783fbcad8d6b94f263", "title": "Audio Feature Extraction in TableTennis App"}, "1243": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py:40-70", "hash": "fc8acc6472950d1663bb0e5258b8aecb", "title": "Audio Feature Extraction with MFCCs"}, "1244": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py:71-91", "hash": "7dd5f6fcb5148f8ce60b8c5546ffed76", "title": "MFCC Feature Extraction for Speech Processing"}, "1245": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py:92-112", "hash": "0b4a8af6d949ed962117340831e211f1", "title": "Generate Spectrogram from Audio Data"}, "1246": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py:113-137", "hash": "8bd2e767aba04511c6a7118dce01ef36", "title": "Mel Spectrogram Conversion and Wav Data Processing"}, "1247": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py:138-158", "hash": "b356029775a4bcd3298689f6cd8dc0e0", "title": "Table Tennis Audio Feature Extraction"}, "1248": {"path": "/applications/TableTennis/predict/action_detect/mfcc/feature_extractor.py:160-183", "hash": "2fb57c03975e4e4a56340a1d68a8ded2", "title": "MFCC Extraction with VGG-16"}, "1249": {"path": "/applications/TableTennis/predict/action_detect/mfcc/model_config.py", "hash": "574c1392fd9221b3a4d9820af61e3c18", "title": "Audio Feature Extraction Model"}, "1250": {"path": "/applications/TableTennis/predict/action_detect/mfcc/vgg_params.py", "hash": "48665dcb4614e556d4cc94b8dcd68918", "title": "Global VGGish Parameters for Action Detection"}, "1251": {"path": "/applications/TableTennis/predict/action_detect/models/audio_infer.py", "hash": "d5268ab941ce39d3589c4911b8d70db7", "title": "Audio Inference with PaddleVideo"}, "1252": {"path": "/applications/TableTennis/predict/action_detect/models/audio_infer.py:1-37", "hash": "2de0cc0fe8f56720f65df4e3c99dec9c", "title": "Audio Model Inference Initialization"}, "1253": {"path": "/applications/TableTennis/predict/action_detect/models/audio_infer.py:39-67", "hash": "5a48db26b2b0a3e73d966f71435741c8", "title": "Audio Inference Class with PaddleVideo"}, "1254": {"path": "/applications/TableTennis/predict/action_detect/models/audio_infer.py:69-78", "hash": "d50fa409ea9c08c993b1c2a011c7719e", "title": "Audio Inferencing and Prediction"}, "1255": {"path": "/applications/TableTennis/predict/action_detect/models/bmn_infer.py", "hash": "798f43b17c8fae303b74c3306aa68e8b", "title": "GPU-Optimized Action Detection"}, "1256": {"path": "/applications/TableTennis/predict/action_detect/models/bmn_infer.py:1-39", "hash": "bf2aa376038c4947a9466faa2db2e1b2", "title": "BMN Infer Model Class"}, "1257": {"path": "/applications/TableTennis/predict/action_detect/models/bmn_infer.py:40-65", "hash": "d59ee6d035fcca507d91b19e22b78f19", "title": "Inference Model Setup and Generation"}, "1258": {"path": "/applications/TableTennis/predict/action_detect/models/bmn_infer.py:66-87", "hash": "ba0792e830b1495d8f5b0348ea644bc7", "title": "Boundary Proposition Generator"}, "1259": {"path": "/applications/TableTennis/predict/action_detect/models/bmn_infer.py:88-112", "hash": "2c49fde5b09170481c6e6ebe8355881a", "title": "Boundary-Based Prediction Model"}, "1260": {"path": "/applications/TableTennis/predict/action_detect/models/bmn_infer.py:113-135", "hash": "6861da5a3b176f065491c5cb96bc08d3", "title": "Running Average Window Predictions"}, "1261": {"path": "/applications/TableTennis/predict/action_detect/models/bmn_infer.py:137-164", "hash": "e708d79ca8b20b2f59d3ac40d13bca10", "title": "BMN Infer Model Prediction"}, "1262": {"path": "/applications/TableTennis/predict/action_detect/models/lstm_infer.py", "hash": "61f49fa4011bf8cf63aea20684365897", "title": "LSTM-Based Table Tennis Action Detection"}, "1263": {"path": "/applications/TableTennis/predict/action_detect/models/lstm_infer.py:1-38", "hash": "a68bb081312e1133957919b718e066b9", "title": "LSTM Action Detection Model Inferencing"}, "1264": {"path": "/applications/TableTennis/predict/action_detect/models/lstm_infer.py:40-62", "hash": "c01c8f5b71d67d17f6800ca6678e1bff", "title": "LSTM Inferencing Setup"}, "1265": {"path": "/applications/TableTennis/predict/action_detect/models/lstm_infer.py:63-92", "hash": "704d2cf4c87c4a3f256c88239f7fa232", "title": "Table Tennis Action Detection Model"}, "1266": {"path": "/applications/TableTennis/predict/action_detect/models/lstm_infer.py:93-111", "hash": "3c44b1d03bdba0b51da6ecab2446a214", "title": "LSTM Action Detection Inference"}, "1267": {"path": "/applications/TableTennis/predict/action_detect/models/lstm_infer.py:113-136", "hash": "41b58faf8ab11d95addecb538d160f4f", "title": "LSTM-Based Table Tennis Action Detection"}, "1268": {"path": "/applications/TableTennis/predict/action_detect/models/lstm_infer.py:138-158", "hash": "d19d2b5f7a5c561a6eabccc3cff4a351", "title": "LSTM Predicts Table Tennis Action"}, "1269": {"path": "/applications/TableTennis/predict/action_detect/models/pptsm_infer.py", "hash": "4daba0d8c8459ad1f852dda1f9f04e99", "title": "PPTSM Inference with PaddlePaddle"}, "1270": {"path": "/applications/TableTennis/predict/action_detect/models/pptsm_infer.py:1-38", "hash": "29a38bfe92cc70fba93f8b35909caeae", "title": "Initialize PPTSM InferModel with PaddlePaddle"}, "1271": {"path": "/applications/TableTennis/predict/action_detect/models/pptsm_infer.py:40-68", "hash": "fa59ead75b04e90520a231ea316df989", "title": "InferModel Video Frame Inference"}, "1272": {"path": "/applications/TableTennis/predict/action_detect/models/pptsm_infer.py:69-77", "hash": "530bc4743cca1584885036b45291dca9", "title": "Efficient Image Inference and Prediction"}, "1273": {"path": "/applications/TableTennis/predict/action_detect/reader/__init__.py", "hash": "e80aa10801f2544132dd12590a368447", "title": "Alphabetical Reader Registration"}, "1274": {"path": "/applications/TableTennis/predict/action_detect/reader/bmninf_reader.py", "hash": "3ebc1f6bf2c5d5afdaafee58d2c6a29a", "title": "BMNINF Reader for Table Tennis"}, "1275": {"path": "/applications/TableTennis/predict/action_detect/reader/bmninf_reader.py:1-49", "hash": "6645052c4a5973d9cd292e1e74285713", "title": "BMNINF Reader for PaddleVideo"}, "1276": {"path": "/applications/TableTennis/predict/action_detect/reader/bmninf_reader.py:50-72", "hash": "fc9447c52d132ee3fd4d402a6266abc4", "title": "BMNINF Reader for Table Tennis"}, "1277": {"path": "/applications/TableTennis/predict/action_detect/reader/bmninf_reader.py:73-103", "hash": "b8ef4c607184227d424fe3fedaa38567", "title": "Video Analysis Dataset Creation Code"}, "1278": {"path": "/applications/TableTennis/predict/action_detect/reader/bmninf_reader.py:104-133", "hash": "5bf98e1c9cbd4b4be997920e649d2871", "title": "CTCN Model Reader for Table Tennis Action Detection"}, "1279": {"path": "/applications/TableTennis/predict/action_detect/reader/bmninf_reader.py:134-154", "hash": "acacfa735c775828f2ab13bb702c5781", "title": "Inference Reader: Iterating and Yielding Batches"}, "1280": {"path": "/applications/TableTennis/predict/action_detect/reader/feature_reader.py", "hash": "ea8814661b1e19367e995adc01a68929", "title": "Table Tennis Action Detection Reader"}, "1281": {"path": "/applications/TableTennis/predict/action_detect/reader/feature_reader.py:1-34", "hash": "3df0e1ef9a2b7a18dcfa3192fdc267a0", "title": "YouTube-8M Dataset Feature Reader"}, "1282": {"path": "/applications/TableTennis/predict/action_detect/reader/feature_reader.py:36-71", "hash": "4cf086e9919632ac1b6939bfa30c7919", "title": "Table Tennis Action Detector Feature Reader"}, "1283": {"path": "/applications/TableTennis/predict/action_detect/reader/feature_reader.py:72-91", "hash": "f90bba92e165376c4bae3c8c23cb9e2e", "title": "Feature Extractor: Table Tennis Action Prediction"}, "1284": {"path": "/applications/TableTennis/predict/action_detect/reader/reader_utils.py", "hash": "1cf7a67375551557c23d8fc74b80d8b8", "title": "Handling Errors in TableTennis Reader"}, "1285": {"path": "/applications/TableTennis/predict/action_detect/reader/reader_utils.py:1-33", "hash": "44ea3247f788801708aa83f0c6fab14c", "title": "Reader Error Handling in PaddleVideo TableTennis"}, "1286": {"path": "/applications/TableTennis/predict/action_detect/reader/reader_utils.py:34-81", "hash": "bec22c02be51f6889c4721ece66356d5", "title": "Video Reader Classes and Registry"}, "1287": {"path": "/applications/TableTennis/predict/action_detect/reader/reader_utils.py:82-107", "hash": "e5d5deec66afb3706010717423afa211", "title": "Singleton Reader Registration Utilities"}, "1288": {"path": "/applications/TableTennis/predict/action_detect/utils/config_utils.py", "hash": "3ad548cbc9d705a0ab69a545c42623fe", "title": "Config Utilities for TableTennis"}, "1289": {"path": "/applications/TableTennis/predict/action_detect/utils/config_utils.py:1-47", "hash": "8cbd019486bd442bb0529c84c679d41c", "title": "Config Utils for TableTennis"}, "1290": {"path": "/applications/TableTennis/predict/action_detect/utils/config_utils.py:48-80", "hash": "a6767b4b25cd43b1b7ce37b1f63ad8dd", "title": "Config Utils for AttrDict Manipulation"}, "1291": {"path": "/applications/TableTennis/predict/action_detect/utils/config_utils.py:81-81", "hash": "42b405179529f6092c96ffa42a2ec624", "title": "Context Changer Logging"}, "1292": {"path": "/applications/TableTennis/predict/action_detect/utils/preprocess.py", "hash": "cc39dd0af799de49f7c95e85d75d8198", "title": "Preprocess.py: Video, Audio, Image Toolkit"}, "1293": {"path": "/applications/TableTennis/predict/action_detect/utils/process_result.py", "hash": "9f3fc1e9815b047a61ae087d908fe6f8", "title": "One-Dimensional NMS for Video Analysis"}, "1294": {"path": "/applications/TableTennis/predict/action_detect/utils/process_result.py:1-39", "hash": "da8838534b17f2fb5e8e315f7154fa45", "title": "Video Action Detection Result Calculator"}, "1295": {"path": "/applications/TableTennis/predict/action_detect/utils/process_result.py:42-78", "hash": "6335272fc27ac8777649b51213e9ac80", "title": "Non-Maximal Suppression for Bounding Boxes"}, "1296": {"path": "/applications/TableTennis/predict/action_detect/utils/process_result.py:79-110", "hash": "d16babe93e6d3cfcb734a319454052ba", "title": "Efficient Video Property Processing and Classification"}, "1297": {"path": "/applications/TableTennis/predict/action_detect/utils/process_result.py:111-136", "hash": "e3a6763b8baca5c3e42beb216ea75003", "title": "Sorting Prop Filter Timestamps for Action Detection"}, "1298": {"path": "/applications/TableTennis/predict/action_detect/utils/process_result.py:137-155", "hash": "1b99eac94c589d2843861be0bc101faf", "title": "Non-Max Suppression Result Function"}, "1299": {"path": "/applications/TableTennis/predict/eval.py", "hash": "1fb8e078879c908529973c8216aca7a4", "title": "Optimized Table Tennis Predictions"}, "1300": {"path": "/applications/TableTennis/predict/eval.py:1-41", "hash": "4c2f49595b830a9360e89a2d535607bf", "title": "Loading and Processing Ground Truth Data"}, "1301": {"path": "/applications/TableTennis/predict/eval.py:42-73", "hash": "90ea47c2270434e5b23cc6723bf53624", "title": "Computer Vision Interval Union: Filter Proposals"}, "1302": {"path": "/applications/TableTennis/predict/eval.py:74-108", "hash": "4fbbdce86c407013f4540c9b4b314276", "title": "Converters for Boxes and Labels"}, "1303": {"path": "/applications/TableTennis/predict/eval.py:109-142", "hash": "73d4e0ac365db690a55976471d69a5a2", "title": "Evaluating Model Performance on Video Frames"}, "1304": {"path": "/applications/TableTennis/predict/eval.py:145-166", "hash": "0aa09a25c32f31b52ce68a95f784bf00", "title": "IoU-based Box Evaluation"}, "1305": {"path": "/applications/TableTennis/predict/eval.py:167-186", "hash": "90d8fb3304eaee5dbf4b54f5592e3a09", "title": "Precision-Recall Calculator"}, "1306": {"path": "/applications/TableTennis/predict/eval.py:187-210", "hash": "d9a22d379da23324e894209bcb75e82a", "title": "Table Tennis Prediction Model Evaluation"}, "1307": {"path": "/applications/TableTennis/predict/eval.py:212-239", "hash": "d75cfc7d847df2575de724919c9eef98", "title": "Table Tennis Video Analysis Model Evaluator"}, "1308": {"path": "/applications/TableTennis/predict/eval.py:240-270", "hash": "12078adb494ea9f65a0b42ebecf60970", "title": "Table Tennis Prediction Evaluation"}, "1309": {"path": "/applications/TableTennis/predict/eval.py:271-287", "hash": "ef2b51cee2c58030d8a809334b03a443", "title": "Optimizing IOU and Scores for F1 Evaluation"}, "1310": {"path": "/applications/TableTennis/predict/predict.py", "hash": "fa344d2aa345ab1013a9dae21dd11ce8", "title": "TableTennis Video Prediction"}, "1311": {"path": "/applications/TableTennis/predict/predict.py:1-35", "hash": "1e886a2e690f58e1c462a4e6cfd39630", "title": "Video Prediction Setup: PaddleVideo's TableTennis"}, "1312": {"path": "/applications/TableTennis/predict/predict.py:36-36", "hash": "e1e481cfaa70f445ad6d97b8715e623b", "title": "Saving Data to File"}, "1313": {"path": "/applications/TableTennis/val_split.py", "hash": "7e394ef2864eeac0738e68b8db01e749", "title": "JSON Split for Validation and Training Sets"}, "1314": {"path": "/applications/VideoQualityAssessment/README.md", "hash": "1a9aa48f48816c5357cec5b07e025400", "title": "PaddlePaddle 2.1 Video Quality Assessment Model"}, "1315": {"path": "/applications/VideoQualityAssessment/README.md:1-58", "hash": "39e89e979c8985131099444fcf296b99", "title": "Video Quality Assessment Model with PaddlePaddle"}, "1316": {"path": "/applications/VideoQualityAssessment/README.md:59-98", "hash": "9a890456fe343a2680e27ebc9511039b", "title": "Multigpu Distributed Training with PaddleVideo"}, "1317": {"path": "/applications/VideoQualityAssessment/README.md:101-144", "hash": "4f12de5dda7d26d9c920e5477c04d029", "title": "Epoch Analysis and Fine-tuning"}, "1318": {"path": "/applications/VideoQualityAssessment/README.md:145-179", "hash": "f080dff2404216752b99484dc2c6be67", "title": "PaddleVideo: TSM Regression for Video Quality"}, "1319": {"path": "/applications/VideoQualityAssessment/README.md:181-189", "hash": "75130cb72c39490b6667461f19b1a3ed", "title": "Video Quality Assessment with SROCC and PLCC"}, "1320": {"path": "/applications/VideoQualityAssessment/main.py", "hash": "bcb3e1b1dc1a0eaec7bcc4b82f5a0427", "title": "Video Quality Assessment Training and Testing with PaddleVideo"}, "1321": {"path": "/applications/VideoQualityAssessment/main.py:1-30", "hash": "c73533a0c478058cac1ab10abf8be3f1", "title": "Training Models with PaddleVideo"}, "1322": {"path": "/applications/VideoQualityAssessment/main.py:31-52", "hash": "747059b7041a2c0ed51539d9f6930e69", "title": "Command-Line Arguments for Video Quality Assessment"}, "1323": {"path": "/applications/VideoQualityAssessment/main.py:53-88", "hash": "b6a15b732e19caf5d73838c486566ce1", "title": "Command Line Args for Model Training and Testing"}, "1324": {"path": "/applications/VideoQualityAssessment/paddlevideo/__init__.py", "hash": "009ca96f7dacbeed46d40a860ce22cce", "title": "PaddleVideo License and Import"}, "1325": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/__init__.py", "hash": "271817cba2de0ccb76cfec66932d6a99", "title": "Video Dataset Loader for PaddleVideo"}, "1326": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/builder.py", "hash": "180ec5be148951be0f3aeab220a9a0e4", "title": "PaddleVideo Dataset Builder and Loader"}, "1327": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/builder.py:1-33", "hash": "6a8676fcc933b817121eb6543858b9cc", "title": "Video Pipeline Builder in Python"}, "1328": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/builder.py:34-74", "hash": "07ddf700828dddce60abd032aedf3531", "title": "Video Quality Assessment Dataset and Dataloader Builder"}, "1329": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/builder.py:75-97", "hash": "a0587a07e07cc25047720791510ea4fd", "title": "DistributedBatchSampler Creation"}, "1330": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/builder.py:99-126", "hash": "8c2f6dc02d2e0860741c5edaa9fec8e5", "title": "Create and Manage DataLoaders with Signal Handlers"}, "1331": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/__init__.py", "hash": "96e2d1dc05e5be2416fb58057c19d75c", "title": "Python Video Dataset Module"}, "1332": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/base.py", "hash": "d1de88ed1b4c93c4db41534b7acbbcf6", "title": "Video Dataset Loader Class"}, "1333": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/base.py:1-34", "hash": "086b0ea28e215d96ad5cb18c8fe54950", "title": "Base Dataset Class for Custom Loaders"}, "1334": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/base.py:36-62", "hash": "64614ea2e7b0a3ca6be7d32b86802a96", "title": "Video Index Loader Class"}, "1335": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/base.py:63-83", "hash": "df50ac335ccb3c2ac8d0770c7a11bcf2", "title": "Dataset Class with Train-Test Methods"}, "1336": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/frame_rec.py", "hash": "78dd426ff8e79de1a561da847f9dea07", "title": "Frame-Rec Dataset Loader for PaddleVideo"}, "1337": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/frame_rec.py:1-32", "hash": "9a864fcf32a710f9d99f88929264adf5", "title": "FrameRecDataset: PaddleVideo's Action Recognition Dataset"}, "1338": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/frame_rec.py:32-62", "hash": "0a79990418aa3806966103dc94b081d3", "title": "Video Index File Loader Class"}, "1339": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/frame_rec.py:63-88", "hash": "6c8d0413195eb2d8134194b09624e26f", "title": "Frame Dataset Preparer"}, "1340": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/frame_rec.py:89-110", "hash": "bd5bca0950ad2481b502d66172e142cf", "title": "Retry Loading Frames in Exception Handling"}, "1341": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py", "hash": "8c22f8cc709659c66a9c9a15cedaa2bf", "title": "PaddleVideo Dataset Loader"}, "1342": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py:1-32", "hash": "5c1602a2fdc4a7c9deeb75345c68dba0", "title": "Python Video Dataset Loader"}, "1343": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py:33-58", "hash": "8df1967a9bc974926e61ae353bc0329c", "title": "Video Dataset Loader Initialization"}, "1344": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py:59-81", "hash": "d0866574499c99fb740453ffc52259b7", "title": "Video Dataset Loader: Robust Read, Pipeline, and Testing"}, "1345": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/dataset/video.py:82-95", "hash": "3fc94efffbc0a1c217c4e885288162eb", "title": "Retry-Based Video File Reader"}, "1346": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/__init__.py", "hash": "1a0d88d0ba100a2c1c8d95c0babcac50", "title": "PaddleVideo Pipeline Modules"}, "1347": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/__init__.py:1-40", "hash": "263ab0578de7c0c9b638de77b534b2e8", "title": "PaddleVideo Loader Pipelines"}, "1348": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/__init__.py:41-50", "hash": "1133c8338e9fe3dcdc9b320c1ad0408b", "title": "PaddleVideo Pipeline Modules"}, "1349": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py", "hash": "2c7c06e54c0f6949744437bfb54629b8", "title": "Multi-Scale Image Augmentation in PaddleVideo"}, "1350": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:1-35", "hash": "c97f1607facb00da5dec52b41185002c", "title": "Scale Class for Image Resizing"}, "1351": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:36-61", "hash": "cd5ba2d5e201f70853aa9039162044cf", "title": "Preserve Aspect Ratio Resizing"}, "1352": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:62-95", "hash": "78d06ff1b62db331c0afee3534d871e5", "title": "Random Crop Pipeline for PaddleVideo"}, "1353": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:97-130", "hash": "aefb001e024bc7f3a7b5f7b8050c689f", "title": "Center Crop Image Augmentation"}, "1354": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:131-160", "hash": "7afa4a23d4bd6aa1f617fc181cd1b6dd", "title": "MultiScaleCrop: Image Resizing and Cropping"}, "1355": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:161-192", "hash": "4d951878e37f52f6a2b4dce16bcf0310", "title": "Random Crop Size Sampling"}, "1356": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:193-215", "hash": "e7a77305f997864c5c9264138c71c34b", "title": "Crop Position List Generator"}, "1357": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:216-247", "hash": "ca94e62ad0a32dd644a0b6374a77d4f3", "title": "Random Crop and Flip Augmentation"}, "1358": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:248-281", "hash": "f4a0943211b4466078af2b849aecfb05", "title": "Random Flip and Image Pipeline"}, "1359": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:282-310", "hash": "2e83fef5fe6e85281c12c46e2806c452", "title": "PIL Images to Numpy Array Augmentation"}, "1360": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:311-344", "hash": "fd09330c1ff3f1b44141daed688df323", "title": "Dynamic Image Scaling Augmentation"}, "1361": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:345-370", "hash": "1fbd91e5b97717d733cd686f7db08b1c", "title": "Jitter Resize and Random Scale Augmentation"}, "1362": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:371-403", "hash": "67472f99bd64628f160b52fe9f46401d", "title": "MultiCrop Image Resizer"}, "1363": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:404-430", "hash": "398a524543a3d697f4c6a3b3dfc1e7eb", "title": "Random Cropping Augmentation"}, "1364": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:431-452", "hash": "87a4a1197969682ce9958301aee86c8e", "title": "Image Cropping with Random Offsets"}, "1365": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:453-484", "hash": "412eedbf917ffb03e7d734263fd71eef", "title": "Image Crop and Append Function"}, "1366": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/augmentations.py:485-498", "hash": "27c91c057786cc824e672702d01da099", "title": "Slower Pathway Frame Selection"}, "1367": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/compose.py", "hash": "49e9aa50dbb405cf3ad59c8dac740dd4", "title": "Compose Class for Video Pipeline"}, "1368": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/compose.py:1-33", "hash": "086ec70eb9d0c62d4d80a00eaab5798e", "title": "Compose Class Pipeline"}, "1369": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/compose.py:34-61", "hash": "faf28522e72258a688091d5e09e4b597", "title": "Compose Class Sequentially Combines Transforms"}, "1370": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/compose.py:62-79", "hash": "70dd31918af6130abb0e5ea492de552c", "title": "Video Pipeline Composer"}, "1371": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/decode.py", "hash": "e0af7f275b1c2dece16e75c219c271b9", "title": "PaddleVideo: MP4 Decoding and Feature Extraction"}, "1372": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/decode.py:1-42", "hash": "ff53cc021fa903eb7952cbb2c8d4c106", "title": "PaddleVideo: MP4 Decoding"}, "1373": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/decode.py:43-80", "hash": "1557a977c8078c819391602e7ab46265", "title": "Multi-Decoder for Data Types"}, "1374": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/decode.py:81-113", "hash": "f038f329ab08c2481db1c0792b28a764", "title": "Decoding Pipeline for .pkl Files"}, "1375": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/decode.py:114-139", "hash": "916b219bd6d196a00c6a3e1406f379b5", "title": "Initialize Feature Paddings and Masks"}, "1376": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/decode.py:140-165", "hash": "7d859e577055785bc23bf463f762503a", "title": "Decode, Dequantize, One-Hot Labels"}, "1377": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/mix.py", "hash": "905af2eb67b6a7167bfb79f00589f8ac", "title": "Mixup for Video Quality Assessment"}, "1378": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/mix.py:1-36", "hash": "d3910f5902bad63002b74ef992f39a1d", "title": "Mixup for Video Quality Assessment"}, "1379": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/mix.py:37-72", "hash": "daa1d186e315213c5fe151b35265b0f0", "title": "Cutmix: Mixing Images and Labels in Datasets"}, "1380": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/mix.py:74-91", "hash": "84798e213023ce96a1420a5af2c224c8", "title": "Random Bounding Box Data Augmentation"}, "1381": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/sample.py", "hash": "bace34aa6d4422dbfa05a945d135949b", "title": "Custom Sampler for PIL-based Video Frames"}, "1382": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/sample.py:1-32", "hash": "b9e91da9a785d568b8efa5830bdbb507", "title": "Sampler: Efficient Video Frame Sampling"}, "1383": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/sample.py:33-70", "hash": "b599d5af712631fa4ecca48d872496f4", "title": "Sample Pipeline Class Definition"}, "1384": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/sample.py:71-96", "hash": "4ada42d1ea9befba36d48e370d473c44", "title": "Video Frame Index Calculator"}, "1385": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/pipelines/sample.py:97-102", "hash": "3fd943ce1f02fee8f84d4b4c6ecf5c4e", "title": "Frame Indexing in Video Loader"}, "1386": {"path": "/applications/VideoQualityAssessment/paddlevideo/loader/registry.py", "hash": "a312ad6f5e2761b580b30bf084fa90e5", "title": "PaddleVideo Registry Management"}, "1387": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/__init__.py", "hash": "b30dbab3c2a0b1aaa73ae2fc3ddf1bd9", "title": "Video Quality Assessment Metrics Initiation"}, "1388": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/base.py", "hash": "fd19f46e4be632e3ce4d6bee345ca315", "title": "BaseMetric: Foundation for Video Quality Metrics"}, "1389": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/base.py:1-36", "hash": "2645be2267d7aaac86a722cbbcd2b36b", "title": "Base Metric Class for Video Quality Assessment"}, "1390": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/base.py:37-39", "hash": "eb8959a36b1d82b9eb0028be013e0c81", "title": "Base Class Accumulate Method"}, "1391": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/build.py", "hash": "1335e2fdd322045e27c0d41ba098206d", "title": "PaddleVideo Metric Builder"}, "1392": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/quality_metric.py", "hash": "cabb18365957ed89a5c56fc9aba4c922", "title": "Pearson and Spearman Correlation Metric"}, "1393": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/quality_metric.py:1-35", "hash": "fcbba15682443df0cd1d6ea219fc0bb1", "title": "Video Quality Metric Class Definition"}, "1394": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/quality_metric.py:36-62", "hash": "3080da7ba4b21ba59d5327ed2c930c70", "title": "Pearson and Spearman Correlation Calculator Class"}, "1395": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/quality_metric.py:64-72", "hash": "bf880ab1e34b72c5a7404e34a002a316", "title": "Calculate PLCC and SROCC from Output and Label Pair"}, "1396": {"path": "/applications/VideoQualityAssessment/paddlevideo/metrics/registry.py", "hash": "ee90d4e36fd327578b4c5eaa81f0d350", "title": "PaddleVideo Metrics Registry"}, "1397": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/__init__.py", "hash": "9056ed690005965067f2a6923f12b2e8", "title": "PaddleVideo Modeling"}, "1398": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/__init__.py:1-24", "hash": "a3eb8d9db754ae9555befe158ff533a4", "title": "Universal Model Registration"}, "1399": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/__init__.py:26-45", "hash": "c2b4acc3dd0c8ce53f678bb90c869e29", "title": "Video Model Building Toolkit"}, "1400": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/__init__.py", "hash": "2b46a96824ad00d7b43582d740157e48", "title": "ResNet and ResNetTweaksTSM Imported"}, "1401": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py", "hash": "88da5f08cb869a57f68574aeb6efd71c", "title": "Dynamically Configurable ResNet Backbone"}, "1402": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:1-35", "hash": "29c7f811707199d730fa146bd0caf284", "title": "ConvBNLayer: PaddlePaddle Backbone Customization"}, "1403": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:36-58", "hash": "97d4171e438232b0f369ad51aec68742", "title": "ConvBNLayer Class Definition"}, "1404": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:59-89", "hash": "02d19295275c95ba854e76609e6ebcc5", "title": "ResNet Convolutional Layer Design"}, "1405": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:90-113", "hash": "052eb1da6d39995bd7d9d824850a3506", "title": "Bottleneck Block Construction in PaddleVideo"}, "1406": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:114-146", "hash": "640c6b62f05ccc2eb5d6523cbc90b3f1", "title": "Convolutional Neural Network BasicBlock"}, "1407": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:147-174", "hash": "a3917b6aa490d7c5262ce6ee592006ec", "title": "ResNet Forward Function Definition"}, "1408": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:175-210", "hash": "e1937759298b445a3829d5d17ebde5ce", "title": "ResNet Backbone Creator"}, "1409": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:211-232", "hash": "a6d6840f4092581f601c377f966fe365", "title": "ResNet Model Definition"}, "1410": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:233-252", "hash": "ec22b724f69bc25b9e31ce03cf09073a", "title": "Dynamic ResNet Model Architecture"}, "1411": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:253-270", "hash": "0d2fb4a6b482488f91d4bcd1c4b41030", "title": "Backbone Model Weight Initialization"}, "1412": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet.py:271-290", "hash": "3e3bd9982244fd36e6f27389fc54b973", "title": "Forward Pass for Backbone: Conv and Pooling"}, "1413": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py", "hash": "654222887c82712c6619466c3323bcef", "title": "TSM-ResNet-C Model"}, "1414": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:1-34", "hash": "dff2e1f3a22049c42aa0366df4b8bc5b", "title": "ConvBNLayer: Convolutional BatchNorm Layer"}, "1415": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:36-60", "hash": "9cce8b484957dca98ca62602fa50b490", "title": "ConvBNLayer: Batch Normalization and Activation Layer"}, "1416": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:61-85", "hash": "29c2cf0e18cea7df1106d2d8ee98d22b", "title": "TSM ResNet Backbone Definition"}, "1417": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:86-114", "hash": "b83c9c06d6a6a203c4bf440c7f32b880", "title": "Bottleneck Block in ResNet Model"}, "1418": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:115-140", "hash": "e26511fc4e07ec8ba4103f3d01999320", "title": "Custom ResNet-D Layer with Optional Pooling"}, "1419": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:141-170", "hash": "629665bb179f2a478041e4525d96454c", "title": "TSM Convolutional Block with Shortcut Connection"}, "1420": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:171-206", "hash": "70104addbf817ecd98cc5a5ce1ca21c3", "title": "ResNet TSM Backbone with Shortcuts"}, "1421": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:207-235", "hash": "8902043e6020fb88ac54c269874102c0", "title": "ResNetTweaksTSM Instance Initialization"}, "1422": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:236-258", "hash": "354bb1e5446cb48e08311b1674d931cb", "title": "TSM-ResNet Backbone Definition"}, "1423": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:259-278", "hash": "622665f93d970b95323f07a1ccf0e616", "title": "TSM ResNet Model Builder"}, "1424": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:279-297", "hash": "9b5a944e27e8c1f2a255cff6b5c0ec7c", "title": "ResNet Weights Initialization"}, "1425": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:297-317", "hash": "c2e8e9663c3a91ec54b0314062bcd8ca", "title": "Initializing Backbone for Video Quality Assessment"}, "1426": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:318-328", "hash": "7873b1f99655b51417906aa23b7c23f8", "title": "ResNet-C Backbone for Video Quality"}, "1427": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/builder.py", "hash": "0d7be2035e3789c744dcd3d6f3a6d819", "title": "Computer Vision Model Builders"}, "1428": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/builder.py:1-36", "hash": "6ff4abd0b1e4fe47956f9be0b2c1e28d", "title": "Building Computer Vision Model Components"}, "1429": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/builder.py:39-52", "hash": "de08fe385e3c808abc1bdecbe6240c14", "title": "Building Localizer and Model Functions"}, "1430": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/__init__.py", "hash": "df1e5d9adf1eaa5b6f6ee69f0f19103e", "title": "Importing Recognizers for Video Modeling"}, "1431": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/__init__.py", "hash": "d3c62b0746c8599c92b1ed960d7469fc", "title": "Importing Recognizers in Video Framework"}, "1432": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/base.py", "hash": "25bbbe5d2d22984ec79e5483835aadfa", "title": "Base Recognizer Class for PaddleVideo"}, "1433": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/base.py:1-38", "hash": "8d1b92020590839a99fdea989e629010", "title": "Base Recognizer: Train, Validate, Test Init"}, "1434": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/base.py:39-75", "hash": "99df2497584dad339a865c644a0e07ed", "title": "Base Model Recognizer Initialization"}, "1435": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/base.py:76-97", "hash": "6f9129d3f977e33db92de221f0fa95ff", "title": "Abstract Recognizer Model Base Class"}, "1436": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/recognizer2d.py", "hash": "fce895b58badfb24a396eceb6f3f0695", "title": "Training Recognizer2D for 2D Models"}, "1437": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/recognizer2d.py:1-29", "hash": "c4ad2e041c612c3a4989d1a1fc2802d7", "title": "PaddleVideo's 2D Recognizer Model Training"}, "1438": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/framework/recognizers/recognizer2d.py:31-52", "hash": "08043deddbd1aed5fe29d50b7f2c4ac2", "title": "Recognizer2D: Validation and Test Methods"}, "1439": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/__init__.py", "hash": "ff93c75b0c0e5f936c1c621f1c61607c", "title": "PaddleVideo Heads for Video Quality Assessment"}, "1440": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/base.py", "hash": "792596d1dacf82b8316c6835fe8a14b0", "title": "VideoQualityAssessment BaseHead Class"}, "1441": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/base.py:1-36", "hash": "57235a6c5fcd6b43a0117af622f36f10", "title": "PaddleVideo BaseHead Class Definition"}, "1442": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/base.py:37-67", "hash": "d2223b844526405901daddb77c7d8953", "title": "BaseHead: Initializing PaddleVideo's Head Network"}, "1443": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/base.py:69-96", "hash": "26591804bd8e2c60fb45a7ad0c59593f", "title": "VideoQualityAssessment Base Head Definition"}, "1444": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/base.py:97-120", "hash": "3cdb297b9155fda69049275cda3f8183", "title": "Label Smoothing Loss Calculator"}, "1445": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/base.py:121-143", "hash": "3b5b15513609f6a6080abf448668ded0", "title": "Label Smooth Loss and Accuracy Functions"}, "1446": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsm_rec_head.py", "hash": "9c63f670c0a9f33cba293b97d6ac743b", "title": "TSM Recurrent Head: TSN-Based Classifier for Video QA"}, "1447": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsm_rec_head.py:1-33", "hash": "e09feb4a425dc34f75d5d64dddc22e9b", "title": "TSM RecHead: TSN-Based Classifier for TSMs"}, "1448": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsm_rec_head.py:34-62", "hash": "7cce04a11d600c4b9dd009337b19f9a8", "title": "Uniform Weights Initialization for FC Layer"}, "1449": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsm_rec_head.py:63-91", "hash": "06d5bee6a82895cdcb7e4d3bceb3a5cd", "title": "TSM Recognition Head Definition"}, "1450": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsm_rec_head.py:92-122", "hash": "5260c180aa2166cd3b4b295fec1ccff1", "title": "Loss Function for Score Prediction Model"}, "1451": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsm_rec_head.py:123-149", "hash": "29176d771b6523864abd738378d1b1c1", "title": "Loss Calculation for TSM-REC Head"}, "1452": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsm_rec_head.py:150-153", "hash": "bb6f256ebcda3f004cbfdcc52ecbb609", "title": "Squeeze and Label Smooth Loss Calculation"}, "1453": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsn_head.py", "hash": "bfb31dc7ad91ac72ae410aeeb44bce28", "title": "TSN Head: Video Quality Assessment"}, "1454": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsn_head.py:1-31", "hash": "2034b3e9285f8322145b405979c67180", "title": "TSN Head: PaddlePaddle Video Quality Assessment"}, "1455": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsn_head.py:32-64", "hash": "dd5e8b038a74fe3636b88110bfc50116", "title": "Image Classification Head with GAP and Dropout"}, "1456": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsn_head.py:65-96", "hash": "ff95d076590704fadc38d28799c407b5", "title": "Forward Pass Function for Neural Network Head"}, "1457": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/heads/tsn_head.py:97-97", "hash": "aee4831a79739a3e74b2745cd96e5a0a", "title": "Return Calculated Score"}, "1458": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/__init__.py", "hash": "89d694f7ba12e86564cdb7cfa60b4d39", "title": "PaddleVideo Loss Functions"}, "1459": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/base.py", "hash": "8fcff239ea631b0edc04c334fa9c124d", "title": "Base Loss Function in PaddleVideo"}, "1460": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/base.py:1-33", "hash": "ac9b38b3d243566dfdd27ed8c6104f5c", "title": "Base Loss Function in PaddleVideo"}, "1461": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/base.py:34-51", "hash": "515d71faec4f3a82fef7edeff0d495c0", "title": "Abstract Loss Function Base Class"}, "1462": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/l1_loss.py", "hash": "6630bf556d88f5cff1dbb07f520caadf", "title": "L1 Loss for Video Quality"}, "1463": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/l1_loss.py:1-33", "hash": "834cd3b336a62f15f9ec7ec299c8ab08", "title": "L1 Loss for Video Quality"}, "1464": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/l1_loss.py:34-38", "hash": "56ab626d7b2ac32cfd6a761e8876a772", "title": "L1 Loss Calculator"}, "1465": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/smooth_l1_loss.py", "hash": "d3c21bd708dd0dc7f38ef72523e5be33", "title": "Custom SmoothL1 Loss in Video Quality Assessment"}, "1466": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/smooth_l1_loss.py:1-33", "hash": "779cc57e98eec524a4612720b9142159", "title": "Custom Smooth L1 Loss Function"}, "1467": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/losses/smooth_l1_loss.py:34-39", "hash": "7ecef77c2631770efa5225f0bb741628", "title": "Smooth L1 Loss Calculation"}, "1468": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/registry.py", "hash": "2239c3a5ce78d21d40203d506804d79e", "title": "Model Registry in PaddleVideo's Video Quality Assessment"}, "1469": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/weight_init.py", "hash": "f936096a9957982375e000db703092ec", "title": "Weight Initialization in PaddlePaddle"}, "1470": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/weight_init.py:1-36", "hash": "d3026a66e0467d65d1d51f0a52e2b1d7", "title": "Weight Initialization in PaddlePaddle Layers"}, "1471": {"path": "/applications/VideoQualityAssessment/paddlevideo/modeling/weight_init.py:37-55", "hash": "a75ee2a521bbdb217d0bcc73ee08bdeb", "title": "Neural Network Weight Initialization"}, "1472": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/__init__.py", "hash": "ca932b3b14098f24391c0376697f2272", "title": "Video Quality Assessment Optimizer"}, "1473": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py", "hash": "63e95afb7c32f70b3905376de20f52b3", "title": "Custom Learning Rate Schedulers for PaddleVideo"}, "1474": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:1-33", "hash": "2ee153163b3a22639123e012730fb230", "title": "CustomWarmupCosineDecay Scheduler"}, "1475": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:34-55", "hash": "e58b82c334cca50977e08a743364c1df", "title": "Customizable Learning Rate Scheduler"}, "1476": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:56-81", "hash": "1f2402ff7597771c1c723f285cbfed57", "title": "CustomWarmupCosineDecay: Cosine Decay Learning Rate Optimizer"}, "1477": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:82-108", "hash": "af75182f1f399acaa299107cd3e3e234", "title": "Warmup-Cosine LR Scheduler for Video Quality"}, "1478": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:109-134", "hash": "05276312e44d8a5dc809800c13890c0c", "title": "Customizable Learning Rate Scheduler"}, "1479": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:135-160", "hash": "3971fde25375d3b95c1c22bd67d83e51", "title": "Custom Learning Rate Scheduler for Optimizers"}, "1480": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:161-196", "hash": "13e4c2d4850010851ac691fb3eb33aea", "title": "Custom Learning Rate Scheduler for PaddleVideo"}, "1481": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/custom_lr.py:197-201", "hash": "a4060b42ce0f1d678e644e0d28e41d5f", "title": "Custom Learning Rate Scheduler"}, "1482": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/lr.py", "hash": "1149ca3e17e9af94d457bc19cac3ef0a", "title": "VideoQualityAssessment LR Scheduler"}, "1483": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/lr.py:1-33", "hash": "f880fcd799f1820615ed596b48d61ac9", "title": "Learning Rate Scheduler Builder"}, "1484": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/lr.py:35-49", "hash": "43646cfc2599bf675f80b36277bd8779", "title": "Learning Rate Configurer"}, "1485": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/optimizer.py", "hash": "59472e93ced58a78ac0b8141922aec16", "title": "Weight Decay Optimizer Scheduler"}, "1486": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/optimizer.py:1-36", "hash": "a71bd772c29ebb9b3a15b53b82a1d439", "title": "Configurable Optimizer Builder\n\nTitle within 3 to 7 words: Configurable Optimizer Builder"}, "1487": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/optimizer.py:37-68", "hash": "c002bd389147b64f6486074e0ee6a7a7", "title": "Adam Optimizer with L2Decay and L1Decay Regularization"}, "1488": {"path": "/applications/VideoQualityAssessment/paddlevideo/solver/optimizer.py:69-79", "hash": "6b5f1ef93f35a74006b352bb9d6a0b33", "title": "Weight Decay Optimizer Configurator"}, "1489": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/__init__.py", "hash": "30445fa3b5e2b3ea1cebddbcec743d69", "title": "Training and Testing Functions"}, "1490": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/test.py", "hash": "1980ce1b7e2d15f94bab6854e2add6df", "title": "Paddle Video Testing with Multi-Card Datasets"}, "1491": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/test.py:1-35", "hash": "4c690aaf19ac77c9310f28a166280cc0", "title": "Test Model Using Paddle Framework"}, "1492": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/test.py:36-66", "hash": "a6c3fd44b716042e12e5474c153d393a", "title": "Multi-Card GPU Model Training"}, "1493": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/test.py:67-78", "hash": "bd8b36851fc5935e13d81d288b57902d", "title": "Batch Size, Metric Building, Iteration & Accumulation"}, "1494": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py", "hash": "e0db0db8f80e051bb038fe5155ad327b", "title": "Efficient Video Quality Assessment Training with PaddleVideo"}, "1495": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:1-28", "hash": "fd2c94dad2538f61872e2df993678478", "title": "Video Quality Assessment with PaddleVideo"}, "1496": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:29-61", "hash": "91bec0655f7b97b7ab9aa38c2829f4f2", "title": "GPU-Accelerated Model Training"}, "1497": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:62-89", "hash": "5c5cff0b795476c5caebea4f42f8bda1", "title": "Efficient Model Training Setup"}, "1498": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:90-113", "hash": "8a86e4562395988e2db32b9aade6d546", "title": "Resume Training with Data Loader and Optimizer"}, "1499": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:114-147", "hash": "782922fb64dd8cf18c6a3798c705eb5a", "title": "Training Model Iteration"}, "1500": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:148-171", "hash": "cb7d3a5bb1b4aaa1ad36a75a98d9b9df", "title": "Model Training Step in Video Quality Assessment"}, "1501": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:173-198", "hash": "e25d32b55af7d086e2df5985f1ee2c0a", "title": "Backward Propagation Optimizer"}, "1502": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:199-229", "hash": "3f753dc07d986c56e6fdd56b183eebe3", "title": "Training Video Quality Model: Update Learning Rate"}, "1503": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:230-254", "hash": "a8a7945444fbd460ce62c210257cf134", "title": "Validation Metrics Updater"}, "1504": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:255-276", "hash": "41c15f3d83bc2f0ed29e7d108becf923", "title": "Optimizer and Model State Saver"}, "1505": {"path": "/applications/VideoQualityAssessment/paddlevideo/tasks/train.py:278-295", "hash": "32f3da58eb7eb661ca7711aa95e32dcf", "title": "Model Validation and Saving in Training Process"}, "1506": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/__init__.py", "hash": "89548a651b0a623fb6c8aa5fc54690c6", "title": "PaddleVideo Utilities Module"}, "1507": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/build_utils.py", "hash": "3c23259bbff56c40854c5425b7845402", "title": "Python Config Module Builder"}, "1508": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/build_utils.py:1-30", "hash": "1e2d80d516362e050f59245618913ea6", "title": "Build Module from Config"}, "1509": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/build_utils.py:32-36", "hash": "79fe22bf5c9b7bfeb4cc938b6364c21a", "title": "Retrieve and Instantiate Object Classes from Registry"}, "1510": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/config.py", "hash": "6a38c1183db117403f01c4664518a54b", "title": "Config Management in PaddleVideo"}, "1511": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/config.py:1-35", "hash": "22d6c733e5f058eec90ce1aea770f855", "title": "PaddleVideo Config Class & Logger"}, "1512": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/config.py:38-71", "hash": "c76364d656b8a1d72c26abe604ae8e9b", "title": "Config Parser Functions"}, "1513": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/config.py:72-110", "hash": "98ef66a21b2a7e489234e21ae2e7896f", "title": "Config File Utilities"}, "1514": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/config.py:111-142", "hash": "5912b06a97e117f2a7befd0b98ca8cdc", "title": "Config Override Function"}, "1515": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/config.py:143-174", "hash": "a1cf7d107eabc62aa75b6beea96d93ef", "title": "Config Override Function"}, "1516": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/config.py:175-180", "hash": "8df73a0a96389348ae5a4618a79fa15d", "title": "Config Parser and Validator"}, "1517": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/dist_utils.py", "hash": "e0cdddedb9226731605f52ed2cd5471c", "title": "Distributed Computation Utilities"}, "1518": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/dist_utils.py:1-35", "hash": "63eb0ff6b978aa6becd2f040b980ca74", "title": "Distributed Computation Utilities"}, "1519": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/dist_utils.py:36-36", "hash": "0066016f4fdbaa655a182e5e20bcc486", "title": "Returning Modified Objects"}, "1520": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/logger.py", "hash": "3ea64a782c24febea31215b3ebebc7ec", "title": "Distributed Logger for PaddleVideo"}, "1521": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/logger.py:1-40", "hash": "aac067a414805c913dec4f49af497869", "title": "PaddleVideo's Logger Class"}, "1522": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/logger.py:41-74", "hash": "c3b4f2ab38310801767f75057ffb1179", "title": "Initialize PaddleVideo Logger"}, "1523": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/logger.py:75-103", "hash": "0bb4d1a06835c61f9817ed654fe47bb0", "title": "Distributed App Logging Config"}, "1524": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/logger.py:104-117", "hash": "97fdeca9a1820437c900970ed33104de", "title": "Setup and Retrieve Logger"}, "1525": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/precise_bn.py", "hash": "5ce109fc47bbbfaa109bdd6798af4c1c", "title": "Precise Batch Normalization Update"}, "1526": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/precise_bn.py:1-31", "hash": "7d272fc737f40bb801d1fcd09793a367", "title": "Precise Batch Normalization for PaddleVideo"}, "1527": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/precise_bn.py:32-55", "hash": "901cbb8af2cb1fdd7c1f380bf28b031f", "title": "Precise BN Stats for Improved Validation"}, "1528": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/precise_bn.py:56-82", "hash": "b2972dd7691b867d78733e12dddff771", "title": "Precise Batch Normalization Accumulation"}, "1529": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/precise_bn.py:83-84", "hash": "c89ad2834c8b121f0aace6971731d763", "title": "Dynamic Batch Normalization Update"}, "1530": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/record.py", "hash": "c56fa3f4c0b16e2946c85537d0a64a5b", "title": "Training Metrics Logger"}, "1531": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/record.py:1-29", "hash": "0f90873be9196f562840b850ecfe0b6a", "title": "Building Record List for PaddleVideo"}, "1532": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/record.py:30-51", "hash": "9951931d31102c7281b0cb93cb154773", "title": "Building Record List for Metric Tracking"}, "1533": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/record.py:52-90", "hash": "aa2f6a4cad65f0b86129724c21cf67ce", "title": "Record List and Average Meter Definition"}, "1534": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/record.py:91-115", "hash": "6d576b4ccd9f3e631d0d6cc84a721680", "title": "Batch and Epoch Metric Logger"}, "1535": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/record.py:117-122", "hash": "9778ef7d726f3a7398ae952261d3263d", "title": "Epoch Logger with Color Coding"}, "1536": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/registry.py", "hash": "347c71f8273cfc36338fc2dd3d7ac8fc", "title": "Registry-Based Module Customization"}, "1537": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/registry.py:1-35", "hash": "0b950c7011f77e0bb9101deedc14227a", "title": "Registry for Customizable Modules"}, "1538": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/registry.py:37-72", "hash": "542715d8799b825d83813f274a200495", "title": "Registry Class for Building Modules"}, "1539": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/registry.py:73-98", "hash": "b38e5b62d02dfa758856b3904f8b46b1", "title": "Registry Class and Function Registration"}, "1540": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/save_load.py", "hash": "3ca01f4097422a347e1332844b4f7eb8", "title": "Save/Load Weights Utilities"}, "1541": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/save_load.py:1-37", "hash": "7cf10193c2440861e64380a62d080d8e", "title": "Load Checkpoint for Video Quality Assessment"}, "1542": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/save_load.py:38-63", "hash": "ddf7120aa09b20df86b93bd2d215f387", "title": "Loading Checkpoint Weights in Paddle"}, "1543": {"path": "/applications/VideoQualityAssessment/paddlevideo/utils/save_load.py:64-87", "hash": "4df47b949ade28584e84d3229bc617fb", "title": "Paddle Save, Load, and Create Directory Functions"}, "1544": {"path": "/applications/VideoQualityAssessment/paddlevideo/version.py", "hash": "95ac075b24d8b9990f61532a65a4a733", "title": "PaddleVideo Version Info"}, "1545": {"path": "/applications/VideoQualityAssessment/run.sh", "hash": "c6186ae37117ed34988d05dd4f1b5d31", "title": "TSM Model Training in PaddlePaddle"}, "1546": {"path": "/applications/VideoQualityAssessment/run.sh:1-19", "hash": "b7adf6b24dcb5098078eb0850ae634f6", "title": "CUDA-PaddlePaddle Shell Script"}, "1547": {"path": "/applications/VideoQualityAssessment/run.sh:20-20", "hash": "44a6089bdd9bd9ff7f8ee641f5c722aa", "title": "Custom Predict Model with Disabled Benchmarking"}, "1548": {"path": "/applications/VideoQualityAssessment/save_model.sh", "hash": "46996602fb17596940c2c78a93876a40", "title": "Export Best Model for Video Quality Assessment"}, "1549": {"path": "/applications/VideoQualityAssessment/setup.py", "hash": "d81b40bd9b3b882ae68b3e27e0ed077a", "title": "PaddleVideo: Video Analysis Toolkit"}, "1550": {"path": "/applications/VideoQualityAssessment/setup.py:1-34", "hash": "f3f41a07826de5c4f626256302ff01fa", "title": "Setting Up PaddleVideo Package"}, "1551": {"path": "/applications/VideoQualityAssessment/setup.py:35-56", "hash": "fe67522ff5cc9e941969a7f0d5e5a100", "title": "ppvideo: PaddlePaddle-Based Video Package Setup"}, "1552": {"path": "/applications/VideoQualityAssessment/setup.py:57-57", "hash": "4d9f2430b04cc15798a6e89028e52bfa", "title": "Creating Empty Tuple"}, "1553": {"path": "/applications/VideoTag/FineTune.md", "hash": "53c69f401eff3719b9cfa3325631f347", "title": "Fine-Tuning VideoTag: AttentionLSTM & TSN"}, "1554": {"path": "/applications/VideoTag/FineTune.md:1-32", "hash": "6cb43bd2846a2528a62490cc5ca0456c", "title": "Fine-Tuning VideoTag Models"}, "1555": {"path": "/applications/VideoTag/FineTune.md:34-81", "hash": "da4e2e2f5fb851708cf5b181ad5800d8", "title": "TSN Features Extraction and AttentionLSTM Fine-tuning"}, "1556": {"path": "/applications/VideoTag/FineTune.md:83-113", "hash": "f558887f1d2cb2329ec2dcd8141c8d5c", "title": "Fine-tuning AttentionLSTM in VideoTag"}, "1557": {"path": "/applications/VideoTag/FineTune.md:115-152", "hash": "35f2349f0e6bb7e36ae118d6cdead774", "title": "PaddleVideo Fine-Tuning Guide"}, "1558": {"path": "/applications/VideoTag/FineTune.md:153-188", "hash": "cfd693f6a8b34d4c96b105bb5a670559", "title": "TSN Model Training, Evaluation and Prediction"}, "1559": {"path": "/applications/VideoTag/FineTune.md:190-206", "hash": "0091aeddce8735626702687e8c386496", "title": "Preparing Data for TSN and AttentionLSTM"}, "1560": {"path": "/applications/VideoTag/README.md", "hash": "affe37ce7d65bfec8881a2e388f73817", "title": "Large-scale Video Classification with PaddlePaddle"}, "1561": {"path": "/applications/VideoTag/Run.md", "hash": "16f6ca4fc2c2427b1c07c868120672cc", "title": "VideoTag App Installation and Usage"}, "1562": {"path": "/applications/VideoTag/Run.md:1-54", "hash": "7b9fdc303dcfd2b32e0be23c1dd83c28", "title": "Install and Prepare Data for VideoTag"}, "1563": {"path": "/applications/VideoTag/Run.md:55-105", "hash": "098acda81a4232f8b75f10e7fbd6bbe6", "title": "Video Tag Testing Guide"}, "1564": {"path": "/applications/VideoTag/Run.md:106-109", "hash": "f5c9f264a7049c309da734c7a26487a9", "title": "Video Classification Dictionary"}, "1565": {"path": "/applications/VideoTag/Test.md", "hash": "134ad72acf76fe346ff0fd6435b25c52", "title": "VideoTag Testing Guide"}, "1566": {"path": "/applications/VideoTag/eval.py", "hash": "d716750360b7ba61b55fb51d87fae2e8", "title": "PaddlePaddle Evaluation Setup"}, "1567": {"path": "/applications/VideoTag/eval.py:1-33", "hash": "ec2d061046f2bd6f71351234870c848f", "title": "Setting Up PaddlePaddle Application Environment"}, "1568": {"path": "/applications/VideoTag/eval.py:34-64", "hash": "2c988cc4a458d34b58c49d381a3d5ebd", "title": "Command Line Argument Parser Function"}, "1569": {"path": "/applications/VideoTag/eval.py:65-95", "hash": "11663a7f4a610f55659db484cb33fcb3", "title": "Test Model Evaluation Function"}, "1570": {"path": "/applications/VideoTag/eval.py:96-122", "hash": "c2c3ef36416a1c958328e6c4cae752d0", "title": "Batch-by-batch Model Evaluation and Metrics"}, "1571": {"path": "/applications/VideoTag/eval.py:123-134", "hash": "c5768bd1fd4e616bd7fd675a7df58466", "title": "Automating Paddle Test Metrics and GPU Checks"}, "1572": {"path": "/applications/VideoTag/metrics/__init__.py", "hash": "72caeea884f99f4ccb4f5b1b35f6c4ff", "title": "Import Metrics Function for Video Analysis"}, "1573": {"path": "/applications/VideoTag/metrics/kinetics/accuracy_metrics.py", "hash": "677ea02c9627937841eeaa2073f86c50", "title": "AccuracyMetrics Calculator"}, "1574": {"path": "/applications/VideoTag/metrics/kinetics/accuracy_metrics.py:1-34", "hash": "56c84620c2edf55bd93d1ce80e31e2fb", "title": "PaddleVideo MetricsCalculator Class"}, "1575": {"path": "/applications/VideoTag/metrics/kinetics/accuracy_metrics.py:35-62", "hash": "ca89daa2cbbfc876f668b70d653bb8a1", "title": "Accuracy Metrics Computation"}, "1576": {"path": "/applications/VideoTag/metrics/kinetics/accuracy_metrics.py:63-90", "hash": "12a799794e81385f27c1a481f6000d44", "title": "Average Loss and Accuracy Metrics"}, "1577": {"path": "/applications/VideoTag/metrics/kinetics/accuracy_metrics.py:92-107", "hash": "92bea9f41accc85cc4804ec900d337c6", "title": "Top-K Accuracy Metric"}, "1578": {"path": "/applications/VideoTag/metrics/metrics_util.py", "hash": "98671b37115c597b8648fa8946aa8749", "title": "Video Metrics Evaluator Class"}, "1579": {"path": "/applications/VideoTag/metrics/metrics_util.py:1-33", "hash": "ff37a28056d8b536b7a384938c1114ef", "title": "Video Metrics Evaluation Utilities"}, "1580": {"path": "/applications/VideoTag/metrics/metrics_util.py:34-69", "hash": "65afe446a499a98d2440358f98ce0da2", "title": "Youtube8m Metrics Calculation"}, "1581": {"path": "/applications/VideoTag/metrics/metrics_util.py:70-90", "hash": "cd42ec15caf0140dfb4699f0a2a4fb47", "title": "Accumulating Metrics for Video Tagging"}, "1582": {"path": "/applications/VideoTag/metrics/metrics_util.py:92-113", "hash": "53b26f42aebc8c11dcd7973ed5d57d87", "title": "VideoTag: Logging Final Results for Each Video"}, "1583": {"path": "/applications/VideoTag/metrics/metrics_util.py:114-135", "hash": "932a19611d4f6d8411b0e769ffcb2c37", "title": "Video Tagging Metrics Calculator"}, "1584": {"path": "/applications/VideoTag/metrics/metrics_util.py:138-163", "hash": "664512b7281a6c996558b79d63a39906", "title": "Kinetics400 Metrics Calculator"}, "1585": {"path": "/applications/VideoTag/metrics/metrics_util.py:164-187", "hash": "f26bc5bcf650ef978704de6e46ccdaf4", "title": "Evaluate Video Predictions and Losses"}, "1586": {"path": "/applications/VideoTag/metrics/metrics_util.py:188-210", "hash": "62784b4d5d32f32731562f9771d72727", "title": "Infer Results Printer Function"}, "1587": {"path": "/applications/VideoTag/metrics/metrics_util.py:212-237", "hash": "91a786c642233a3b9ebe526dae10ac45", "title": "Metrics Utilities: Save, Calculate, and Log"}, "1588": {"path": "/applications/VideoTag/metrics/metrics_util.py:238-278", "hash": "20e1a9e27432ea9dd71f844054f7ec1b", "title": "MetricsZoo Class for Metrics Management"}, "1589": {"path": "/applications/VideoTag/metrics/metrics_util.py:279-279", "hash": "6c93cc00e676d9d4918cba3f4676af88", "title": "Registering TSN Metric"}, "1590": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py", "hash": "496e07c367316dea02129f6c9866d303", "title": "Interpolated Average Precision Calculator"}, "1591": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:1-23", "hash": "d6445d1b440eec05e6c95f741aa8e864", "title": "Interpolated Average Precision Calculator"}, "1592": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:25-55", "hash": "584a49984d26cb597b8affe133ba9aed", "title": "Interpolated Average Precision Calculator"}, "1593": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:57-86", "hash": "db7db67821fcde5ce348b3a546ab813a", "title": "Average Precision Calculator Class"}, "1594": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:87-108", "hash": "083d2314411f46f8b54b8489dc9ba991", "title": "Average Precision Calculator"}, "1595": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:109-134", "hash": "eb327d3285328733190d44849895a266", "title": "Average Precision Calculator"}, "1596": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:136-166", "hash": "69cfef1223ce2584bc56f8c0d3544686", "title": "Non-Interpolated Average Precision Calculator"}, "1597": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:168-192", "hash": "0a57aeaf7b7d5e30122989cc0f264029", "title": "Average Precision Calculator"}, "1598": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:193-220", "hash": "80167967805e2ddf7cbe272f92a18ef8", "title": "Average Precision Calculator"}, "1599": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:221-256", "hash": "232aa8f24bed0209f05a264b0ff3eb00", "title": "Average Precision Calculator"}, "1600": {"path": "/applications/VideoTag/metrics/youtube8m/average_precision_calculator.py:257-274", "hash": "7025780b7319af9be3a1a3fa3f0040ca", "title": "Normalized Predictions: Min-Max Scaling"}, "1601": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py", "hash": "ba8fecad55bd602f5fed2c7eb6b22a1a", "title": "PaddleVideo Metrics for Model Evaluation"}, "1602": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:1-28", "hash": "5acbe7806f88f63d044b4f7a6bab6281", "title": "YouTube8M Evaluation Utilities"}, "1603": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:30-59", "hash": "6b0bf3c68eecf1535e4c6d1dfcfe836b", "title": "Precision-Recall Average Hit at One"}, "1604": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:60-87", "hash": "44025cb46595e955e6f842fafcbd0a56", "title": "Global Average Precision Calculation"}, "1605": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:88-109", "hash": "2802c7967bdeea49b57825bf73ea45ed", "title": "Top K Video Predictions Evaluation"}, "1606": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:110-135", "hash": "1d0a3f8e68c6a10a0b89bfe41ecc850b", "title": "Top-K Video Classification Evaluation"}, "1607": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:136-164", "hash": "530f7781187acecbcb8d51fbee7c2801", "title": "Evaluation Metrics Class"}, "1608": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:165-190", "hash": "e5e14eeb99f2ac623bb78d9393e68ea4", "title": "Batch Metrics Calculation Function"}, "1609": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:191-219", "hash": "fee4b195e8b589e49fa77f562ead1c84", "title": "Epoch Metrics Calculator"}, "1610": {"path": "/applications/VideoTag/metrics/youtube8m/eval_util.py:220-244", "hash": "69bb49c9818a1b13399d0b900f9ee770", "title": "YouTube8m Metrics Evaluator"}, "1611": {"path": "/applications/VideoTag/metrics/youtube8m/mean_average_precision_calculator.py", "hash": "da75a3e928616fe8679559be26ee25c4", "title": "YouTube-8m Mean Average Precision Calculator"}, "1612": {"path": "/applications/VideoTag/metrics/youtube8m/mean_average_precision_calculator.py:1-27", "hash": "37a562c586626d3d311800356cb3175e", "title": "Mean Average Precision Calculator"}, "1613": {"path": "/applications/VideoTag/metrics/youtube8m/mean_average_precision_calculator.py:28-58", "hash": "c5e7b7fb3c0e72923a079a7eb39388f0", "title": "Mean Average Precision Calculation in YouTube8M"}, "1614": {"path": "/applications/VideoTag/metrics/youtube8m/mean_average_precision_calculator.py:59-79", "hash": "a988dc888b2e2e1d3f7717e8a1cfba90", "title": "Mean Average Precision Calculator"}, "1615": {"path": "/applications/VideoTag/metrics/youtube8m/mean_average_precision_calculator.py:80-111", "hash": "9ecf27e1664f066e9b3e4426bdcfcc89", "title": "Mean Average Precision Calculator"}, "1616": {"path": "/applications/VideoTag/metrics/youtube8m/mean_average_precision_calculator.py:112-113", "hash": "6fbc03385d05d32795afd35c633bb841", "title": "Mean Average Precision Calculator"}, "1617": {"path": "/applications/VideoTag/models/__init__.py", "hash": "bba86ce05faed28c97fcd1e7f3647922", "title": "Model Registry in VideoTag"}, "1618": {"path": "/applications/VideoTag/models/attention_lstm/__init__.py", "hash": "153ddf4aa28b2b5e631fed1495fe1b02", "title": "Import Attention LSTM Functions"}, "1619": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py", "hash": "72f6ccd6c840a696635b1e2b1518c933", "title": "Attention LSTM Video Tagging Model"}, "1620": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py:1-31", "hash": "3af41a7eb0183285e1a9aed459039f11", "title": "Attention LSTM Model Definition"}, "1621": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py:33-54", "hash": "62809f066c4595a96fec8145c234de94", "title": "Attention LSTM Model Configuration"}, "1622": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py:55-76", "hash": "38efa3a77a164008585b523fff21b796", "title": "Initializing Feature and Label Inputs"}, "1623": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py:77-103", "hash": "c840dae7528a57f8172ea50427409bf7", "title": "LSTM Attention Model with Multi-Input Features"}, "1624": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py:104-125", "hash": "fa862df27d886106e74dde62a49183ec", "title": "Attention LSTM Model for Video Tagging"}, "1625": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py:126-151", "hash": "7660a05c71aba9cf98b616c5d775f857", "title": "Attention LSTM Model with Learning Rate Decay"}, "1626": {"path": "/applications/VideoTag/models/attention_lstm/attention_lstm.py:152-180", "hash": "bb184c883d27ce4a9e5e5a873a55358a", "title": "Attention LSTM Model Class Definition"}, "1627": {"path": "/applications/VideoTag/models/attention_lstm/lstm_attention.py", "hash": "a7c51ffe17fccab9521050af8171af0c", "title": "Bidirectional LSTM Attention Model"}, "1628": {"path": "/applications/VideoTag/models/attention_lstm/lstm_attention.py:1-31", "hash": "3ab8c58bfaf2b9cadeb0cf9f482d2768", "title": "LSTM Attention Model Code"}, "1629": {"path": "/applications/VideoTag/models/attention_lstm/lstm_attention.py:32-58", "hash": "30da813ec0b14b0f562fd5ade9b8c022", "title": "Dynamic LSTM for Video Tagging"}, "1630": {"path": "/applications/VideoTag/models/attention_lstm/lstm_attention.py:60-83", "hash": "9cc043ca6d5549e02aa66c63f63c08df", "title": "Dynamic LSTM Model for Sequence Classification"}, "1631": {"path": "/applications/VideoTag/models/model.py", "hash": "e0cf1296f183c6e89f858a6052031544", "title": "Python Module: PaddleVideo's VideoTag Model Handler"}, "1632": {"path": "/applications/VideoTag/models/model.py:1-36", "hash": "3d55d5ae5389b6c7671d5b82eeda74dd", "title": "VideoTag Model Initialization"}, "1633": {"path": "/applications/VideoTag/models/model.py:37-69", "hash": "46eaff64d9ce7d4b1efaaa9cf9fa2bb3", "title": "Custom Exceptions and Model Base Class"}, "1634": {"path": "/applications/VideoTag/models/model.py:70-105", "hash": "77777583e300f8964ec0c37f9414c96d", "title": "Subclassing Model Class for Implementation"}, "1635": {"path": "/applications/VideoTag/models/model.py:107-139", "hash": "5c6bf60427650610934b34b256998789", "title": "Model Utilities: Dataset, Weights, and Pretraining"}, "1636": {"path": "/applications/VideoTag/models/model.py:140-167", "hash": "4814b694e6c59b940bf4d37664e136b7", "title": "Weight Handling Functions"}, "1637": {"path": "/applications/VideoTag/models/model.py:168-192", "hash": "93f088549c54f8158b5075fbb2cbbabe", "title": "ModelZoo: Managing and Retrieving Models"}, "1638": {"path": "/applications/VideoTag/models/tsn/__init__.py", "hash": "675a7ffc6f26a8a3a23e4cc4d2ea9a7b", "title": "Effortless TSN Import"}, "1639": {"path": "/applications/VideoTag/models/tsn/tsn.py", "hash": "7f7dbe649ea5de50a104ccef37e6dcf0", "title": "TSN Model Initialization"}, "1640": {"path": "/applications/VideoTag/models/tsn/tsn.py:1-34", "hash": "52d099369c342dbd3f60dc48ed9b4e20", "title": "TSN Model Class"}, "1641": {"path": "/applications/VideoTag/models/tsn/tsn.py:35-52", "hash": "be028f21e52fb65e5d39da739b89812d", "title": "TSN Model Initialization"}, "1642": {"path": "/applications/VideoTag/models/tsn/tsn.py:53-75", "hash": "63fecae7fc1f6f65a5bc89ecb29a57ad", "title": "TSN Model Input Generation"}, "1643": {"path": "/applications/VideoTag/models/tsn/tsn.py:77-101", "hash": "b2b96091e9b949beeeac72c9c40a6e9b", "title": "TSN Model Configurable Parameters"}, "1644": {"path": "/applications/VideoTag/models/tsn/tsn.py:102-129", "hash": "15abafe1c274a4e70ac8d4acfe8e9ee3", "title": "Piecewise Learning Rate Decay Optimizer"}, "1645": {"path": "/applications/VideoTag/models/tsn/tsn.py:130-159", "hash": "8fafe7609e5b9b8d6f30aa40c5752f07", "title": "Multi-Mode Model with Pre-Trained Weights"}, "1646": {"path": "/applications/VideoTag/models/tsn/tsn.py:160-165", "hash": "cb0dbb4a92917da1b7db509483b8bdb5", "title": "Prune Pretrained Parameters"}, "1647": {"path": "/applications/VideoTag/models/tsn/tsn_res_model.py", "hash": "1d9f65120a105308487d525db7bcd164", "title": "TSN ResNet Model in PaddlePaddle"}, "1648": {"path": "/applications/VideoTag/models/tsn/tsn_res_model.py:1-34", "hash": "ccf2d0a7da4e638966905f2ea03f7f7f", "title": "TSN ResNet Model Definition"}, "1649": {"path": "/applications/VideoTag/models/tsn/tsn_res_model.py:35-63", "hash": "bf138cb37216212bf2413251c0f929b4", "title": "Convolutional Layer with Batch Normalization"}, "1650": {"path": "/applications/VideoTag/models/tsn/tsn_res_model.py:65-86", "hash": "545b1750bc75fbcc1cdf430f603361c9", "title": "Bottleneck Block and Shortcut Functions"}, "1651": {"path": "/applications/VideoTag/models/tsn/tsn_res_model.py:87-118", "hash": "9580c8929a831fab32f2ea1e6d8c4ba3", "title": "TSN ResNet Model: Conv-Batch Normalization Layers"}, "1652": {"path": "/applications/VideoTag/models/tsn/tsn_res_model.py:119-142", "hash": "45685a61796394beb6f48245f271f627", "title": "ResNet Model Implementation with PaddlePaddle"}, "1653": {"path": "/applications/VideoTag/models/tsn/tsn_res_model.py:143-161", "hash": "66ba4bf0d074ee31770369ca76c44c63", "title": "Adaptive Average Pooling and Softmax Output"}, "1654": {"path": "/applications/VideoTag/models/utils.py", "hash": "ae047952ffb6194fc72c19b2be407cc8", "title": "Comprehensive File Operations Utility"}, "1655": {"path": "/applications/VideoTag/models/utils.py:1-36", "hash": "2222542d668f40d548584ed8b70abdfd", "title": "Decompress and Download Utilities"}, "1656": {"path": "/applications/VideoTag/models/utils.py:39-47", "hash": "b5e1e8bcf5ce69e9b75ebf7564204806", "title": "AttrDict Class: Access Attributes Easily"}, "1657": {"path": "/applications/VideoTag/predict.py", "hash": "fed05e80e9fbbd65d35a4d2bc784a354", "title": "PaddleVideo: Predicting Video Tags with AI"}, "1658": {"path": "/applications/VideoTag/predict.py:1-37", "hash": "b2dea5f024eef0e22acc829492b2e94f", "title": "Import and Initialization Script"}, "1659": {"path": "/applications/VideoTag/predict.py:38-64", "hash": "bbb03a9dc905282a8effdab272b0bebd", "title": "Setting Up Logger and Parsing Arguments"}, "1660": {"path": "/applications/VideoTag/predict.py:65-87", "hash": "325cd19a56d74de2c5d4d82f502db728", "title": "Video Tag Prediction Python Script"}, "1661": {"path": "/applications/VideoTag/predict.py:88-115", "hash": "671df5265c32d6302245063c3c9389bb", "title": "Building PaddleVideo Inference Model"}, "1662": {"path": "/applications/VideoTag/predict.py:117-141", "hash": "f6f2e992709ed5b8787902ac93b9b02e", "title": "Video Tag Prediction Model"}, "1663": {"path": "/applications/VideoTag/predict.py:143-171", "hash": "243d1dceca3ad2b8a07366af05955b62", "title": "Average Processing Time Logger"}, "1664": {"path": "/applications/VideoTag/reader/__init__.py", "hash": "a5c3c5d8894c9f098d531f02c5fa7ffd", "title": "Alphabetical Reader Registration"}, "1665": {"path": "/applications/VideoTag/reader/feature_reader.py", "hash": "282474179a67cfdf47e10ea9938bf82e", "title": "DataReader: LSTM-based YouTube Dataset Processing"}, "1666": {"path": "/applications/VideoTag/reader/feature_reader.py:1-34", "hash": "4ae4802aa988c532c71803c722a14946", "title": "Youtube-8M Dataset LSTM Feature Reader"}, "1667": {"path": "/applications/VideoTag/reader/feature_reader.py:35-64", "hash": "d58874f442af6a35bb11212913448db7", "title": "Feature Reader Initialization"}, "1668": {"path": "/applications/VideoTag/reader/feature_reader.py:65-80", "hash": "e28f27b80de7c15bac356aad4b02ee2f", "title": "One-Hot Video Frame Labeling"}, "1669": {"path": "/applications/VideoTag/reader/kinetics_reader.py", "hash": "040d30ed18827899c23f3cec8ea96ad1", "title": "Efficient Kinetics Dataset Reader"}, "1670": {"path": "/applications/VideoTag/reader/kinetics_reader.py:1-41", "hash": "0a76d0da43479bcceb86d8db90bc37d6", "title": "PaddleVideo's Kinetics Reader: Frame Data and License"}, "1671": {"path": "/applications/VideoTag/reader/kinetics_reader.py:42-79", "hash": "b45b31d4b22e9e0382b3eb211e673aab", "title": "Kinetics Reader: MP4/PKL Dataset Access"}, "1672": {"path": "/applications/VideoTag/reader/kinetics_reader.py:80-98", "hash": "3ac2850577c49a77ee9fe719c79d09dd", "title": "Kinetics Reader Initialization"}, "1673": {"path": "/applications/VideoTag/reader/kinetics_reader.py:99-121", "hash": "e98747160930df3f3c48a6320164b010", "title": "Configure Video Reader: Batch Size, File List, Random Seed"}, "1674": {"path": "/applications/VideoTag/reader/kinetics_reader.py:122-151", "hash": "f6264196146b8de8417f5822e3c93fbd", "title": "MP4 Reader Function"}, "1675": {"path": "/applications/VideoTag/reader/kinetics_reader.py:152-176", "hash": "cf0423543750b610a6e99bb05c328d11", "title": "Frames and Labels: Kinetics Reader"}, "1676": {"path": "/applications/VideoTag/reader/kinetics_reader.py:177-204", "hash": "56ae223d228651c5e7fa0dd0f1399ff8", "title": "Video Frame Loader and Error Handler"}, "1677": {"path": "/applications/VideoTag/reader/kinetics_reader.py:205-233", "hash": "d8f8f6a1d69bc5ff1f5ffddeeabe2e46", "title": "Video Decoder Selector"}, "1678": {"path": "/applications/VideoTag/reader/kinetics_reader.py:234-266", "hash": "cfd277c89177fdb4898a69b82ca94617", "title": "Data Augmentation for Image Processing"}, "1679": {"path": "/applications/VideoTag/reader/kinetics_reader.py:269-305", "hash": "23356222c75b7bb6558f32a9b27bcd1b", "title": "Versatile Image and Video Processing Functions"}, "1680": {"path": "/applications/VideoTag/reader/kinetics_reader.py:306-340", "hash": "27eefd17dae145c7a75d5a502b8abf66", "title": "Frame Subset Selector"}, "1681": {"path": "/applications/VideoTag/reader/kinetics_reader.py:341-367", "hash": "3375abb31265e55ef7756349a4954889", "title": "Video Frame Duration Analyzer"}, "1682": {"path": "/applications/VideoTag/reader/reader_utils.py", "hash": "96e5a241e0b2b1a901f7e896b8034edb", "title": "Reader Zoo Class and Utilities"}, "1683": {"path": "/applications/VideoTag/reader/reader_utils.py:1-31", "hash": "41ac5d6c5c797ecebf8e01d9f5b61ac7", "title": "Importing Libraries and Defining Reader Exceptions"}, "1684": {"path": "/applications/VideoTag/reader/reader_utils.py:32-70", "hash": "2eebf43092b9f925325d01f7c2763b0c", "title": "Video Reader Classes and Registry"}, "1685": {"path": "/applications/VideoTag/reader/reader_utils.py:71-80", "hash": "fa54334cfe369e581c2a00baf1735bde", "title": "Register and Retrieve Readers Class"}, "1686": {"path": "/applications/VideoTag/train.py", "hash": "a9cbad99274e254ae5335c74b1a5a0d2", "title": "VideoTag: CUDA-Powered Model Training and Saving"}, "1687": {"path": "/applications/VideoTag/train.py:1-32", "hash": "f3580ad99140f470e6d40a266b7b8321", "title": "VideoTag: Setting Up and Importing"}, "1688": {"path": "/applications/VideoTag/train.py:33-60", "hash": "b6377d4f28796dff69c844a50ab7d2a8", "title": "Argparse Configuration and Default Values"}, "1689": {"path": "/applications/VideoTag/train.py:61-82", "hash": "1b00ac68ffe7b2e8cb4613499150f8b6", "title": "Command Line Arguments for Training Program"}, "1690": {"path": "/applications/VideoTag/train.py:83-109", "hash": "878d22aa908ec2eab4413896510165e6", "title": "Command Line Argument Parsing"}, "1691": {"path": "/applications/VideoTag/train.py:110-134", "hash": "f53058fed436cd6cba43a45843e668c6", "title": "Training Model Initialization"}, "1692": {"path": "/applications/VideoTag/train.py:136-161", "hash": "44dd9e120328d834d3fa2045e37e9997", "title": "GPU-Aware Program Compilation"}, "1693": {"path": "/applications/VideoTag/train.py:162-181", "hash": "296f6d1a2e5339caf6a4edc4c9db79d3", "title": "Batch Size and Data Loading Setup"}, "1694": {"path": "/applications/VideoTag/train.py:182-205", "hash": "6d79f73551f92d520da8d2f573e79fce", "title": "Video Tagging Model Training with PaddlePaddle"}, "1695": {"path": "/applications/VideoTag/train.py:206-212", "hash": "c9be8dd4ca6eefafb9d207cb0e1dc747", "title": "Directory Check and Training Initiation"}, "1696": {"path": "/applications/VideoTag/tsn_extractor.py", "hash": "43f2f750921ad828a47d3314e2ec6cb6", "title": "Video Inference and Feature Extraction"}, "1697": {"path": "/applications/VideoTag/tsn_extractor.py:1-37", "hash": "1020a24b8f774df53c5b092128ff4c47", "title": "Python Script for PaddlePaddle Model Training"}, "1698": {"path": "/applications/VideoTag/tsn_extractor.py:38-66", "hash": "81c0250459c76c0d68cf6b95313da6c6", "title": "Command-Line Arguments for Model Training"}, "1699": {"path": "/applications/VideoTag/tsn_extractor.py:67-93", "hash": "d1f84b01b39a8ae3b38c76c64de8998d", "title": "Command Line Arguments and Parsing in TsnExtractor"}, "1700": {"path": "/applications/VideoTag/tsn_extractor.py:94-118", "hash": "f5293080ebd110612a69ab51cd63c206", "title": "Infer Model Initialization"}, "1701": {"path": "/applications/VideoTag/tsn_extractor.py:120-144", "hash": "150153126a0d38708fd2f9c78ca841e2", "title": "Model Weights Downloader and Inferencer"}, "1702": {"path": "/applications/VideoTag/tsn_extractor.py:145-158", "hash": "e94116cda27666fc0276a5fc39a504f2", "title": "Extract and Log Features for Inference"}, "1703": {"path": "/applications/VideoTag/utils/config_utils.py", "hash": "f18131592ad31cf79da3fec92fa93f71", "title": "Config Handler for VideoTag"}, "1704": {"path": "/applications/VideoTag/utils/config_utils.py:1-37", "hash": "809882757a8111e3274f41bea256e2dc", "title": "VideoTag Config Utils"}, "1705": {"path": "/applications/VideoTag/utils/config_utils.py:38-73", "hash": "59092fe8103e520fbbe4af0bb3378554", "title": "YAML Config Processing and Merging Utils"}, "1706": {"path": "/applications/VideoTag/utils/config_utils.py:74-75", "hash": "a155aaed7cdfaea866ff16b33515c82e", "title": "Config Log Separation"}, "1707": {"path": "/applications/VideoTag/utils/train_utils.py", "hash": "51c390e23dc5ad31a4e7399967a0821b", "title": "Train Utils with PaddlePaddle"}, "1708": {"path": "/applications/VideoTag/utils/train_utils.py:1-32", "hash": "cf0031b4ca4cfd4f1d7eb07f424eb91b", "title": "Logging Learning Rate in PaddlePaddle"}, "1709": {"path": "/applications/VideoTag/utils/train_utils.py:33-57", "hash": "f749c60d8bc719595b4e5515c2749bae", "title": "Retrieve and Print Learning Rate\n(or)\nLearning Rate Retrieval and Display"}, "1710": {"path": "/applications/VideoTag/utils/train_utils.py:58-80", "hash": "bd7952ddb63fc1f4351ce26fc6188a04", "title": "Train Model with Dataloader Function"}, "1711": {"path": "/applications/VideoTag/utils/train_utils.py:81-109", "hash": "88bd0ec991a75f19ecb58f751cf72b5f", "title": "Epoch Loop Initialization"}, "1712": {"path": "/applications/VideoTag/utils/train_utils.py:110-135", "hash": "d0fa34e7a631af133be1bfcf7bcd34de", "title": "Training Progress Tracker"}, "1713": {"path": "/applications/VideoTag/utils/train_utils.py:136-159", "hash": "fe8b40c470db9c253544b4afa1324a53", "title": "Model Saving and Testing Procedure"}, "1714": {"path": "/applications/VideoTag/utils/train_utils.py:161-161", "hash": "ef56ee7015191efc4d76aa94df585e26", "title": "Incomplete Code Snippet"}, "1715": {"path": "/applications/VideoTag/utils/utility.py", "hash": "e1841f8d7ee769a6fe725b41f997feec", "title": "Python Utility: PaddlePaddle Checker"}, "1716": {"path": "/applications/VideoTag/utils/utility.py:1-37", "hash": "9b483364c49237cdd68050cb63fd3648", "title": "Python Utility Script"}, "1717": {"path": "/applications/VideoTag/utils/utility.py:39-66", "hash": "af682fde4c8fe4b7c488ae461bd5054b", "title": "Compatibility and GPU Handling for PaddlePaddle"}, "1718": {"path": "/applications/VideoTag/utils/utility.py:67-70", "hash": "d07b5334ddccd6e5ec4d260a7924441f", "title": "Check Version Installation"}, "1719": {"path": "/applications/VideoTag/videotag_test.py", "hash": "5d0905c00faf919931ca229cf3fcf8ef", "title": "Efficient Video Tagging with PaddlePaddle"}, "1720": {"path": "/applications/VideoTag/videotag_test.py:1-34", "hash": "1f06306e3b7348bd1d0e6188fde7647b", "title": "VideoTag Test Log Config"}, "1721": {"path": "/applications/VideoTag/videotag_test.py:35-62", "hash": "b5162d95f820af6597d9be0ea830b69a", "title": "Command-Line Argument Parser for VideoTag"}, "1722": {"path": "/applications/VideoTag/videotag_test.py:63-86", "hash": "be79fd1199d58f7a734cbc6da171c1c8", "title": "Command-Line Arguments for Video Tagging"}, "1723": {"path": "/applications/VideoTag/videotag_test.py:87-111", "hash": "c3c52696214583c8bfa9aa7b6a4e1855", "title": "Video Classification Model with PaddlePaddle"}, "1724": {"path": "/applications/VideoTag/videotag_test.py:112-134", "hash": "da78cf0634b8cafcc0c8be976c8fbb37", "title": "Video Tagging Inference Model"}, "1725": {"path": "/applications/VideoTag/videotag_test.py:135-154", "hash": "28ad9acce37edbfc8c2586798032d48d", "title": "Extractor Setup and Timing in PaddleVideo"}, "1726": {"path": "/applications/VideoTag/videotag_test.py:156-177", "hash": "2238ce35f8201d3ce6788b155bb2b054", "title": "Configure and Prepare Input Data"}, "1727": {"path": "/applications/VideoTag/videotag_test.py:179-199", "hash": "0774cbe8eb1718e3e4c5f6de529159c6", "title": "Efficient Model Predictor Setup"}, "1728": {"path": "/applications/VideoTag/videotag_test.py:201-221", "hash": "6106c27cfcdc5f18d1d1d14f3e63dd0b", "title": "DataFeeder Initialization and Model Execution"}, "1729": {"path": "/applications/VideoTag/videotag_test.py:222-238", "hash": "7f81fcba1ba488e91a8ef463d73a7011", "title": "Inference Time Logger"}, "1730": {"path": "/benchmark/TimeSformer/README.md", "hash": "09c748fc99382f675ca3a370325409f0", "title": "TimeSformer Benchmarking Guide"}, "1731": {"path": "/benchmark/TimeSformer/run_all.sh", "hash": "0ff8a76d640c8e8e3dfa284b13ee0e47", "title": "TimeSformer Benchmarking Script"}, "1732": {"path": "/benchmark/TimeSformer/run_all.sh:1-20", "hash": "d7f5a67d615ec9b268eb4499c02c5200", "title": "TimeSformer Model Benchmark Setup"}, "1733": {"path": "/benchmark/TimeSformer/run_all.sh:20-47", "hash": "70717b1ee3155134b62224605c4ecfc6", "title": "TimeSformer Dataset Prep & Benchmark"}, "1734": {"path": "/benchmark/TimeSformer/run_all.sh:47-57", "hash": "ce8c2cf92873d887c4f02570e74e1105", "title": "Multi-GPU Performance Testing for TimeSformer"}, "1735": {"path": "/benchmark/TimeSformer/run_benchmark.sh", "hash": "658adb2db8269996dd9172b6cc6a1e07", "title": "TimeSformer Benchmarking"}, "1736": {"path": "/benchmark/TimeSformer/run_benchmark.sh:1-28", "hash": "1a7a88f78f71acacca00026edbd524fd", "title": "TimeSformer Benchmark Script"}, "1737": {"path": "/benchmark/TimeSformer/run_benchmark.sh:29-48", "hash": "418fef8fc6337b4b4e167535a3783d8a", "title": "Run TimeSformer Benchmark"}, "1738": {"path": "/benchmark/TimeSformer/run_benchmark.sh:49-77", "hash": "046fc124f07bad83398d22fe057c56ab", "title": "Run TimeSformer Benchmark"}, "1739": {"path": "/data/50salads/prepare_asrf_data.py", "hash": "858fe004037c6c05c0a9b035674c1724", "title": "Prepare ASRF Data for 50Salads"}, "1740": {"path": "/data/50salads/prepare_asrf_data.py:1-42", "hash": "211d25ad4089f60e5ca42fe730726b89", "title": "Dataset Class ID Mapping and Argument Parsing"}, "1741": {"path": "/data/50salads/prepare_asrf_data.py:43-74", "hash": "dbd2afa713d0ad31ada5cc8e0afab845", "title": "Setup Dataset Directory and Index Classes"}, "1742": {"path": "/data/50salads/prepare_asrf_data.py:76-106", "hash": "b644d7de14b70a1b0ffaf37911c56f37", "title": "Preparing ASRF Data for Salad Classification"}, "1743": {"path": "/data/50salads/prepare_asrf_data.py:107-113", "hash": "13ac1065185180c4257d8b44c6383342", "title": "Checks Direct Execution"}, "1744": {"path": "/data/50salads/transform_segmentation_label.py", "hash": "1afb823e1d8c8008c6d1ba77ff711c64", "title": "Video Data Labeling Tool"}, "1745": {"path": "/data/50salads/transform_segmentation_label.py:1-34", "hash": "8686527bbfd5cf81201e68dd70febeea", "title": "Label Conversion Tool"}, "1746": {"path": "/data/50salads/transform_segmentation_label.py:35-55", "hash": "6a2b7e0c6beb8c6382c271b0e02f2186", "title": "Action Detection and Labeling in Transform Segmentation"}, "1747": {"path": "/data/50salads/transform_segmentation_label.py:56-90", "hash": "43ff121cdfebbeca1bbde7fc0230529b", "title": "Video Segmentation Label Conversion"}, "1748": {"path": "/data/50salads/transform_segmentation_label.py:91-119", "hash": "6d7b3f793eb276934668e75b6765a5ef", "title": "Generate Action Labels from Segmentation"}, "1749": {"path": "/data/50salads/transform_segmentation_label.py:120-147", "hash": "1ff5e7a223b266c75ef39cb14375a257", "title": "Segmentation Label Writer"}, "1750": {"path": "/data/50salads/transform_segmentation_label.py:148-173", "hash": "029bfed3e9fd5e2c99e56dd7e57bbe09", "title": "Label File Processing and Conversion"}, "1751": {"path": "/data/50salads/transform_segmentation_label.py:174-195", "hash": "4e874d280c40ff77154c71ca1ad67688", "title": "Command Line Arguments Parser for Label Conversion"}, "1752": {"path": "/data/ntu-rgb-d/download_dataset.sh", "hash": "02bbc12719dccf7f2788d9f94f26f010", "title": "Download and Extract Skeleton Data"}, "1753": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py", "hash": "f4f1cff114e7953d8e6268a0b75adbb9", "title": "NTU Dataset Data Cleaning & Denoising"}, "1754": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:1-38", "hash": "35802a95df545a35575dfe8def193375", "title": "Setting Up Directories and Loggers"}, "1755": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:39-63", "hash": "8be1a38e8f458c0d4c76fed48816ac3d", "title": "Organized Logging in NTU RGB-D Data Processing"}, "1756": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:64-86", "hash": "acfcc5a88f559c502ee1a4f32bffc10f", "title": "Denoising Skeleton Frames: Multiple Loggers"}, "1757": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:87-116", "hash": "f959492281097e0df2ea12c1129463a7", "title": "Threshold-Based Body Filtration"}, "1758": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:117-147", "hash": "72b21756b65b660ef4a1cf04585f1f5e", "title": "Denoising Bodies by Spread Threshold"}, "1759": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:148-172", "hash": "4599758b8e937a1d61073beb01cdc2eb", "title": "Noisy Frame Filter"}, "1760": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:173-198", "hash": "25bfe119077b68d6d821a5e02df8bd94", "title": "Denoising Body Motion Data"}, "1761": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:200-225", "hash": "719fb02663ab342587841e62a55df1f0", "title": "Denoising Bodies Data by Frame Length and Spread"}, "1762": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:226-252", "hash": "8a11fc6e287cd6363657381ec6c0c082", "title": "Denoising NTU RGB-D Data with Motion Integration"}, "1763": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:253-280", "hash": "f7789870d1e0ae3911ac85c7dd2511e5", "title": "Extract Joints and Colors from Body Data"}, "1764": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:281-303", "hash": "78f1fe80eabf46dd6af653af67ba74b1", "title": "Missing Frame Detection and Update"}, "1765": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:305-329", "hash": "bdc028d3736c1a6f931f445cef733a5d", "title": "Extracting Bodies Data and Points"}, "1766": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:331-358", "hash": "e95ea0799ada4e15932a659d38f7f09a", "title": "Denoising and Extracting Data from NTU RGB-D Dataset"}, "1767": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:359-377", "hash": "1047522fb284320576feffbb5a1cb2ed", "title": "Extracting Actor Data from NTU-RGB-D"}, "1768": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:378-403", "hash": "fe6f3897656942994104591f0355e886", "title": "Extracting and Denoising Skeleton Data"}, "1769": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:405-419", "hash": "8df0c3b1f8f9fd5bb4ad6bfbf88f3b32", "title": "Raw Skeleton Data Processing"}, "1770": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:420-445", "hash": "2cb1a300c69b5b5436312ed191cd2a1a", "title": "Raw Skeleton Sequence Data Processing"}, "1771": {"path": "/data/ntu-rgb-d/get_raw_denoised_data.py:446-471", "hash": "a9abe992f4ca13ed85368258bbb7746a", "title": "Data Extraction and Analysis Tool"}, "1772": {"path": "/data/ntu-rgb-d/get_raw_skes_data.py", "hash": "ac41b02960935a8640ed390e4c1cdbf8", "title": "NTU Skeleton Data Extractor"}, "1773": {"path": "/data/ntu-rgb-d/get_raw_skes_data.py:1-28", "hash": "e31925071e166d8957f0f6e86cc7129d", "title": "Extracting Skeleton Data"}, "1774": {"path": "/data/ntu-rgb-d/get_raw_skes_data.py:29-58", "hash": "c50d647c672a118d8736df0bcbf79d10", "title": "Joint Counting from .skeleton Files"}, "1775": {"path": "/data/ntu-rgb-d/get_raw_skes_data.py:59-76", "hash": "be680cdab0456fc38f93ea9177707ec6", "title": "Extract and Update Body Data"}, "1776": {"path": "/data/ntu-rgb-d/get_raw_skes_data.py:77-100", "hash": "dc62c3304493edcb0c14fa39324b80c6", "title": "NTU Skeleton Data Retriever"}, "1777": {"path": "/data/ntu-rgb-d/get_raw_skes_data.py:101-130", "hash": "50cb1636548940511a774d1ea0f23d51", "title": "Combine Raw Skeleton Data Files"}, "1778": {"path": "/data/ntu-rgb-d/get_raw_skes_data.py:132-157", "hash": "c5935bf3c7d742aac76b069e595301f3", "title": "NTU Dataset Filter & Save"}, "1779": {"path": "/data/ntu-rgb-d/seq_transformation.py", "hash": "71904de86abccb870e504a82dc312bcb", "title": "NTU-RGB-D Dataset Transformation"}, "1780": {"path": "/data/ntu-rgb-d/seq_transformation.py:1-34", "hash": "14167af7fe38301eb88bb7a1ee1b0683", "title": "Directory Check and Frame Filtering"}, "1781": {"path": "/data/ntu-rgb-d/seq_transformation.py:35-63", "hash": "e729c22af21a80e98d9a2774ef64eea1", "title": "Seq Transformation: Filtering and Calculating Origin Points"}, "1782": {"path": "/data/ntu-rgb-d/seq_transformation.py:64-89", "hash": "d0f0661adda269586f2cd5a50d1922d3", "title": "Sequence Transformation for NTU RGB+D Dataset"}, "1783": {"path": "/data/ntu-rgb-d/seq_transformation.py:90-118", "hash": "dd230da585f67f213051bcdf527d1082", "title": "Skeleton Alignment and Frame Count Update"}, "1784": {"path": "/data/ntu-rgb-d/seq_transformation.py:119-150", "hash": "7852436edf73cd944c38f716bc86c5b6", "title": "Sequence Transformation and Encoding Functions"}, "1785": {"path": "/data/ntu-rgb-d/seq_transformation.py:151-176", "hash": "6814ac5e5952f161af23933e67fd799e", "title": "Train-Validation Split Function"}, "1786": {"path": "/data/ntu-rgb-d/seq_transformation.py:178-204", "hash": "26f1e72341577116d838592cafbda7a0", "title": "Evaluating and Initializing Data Paths"}, "1787": {"path": "/data/ntu-rgb-d/seq_transformation.py:205-235", "hash": "22e575a24cbdbd651dbbeabe4cfbc956", "title": "Get Indices for Cross-Subject or View Evaluation"}, "1788": {"path": "/data/ntu-rgb-d/seq_transformation.py:236-263", "hash": "670fae7515a8f6551504be6db29f340d", "title": "NTU Load and Preprocessing"}, "1789": {"path": "/data/ntu-rgb-d/seq_transformation.py:264-266", "hash": "dc4bc3a66946deaf767d5a82b2dfd1e3", "title": "Split and Process NTU Dataset"}, "1790": {"path": "/deploy/cpp_infer/external-cmake/auto-log.cmake", "hash": "b1c6a7df6492e87b0b4e8ac556b6d773", "title": "Including Git External Project with CMake"}, "1791": {"path": "/deploy/cpp_infer/include/postprocess_op.h", "hash": "ebb2e6da0b138a6ff956d64bdd527f8c", "title": "Softmax Inplace Run for PaddleVideo"}, "1792": {"path": "/deploy/cpp_infer/include/postprocess_op.h:1-39", "hash": "9f59c55d646a8a3d3e30628894bd3e70", "title": "Softmax In-Place Transformation"}, "1793": {"path": "/deploy/cpp_infer/include/postprocess_op.h:40-43", "hash": "a75aa6b5f9cf714f47d9ff360fb27c88", "title": "Postprocess Vector Float Iterators"}, "1794": {"path": "/deploy/cpp_infer/include/preprocess_op.h", "hash": "12114a6d00b2fbe27092d939fc305bbb", "title": "Image Preprocessing Operations"}, "1795": {"path": "/deploy/cpp_infer/include/preprocess_op.h:1-39", "hash": "2b80d8d5f8f5c1c6f87bb8142da1cbda", "title": "Normalize Class in PaddleVideo Library"}, "1796": {"path": "/deploy/cpp_infer/include/preprocess_op.h:40-74", "hash": "7f8b8bb1b758f880e71eec4c6a460ff5", "title": "Versatile Image Preprocessing for PaddleVideo"}, "1797": {"path": "/deploy/cpp_infer/include/utility.h", "hash": "90b7c5e0a8d6ece9ae7f31a843ec1028", "title": "Utility Functions for PaddleVideo"}, "1798": {"path": "/deploy/cpp_infer/include/utility.h:1-40", "hash": "5f003242bf21c7c35f2a0101e8c3ad36", "title": "Utility Class for PaddleVideo"}, "1799": {"path": "/deploy/cpp_infer/include/utility.h:42-54", "hash": "a62d54da182522c4a569360f8d9728fa", "title": "Utility Functions for PaddleVideo"}, "1800": {"path": "/deploy/cpp_infer/include/video_rec.h", "hash": "b59f2ef89e2101d745e04d76bc089826", "title": "VideoRecognizer: OpenCV-PaddlePaddle Integration"}, "1801": {"path": "/deploy/cpp_infer/include/video_rec.h:1-34", "hash": "2205daaa30173c141f4bdeaebb2226a7", "title": "OpenCV & PaddlePaddle Licensing and Video Recording API"}, "1802": {"path": "/deploy/cpp_infer/include/video_rec.h:36-57", "hash": "25695ecb26e64ce2c6f48ee95bb4d5e3", "title": "VideoRecognizer Object Creation and Configuration"}, "1803": {"path": "/deploy/cpp_infer/include/video_rec.h:58-86", "hash": "27caf78e53d3618bcf072381484c5cb8", "title": "Video Recognition Class Initialization"}, "1804": {"path": "/deploy/cpp_infer/include/video_rec.h:87-105", "hash": "a7d381bebe4fcde73e08bfc1fdb65aed", "title": "VideoRecognizer Initialization Code"}, "1805": {"path": "/deploy/cpp_infer/readme.md", "hash": "a21f98e099f7d9e8964cd0cdab891848", "title": "C++ PaddleVideo Deployment Error"}, "1806": {"path": "/deploy/cpp_infer/readme.md:1-45", "hash": "c797a4970d73cc44a73568b20c4d0dc3", "title": "Deploying PaddleVideo Models with C++"}, "1807": {"path": "/deploy/cpp_infer/readme.md:46-91", "hash": "b731c9ddb6eea858f127eb117071122e", "title": "Compiling OpenCV for C++ Video Inference"}, "1808": {"path": "/deploy/cpp_infer/readme.md:93-125", "hash": "82a1274485ed53d882cffd467b3b5006", "title": "Two Ways to Obtain Paddle Prediction Library"}, "1809": {"path": "/deploy/cpp_infer/readme.md:126-170", "hash": "41e98b65702408c4074817ba7f7bc27a", "title": "Compiling Paddle Inference API Library: Steps and Build Parameters"}, "1810": {"path": "/deploy/cpp_infer/readme.md:172-213", "hash": "72514677bbb2d8729cb8c623e4d2e9e0", "title": "Compiling PaddleVideo C++ Demo for Inference"}, "1811": {"path": "/deploy/cpp_infer/readme.md:214-259", "hash": "acb68f2225c283e4607831c1f3e1bfdd", "title": "C++ Prediction Demo Instructions"}, "1812": {"path": "/deploy/cpp_infer/readme.md:260-273", "hash": "60323553dc9fac916587c47c806d66c5", "title": "Video Recognition Model Execution Parameters"}, "1813": {"path": "/deploy/cpp_infer/readme.md:274-289", "hash": "8d21217a62b877963331a053fc33107f", "title": "Model Configuration and Detection Demo"}, "1814": {"path": "/deploy/cpp_infer/readme.md:290-304", "hash": "6027319fefcb287982193325ddba76ba", "title": "Optimizing Inference Engine Configuration"}, "1815": {"path": "/deploy/cpp_infer/readme.md:304-324", "hash": "da3ef92d009bd77ba7f32ef5ced83eb0", "title": "C++ Inference Time & Libcudnn Issue"}, "1816": {"path": "/deploy/cpp_infer/readme_en.md", "hash": "82920315b8bb9e67fe472c6684fac603", "title": "PaddleVideo Linux Deployment Guide"}, "1817": {"path": "/deploy/cpp_infer/readme_en.md:1-20", "hash": "4ad53256f941515db69fc528e5bd9c3d", "title": "C++ Deployment Guide for PaddleVideo"}, "1818": {"path": "/deploy/cpp_infer/readme_en.md:20-37", "hash": "53f9fddac15b57958b64af61897f4582", "title": "Linux Video Reading Setup"}, "1819": {"path": "/deploy/cpp_infer/readme_en.md:39-76", "hash": "082fb201f6939a29eec8bb20dc63543a", "title": "OpenCV Linux Compilation Guide"}, "1820": {"path": "/deploy/cpp_infer/readme_en.md:77-110", "hash": "040e6e20a4152b10539efd785ba88fde", "title": "OpenCV Library Setup and C++ Video Inference"}, "1821": {"path": "/deploy/cpp_infer/readme_en.md:110-123", "hash": "b93f83922fc91aeab1a07ccb85c9250d", "title": "Downloading and Unzipping Paddle Inference Library"}, "1822": {"path": "/deploy/cpp_infer/readme_en.md:123-150", "hash": "0d3545bc2905f69bcf611fb64b3948d2", "title": "Install Paddle Prediction Library: C++ Edition"}, "1823": {"path": "/deploy/cpp_infer/readme_en.md:150-173", "hash": "22feb5333a24d8e1e3ad5a793593acc8", "title": "Library Generation and Version Information"}, "1824": {"path": "/deploy/cpp_infer/readme_en.md:174-203", "hash": "56c452fd8fa91ef39bbdbc46f2599b51", "title": "Compiling PaddleVideo C++ Demo Instructions"}, "1825": {"path": "/deploy/cpp_infer/readme_en.md:204-231", "hash": "ed7c973130858310f6122a5fa5dfe8e7", "title": "TensorRT Deployment with PaddleVideo"}, "1826": {"path": "/deploy/cpp_infer/readme_en.md:232-258", "hash": "2e8c1bc0f5b6048e0ebcb3339954f822", "title": "Customize PaddleVideo Inference Parameters"}, "1827": {"path": "/deploy/cpp_infer/readme_en.md:259-271", "hash": "f24e1cae8586235fa1da3f354688a275", "title": "Video Recognition Model Configuration Parameters"}, "1828": {"path": "/deploy/cpp_infer/readme_en.md:273-289", "hash": "43623dfa15189f9c29df318ddf033987", "title": "TensorRT CPP Inference Code Snippet"}, "1829": {"path": "/deploy/cpp_infer/readme_en.md:290-308", "hash": "b9b7a62cf6cd15763316a1a323559ac7", "title": "Missing CUDA Library: Inference Details"}, "1830": {"path": "/deploy/cpp_infer/readme_en.md:309-316", "hash": "f2d41359132830a6289d85a9ef4bc1cf", "title": "CMake: Missing libcudnn.so Error"}, "1831": {"path": "/deploy/cpp_infer/src/main.cpp", "hash": "addfd1d04728c59846cf3f1d7f44600c", "title": "OpenCV Video Recognition in C++"}, "1832": {"path": "/deploy/cpp_infer/src/main.cpp:1-35", "hash": "8469c1d47f5afc720a126ea0a12e8868", "title": "OpenCV License and Headers"}, "1833": {"path": "/deploy/cpp_infer/src/main.cpp:37-54", "hash": "96d6d513b81a61d3f41eb133796aa136", "title": "Inference Parameters"}, "1834": {"path": "/deploy/cpp_infer/src/main.cpp:55-85", "hash": "f66914ecebec904c84906bf0d2a1a1a1", "title": "Batch Video Processing with Video Recognition"}, "1835": {"path": "/deploy/cpp_infer/src/main.cpp:86-109", "hash": "234f2282da3675e8688c789b4cb2b99e", "title": "Batch Video Frame Recognition with PaddleVideo"}, "1836": {"path": "/deploy/cpp_infer/src/main.cpp:110-138", "hash": "357a39f1d8d9ffbbf991685a3ea169a5", "title": "Video Inference Parameter Check"}, "1837": {"path": "/deploy/cpp_infer/src/main.cpp:139-170", "hash": "8a60fdb9a906b3147f6dfd167a39706c", "title": "Validate and Launch Recording Mode"}, "1838": {"path": "/deploy/cpp_infer/src/main.cpp:171-173", "hash": "45fdeb3c6bc2e95daf9f652e4085945e", "title": "Program Termination and Return Statement"}, "1839": {"path": "/deploy/cpp_infer/src/postprocess_op.cpp", "hash": "3fa0cbb18b9cd1e1dda68f75cf591f93", "title": "Softmax In-Place Normalization"}, "1840": {"path": "/deploy/cpp_infer/src/postprocess_op.cpp:1-26", "hash": "e02a8661b4c6119a6e676d6e7d9daa1d", "title": "Softmax In-place Implementation in PaddleVideo"}, "1841": {"path": "/deploy/cpp_infer/src/postprocess_op.cpp:27-50", "hash": "e8abf5fb64e1fd430a5c865adfa583d0", "title": "Softmax Implementation"}, "1842": {"path": "/deploy/cpp_infer/src/preprocess_op.cpp", "hash": "6c0649972821c6dc91fe14c97c4cc35b", "title": "Image Preprocessing for PaddleVideo Inference"}, "1843": {"path": "/deploy/cpp_infer/src/preprocess_op.cpp:1-36", "hash": "e654502d7d2a8e751bae0354ebfdfa58", "title": "Permute Class for OpenCV and Paddle API"}, "1844": {"path": "/deploy/cpp_infer/src/preprocess_op.cpp:37-66", "hash": "0e4e4c521ceaad1575e4202d19924e2a", "title": "Image Channel Preprocessing"}, "1845": {"path": "/deploy/cpp_infer/src/preprocess_op.cpp:67-104", "hash": "714894fc7a91f74e8c091b5db0fab33f", "title": "Resizable and Croppable Image Processing"}, "1846": {"path": "/deploy/cpp_infer/src/preprocess_op.cpp:105-132", "hash": "01c3b3dd6b76782b0b4691be2a57b3c3", "title": "Ten-Crop Image Preprocessing"}, "1847": {"path": "/deploy/cpp_infer/src/preprocess_op.cpp:133-135", "hash": "3a4d39478905ed4b7a90721fa22456e0", "title": "Pre-processing for PaddleVideo"}, "1848": {"path": "/deploy/cpp_infer/src/utility.cpp", "hash": "6a43516cc449447a8e67ec130c8e8b7c", "title": "Utility Functions in PaddleVideo Library"}, "1849": {"path": "/deploy/cpp_infer/src/utility.cpp:1-33", "hash": "c4ffc749704d52caec5c256b88d773a9", "title": "Utility Function in PaddleVideo Library"}, "1850": {"path": "/deploy/cpp_infer/src/utility.cpp:34-67", "hash": "a8ae6f84a6f8d46a61c73bff67528fc7", "title": "Reads Label File and Retrieves Directory Contents"}, "1851": {"path": "/deploy/cpp_infer/src/utility.cpp:68-93", "hash": "4befb993da6e4a402913653ee74cb4c4", "title": "Directory File Path Vectorization and Image Bounding Box"}, "1852": {"path": "/deploy/cpp_infer/src/utility.cpp:94-118", "hash": "e85b751693b9fa9c49a8872d3da9435f", "title": "Crop and Standardize Image Points"}, "1853": {"path": "/deploy/cpp_infer/src/utility.cpp:119-146", "hash": "f2a74201471c054b68d66c0c9b63e5b6", "title": "Perspective Image Transformation"}, "1854": {"path": "/deploy/cpp_infer/src/utility.cpp:147-181", "hash": "bd2e9b5665eafacec80a01a06d084fc0", "title": "Video Frame Sampler"}, "1855": {"path": "/deploy/cpp_infer/src/utility.cpp:182-192", "hash": "59ba5f8107851b2ff0a27a947476d1d9", "title": "Video Frame Sampling"}, "1856": {"path": "/deploy/cpp_infer/src/video_rec.cpp", "hash": "836250b8e4de4d1e82181e27301b9b36", "title": "AI-powered Video Processing"}, "1857": {"path": "/deploy/cpp_infer/src/video_rec.cpp:1-26", "hash": "88d3e44ad259d174e9212c5767b49196", "title": "Batch Size Operations"}, "1858": {"path": "/deploy/cpp_infer/src/video_rec.cpp:27-55", "hash": "59ccde7d84c616f8fdff890bb285a6bd", "title": "Video Frame Preprocessing for Inference"}, "1859": {"path": "/deploy/cpp_infer/src/video_rec.cpp:56-80", "hash": "97088254cd9b7bd9ddfe80e2640bc8c2", "title": "Video Frame Processing and Conversion"}, "1860": {"path": "/deploy/cpp_infer/src/video_rec.cpp:81-105", "hash": "25d2ab1e7c02729a7d29846bb7f158e8", "title": "Batch Segment Data Preprocessing"}, "1861": {"path": "/deploy/cpp_infer/src/video_rec.cpp:106-129", "hash": "a90a129a8a1d76831d45f8ad5d854bba", "title": "Image Preprocessing for Video Frames"}, "1862": {"path": "/deploy/cpp_infer/src/video_rec.cpp:130-152", "hash": "a867e2a034804cee42373d85bff596fb", "title": "Vector Initialization and Inference"}, "1863": {"path": "/deploy/cpp_infer/src/video_rec.cpp:153-175", "hash": "3f41c4909a877d9296865429c4f258cf", "title": "Softmax-Based AI Inference"}, "1864": {"path": "/deploy/cpp_infer/src/video_rec.cpp:177-198", "hash": "8dc2b9ff69baaee23ecfa2297a8c8dc3", "title": "Post-processing Object Detection Results"}, "1865": {"path": "/deploy/cpp_infer/src/video_rec.cpp:199-223", "hash": "58a029bb7828216d5d9edcc277dd94bd", "title": "Paddle Video Recognizer Initialization"}, "1866": {"path": "/deploy/cpp_infer/src/video_rec.cpp:225-247", "hash": "74b5b43198c63bd61742db96c3b3fdf4", "title": "Configure TensorRT Engine for Video Models"}, "1867": {"path": "/deploy/cpp_infer/src/video_rec.cpp:248-271", "hash": "73925307266dc4bea3f4a808c0580c24", "title": "Configure TensorRT Parameters"}, "1868": {"path": "/deploy/cpp_infer/src/video_rec.cpp:272-304", "hash": "ac6a0ea584d3fb1949bf75c9ebc06c58", "title": "Initialize PaddleVideo Predictor with TRT Options"}, "1869": {"path": "/deploy/cpp_infer/tools/build.sh", "hash": "f7c57092eba3704c78d033aa2d5269f7", "title": "Build C++ Inference Script"}, "1870": {"path": "/deploy/cpp_serving/paddle_env_install.sh", "hash": "9efe88629217769cf3ffab14c7ae7138", "title": "PaddleVideo C++ Serving Environment Setup"}, "1871": {"path": "/deploy/cpp_serving/paddle_env_install.sh:1-22", "hash": "9c84a788abbdc049e797c5311710d58c", "title": "Install TensorRT and PaddleVideo Dependencies"}, "1872": {"path": "/deploy/cpp_serving/paddle_env_install.sh:23-35", "hash": "06fae4d23e5a99228fcb440d6cf0af61", "title": "PaddleVideo C++ Serving Environment Setup"}, "1873": {"path": "/deploy/cpp_serving/preprocess_ops.py", "hash": "564d0f42205c6cb3b7a53a666ba103ac", "title": "Preprocessing Functions in CPP Serving"}, "1874": {"path": "/deploy/cpp_serving/preprocess_ops.py:1-34", "hash": "ef4ffd55cb3742448c3cf38602444776", "title": "Image Processing Composition"}, "1875": {"path": "/deploy/cpp_serving/preprocess_ops.py:35-76", "hash": "efe287bd94a14f1ac56335517289e00f", "title": "Video Preprocessing Function"}, "1876": {"path": "/deploy/cpp_serving/preprocess_ops.py:77-111", "hash": "8d60737e32245e0dbeb64975a5f85e94", "title": "Video Preprocessing Function"}, "1877": {"path": "/deploy/cpp_serving/preprocess_ops.py:113-126", "hash": "c6d325e4f89f75a6fde3ce25d1bba428", "title": "Model-Based Preprocess Function"}, "1878": {"path": "/deploy/cpp_serving/readme.md", "hash": "7f3497e8c4a08e9cf5fc6369679ce438", "title": "Deploy Paddle Serving with Docker"}, "1879": {"path": "/deploy/cpp_serving/readme.md:1-32", "hash": "d6c98e46a0c133f987e152af08bd7a80", "title": "Deploy Paddle Serving with Docker"}, "1880": {"path": "/deploy/cpp_serving/readme.md:34-64", "hash": "f08488a23b78a35a49bbaa44e3d08606", "title": "Speed Up PaddleServing Installation and Deployment"}, "1881": {"path": "/deploy/cpp_serving/readme.md:65-81", "hash": "375da90f6f09946e06e62c11f2367ae2", "title": "PaddleVideo Deployment Guide"}, "1882": {"path": "/deploy/cpp_serving/readme.md:82-118", "hash": "28a9b63eb2e8f68f5895c5fa7825a932", "title": "Rename Alias to 'outputs' for Fetch Variable"}, "1883": {"path": "/deploy/cpp_serving/readme.md:119-158", "hash": "9ce1226bb2543b2d801c0ecfaddcca9a", "title": "Deploy C++ Serving Server"}, "1884": {"path": "/deploy/cpp_serving/readme.md:160-164", "hash": "5971390198b5f347eb3dc902a4b4a68c", "title": "Disable Proxies Before Starting Service"}, "1885": {"path": "/deploy/cpp_serving/readme_en.md", "hash": "7f7055144e2f8aadf4b2a1734c8a093d", "title": "Accelerated Docker PaddleServing Deployment"}, "1886": {"path": "/deploy/cpp_serving/readme_en.md:1-17", "hash": "f664ae01ba03169c921e5b27e5f401e3", "title": "PaddleServing Docker Installation Guide"}, "1887": {"path": "/deploy/cpp_serving/readme_en.md:18-41", "hash": "e44e3df75e7c3c41d19f00874156be0a", "title": "Install Docker Container for PaddlePaddle Serving"}, "1888": {"path": "/deploy/cpp_serving/readme_en.md:42-65", "hash": "e58da088fa93839a6a81fca906b5e289", "title": "Speed Up PaddleServing Deployment with Action Recognition"}, "1889": {"path": "/deploy/cpp_serving/readme_en.md:66-79", "hash": "f87fa89e3eaf15e4c03d3dd537e4b1df", "title": "Directory and Model Specification for PaddleVideo Inference"}, "1890": {"path": "/deploy/cpp_serving/readme_en.md:79-94", "hash": "4a7299e4d5f42940233dae8c6a17b34c", "title": "Update Model Files and Configs"}, "1891": {"path": "/deploy/cpp_serving/readme_en.md:96-122", "hash": "4d9a3ea8b586062bf896d879c2faa7ea", "title": "Compatibility Rename Function for Model Deployment"}, "1892": {"path": "/deploy/cpp_serving/readme_en.md:123-152", "hash": "ee95483c9ce461694572f400365a8275", "title": "C++ PaddleVideo Serving Setup"}, "1893": {"path": "/deploy/cpp_serving/readme_en.md:152-165", "hash": "a9c377c9a51ffc8f4807210253d01e20", "title": "Proxy Settings in Cpp Serving Deployment"}, "1894": {"path": "/deploy/cpp_serving/run_cpp_serving.sh", "hash": "39f3673268def1a972681289ee3a3b89", "title": "Deploy PaddleVideo Server with PP-TSM/TSN"}, "1895": {"path": "/deploy/cpp_serving/serving_client.py", "hash": "bd57c4804e4e6c09c64ba8f0b34050a9", "title": "PaddleServing and PaddleVideo Integration"}, "1896": {"path": "/deploy/cpp_serving/serving_client.py:1-32", "hash": "24bc04ac19e4ce3240304205b1dcb3d3", "title": "Postprocess Paddle Serving Predictions"}, "1897": {"path": "/deploy/cpp_serving/serving_client.py:33-62", "hash": "ab5ad420bd1eb7c139278b7b4d04896c", "title": "CPP Serving Client Function"}, "1898": {"path": "/deploy/cpp_serving/serving_client.py:63-95", "hash": "e889b260019e1aea298e1608e4d02f33", "title": "Video Prediction Client in Python"}, "1899": {"path": "/deploy/paddle2onnx/predict_onnx.py", "hash": "d1dbdd2d6f221b9683de8a906073ade3", "title": "Paddle2ONNX Video Detection"}, "1900": {"path": "/deploy/paddle2onnx/predict_onnx.py:1-31", "hash": "9f278c45006c1a594c2bf49900be2614", "title": "PaddleVideo Inference Environment Setup"}, "1901": {"path": "/deploy/paddle2onnx/predict_onnx.py:32-54", "hash": "5e539a3eecedd04fb8004cf26b0466b9", "title": "Parse ONNX Prediction Parameters"}, "1902": {"path": "/deploy/paddle2onnx/predict_onnx.py:57-92", "hash": "ecd1f83a64047022513ead3dd9bc2b5f", "title": "Onnx Predictor Creation and Inference"}, "1903": {"path": "/deploy/paddle2onnx/predict_onnx.py:94-122", "hash": "5fcb0cb913ece2277cda93f31f12adfe", "title": "Building ONNX Inference Helper"}, "1904": {"path": "/deploy/paddle2onnx/predict_onnx.py:123-153", "hash": "44267a224897264892ec21a069421445", "title": "Batch Video Inference with Paddle2Onnx Predictor"}, "1905": {"path": "/deploy/paddle2onnx/predict_onnx.py:154-171", "hash": "27f726b4888b32e61670b0fd2dad351a", "title": "Benchmarked Predict: Autolog and Postprocess"}, "1906": {"path": "/deploy/paddle2onnx/readme.md", "hash": "e40bc2fcc416b538fe89d44c7fec43aa", "title": "Paddle to ONNX Conversion for Inference"}, "1907": {"path": "/deploy/paddle2onnx/readme.md:1-48", "hash": "edcc3627f0cce5a93babac904ed4dfea", "title": "Paddle2ONNX Model Conversion"}, "1908": {"path": "/deploy/paddle2onnx/readme.md:49-70", "hash": "7397a322904ab38fdcac29c0b1eb868e", "title": "ONNX-Paddle Inference Parity"}, "1909": {"path": "/deploy/paddle2onnx/readme_en.md", "hash": "b7f346c9d38e045a5d5dddfd76596040", "title": "Deploy Paddle2ONNX for PP-TSN Prediction"}, "1910": {"path": "/deploy/paddle2onnx/readme_en.md:1-28", "hash": "2595fb6814180d687e8f58dbd80c32b8", "title": "Paddle2ONNX Model Conversion"}, "1911": {"path": "/deploy/paddle2onnx/readme_en.md:29-61", "hash": "1fe060d5eaa43ac07aedb5e21d5247ad", "title": "Paddle2ONNX: Model Conversion and Prediction"}, "1912": {"path": "/deploy/paddle2onnx/readme_en.md:62-70", "hash": "d4b6bd175a5e36f142bdfcc8f2d5dbd6", "title": "Generate Output for Video File using PaddleVideo"}, "1913": {"path": "/deploy/python_serving/pipeline_http_client.py", "hash": "19cff51357732cb79ae0e6a63482f78f", "title": "Video Model Serving Pipeline with HTTP Client"}, "1914": {"path": "/deploy/python_serving/pipeline_http_client.py:1-30", "hash": "8d7759c8fbf5a667ea02612974beb2cb", "title": "Python PaddleVideo Serving Client"}, "1915": {"path": "/deploy/python_serving/pipeline_http_client.py:31-62", "hash": "3c5aa8fc31f4b81cf7abfd41c89a8cb9", "title": "Video HTTP Client"}, "1916": {"path": "/deploy/python_serving/pipeline_http_client.py:63-70", "hash": "44a81044b801fda605a7d67909579091", "title": "POST Request with JSON Data in Python"}, "1917": {"path": "/deploy/python_serving/pipeline_rpc_client.py", "hash": "3b5e6fdb0a4fa24c5836d0fb3b3f21f9", "title": "PaddleVideo Model Web Serving"}, "1918": {"path": "/deploy/python_serving/pipeline_rpc_client.py:1-29", "hash": "ee7370c60565c2368e6c3f05b9db048c", "title": "Handling PaddleVideo Model Execution"}, "1919": {"path": "/deploy/python_serving/pipeline_rpc_client.py:30-60", "hash": "0a2211bff9d692903f1cf69f17ff2d9e", "title": "Command Line RPC Client for Video Processing"}, "1920": {"path": "/deploy/python_serving/pipeline_rpc_client.py:61-68", "hash": "c3d95e1e743ce561f725cf3c5f082966", "title": "Video Prediction with PaddleVideo Client"}, "1921": {"path": "/deploy/python_serving/readme.md", "hash": "4479e38aa6703ff2aeeab898fc6656af", "title": "Deploy PaddlePaddle Model for Serving"}, "1922": {"path": "/deploy/python_serving/readme.md:1-32", "hash": "74ca79e2aa5a63df2e766c707aa65d24", "title": "Deploy PaddleServing Model on Linux"}, "1923": {"path": "/deploy/python_serving/readme.md:33-58", "hash": "bdd9612beac31c3f76c16b3e4bcd4ec0", "title": "Install PaddlePaddle for CPU and GPU"}, "1924": {"path": "/deploy/python_serving/readme.md:59-83", "hash": "ef020ed4f739914337dcdf8e676d9d28", "title": "Converting PaddlePaddle Model for Server Deployment"}, "1925": {"path": "/deploy/python_serving/readme.md:84-103", "hash": "8b02c578f52bec94666f19f9844dbba1", "title": "Configure PP-TSM Model Transformation Parameters"}, "1926": {"path": "/deploy/python_serving/readme.md:105-152", "hash": "79839fea34a2f52577a3ba6f5b900949", "title": "PaddleVideo Deployment: Input-Output Config"}, "1927": {"path": "/deploy/python_serving/readme.md:154-185", "hash": "75a89badba9b6cde948d0e19320760c0", "title": "RPC-based PaddleVideo Prediction"}, "1928": {"path": "/deploy/python_serving/readme_en.md", "hash": "73b11684ee82a88c4ccd4158a098d312", "title": "Deploying PaddleServing for Deep Learning via HTTP"}, "1929": {"path": "/deploy/python_serving/readme_en.md:1-16", "hash": "77c005f1501c5516693091b74e0b0424", "title": "Deploying Deep Learning Model with PaddleServing"}, "1930": {"path": "/deploy/python_serving/readme_en.md:17-41", "hash": "6214f5bcfbd297386e2a737a230825dc", "title": "Install PaddleServing for CPU and GPU"}, "1931": {"path": "/deploy/python_serving/readme_en.md:42-63", "hash": "dabedccebfb2fd677ca022509d56c7d1", "title": "Deploy Behavior Recognition Service with PaddleServing"}, "1932": {"path": "/deploy/python_serving/readme_en.md:64-83", "hash": "803912110e40dda062f844b4cdad3339", "title": "Model Conversion for Server Deployment"}, "1933": {"path": "/deploy/python_serving/readme_en.md:83-94", "hash": "d398c45bdc00fa22b903fb8dd1fdac26", "title": "PP-TSM Inference Model Conversion and Serving"}, "1934": {"path": "/deploy/python_serving/readme_en.md:95-119", "hash": "bead76939fe9f4043197424a956aa18b", "title": "Config File Alias Name Modification for Model Compatibility"}, "1935": {"path": "/deploy/python_serving/readme_en.md:120-145", "hash": "19583c30c092ef4693239f696111e55a", "title": "Start PaddleVideo Service with Python"}, "1936": {"path": "/deploy/python_serving/readme_en.md:146-175", "hash": "4c283e68598c4fe983d2b338c3874bdd", "title": "Python Web Service for Model Prediction"}, "1937": {"path": "/deploy/python_serving/readme_en.md:175-185", "hash": "147f8ab4a4e4d6c7411e3733813fa19b", "title": "Closing Proxy, Starting Service"}, "1938": {"path": "/deploy/python_serving/recognition_web_service.py", "hash": "4e7ebfecc9fd5abc2a4cc98cf11b784e", "title": "PaddleVideo Web Service Setup"}, "1939": {"path": "/deploy/python_serving/recognition_web_service.py:1-28", "hash": "4f51143a2d79e6a77c40e641434d3e18", "title": "Building Image Recognition Web Service Base"}, "1940": {"path": "/deploy/python_serving/recognition_web_service.py:29-62", "hash": "3a68268430c51ed3bf99416c127881bd", "title": "Preprocessing Function for Recognition Models"}, "1941": {"path": "/deploy/python_serving/recognition_web_service.py:63-102", "hash": "6259d22907ef23150f40f2239f70f38c", "title": "Video Processing Class in Recognition Web Service"}, "1942": {"path": "/deploy/python_serving/recognition_web_service.py:103-125", "hash": "14179bb8284d844289699cc91a0b2f6a", "title": "Decode and Reshape Frames Data"}, "1943": {"path": "/deploy/python_serving/recognition_web_service.py:126-149", "hash": "5785b05ac7cf485ed08a17d170e2fad1", "title": "Image Preprocessing and Post-Processing Methods"}, "1944": {"path": "/deploy/python_serving/recognition_web_service.py:150-182", "hash": "74e5d6b4af9115da400f9ecb1fac2fe3", "title": "Video Web Service Input Parser"}, "1945": {"path": "/deploy/python_serving/recognition_web_service.py:183-208", "hash": "a9a55be55faaaa31792629d69d53dc86", "title": "Command-Line Parsing for PaddleVideo Service"}, "1946": {"path": "/deploy/python_serving/utils.py", "hash": "d326a8520c1a4409e50713b2003dbf04", "title": "Video to Base64 Conversion Utils"}, "1947": {"path": "/deploy/python_serving/utils.py:1-37", "hash": "d6bc4eb7065f0181a1e393b02162f495", "title": "Video and Numpy Array Conversion Utilities"}, "1948": {"path": "/deploy/python_serving/utils.py:39-78", "hash": "e05e24efd2ebaab91e4ebbd17f3a1d8e", "title": "Video Frames Parser"}, "1949": {"path": "/deploy/python_serving/utils.py:79-81", "hash": "9e624fa4b8c7bb99038b41c9bf184f7c", "title": "Joining File Paths from List"}, "1950": {"path": "/deploy/slim/quant_post_static.py", "hash": "feeec92b531ce09f54dc31237256f5ef", "title": "Quantized Model for GPU Efficiency"}, "1951": {"path": "/deploy/slim/quant_post_static.py:1-32", "hash": "aa9419013b5b65f121b6c57029360f18", "title": "Python Licensing and Libraries"}, "1952": {"path": "/deploy/slim/quant_post_static.py:33-63", "hash": "52d39e746a3a842f6aa52f16e1d56fb4", "title": "Post-Training Quantization Function"}, "1953": {"path": "/deploy/slim/quant_post_static.py:65-84", "hash": "92392139e0dff5c8e3d6dac133d3d25b", "title": "Dynamic Dataset Loading for Quantization"}, "1954": {"path": "/deploy/slim/quant_post_static.py:86-114", "hash": "4f1a5c1ca7ae1720621a2888d966d740", "title": "Post-Training Quantization with Static Graph"}, "1955": {"path": "/deploy/slim/quant_post_static.py:117-120", "hash": "d9d1a0e9f9b9bd8db5045a418d007b00", "title": "Post-Training Quantization Function"}, "1956": {"path": "/deploy/slim/readme.md", "hash": "d1655321d1fd391e4eb3bc369190a0ab", "title": "Model Compression with PaddleSlim"}, "1957": {"path": "/deploy/slim/readme.md:2-44", "hash": "93124766dad8e81f16283d8036c8648d", "title": "PaddleSlim: Model Compression for PaddleVideo"}, "1958": {"path": "/deploy/slim/readme.md:46-91", "hash": "3b8b304f1337bb03b0f0a3e2ca8e56a7", "title": "Offline Quantization in PaddleVideo"}, "1959": {"path": "/deploy/slim/readme.md:93-133", "hash": "0516d1e6221e235169641048eb8135c9", "title": "PaddleVideo Quantized Model Deployment"}, "1960": {"path": "/deploy/slim/readme_en.md", "hash": "5311b38c10d20fdcd899e2d236deaf65", "title": "Efficient Model Compression for PaddleVideo"}, "1961": {"path": "/deploy/slim/readme_en.md:1-9", "hash": "9e5880df6e9cc72e6b510df801f25096", "title": "Efficient PaddleVideo Model Compression with PaddleSlim"}, "1962": {"path": "/deploy/slim/readme_en.md:10-30", "hash": "fdbaa6b8fb134834e2dc3e0c3e2564b0", "title": "PaddleSlim: Model Compression Tools"}, "1963": {"path": "/deploy/slim/readme_en.md:31-64", "hash": "2b1def45d4cc887c32c64bc525e70e63", "title": "Installing PaddleSlim, Model Preparation & Offline Quantization"}, "1964": {"path": "/deploy/slim/readme_en.md:64-87", "hash": "1d78546bab2c3bcb9b984010fd09025f", "title": "Offline Quantization in PaddleVideo"}, "1965": {"path": "/deploy/slim/readme_en.md:87-111", "hash": "dfbdf88b9850d56c3757df801f999662", "title": "Deploying PP-TSM Model for Prediction"}, "1966": {"path": "/deploy/slim/readme_en.md:112-132", "hash": "a21f042144b58ed96f9b120351934f57", "title": "Model Pruning and Deployment with PaddleLite"}, "1967": {"path": "/english_documents/benchmark.md", "hash": "bf41cfc8bcc6efdc937b5c1e82e0dcaa", "title": "PaddleVideo: Benchmarking Speed and Action Segmentation"}, "1968": {"path": "/english_documents/benchmark.md:1-27", "hash": "7323f41a7baf40867e970cec660e776b", "title": "PaddleVideo Speed Benchmark"}, "1969": {"path": "/english_documents/benchmark.md:29-45", "hash": "815e06e6cdd9960e0f8d49018e83715d", "title": "PaddleVideo Model Comparison"}, "1970": {"path": "/english_documents/benchmark.md:47-64", "hash": "185387b41fc079429e82f4d270c323c4", "title": "Sequential Action Segmentation Model Comparison"}, "1971": {"path": "/english_documents/benchmark.md:64-68", "hash": "95a9459d88f95d964adec3d50a0e78dc", "title": "PaddleVideo Benchmarking: Test Time & Parameters"}, "1972": {"path": "/english_documents/benchmark.md:68-69", "hash": "dfcf3fe37a1cbb6e4067990173fc945b", "title": "Reasoning Model Tested on GPU with Batch Size 2"}, "1973": {"path": "/english_documents/dataset/AVA.md", "hash": "c17aada34077f745f0ff9bd80e3ad105", "title": "AVA Dataset Preparation Process"}, "1974": {"path": "/english_documents/dataset/AVA.md:1-23", "hash": "fa739470479c9a88308ec6faa7a40e7c", "title": "AVA Dataset Preparation Process"}, "1975": {"path": "/english_documents/dataset/AVA.md:26-78", "hash": "e501e01c6f034b8f4197cb8b53793481", "title": "Preparing AVA Dataset for Action Recognition"}, "1976": {"path": "/english_documents/dataset/AVA.md:79-112", "hash": "d4eebe26a35757d005ad2d4e6da6ce92", "title": "Folder Structure for AVA Dataset in PaddleVideo"}, "1977": {"path": "/english_documents/dataset/AVA.md:113-113", "hash": "caad05b01c04fd43ec23aa1f0260ae0e", "title": "Video Frame Count Calculator"}, "1978": {"path": "/english_documents/dataset/ActivityNet.md", "hash": "e79c70ff0f94449e42859f48c97f18b2", "title": "ActivityNet Dataset Preparation"}, "1979": {"path": "/english_documents/dataset/ActivityNet.md:1-24", "hash": "661e9d51ee7cc7188b03e5b818cb9ec0", "title": "ActivityNet: Large-Scale Video Dataset for Understanding"}, "1980": {"path": "/english_documents/dataset/ActivityNet.md:25-45", "hash": "fc0e773742e749af47ef8afcdcf653cd", "title": "ActivityNet Dataset Video Feature Extraction"}, "1981": {"path": "/english_documents/dataset/ActivityNet.md:46-77", "hash": "4af9d8fe13bf8a7ebc4c14664b05fa73", "title": "ActivityNet Annotations Structure"}, "1982": {"path": "/english_documents/dataset/ActivityNet.md:78-80", "hash": "fc9f0d87ab9313a5ee23b7b8d4fecdda", "title": "Update Configuration Paths"}, "1983": {"path": "/english_documents/dataset/Oxford_RobotCar.md", "hash": "1ed8e2370dd95a3caa7f03ec04511a6c", "title": "Oxford-RobotCar Dataset Preparation"}, "1984": {"path": "/english_documents/dataset/Oxford_RobotCar.md:1-24", "hash": "f7cc365570118ccf13a3fd80d51176fa", "title": "Oxford-RobotCar Dataset Preparation"}, "1985": {"path": "/english_documents/dataset/Oxford_RobotCar.md:25-46", "hash": "7b5c10f822bf49244284d5eea80cbf12", "title": "BibTeX Citations for Datasets"}, "1986": {"path": "/english_documents/dataset/Oxford_RobotCar.md:47-64", "hash": "5c24e3da84c484bc9869cc752cdd21ec", "title": "Oxford RobotCar Dataset Download"}, "1987": {"path": "/english_documents/dataset/Oxford_RobotCar.md:65-80", "hash": "86ac248f3dc559cbfe31b844cf573fe4", "title": "RobotCar Dataset Training Links"}, "1988": {"path": "/english_documents/dataset/Oxford_RobotCar.md:81-98", "hash": "34de97189d77e54077790e8f98a624ed", "title": "Oxford RobotCar Dataset File URLs"}, "1989": {"path": "/english_documents/dataset/Oxford_RobotCar.md:101-114", "hash": "9a56ed532a6fc3eb203bb90ef6286b1c", "title": "Dynamic Frame Filtering and Timestamp Renaming"}, "1990": {"path": "/english_documents/dataset/Oxford_RobotCar.md:115-137", "hash": "e475accb2f6c5dfb644c68da4e8d42fd", "title": "RobotCar Dataset with CycleGAN"}, "1991": {"path": "/english_documents/dataset/Oxford_RobotCar.md:137-150", "hash": "45f7153c6ea075cdc56134e08fb2597e", "title": "Oxford-RobotCar Dataset Structure"}, "1992": {"path": "/english_documents/dataset/Oxford_RobotCar.md:151-162", "hash": "9c43a9e8efbe3a99190c318afae2e125", "title": "Directory Structure: Day/Night Training & Verification Images"}, "1993": {"path": "/english_documents/dataset/README.md", "hash": "7fdb17f2e3267d391ff31264bc34d657", "title": "Comprehensive Action Datasets Table"}, "1994": {"path": "/english_documents/dataset/README.md:1-28", "hash": "2d081a3219273c790577f710872098dd", "title": "Action Recognition Datasets Table"}, "1995": {"path": "/english_documents/dataset/README.md:29-58", "hash": "296c4853065a263acf5660ca70db8635", "title": "Dataset Table: Skeleton, Depth, Text"}, "1996": {"path": "/english_documents/dataset/README.md:58-73", "hash": "5731a12f712a8ee3f37124cb4e9282f4", "title": "HTML Table of Multimodal Datasets with Publication Years"}, "1997": {"path": "/english_documents/dataset/SegmentationDataset.md", "hash": "c8d70a1507664d3e13770dafb077884b", "title": "Video Action Segmentation Dataset"}, "1998": {"path": "/english_documents/dataset/fsd.md", "hash": "5f983d0a9030937fc201010fdb11a6f1", "title": "Figure Skating Dataset Overview"}, "1999": {"path": "/english_documents/dataset/fsd.md:1-26", "hash": "777541f4b28d3bdbfb9f97808f5309b5", "title": "Figure Skating OpenPose Dataset"}, "2000": {"path": "/english_documents/dataset/fsd.md:26-47", "hash": "411d1b714d46761a212576a941f84b3f", "title": "Tensor Structure and Joint Points in Dataset"}, "2001": {"path": "/english_documents/dataset/fsd.md:49-55", "hash": "942f93bf5819d9b6775199d1597e2974", "title": "Train Dataset Details"}, "2002": {"path": "/english_documents/dataset/k400.md", "hash": "052d763295b00bee6fd02739ce910bf6", "title": "Kinetics-400 Dataset Download and Extraction"}, "2003": {"path": "/english_documents/dataset/k400.md:1-27", "hash": "e8eae4bf4ae438ec3d8941704f6ca471", "title": "Kinetics-400 Dataset Download Options"}, "2004": {"path": "/english_documents/dataset/k400.md:29-65", "hash": "75c4dbe14d08a955bc0cb3e2f61e0cab", "title": "Accelerating Network Training with Videos"}, "2005": {"path": "/english_documents/dataset/k400.md:65-78", "hash": "11e937a2881fdb0a40e47e9236db5f93", "title": "Extracting K400 Video Frames"}, "2006": {"path": "/english_documents/dataset/msrvtt.md", "hash": "4986bf8f0441aad59069db265821a6fa", "title": "MSR-VTT: Video Transformers Dataset"}, "2007": {"path": "/english_documents/dataset/msrvtt.md:1-29", "hash": "01f9232dc380e4a38994e62336018b2b", "title": "MSR-VTT Dataset Overview"}, "2008": {"path": "/english_documents/dataset/msrvtt.md:31-73", "hash": "92d61f11e66409e1d69c8e73b33a6d6c", "title": "ActBERT MSR-VTT Dataset Download"}, "2009": {"path": "/english_documents/dataset/msrvtt.md:74-79", "hash": "37991f8ff98175ad22198ac8392331a5", "title": "Multi-Modal Transformer Database"}, "2010": {"path": "/english_documents/dataset/ntu-rgbd.md", "hash": "c252d72a2f3f63d22d10e3af8c4b94de", "title": "NTU RGB+D Dataset Preparation for CTR-GCN"}, "2011": {"path": "/english_documents/dataset/ntu-rgbd.md:1-23", "hash": "acf90dbe30a6556d825e64655d7b41f7", "title": "NTU-RGB+D Dataset Overview"}, "2012": {"path": "/english_documents/dataset/ntu-rgbd.md:23-59", "hash": "16d4c5d4913904c52d34a3b9975d4a6c", "title": "NTU-RGB-D Dataset Download and Unzipping"}, "2013": {"path": "/english_documents/dataset/ntu-rgbd.md:60-93", "hash": "e900c6a83d2b3df35a14d42d38476c64", "title": "Preparing NTU-RGBD Dataset for CTR-GCN"}, "2014": {"path": "/english_documents/dataset/ntu-rgbd.md:94-129", "hash": "cb7d7a67ba990e97c4ae91948d038b5f", "title": "NTU-RGBD Dataset Overview"}, "2015": {"path": "/english_documents/dataset/ntu-rgbd.md:130-158", "hash": "49fb5382e59800e458789addfc4cf029", "title": "NTU RGB+D Dataset Organization and Preprocessing"}, "2016": {"path": "/english_documents/dataset/ucf101.md", "hash": "e985fda6e01703ab898b04d9d09038ce", "title": "UCF101 Dataset Organization"}, "2017": {"path": "/english_documents/dataset/ucf101.md:1-40", "hash": "b366b6d73deec39d03815f3d90ac7b08", "title": "UCF101 Dataset Download and Extraction"}, "2018": {"path": "/english_documents/dataset/ucf101.md:41-81", "hash": "04c99f403e910289990d92416f06cacb", "title": "UCF101 Dataset File Organization"}, "2019": {"path": "/english_documents/dataset/ucf101.md:82-86", "hash": "bbbf4c992aae5180774bf9114cee9872", "title": "UCF101: Video Categories and Clips"}, "2020": {"path": "/english_documents/dataset/ucf24.md", "hash": "d1762ae31d0fad47b6f80b5969df4cce", "title": "UCF24 Dataset Preparation Guide"}, "2021": {"path": "/english_documents/dataset/ucf24.md:1-20", "hash": "3bfd7eb733494f9f6b95a2fa207e536d", "title": "UCF24 Dataset Preparation with PaddleVideo"}, "2022": {"path": "/english_documents/dataset/ucf24.md:22-60", "hash": "fa5de639d90d3f4f49cea303b50ddeec", "title": "UCF24 Dataset Preparation with PaddleVideo"}, "2023": {"path": "/english_documents/dataset/ucf24.md:61-73", "hash": "f1f983074de705e3b8c53c29a9cd0b86", "title": "UCF101 Dataset File Structure"}, "2024": {"path": "/english_documents/dataset/youtube8m.md", "hash": "805ffe470acd55f093fd12a0ed6da271", "title": "YouTube-8M: Massive Video Classification Dataset"}, "2025": {"path": "/english_documents/dataset/youtube8m.md:1-20", "hash": "65f9b29860c9d37eb4e6ddae2ea9a8ba", "title": "Large-scale Video Classification Data Set"}, "2026": {"path": "/english_documents/dataset/youtube8m.md:21-44", "hash": "2782aa5079d8b958fdc64a11ec96fa2f", "title": "Prepare Dataset for PaddlePaddle"}, "2027": {"path": "/english_documents/dataset/youtube8m.md:45-56", "hash": "01e912800778b1c31b6c3156d39c8093", "title": "Pkl File Splitting and List Generation"}, "2028": {"path": "/english_documents/install.md", "hash": "0abefc05fab4980f675fec18ab833319", "title": "PaddlePaddle & PaddleVideo Installation Guide"}, "2029": {"path": "/english_documents/install.md:1-41", "hash": "805a8829733b2411783e1c2e0dab0779", "title": "PaddlePaddle GPU Installation Guide"}, "2030": {"path": "/english_documents/install.md:42-72", "hash": "d53e092bc54bd9936a5140b8698ea6f0", "title": "Install and Configure PaddleVideo"}, "2031": {"path": "/english_documents/model_zoo/README.md", "hash": "90f4ad203dc48b8eab15ab39071080ff", "title": "Model Zoo: Action Recognition and Segmentation Models"}, "2032": {"path": "/english_documents/model_zoo/README.md:1-26", "hash": "c4619cfdedcf705594ef97467122ce9e", "title": "Action Recognition Model Zoo"}, "2033": {"path": "/english_documents/model_zoo/README.md:27-61", "hash": "5d366ccafeced071c34afdde9f898ac2", "title": "AI Model Zoo: Action Recognition & Segmentation Models"}, "2034": {"path": "/english_documents/model_zoo/README.md:62-100", "hash": "926e774f8688ec7f6aeb32dab2d1e529", "title": "PaddleVideo Model Zoo Table"}, "2035": {"path": "/english_documents/model_zoo/README.md:101-106", "hash": "f489551a8c1a11fb82882e4cfab963a9", "title": "Empty HTML Table Cell or Row"}, "2036": {"path": "/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md", "hash": "113247221fdbae7373b6bd89e816c242", "title": "SlowFast_FasterRCNN Action Detection Tutorial"}, "2037": {"path": "/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md:1-24", "hash": "b2696453949f9c6e9a847ebceec87c50", "title": "SlowFast_FasterRCNN: Video Action Detection Model"}, "2038": {"path": "/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md:26-64", "hash": "8bb24462dde388100a9f5d9f28ac2df5", "title": "AVA Dataset Video Processing Guide"}, "2039": {"path": "/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md:65-90", "hash": "c7d435f1ac54f27bdf4c3115357f7cf6", "title": "Training and Testing SlowFast Faster RCNN on AVA Dataset"}, "2040": {"path": "/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md:93-126", "hash": "a226d21aa586e160cee9d649379bb4e7", "title": "Action Detection with SlowFast+FasterRCNN"}, "2041": {"path": "/english_documents/model_zoo/detection/SlowFast_FasterRCNN_en.md:127-129", "hash": "2aef124654d86688521c8e470000d06b", "title": "GPU Acceleration, No TensorRT"}, "2042": {"path": "/english_documents/model_zoo/estimation/adds.md", "hash": "43e73a263e2e84709d97e287f9a66120", "title": "ADDS-DepthNet: Estimating Depth with Day & Night Images"}, "2043": {"path": "/english_documents/model_zoo/estimation/adds.md:1-23", "hash": "7ed4c86c4064ce57f59f377585935489", "title": "ADDS-DepthNet: Self-Supervised Monocular Depth Estimation"}, "2044": {"path": "/english_documents/model_zoo/estimation/adds.md:26-49", "hash": "a3f9a56648d5e9a3ac68e2091a0a28dc", "title": "Adding Pre-Trained Model to Oxford RobotCar Dataset"}, "2045": {"path": "/english_documents/model_zoo/estimation/adds.md:50-72", "hash": "178e03d6246cad68ec69a6da6e32cfc2", "title": "Train and Test ADDS-DepthNet with Oxford RobotCar Dataset"}, "2046": {"path": "/english_documents/model_zoo/estimation/adds.md:74-90", "hash": "9b1ccbdea207c51dc306053ea2663ea4", "title": "ADDS Model Testing on RobotCar Dataset"}, "2047": {"path": "/english_documents/model_zoo/estimation/adds.md:92-107", "hash": "361ebe390204d98af617368bc501d710", "title": "Model Performance Comparison Table"}, "2048": {"path": "/english_documents/model_zoo/estimation/adds.md:107-124", "hash": "79792d0a8db2e5456e67efd82bbf11f3", "title": "Predicting Depth Maps with PaddlePaddle's ADDS Model"}, "2049": {"path": "/english_documents/model_zoo/estimation/adds.md:126-133", "hash": "10dc87df8980c819b91d72211795f8de", "title": "Self-supervised Monocular Depth Estimation"}, "2050": {"path": "/english_documents/model_zoo/localization/bmn.md", "hash": "8dbac2263cb59166f57b4d9c44da9cdb", "title": "BMN Model for Action Proposal Generation"}, "2051": {"path": "/english_documents/model_zoo/localization/bmn.md:1-35", "hash": "235ff75f2431a2f4f762b1ec2f880d00", "title": "BMN Model: Training and Evaluation Modules"}, "2052": {"path": "/english_documents/model_zoo/localization/bmn.md:36-68", "hash": "a0e3e00fa04b93bd6df3e58cfd5f97f4", "title": "BMN Localization Model Deployment with PaddlePaddle"}, "2053": {"path": "/english_documents/model_zoo/localization/bmn.md:70-96", "hash": "f376ff1f413ce4be304bdb539755a2bd", "title": "BMN Model Inference: Export and Predict"}, "2054": {"path": "/english_documents/model_zoo/localization/bmn.md:97-104", "hash": "0fabfd11d9e1b0c87b623f357b6a891b", "title": "BMN: Temporal Action Proposal Inference Results"}, "2055": {"path": "/english_documents/model_zoo/localization/yowo.md", "hash": "1bbfe4d48c46609a58a22456fe6ee25e", "title": "YOWO: Efficient Feature Extraction Model"}, "2056": {"path": "/english_documents/model_zoo/localization/yowo.md:1-36", "hash": "0347574ac20dc55edac68a58ba2197c6", "title": "YOWO: Spatio-Temporal Feature Extraction for Localization"}, "2057": {"path": "/english_documents/model_zoo/localization/yowo.md:36-60", "hash": "d650f212059cec5dedc14576eefe7097", "title": "YOWO Localizer: Download and Train with PaddleVideo"}, "2058": {"path": "/english_documents/model_zoo/localization/yowo.md:61-80", "hash": "d24944892e5a2002e177e74f8214e778", "title": "Faster AMP Mixed-Precision Training for Yowo"}, "2059": {"path": "/english_documents/model_zoo/localization/yowo.md:80-101", "hash": "8756082eabb9d38d3ea1130ed33cbfe4", "title": "Evaluating YOWO Model Performance and Exporting Inference Model"}, "2060": {"path": "/english_documents/model_zoo/localization/yowo.md:102-122", "hash": "b22d9a6832681e97ff02a71b350590b3", "title": "Generate and Predict YOWO Model"}, "2061": {"path": "/english_documents/model_zoo/localization/yowo.md:124-138", "hash": "e0cf1ceaee934b6c80d2e7c4ef4b07c6", "title": "YOWO Model Predicts HorseRiding with 0.8 Confidence"}, "2062": {"path": "/english_documents/model_zoo/multimodal/actbert.md", "hash": "5301712b74e42792f3b6efe3294f7ee1", "title": "ActBERT: Multimodal Pretrain Task for Video-Language Tasks"}, "2063": {"path": "/english_documents/model_zoo/multimodal/actbert.md:1-25", "hash": "51fc68b26ce73f0f948daed91a79eddc", "title": "Introducing ActBERT: Multimodal Pretrain Task for Video-Language Tasks"}, "2064": {"path": "/english_documents/model_zoo/multimodal/actbert.md:26-65", "hash": "0994cf5052cbfe061873a20957d85fb5", "title": "Training ActBERT on HowTo100M Dataset"}, "2065": {"path": "/english_documents/model_zoo/multimodal/actbert.md:66-98", "hash": "e9c596bc029674d4716d21a0cfd716aa", "title": "Training ActBERT with AMP and MSR-VTT"}, "2066": {"path": "/english_documents/model_zoo/partition/transnetv2.md", "hash": "334177f207b1c9cd5d3f84a1a797182d", "title": "TransNetV2: Deep Learning Shot Transition Detection"}, "2067": {"path": "/english_documents/model_zoo/partition/transnetv2.md:1-28", "hash": "d827054ccfd1806be4b70ce1923577a7", "title": "TransNetV2: Video Segmentation with DDCNN V2"}, "2068": {"path": "/english_documents/model_zoo/partition/transnetv2.md:28-62", "hash": "386fc3d814ca0ace557b9027ff42d90a", "title": "TransNetV2 Inference Model Guide"}, "2069": {"path": "/english_documents/model_zoo/partition/transnetv2.md:64-80", "hash": "557cc79fb7635fd199ead25990ef6aaf", "title": "TransNetV2 Prediction Demo"}, "2070": {"path": "/english_documents/model_zoo/recognition/agcn.md", "hash": "b1d12a873aabb52e762218b7fc00f96d", "title": "AGCN: Enhanced Video Recognition via Multi-Stream Graph Convs"}, "2071": {"path": "/english_documents/model_zoo/recognition/agcn.md:1-46", "hash": "585e0020d872975bfe040db9ace21bc7", "title": "Adaptive Graph Convolution Network (AGCN) Implementation"}, "2072": {"path": "/english_documents/model_zoo/recognition/agcn.md:49-84", "hash": "ef1c893b923bebdb9dee457892213b52", "title": "AGCN Test Scripts and Results"}, "2073": {"path": "/english_documents/model_zoo/recognition/agcn.md:87-117", "hash": "b903b713b8f4d62aba1f73bf29f2f95f", "title": "AGCN Video Recognition Model Usage"}, "2074": {"path": "/english_documents/model_zoo/recognition/agcn.md:118-129", "hash": "7aceb3b2092e74c9c35b94035c27a18b", "title": "Multi-Stream Adaptive Graph Convolutional Network for Action Recognition"}, "2075": {"path": "/english_documents/model_zoo/recognition/agcn2s.md", "hash": "24d57571b5d1a79216a1d69dce80f486", "title": "AGCN2s: Enhanced Motion Recognition Model"}, "2076": {"path": "/english_documents/model_zoo/recognition/agcn2s.md:1-20", "hash": "f4e3fe815e94da959285bdc85e75b81c", "title": "Introducing 2s-AGCN for Bone Motion Recognition"}, "2077": {"path": "/english_documents/model_zoo/recognition/agcn2s.md:20-40", "hash": "00831997d10696210d7f7051c9fc8e1d", "title": "AGCN2S: Skeleton-based Gesture Recognition Network"}, "2078": {"path": "/english_documents/model_zoo/recognition/agcn2s.md:41-71", "hash": "aaae6079ebfef62c45e2e834bb7fd11e", "title": "2s-AGCN Test Scripts & Results"}, "2079": {"path": "/english_documents/model_zoo/recognition/agcn2s.md:73-79", "hash": "637764d1ca9d7dd1e7b1bb69cfcd803a", "title": "AGCN-2s Model Checkpoints"}, "2080": {"path": "/english_documents/model_zoo/recognition/agcn2s.md:81-103", "hash": "540727c9aa2a57dd5cae5d64edd40721", "title": "Exporting AGCN2s for Action Recognition"}, "2081": {"path": "/english_documents/model_zoo/recognition/agcn2s.md:104-112", "hash": "356f500296e7cc8722ca9e5b4c433520", "title": "AGCN2S Model Prediction Engine"}, "2082": {"path": "/english_documents/model_zoo/recognition/attention_lstm.md", "hash": "8c8f9c4f9302fc7e146325ec75c03d87", "title": "AttentionLSTM Model for YouTube-8M Classification"}, "2083": {"path": "/english_documents/model_zoo/recognition/attention_lstm.md:1-19", "hash": "ae0dd148e1e9429e22fd85792ea39913", "title": "Attention-LSTM for Video Recognition"}, "2084": {"path": "/english_documents/model_zoo/recognition/attention_lstm.md:21-45", "hash": "444c70f1b48e20d84dbbd0c866656131", "title": "Attention LSTM on Youtube-8M with 8 GPUs"}, "2085": {"path": "/english_documents/model_zoo/recognition/attention_lstm.md:47-68", "hash": "3725522451b59acc5930087ac44b7e2d", "title": "Export and Use AttentionLSTM Model"}, "2086": {"path": "/english_documents/model_zoo/recognition/attention_lstm.md:69-84", "hash": "7c545c1919d4267e112aadef3c6514b1", "title": "AttentionLSTM for Video Classification"}, "2087": {"path": "/english_documents/model_zoo/recognition/ctrgcn.md", "hash": "db76cd0c7c5db81d5df3a0e099a9e47b", "title": "Bone-Based Behavior Recognition with CTR-GCN"}, "2088": {"path": "/english_documents/model_zoo/recognition/ctrgcn.md:1-39", "hash": "6f22af889f16bac78141737bfbf8ba7c", "title": "Bone-Based Behavior Recognition with CTR-GCN"}, "2089": {"path": "/english_documents/model_zoo/recognition/ctrgcn.md:41-74", "hash": "5087204f4b1ee828a8ed3e168990ef87", "title": "PaddlePaddle CTR-GCN Model: NTU Dataset Training & Testing"}, "2090": {"path": "/english_documents/model_zoo/recognition/ctrgcn.md:74-90", "hash": "ab60e317dace634cd90247c4e9a0e7b8", "title": "CTRGCN Model Performance on NTU-RGB+D Dataset"}, "2091": {"path": "/english_documents/model_zoo/recognition/ctrgcn.md:93-121", "hash": "af916b213b5d9060fd152d54f2f1439e", "title": "PaddleVideo's CTRGCN Model for Action Recognition"}, "2092": {"path": "/english_documents/model_zoo/recognition/ctrgcn.md:122-128", "hash": "677b4e2846dc8d1637455cb06e7af622", "title": "Top-1 Action Recognition Scores"}, "2093": {"path": "/english_documents/model_zoo/recognition/movinet.md", "hash": "1099e089f1f00ee23ce88a83d79e4dc7", "title": "PaddleVideo's Efficient MoViNet Model"}, "2094": {"path": "/english_documents/model_zoo/recognition/movinet.md:1-40", "hash": "71f2e198740c74709c8438dda8aa5eaf", "title": "MoViNet: Efficient Video Reasoning Model"}, "2095": {"path": "/english_documents/model_zoo/recognition/movinet.md:41-73", "hash": "6dce496a1a1712934404c14778d1183a", "title": "MoViNet Testing and Inference Guide"}, "2096": {"path": "/english_documents/model_zoo/recognition/movinet.md:74-91", "hash": "bd55bbb9c0ce383a5922ac5325251102", "title": "MoViNet Model Configuration"}, "2097": {"path": "/english_documents/model_zoo/recognition/posec3d.md", "hash": "089b9fad898589f82e42d2a35c527ccc", "title": "PoseC3D: Skeleton-Based Action Recognition on UCF101"}, "2098": {"path": "/english_documents/model_zoo/recognition/posec3d.md:1-24", "hash": "c6a35ae2a54111574535a947c0c64342", "title": "PoseC3D: Skeleton-based Action Recognition"}, "2099": {"path": "/english_documents/model_zoo/recognition/posec3d.md:24-39", "hash": "891cfb695ce28459a2939e7860a53d11", "title": "Training PoseC3D on UCF101 with Pre-trained Weights"}, "2100": {"path": "/english_documents/model_zoo/recognition/posec3d.md:40-82", "hash": "fa4b406e059b6a172453a76d16d15b5a", "title": "PoseC3D Model Testing and Inference Guide"}, "2101": {"path": "/english_documents/model_zoo/recognition/posec3d.md:83-100", "hash": "918ed65c46d6268f10219e74e08ed2e8", "title": "Inferring PoseC3D without TensorRT and GPU Acceleration"}, "2102": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md", "hash": "9eb36dd5e37933b23fc89695fc395c98", "title": "Enhanced Video Recognition with PP-TimeSformer"}, "2103": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:1-29", "hash": "428f69e5dbf6df796ac307cbad609de4", "title": "PP-TimeSformer: Video Classification Model"}, "2104": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:31-58", "hash": "2a04e24c6afe51f26b6059e404e7c5fd", "title": "Download and Prepare Data for Video Recognition"}, "2105": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:60-75", "hash": "e5d69e738428377c94043c2bb32ddeed", "title": "Efficient Video Recognition with PaddlePaddle Timesformer"}, "2106": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:78-92", "hash": "edd72321e6814cb45d63f003b3a1cebe", "title": "PP-TimeSformer Test Accuracy"}, "2107": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:93-108", "hash": "2132c904123ea790a12b7e2d8cc2a4b7", "title": "Launching PaddleVideo with Vision Transformer and UniformCrop"}, "2108": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:108-120", "hash": "df00752ead46dada169e1e5dd313a222", "title": "Export PP-TimeSformer Model for Video Recognition"}, "2109": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:121-147", "hash": "1eecd509036ab18615cdb2cbd42796bc", "title": "PaddlePaddle's ppTimeSformer for Video Recognition"}, "2110": {"path": "/english_documents/model_zoo/recognition/pp-timesformer.md:147-156", "hash": "bff8e12dd0112b85bad6c2bb75df00ee", "title": "PP-Timesformer for Video Classification"}, "2111": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md", "hash": "cf84f7f4b5f0cd27a71a7927866dbc0b", "title": "Optimized PP-TSM for Action Recognition"}, "2112": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md:1-31", "hash": "836df62cc06d41e03bfd9e095e3d3a07", "title": "Optimized PP-TSM for Action Recognition"}, "2113": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md:31-64", "hash": "c964843b5932e512cfa776c917b49dac", "title": "Training TSM Models on Kinetics and UCF"}, "2114": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md:64-90", "hash": "fe72b73c28561b9a01c6f9317ceb8c17", "title": "Training PP-TSM with Pretrained Model"}, "2115": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md:92-122", "hash": "3bfac1352ab7584a0fae211a1c53136d", "title": "PP-TSM: Kinetics-400 Training & Testing"}, "2116": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md:122-127", "hash": "e7baac2d91794f2707bb6e02a92d72c8", "title": "Pre-trained PP-TSM Models"}, "2117": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md:129-159", "hash": "f22a086b838e0a62dc9b604dc5fe5fd8", "title": "Export and Use PPTSM Model for Video Classification"}, "2118": {"path": "/english_documents/model_zoo/recognition/pp-tsm.md:160-167", "hash": "41d9b4c4734c05cb4ec7ca765b61e264", "title": "Top1 Prediction: Archery"}, "2119": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md", "hash": "fdeb7d2bfe5264d1b9fe451f5cb982d0", "title": "PP-TSN: Enhanced TSN with Mixed-Precision"}, "2120": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md:1-30", "hash": "ad7f820beadf6ed0fea8abea4b12be07", "title": "PP-TSN Model Documentation"}, "2121": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md:33-61", "hash": "23d66fd79f879bac52e39af1ef7475a0", "title": "Training PP-TSN on Kinetics-400 with 8 GPUs"}, "2122": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md:63-81", "hash": "63c5a5dd50b33b024dbb159da8d44c1c", "title": "Accelerating PP-TSN Training with AMP"}, "2123": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md:81-95", "hash": "5d136aae7be31ac950d1d219d9d73e1b", "title": "Distinct Testing Method for PP-TSN Model"}, "2124": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md:96-105", "hash": "c9489594fdf769dc4616d0f81d3b7ed3", "title": "PP-TSN Model Test Results on Kinetics-400"}, "2125": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md:105-125", "hash": "b84361f5bd078c21243a263ecfeb1db4", "title": "PP-TSN Model Export and Inference"}, "2126": {"path": "/english_documents/model_zoo/recognition/pp-tsn.md:126-146", "hash": "c3ad6675bc72013fd73919fa7b9915f2", "title": "PP-TSN Video Recognition Inference"}, "2127": {"path": "/english_documents/model_zoo/recognition/slowfast.md", "hash": "4cc519177824719106bce060e4e36de2", "title": "SlowFast Model: Multigrid Training for Video Recognition"}, "2128": {"path": "/english_documents/model_zoo/recognition/slowfast.md:1-38", "hash": "cf1633c6dc21a3ff9feb74f5f44ebbe1", "title": "SlowFast: Video Recognition Model Docs"}, "2129": {"path": "/english_documents/model_zoo/recognition/slowfast.md:39-58", "hash": "f4ecc1e7a5e6db27afd58138cacd1726", "title": "Multigrid-Accelerated SlowFast Training"}, "2130": {"path": "/english_documents/model_zoo/recognition/slowfast.md:61-79", "hash": "bd13dc5429ba282cd07fd817a56cbad1", "title": "Testing SlowFast Model in PaddleVideo"}, "2131": {"path": "/english_documents/model_zoo/recognition/slowfast.md:82-112", "hash": "f6a05638a1e451b73b18e62d05f46684", "title": "SlowFast Model Export and Inference Guide"}, "2132": {"path": "/english_documents/model_zoo/recognition/slowfast.md:113-120", "hash": "31d8f233ca844d100563593512e58346", "title": "SlowFast Networks for Video Recognition Code"}, "2133": {"path": "/english_documents/model_zoo/recognition/stgcn.md", "hash": "592f050230fa363ca5cc91b417a44cbd", "title": "ST-GCN Action Recognition Model Training and Testing"}, "2134": {"path": "/english_documents/model_zoo/recognition/stgcn.md:1-49", "hash": "e21feb84b4dbc6d08840910e67fbf68c", "title": "Skeleton-based Action Recognition with ST-GCN"}, "2135": {"path": "/english_documents/model_zoo/recognition/stgcn.md:50-89", "hash": "260990439b016019664c7c02dce42a4b", "title": "Test ST-GCN Model on FSD and NTU-RGB+D Datasets"}, "2136": {"path": "/english_documents/model_zoo/recognition/stgcn.md:90-115", "hash": "5514eabc4aceaade7fb2a81ce9c20142", "title": "Export and Predict with STGCN Model"}, "2137": {"path": "/english_documents/model_zoo/recognition/stgcn.md:116-129", "hash": "f8320b26d30ab433c5a54546d21f414c", "title": "STGCN Recognition Model"}, "2138": {"path": "/english_documents/model_zoo/recognition/timesformer.md", "hash": "f0ad58c2c863fe5d762ab4f8b8c848f3", "title": "TimeSformer: Top Video Classifier"}, "2139": {"path": "/english_documents/model_zoo/recognition/timesformer.md:1-26", "hash": "a71855d03b584f47073830ec4929e5be", "title": "TimeSformer: Efficient Video Classification"}, "2140": {"path": "/english_documents/model_zoo/recognition/timesformer.md:28-57", "hash": "661f24eed9447fcde922cbe13d00acef", "title": "Train Timesformer on Kinetics-400 with 8 GPUs"}, "2141": {"path": "/english_documents/model_zoo/recognition/timesformer.md:58-72", "hash": "99d12fe6501137e4d78b9e81a6bfe34c", "title": "Training Timesformer on Multiple GPUs with AMP"}, "2142": {"path": "/english_documents/model_zoo/recognition/timesformer.md:75-90", "hash": "c1a943809c1b3e3af02c8e037a49f3c4", "title": "Optimizing TimeSformer Testing"}, "2143": {"path": "/english_documents/model_zoo/recognition/timesformer.md:93-107", "hash": "e758a1d2925b123bf639997963fd43db", "title": "Export TimeSformer Inference Model"}, "2144": {"path": "/english_documents/model_zoo/recognition/timesformer.md:108-133", "hash": "1b3bf297dc6789c8fb51e77f5ffc8f96", "title": "TimeSformer Predicts Video Class"}, "2145": {"path": "/english_documents/model_zoo/recognition/timesformer.md:133-137", "hash": "710a35447d13a1c3c7c27c6935d070e8", "title": "TimeSformer: Space-Time Attention for Video Recognition"}, "2146": {"path": "/english_documents/model_zoo/recognition/tokenshift_transformer.md", "hash": "774af1550180e994eae8f33b9ca3420d", "title": "TokenShift Transformer: Versatile Video Classifier"}, "2147": {"path": "/english_documents/model_zoo/recognition/tokenshift_transformer.md:1-36", "hash": "a09895c4ad41066d8b3a0177c2c5d699", "title": "Token Shift Vision Transformer"}, "2148": {"path": "/english_documents/model_zoo/recognition/tokenshift_transformer.md:36-63", "hash": "239c5a86dbf384a9720ff8539a9d627c", "title": "TokenShift Transformer: UCF-101 Training Guide"}, "2149": {"path": "/english_documents/model_zoo/recognition/tokenshift_transformer.md:64-78", "hash": "c1d255e4ce66eba075bf0606afbc49ac", "title": "Token Shift Transformer Training on UCF101 Dataset"}, "2150": {"path": "/english_documents/model_zoo/recognition/tokenshift_transformer.md:78-93", "hash": "eb140f62aa4563e8f0631bb59fef79f7", "title": "VisionTransformer Testing on UCF-101"}, "2151": {"path": "/english_documents/model_zoo/recognition/tokenshift_transformer.md:93-116", "hash": "061416a8d3a2638aedeb7e1eec520f1f", "title": "TokenShift Vision Transformer Inference Guide"}, "2152": {"path": "/english_documents/model_zoo/recognition/tokenshift_transformer.md:117-125", "hash": "011d38a5bac31e2ca24ab07ef7eee365", "title": "Top-1 Prediction: Brushing Teeth, Confidence 0.99"}, "2153": {"path": "/english_documents/model_zoo/recognition/tsm.md", "hash": "a913de807fced367954e30ba622dcace", "title": "Training TSM: ResNet-50 PaddlePaddle AMP UCF-101 Kinetics-400"}, "2154": {"path": "/english_documents/model_zoo/recognition/tsm.md:1-33", "hash": "296d30a9d67bd770709926b168e428e4", "title": "TSM Video Understanding with ResNet-50"}, "2155": {"path": "/english_documents/model_zoo/recognition/tsm.md:35-62", "hash": "f9f3d2665e0ec59c9819d653ac7ade0e", "title": "Training TSM Model on Kinetics-400 with PaddleVideo"}, "2156": {"path": "/english_documents/model_zoo/recognition/tsm.md:64-91", "hash": "3029330bde30c2b8abbbb83645ec4805", "title": "Training TSM Model with PaddlePaddle and AMP"}, "2157": {"path": "/english_documents/model_zoo/recognition/tsm.md:91-118", "hash": "0511b357c5dd743c6f7c76697b1f9e12", "title": "TSM Model Training on UCF-101 Dataset"}, "2158": {"path": "/english_documents/model_zoo/recognition/tsm.md:118-144", "hash": "09ab259f1ef723bc39d3f350eb67a159", "title": "TSM Model Training with PaddleVideo"}, "2159": {"path": "/english_documents/model_zoo/recognition/tsm.md:145-166", "hash": "04898d8ed37b2625a6d7e8552978eed9", "title": "CUDNN Batch Normalization Testing Script"}, "2160": {"path": "/english_documents/model_zoo/recognition/tsm.md:168-181", "hash": "99a726e6ef4be2c38d41be9c60dedf3a", "title": "TSM Models with ResNet50 and Sampling Methods"}, "2161": {"path": "/english_documents/model_zoo/recognition/tsm.md:182-203", "hash": "89f479d906f7aaef36a4f104626316d3", "title": "TSM Model Inference with PaddlePaddle"}, "2162": {"path": "/english_documents/model_zoo/recognition/tsm.md:203-221", "hash": "d94763139ef322954ce7fb8f583173c2", "title": "TSM Training Strategy: Momentum, L2 Decay"}, "2163": {"path": "/english_documents/model_zoo/recognition/tsn.md", "hash": "030deaaa6c6fcf3c543cc962c35ceba2", "title": "TSN: 2D-CNN Video Classification with Sparse Sampling"}, "2164": {"path": "/english_documents/model_zoo/recognition/tsn.md:1-20", "hash": "966c7cf3958801ed9c09da25a13c92c5", "title": "Global TSN for Video Classification"}, "2165": {"path": "/english_documents/model_zoo/recognition/tsn.md:21-48", "hash": "2bc0b115d42a9ea68f15038dd598b692", "title": "Training TSN on Kinetics-400 Dataset"}, "2166": {"path": "/english_documents/model_zoo/recognition/tsn.md:49-65", "hash": "4822482170b75197d7046273da531e18", "title": "Start Training TSN Model with Kinetics-400 and 8 GPUs\"\n\"Test TSN Model in Test Mode: TenCrop vs. CenterCrop"}, "2167": {"path": "/english_documents/model_zoo/recognition/tsn.md:66-81", "hash": "26eb8cf9c2ebc345f56dbcce77e29e25", "title": "TSN Model Testing and Inference"}, "2168": {"path": "/english_documents/model_zoo/recognition/tsn.md:82-103", "hash": "67b27db7a0e431fca0ea56c019ed0eeb", "title": "GPU-Accelerated TSN Model for Video Recognition"}, "2169": {"path": "/english_documents/model_zoo/recognition/tsn.md:103-119", "hash": "c2900aa6bf29da53a687e82098da9266", "title": "Multi-Scale Random Cropping for Frame Enhancement"}, "2170": {"path": "/english_documents/model_zoo/recognition/tsn.md:121-123", "hash": "d3177e5f3471b96282a31067ae8f68c7", "title": "TSN Implementation in PaddleVideo"}, "2171": {"path": "/english_documents/model_zoo/recognition/tsn_dali.md", "hash": "0e972dbcb0d970636e1c4c9f743e552f", "title": "Accelerating TSN with DALI"}, "2172": {"path": "/english_documents/model_zoo/recognition/tsn_dali.md:1-45", "hash": "fcfe856e510096d5925bc23e78a27f7c", "title": "Accelerating TSN Training with DALI"}, "2173": {"path": "/english_documents/model_zoo/recognition/tsn_dali.md:45-82", "hash": "b86fcb06a5e894adf68df18cf75c14af", "title": "TSN-DALI Training with PaddleVideo"}, "2174": {"path": "/english_documents/model_zoo/recognition/tsn_dali.md:84-98", "hash": "33499eead026403ab3665e7eb101f586", "title": "TSN Action Recognition with DALI"}, "2175": {"path": "/english_documents/model_zoo/recognition/videoswin.md", "hash": "e0c3374499c81bdc6d1bb04860c95986", "title": "Swin-Transformer for Video Accuracy"}, "2176": {"path": "/english_documents/model_zoo/recognition/videoswin.md:1-33", "hash": "9c8d79e784b6bb6e5150f769768a7d79", "title": "Video-Swin Transformer Model Card"}, "2177": {"path": "/english_documents/model_zoo/recognition/videoswin.md:35-60", "hash": "9ec1400f8c0b3b3eedcf1156aa1d6cb4", "title": "Training VideoSwin on Kinetics400 with 8 GPUs"}, "2178": {"path": "/english_documents/model_zoo/recognition/videoswin.md:60-75", "hash": "1006875352c10dd70b88d58fe103053f", "title": "Faster Video-Swin-Transformer Training with Mixed Precision"}, "2179": {"path": "/english_documents/model_zoo/recognition/videoswin.md:77-89", "hash": "e67e945424e28cf30b849bf4733c5b4d", "title": "Optimized Video-Swin-Transformer Testing: UniformCrop for Accuracy"}, "2180": {"path": "/english_documents/model_zoo/recognition/videoswin.md:89-92", "hash": "9cdb2928ffc4d20f80d1b4828a63f700", "title": "Pre-Trained Swin-Transformer Checkpoints"}, "2181": {"path": "/english_documents/model_zoo/recognition/videoswin.md:94-117", "hash": "56c530057f84420b6d469207218f342d", "title": "Export and Predict in PaddleVideo"}, "2182": {"path": "/english_documents/model_zoo/recognition/videoswin.md:119-131", "hash": "0a7f9bd35cfa10f70efa6b383efe183a", "title": "VideoSwin-Transformer for Prediction"}, "2183": {"path": "/english_documents/model_zoo/segmentation/asrf.md", "hash": "59fb23e103bbd582b9c115a28262cbe5", "title": "ASRF: Enhanced Video Segmentation with PaddlePaddle"}, "2184": {"path": "/english_documents/model_zoo/segmentation/asrf.md:1-35", "hash": "c40326ed974490520de15f57722a9b4e", "title": "ASRF: Enhanced Video Segmentation Model with PaddlePaddle"}, "2185": {"path": "/english_documents/model_zoo/segmentation/asrf.md:37-55", "hash": "b31d2422ed4c073bce94eb21cf154b8c", "title": "Training ASRF, Testing MS-TCN with Pre-trained Model"}, "2186": {"path": "/english_documents/model_zoo/segmentation/asrf.md:57-80", "hash": "f87b0a18c7aad3d4f320257926c00b13", "title": "MS-TCN Accuracy and Edit Distance on Three Datasets"}, "2187": {"path": "/english_documents/model_zoo/segmentation/asrf.md:81-100", "hash": "a5cdb18ef31f877657d77a01c307b8b1", "title": "ASRF_gtea Model Weights & F1"}, "2188": {"path": "/english_documents/model_zoo/segmentation/asrf.md:102-131", "hash": "60ffdee8a77461b4d807fa542199d73d", "title": "ASRF Model Inference with PaddleVideo Example"}, "2189": {"path": "/english_documents/model_zoo/segmentation/asrf.md:132-139", "hash": "91aeb49638ca3209c7e87baf60dc1ce4", "title": "Write Inference Results to Separate Files"}, "2190": {"path": "/english_documents/model_zoo/segmentation/cfbi.md", "hash": "e64b08615f24a05b8eade670c5998cda", "title": "CFBI Video Object Segmentation Model"}, "2191": {"path": "/english_documents/model_zoo/segmentation/cfbi.md:1-29", "hash": "bf7858bfc9eb1db73016b8c896d83321", "title": "CFBI: Foreground-Background Collaborative Segmentation"}, "2192": {"path": "/english_documents/model_zoo/segmentation/cfbi.md:31-46", "hash": "684f546c42ec63d46a9eba48b8d60764", "title": "Training and Evaluating CFBIp Segmentation Model on DAVIS Dataset"}, "2193": {"path": "/english_documents/model_zoo/segmentation/mstcn.md", "hash": "f84601da7ebde670d4471c8806f2180d", "title": "MS-TCN Model Evaluation and Comparison"}, "2194": {"path": "/english_documents/model_zoo/segmentation/mstcn.md:1-35", "hash": "98fdc9cef6a76cdba9ae01b5a8266428", "title": "Optimized MS-TCN for Precise Video Segmentation"}, "2195": {"path": "/english_documents/model_zoo/segmentation/mstcn.md:36-52", "hash": "bb3a91801b38b50cfec7eb7064de6b6e", "title": "MSTCN Segmentation Training and Testing"}, "2196": {"path": "/english_documents/model_zoo/segmentation/mstcn.md:54-78", "hash": "d157b8a7f7ba51580227d572d82c788b", "title": "MSTCN vs Paper Model: Dataset Comparison"}, "2197": {"path": "/english_documents/model_zoo/segmentation/mstcn.md:79-108", "hash": "71314c1348e38e8b11b1299937a85a59", "title": "Export and Use MSTCN Inference Model"}, "2198": {"path": "/english_documents/model_zoo/segmentation/mstcn.md:109-130", "hash": "d94b46326705080ff380304310ba1684", "title": "Configuring MSTCN Segmentation Model"}, "2199": {"path": "/english_documents/quick_start.md", "hash": "b5befe7b83946fb59e4cac41c852a45c", "title": "PaddleVideo Quick Start Guide: Installation and Usage"}, "2200": {"path": "/english_documents/quick_start.md:1-36", "hash": "1dc43797a2fbc5af8c748295720c2f9e", "title": "Quick Start Guide: PaddleVideo Installation and Usage"}, "2201": {"path": "/english_documents/quick_start.md:38-76", "hash": "b5b2386e29a69f8cb5b648e38bfca34e", "title": "Install and Run PP-Video"}, "2202": {"path": "/english_documents/quick_start.md:78-107", "hash": "4888c122e22c92cfb3eae01787b715ba", "title": "Video Inference with PaddleVideo and PP-TSM_v2"}, "2203": {"path": "/english_documents/quick_start.md:107-122", "hash": "0e18a4945ec46fc1ccf8b538e22a1927", "title": "PaddleVideo Model Parameters"}, "2204": {"path": "/english_documents/quick_start.md:123-142", "hash": "4d0c04c6d646418d48b25d6f051ed5ac", "title": "Consistent Top-5 Classification Performance"}, "2205": {"path": "/english_documents/quick_start.md:143-157", "hash": "492ce8ef095b5c508a42386773ff5707", "title": "PaddleVideo's Action Recognition Model"}, "2206": {"path": "/english_documents/tools.md", "hash": "be983306a84628fb8bb662a45165c2c1", "title": "PaddleVideo Tools Guide"}, "2207": {"path": "/english_documents/tutorials/Action Recognition Datasets", "hash": "c2690ec45e937cabcd4f5825929413eb", "title": "Action Recognition Datasets: A Comprehensive List"}, "2208": {"path": "/english_documents/tutorials/Action Recognition Papers", "hash": "a9107861a65372870e4e7b6efbbc6065", "title": "Top Action Recognition Papers"}, "2209": {"path": "/english_documents/tutorials/Action Recognition Papers:1-16", "hash": "d7a994e5af0a0100a415c01bbeb3111f", "title": "Top Action Recognition Papers for AI"}, "2210": {"path": "/english_documents/tutorials/Action Recognition Papers:17-28", "hash": "0caa1d853c37c85654879f12828f9ef5", "title": "Action Recognition Papers: State-of-the-Art Models"}, "2211": {"path": "/english_documents/tutorials/Action Recognition Papers:29-29", "hash": "742c9419c1ca8d3c20323923cea9badd", "title": "Trajectory-Pooled Deep Convolutional Descriptors for Action Recognition"}, "2212": {"path": "/english_documents/tutorials/Spatio-Temporal Action Detection Papers", "hash": "9d2d506c856530eb9a4dda9e4a3cbe2c", "title": "Spatio-Temporal Action Detection Papers (2015-2017)"}, "2213": {"path": "/english_documents/tutorials/Spatio-Temporal Action Detection Papers:1-13", "hash": "d080bd704a0cef7686b9cd293f998960", "title": "Spatio-Temporal Action Detection Papers List"}, "2214": {"path": "/english_documents/tutorials/Spatio-Temporal Action Detection Papers:14-24", "hash": "6950cf41cad1721ede14f75c4217587f", "title": "Spatio-Temporal Action Detection Papers 2015-2017"}, "2215": {"path": "/english_documents/tutorials/Spatio-Temporal Action Detection Papers:25-30", "hash": "60be8da6e8fff989bdf0a652211e9545", "title": "Spatio-Temporal Action Detection Papers Overview"}, "2216": {"path": "/english_documents/tutorials/TSM.md", "hash": "270270fcdd38094d6af5d3af783f300c", "title": "TSM: Video Understanding with Spatio-Temporal Balance"}, "2217": {"path": "/english_documents/tutorials/TSM.md:1-5", "hash": "51835d06b096f3b683bc80c38ca4285c", "title": "Introducing TSM: Efficient Video Understanding Model"}, "2218": {"path": "/english_documents/tutorials/TSM.md:6-10", "hash": "31b26b2b585eba92f19e9ea4ac047670", "title": "Efficient Video Understanding with Temporal Shift Module"}, "2219": {"path": "/english_documents/tutorials/TSM.md:11-21", "hash": "4f0186e13d840285ed2fa99d4105e881", "title": "TSM: Balancing 2D and 3D CNNs for Video Understanding"}, "2220": {"path": "/english_documents/tutorials/TSM.md:22-27", "hash": "f5054bbdbea1969e294beecd6c0e534e", "title": "TSM: 2D Conv for Spatial-Temporal Info"}, "2221": {"path": "/english_documents/tutorials/TSM.md:28-40", "hash": "50b60128c0be4efad7e3e2d68a890818", "title": "TSM: Bi-Direction, UNI-Direction, and Residual Variants"}, "2222": {"path": "/english_documents/tutorials/TSM.md:40-58", "hash": "eeccdf4e03531c8cb05d957e4d9e715f", "title": "Accelerating TSM Implementation in PaddlePaddle"}, "2223": {"path": "/english_documents/tutorials/TSM.md:60-73", "hash": "4b474181aa1f9195f64f844f5aec2a86", "title": "Implementing TSM in PaddlePaddle"}, "2224": {"path": "/english_documents/tutorials/Temporal Action Detection Papers", "hash": "29dc2144b510165e398eaf802c6d0928", "title": "Temporal Action Detection Papers"}, "2225": {"path": "/english_documents/tutorials/Temporal Action Detection Papers:1-12", "hash": "66536be3f26a66ac5385e7cc8511b788", "title": "Temporal Action Detection Papers: A Comprehensive List"}, "2226": {"path": "/english_documents/tutorials/Temporal Action Detection Papers:12-21", "hash": "0bca8d325a651af53e21a25c84c07537", "title": "Temporal Action Detection Papers Collection"}, "2227": {"path": "/english_documents/tutorials/Temporal Action Detection Papers:22-24", "hash": "16c1d297e27589bfdd02797104567933", "title": "Temporal Action Detection Papers: A Comprehensive Guide"}, "2228": {"path": "/english_documents/tutorials/accelerate.md", "hash": "5d860066d7076df5ae274abeab098bbf", "title": "Dual-Language Tutorial: Accelerate"}, "2229": {"path": "/english_documents/tutorials/config.md", "hash": "63184f63d3ca9ac4f25e8f295334aaac", "title": "Dependency Injection with PaddleVideo: Config-based Modularity"}, "2230": {"path": "/english_documents/tutorials/config.md:1-37", "hash": "bd9bb7657d3143cf6f58eeddf8692f87", "title": "IOC/DI for Modular PaddleVideo"}, "2231": {"path": "/english_documents/tutorials/config.md:39-89", "hash": "eff0aa359458584b92b69cebfe92c232", "title": "DI with Register and Builder: Module Mapping Tutorial"}, "2232": {"path": "/english_documents/tutorials/config.md:90-117", "hash": "47bb970366a7b7abd64293e1485b3254", "title": "Dependency Injection via Config-Driven Class Instantiation"}, "2233": {"path": "/english_documents/tutorials/config.md:118-131", "hash": "0b2fe065958b1c42c17d349fb40ffecd", "title": "Command-Line Arguments for Training Script"}, "2234": {"path": "/english_documents/tutorials/customized_usage.md", "hash": "c5d315001b04656e30c63ff90457c493", "title": "Customizing PaddleVideo Framework Tutorial"}, "2235": {"path": "/english_documents/tutorials/demos", "hash": "20cade6441a851551ca8536565bb8565", "title": "Multi-Task Action Recognition Demo"}, "2236": {"path": "/english_documents/tutorials/deployment.md", "hash": "a479eab2428b0ba55a35573c285a99b1", "title": "Converting Dygraph Models to Static for Deployment"}, "2237": {"path": "/english_documents/tutorials/deployment.md:1-24", "hash": "8412d694b66259fd31196d557e4c13b8", "title": "Dynamic to Static: Deploying Dygraph Models with PaddleVideo"}, "2238": {"path": "/english_documents/tutorials/deployment.md:24-48", "hash": "d5c9c46b119ddc443e5ba20ade2e0583", "title": "PaddleInference Video Inference Testing"}, "2239": {"path": "/english_documents/tutorials/modular_design.md", "hash": "586998d06534985ebc571ef150cbea04", "title": "Bilingual Modular Design Tutorial"}, "2240": {"path": "/english_documents/tutorials/pp-tsm.md", "hash": "d006d97f564de0acc37776727531cc78", "title": "Introducing PP-TSM: Enhanced Video Recognition Model"}, "2241": {"path": "/english_documents/tutorials/pp-tsm.md:1-22", "hash": "b72487a4dfd7eb0f513d590b4c94fca5", "title": "High-Performance Video Recognition with PP-TSM"}, "2242": {"path": "/english_documents/tutorials/pp-tsm.md:23-32", "hash": "ceadc0f168236c4d668fe6f0b4fcc0e6", "title": "Optimizing Model Performance with Enhanced Techniques"}, "2243": {"path": "/english_documents/tutorials/summarize.md", "hash": "12cba0e3c021be561d1b8e88b42e0ef2", "title": "Video Action Recognition: Deep Learning Techniques"}, "2244": {"path": "/english_documents/tutorials/summarize.md:1-18", "hash": "080e3819b483b9f5cc84eb53b2a79305", "title": "Action Recognition: Applications and Classification in Multiple Fields"}, "2245": {"path": "/english_documents/tutorials/summarize.md:18-32", "hash": "cb4151a8807d317eef4e3a4c940256d7", "title": "Multi-modal Video Classification Tasks"}, "2246": {"path": "/english_documents/tutorials/summarize.md:33-49", "hash": "e464f82299daf8014dd049812d3b6958", "title": "Temporal Action Classification and Dense Captioning"}, "2247": {"path": "/english_documents/tutorials/summarize.md:51-72", "hash": "85d04c3678afaac4922b18776449adbe", "title": "Popular Video Action Datasets: Overview and Challenges"}, "2248": {"path": "/english_documents/tutorials/summarize.md:73-87", "hash": "074d1f8851cd177714876324016c18e2", "title": "HMDB51 vs Kinetics: Action Recognition Datasets"}, "2249": {"path": "/english_documents/tutorials/summarize.md:88-104", "hash": "19bdeaf19c10080ea5ddd7f418e65697", "title": "Kinetics: Action Recognition Benchmark"}, "2250": {"path": "/english_documents/tutorials/summarize.md:105-121", "hash": "a5aff108bd10cf82fef1e818add334c1", "title": "Dataset Comparison: Mexaction2 and ActivityNet"}, "2251": {"path": "/english_documents/tutorials/summarize.md:122-138", "hash": "a97c5a724d5afc62f8a45c2a0f842a9b", "title": "Action Recognition with Manual and Deep Learning Methods"}, "2252": {"path": "/english_documents/tutorials/summarize.md:139-154", "hash": "1051b7eea9c3ec46dde34373d20dd00c", "title": "Deep Learning in Video Classification"}, "2253": {"path": "/english_documents/tutorials/summarize.md:156-173", "hash": "60c4f2bc91fce07f394721ed684b63d0", "title": "ActivityNet Competition: Large-Scale Action Recognition from YouTube Videos"}, "2254": {"path": "/english_documents/tutorials/summarize.md:174-193", "hash": "8af2df3589acfdd946eb12146d18b62f", "title": "Action Recognition and Video Classification References"}, "2255": {"path": "/english_documents/tutorials/summarize.md:194-206", "hash": "89f1ad6e1fda5cb68de69c05fb750126", "title": "Video Recognition Paper References List"}, "2256": {"path": "/english_documents/usage.md", "hash": "4286d2d8e49dde7eefefcc9afa1db745", "title": "Efficient PaddleVideo Training on Linux"}, "2257": {"path": "/english_documents/usage.md:1-28", "hash": "495da780efaf293100ba00eb8c825914", "title": "Setting Up PaddleVideo Environment"}, "2258": {"path": "/english_documents/usage.md:29-71", "hash": "bba9f4a37d2723f9ccd49a143395ad18", "title": "Train and Test Models with PaddlePaddle"}, "2259": {"path": "/english_documents/usage.md:71-89", "hash": "1acb0f0ab7deebbf660e7f0a306f5e3e", "title": "Training and Validation Log Format"}, "2260": {"path": "/english_documents/usage.md:91-132", "hash": "8982845dfa72b59a45fa30f414c56ab5", "title": "PaddleVideo: Resume, Finetune, Test Usage"}, "2261": {"path": "/english_documents/usage.md:134-174", "hash": "e04f5a5c51e0b473412e2c4f0e0ece44", "title": "Distributed PaddleVideo Testing and Inference"}, "2262": {"path": "/english_documents/usage.md:175-177", "hash": "d621f8496d3ef81c989ae7ff941babc9", "title": "Enabling/Disabling GPU in PaddleVideo"}, "2263": {"path": "/main.py", "hash": "44c28736406f18f314f6b1327ea13397", "title": "Distributed PaddleVideo Training"}, "2264": {"path": "/main.py:1-29", "hash": "606fc3acbfb34c8311513b679b9f9284", "title": "Train PaddleVideo Model with Argparse"}, "2265": {"path": "/main.py:30-52", "hash": "49a2808e3666c7990f90b6d0efbbeedf", "title": "Command Line Arguments for PaddleVideo"}, "2266": {"path": "/main.py:53-84", "hash": "da7ed2286aa3ddef875f55cbbce53ec3", "title": "Command-Line AMP Training Customization"}, "2267": {"path": "/main.py:87-118", "hash": "6514b1c513a1430a6dc485d317b0e4c9", "title": "Configure and Parse Arguments for Paddle's Main Function"}, "2268": {"path": "/main.py:120-141", "hash": "f303080180843bd489461b0d08b8fada", "title": "Command-Line Driven Model Training"}, "2269": {"path": "/paddlevideo/__init__.py", "hash": "ffb301b1e71c7ebff0b2564fb855f2ef", "title": "Initializing PaddleVideo"}, "2270": {"path": "/paddlevideo/loader/__init__.py", "hash": "12531d48e8da8904d3b6ab9510fa7eb3", "title": "PaddleVideo Dataset and Loader"}, "2271": {"path": "/paddlevideo/loader/builder.py", "hash": "b20086d1b53e4f19f1f5054ede75f88c", "title": "Distributed PaddleVideo Data Loader"}, "2272": {"path": "/paddlevideo/loader/builder.py:1-29", "hash": "5bd09ab778a17fc504594d31de57c0bf", "title": "PaddleVideo Pipeline Builder"}, "2273": {"path": "/paddlevideo/loader/builder.py:30-74", "hash": "9120b45bc11570b1efff48287b286a7a", "title": "Paddle Video Data Loader Builder"}, "2274": {"path": "/paddlevideo/loader/builder.py:75-96", "hash": "06f3674b9e3ba7bed247b0a9ea286a8b", "title": "Data Sampler for ML/DL Models"}, "2275": {"path": "/paddlevideo/loader/builder.py:97-132", "hash": "4da799b0633246eefc0b1cb88165327a", "title": "Variable-Length Batch Data Loader"}, "2276": {"path": "/paddlevideo/loader/dali_loader.py", "hash": "b1e4eb41722afe3a5073d91eba395762", "title": "Dali Loader: Video Processing with PaddleOps"}, "2277": {"path": "/paddlevideo/loader/dali_loader.py:1-32", "hash": "08c0dee99a4d5bd2f3fa02ea52234994", "title": "Dali Loader: Importing PaddlePaddle Iterator"}, "2278": {"path": "/paddlevideo/loader/dali_loader.py:35-65", "hash": "9a8bc59bfa2acd08c5fc74b15f562d67", "title": "Dali Loader: Class Initialization and DALI Reader Building"}, "2279": {"path": "/paddlevideo/loader/dali_loader.py:66-88", "hash": "3a83c296ba95be3596ff916fcb9a951b", "title": "Sharding Data Distribution Code Snippet"}, "2280": {"path": "/paddlevideo/loader/dali_loader.py:89-111", "hash": "8e1b65e2901bc994a136a63185138de0", "title": "Dali Loader: Parallel Video Preprocessing"}, "2281": {"path": "/paddlevideo/loader/dali_loader.py:112-142", "hash": "53c3a174b65e4d95f97c5ed11cd58207", "title": "DALI Video Iterator for PaddleVideo"}, "2282": {"path": "/paddlevideo/loader/dali_loader.py:143-160", "hash": "0583e56be573b628a35e1d5a45da6257", "title": "Dali Video Loader Initialization"}, "2283": {"path": "/paddlevideo/loader/dali_loader.py:161-176", "hash": "e929b3f3c25fe15d658699754996b4d0", "title": "DALI Loader for Image Processing"}, "2284": {"path": "/paddlevideo/loader/dali_loader.py:177-202", "hash": "b0dcc06ff159f61979c8de493704e08a", "title": "DALI Loader Operations"}, "2285": {"path": "/paddlevideo/loader/dali_loader.py:203-206", "hash": "0dbd31a933121e1ab0419f7f2ca00a4e", "title": "Loader Methods and Length Determination"}, "2286": {"path": "/paddlevideo/loader/dataset/MRI.py", "hash": "e2d9d55781c2b85fd6c4e763faea6cab", "title": "MRI Dataset Loader in PaddleVideo"}, "2287": {"path": "/paddlevideo/loader/dataset/MRI.py:1-31", "hash": "9574f6b0a8dfa7a9cc481edb686a892a", "title": "PaddleVideo: MRI Dataset Loader"}, "2288": {"path": "/paddlevideo/loader/dataset/MRI.py:31-61", "hash": "dd88fa69bd109c05919349384425844d", "title": "MRI Dataset Initialization"}, "2289": {"path": "/paddlevideo/loader/dataset/MRI.py:62-86", "hash": "30dc526faf4663e2f3c2561bcb9fbeb2", "title": "Loader: Handling Missing MRI Files"}, "2290": {"path": "/paddlevideo/loader/dataset/MRI.py:87-108", "hash": "d122b4129b5daf581be8daf4ca647b76", "title": "Retry Loading Frames: Exception Handling in MRI Dataset"}, "2291": {"path": "/paddlevideo/loader/dataset/MRI.py:109-109", "hash": "4622165fe52dcfbe2fd300bd2404f23f", "title": "MRI Dataset Loader: Numpy Arrays from Results"}, "2292": {"path": "/paddlevideo/loader/dataset/MRI_SlowFast.py", "hash": "0a519f4036c572e0ccefd8ca968e50c6", "title": "MRI SlowFast Dataset Loader"}, "2293": {"path": "/paddlevideo/loader/dataset/MRI_SlowFast.py:1-31", "hash": "f24cb32526c703363c74614385e926c6", "title": "MRI_SlowFast Dataset Loader"}, "2294": {"path": "/paddlevideo/loader/dataset/MRI_SlowFast.py:31-61", "hash": "fb1800c893ea60af49ff9c6a8140fa75", "title": "MRI Dataset Loader Class"}, "2295": {"path": "/paddlevideo/loader/dataset/MRI_SlowFast.py:62-86", "hash": "99f09c08c6fb9c1603fac738fc9b7b4c", "title": "Paddle Video: MRI Dataset Loading"}, "2296": {"path": "/paddlevideo/loader/dataset/MRI_SlowFast.py:87-108", "hash": "3daa26aa34997462c42a47ea0ef2f7fc", "title": "Retry Loader with Error Logging"}, "2297": {"path": "/paddlevideo/loader/dataset/MRI_SlowFast.py:109-111", "hash": "70763cda1b5486cb6cfb6ac3ad13fe67", "title": "MRI Dataset Loader"}, "2298": {"path": "/paddlevideo/loader/dataset/__init__.py", "hash": "c867b8d28a633d6c145c47b36f2553f1", "title": "PaddleVideo Datasets: Load and Understand"}, "2299": {"path": "/paddlevideo/loader/dataset/__init__.py:1-25", "hash": "26d6e1ceca3c3b1efd935d8471e7111a", "title": "PaddleVideo Dataset Importer"}, "2300": {"path": "/paddlevideo/loader/dataset/__init__.py:26-41", "hash": "5c03595c46ad8b68744f40ae42019bc8", "title": "Importing and Exporting Datasets"}, "2301": {"path": "/paddlevideo/loader/dataset/actbert_dataset.py", "hash": "e25cfa618651a0cc12e56af47e57fd8a", "title": "ActBERT Dataset Setup in PaddlePaddle"}, "2302": {"path": "/paddlevideo/loader/dataset/actbert_dataset.py:1-31", "hash": "00f873ddbe30353443da94f1c0190948", "title": "Setting Up ActBERT Dataset in PaddleVideo"}, "2303": {"path": "/paddlevideo/loader/dataset/actbert_dataset.py:32-66", "hash": "8d53b80c0eff6f65d483179fa926f589", "title": "Class ActBertDataset Loader"}, "2304": {"path": "/paddlevideo/loader/dataset/actbert_dataset.py:67-74", "hash": "a654df98d44cc9de34ff82b941b84b66", "title": "ActBERT Dataset Preparation"}, "2305": {"path": "/paddlevideo/loader/dataset/asrf_dataset.py", "hash": "83fd932b91e8640ad85024e07d9775b6", "title": "ASRF Dataset Loader"}, "2306": {"path": "/paddlevideo/loader/dataset/asrf_dataset.py:1-38", "hash": "e81f050bf59e4cfaa84162379a472324", "title": "ASRF Dataset: Action Segmentation Videos"}, "2307": {"path": "/paddlevideo/loader/dataset/asrf_dataset.py:39-68", "hash": "572e9a05548382c1d5c2bb636213ad25", "title": "ASRF Dataset Loader"}, "2308": {"path": "/paddlevideo/loader/dataset/asrf_dataset.py:69-92", "hash": "30ba0f80d7bbd5fed3ed210c4ed1f566", "title": "PaddleVideo Dataset Loader"}, "2309": {"path": "/paddlevideo/loader/dataset/asrf_dataset.py:94-104", "hash": "0a091d9cf1c707e21e40bdd31be44d0a", "title": "Boundary Data Loading and Processing"}, "2310": {"path": "/paddlevideo/loader/dataset/ava_dataset.py", "hash": "a3adc13af624ffd0f2f373603b3a331e", "title": "AVA Dataset Class in PaddleVideo"}, "2311": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:1-32", "hash": "fd5230ab257ec029514dd98c3b960d43", "title": "AVA Dataset Class in PaddleVideo"}, "2312": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:33-62", "hash": "97338e794f26b21180f8d2ddc86fe76b", "title": "AVA Dataset Initialization and Validation"}, "2313": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:63-93", "hash": "9e27aab0275590477e55a05f52408bce", "title": "AVA Dataset Initialization and Validation"}, "2314": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:94-122", "hash": "1cf7c15a9d21bed30975239d408676f9", "title": "Excluding Mismatched Entity Boxes"}, "2315": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:123-148", "hash": "852b86c06a488b930867cf23c74c2e52", "title": "AVA Dataset Loader"}, "2316": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:149-170", "hash": "ceb0429097b71fcdea8dddd8bb6833f6", "title": "AVA Dataset Video Processing"}, "2317": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:171-197", "hash": "f3f5b3d51140634b7f3a72df78ddf7c0", "title": "Initialize and Append Video Information"}, "2318": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:198-221", "hash": "137e37ac27d8aa2a227fd34d18a03bf7", "title": "Filtering and Padding AVA Dataset Proposals"}, "2319": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:222-240", "hash": "339a6a4f2f32f8439ef4eb58bfc64bb8", "title": "Feature Padding in Ava Dataset"}, "2320": {"path": "/paddlevideo/loader/dataset/ava_dataset.py:241-249", "hash": "549ff783af458b1ad991fab23d46ba4c", "title": "AVA Dataset Preparation and Evaluation"}, "2321": {"path": "/paddlevideo/loader/dataset/base.py", "hash": "39ad39c8b39a78966e690354999d1a8c", "title": "BaseDataset: Loading and Preparing PaddlePaddle Data"}, "2322": {"path": "/paddlevideo/loader/dataset/base.py:1-32", "hash": "61efd3ddf628049c96c4f2f020ae1817", "title": "BaseDataset: Python Class for PaddlePaddle Datasets"}, "2323": {"path": "/paddlevideo/loader/dataset/base.py:34-59", "hash": "20e09235bd284e6489db569e9eb6f254", "title": "Initializing Base Dataset Class"}, "2324": {"path": "/paddlevideo/loader/dataset/base.py:60-80", "hash": "2e6a4f416fb784c91e75ffac4e53f42e", "title": "Dataset Class for Paddle.io Video Loading"}, "2325": {"path": "/paddlevideo/loader/dataset/bmn_dataset.py", "hash": "c1bec29bf2ffe9c9d29510ac93a214a2", "title": "BMN Dataset Loader"}, "2326": {"path": "/paddlevideo/loader/dataset/bmn_dataset.py:1-36", "hash": "36a888afd139303e464a26379e0c57be", "title": "BMNDataset: Action Localization Videos"}, "2327": {"path": "/paddlevideo/loader/dataset/bmn_dataset.py:38-64", "hash": "98e62e11b6250e47dbfd1721a3e954e1", "title": "Video Index Loading and Sorting in BMN Dataset"}, "2328": {"path": "/paddlevideo/loader/dataset/bmn_dataset.py:65-72", "hash": "3c8d42adda7aa170bfc31a539e7f7534", "title": "Prepare Test Data with BMN Dataset"}, "2329": {"path": "/paddlevideo/loader/dataset/davis_dataset.py", "hash": "30416a71f8fe6561eb67e49ae2c68992", "title": "Davis Dataset for Video Segmentation"}, "2330": {"path": "/paddlevideo/loader/dataset/davis_dataset.py:1-37", "hash": "9f3d53d8b3ca5fa812e540706c336043", "title": "PaddleVideo's VOS Dataset Processing"}, "2331": {"path": "/paddlevideo/loader/dataset/davis_dataset.py:38-66", "hash": "4032590b84cad76572075e7e170712b4", "title": "Davis Dataset Initialization"}, "2332": {"path": "/paddlevideo/loader/dataset/davis_dataset.py:67-94", "hash": "4c8d5e85d065162d65efefb7680856c1", "title": "DAVIS Dataset Image Loader"}, "2333": {"path": "/paddlevideo/loader/dataset/davis_dataset.py:96-127", "hash": "a8b4107865ddec41e41daecc78dcca69", "title": "Dataset Sample Generation"}, "2334": {"path": "/paddlevideo/loader/dataset/davis_dataset.py:128-158", "hash": "e451f49ecc04265a41ca8251ae668139", "title": "Davis 2017 Dataset Initialization"}, "2335": {"path": "/paddlevideo/loader/dataset/davis_dataset.py:159-182", "hash": "a14ff96351e9d79706094f2007f5b1eb", "title": "VOS Test Dataset Preparation"}, "2336": {"path": "/paddlevideo/loader/dataset/davis_dataset.py:183-189", "hash": "a0b650c2d1275d396b79b66980619a85", "title": "Dataset Loading in PaddleVideo"}, "2337": {"path": "/paddlevideo/loader/dataset/feature.py", "hash": "94f71b85842b6af98ff57a7d8f24185b", "title": "FeatureDataset: PaddleVideo's Action Recognition Tool"}, "2338": {"path": "/paddlevideo/loader/dataset/feature.py:1-36", "hash": "11fe5e8bcd62cb4e1df972437ee53344", "title": "FeatureDataset: Action Recognition in PaddleVideo"}, "2339": {"path": "/paddlevideo/loader/dataset/feature.py:38-63", "hash": "923fab937361e43de03a0bcde5d486ce", "title": "Video Dataset Loader Methods"}, "2340": {"path": "/paddlevideo/loader/dataset/feature.py:64-80", "hash": "72c6bbec091c3933cce874ca2b604c3f", "title": "Preparing Test Data with Pipeline"}, "2341": {"path": "/paddlevideo/loader/dataset/frame.py", "hash": "46ce97ecc09d15b4847dda60a0b07b6a", "title": "PaddleVideo: Efficient Video Datasets"}, "2342": {"path": "/paddlevideo/loader/dataset/frame.py:1-31", "hash": "2e86c972a65af70952161bf29357d5b6", "title": "Frame Dataset Class in PaddleVideo"}, "2343": {"path": "/paddlevideo/loader/dataset/frame.py:31-61", "hash": "b58640212da7c3b8a7ee93ef52077d02", "title": "Video Index Loader Class"}, "2344": {"path": "/paddlevideo/loader/dataset/frame.py:62-86", "hash": "f71634b80bcb834aaea41580a4fd62f2", "title": "Frame Data Reader with Exception Handling"}, "2345": {"path": "/paddlevideo/loader/dataset/frame.py:87-108", "hash": "a99a5e2043f4198cb190c60bbc8e9790", "title": "Exception Handling for Loading Frames"}, "2346": {"path": "/paddlevideo/loader/dataset/frame.py:111-136", "hash": "33fe7236b34ed2e51c5d77ca8a7cc0b5", "title": "FrameDataset for Sports Videos"}, "2347": {"path": "/paddlevideo/loader/dataset/frame.py:137-158", "hash": "47bf4345faeb4e85ebcf19df8089699b", "title": "Frame Directory Data Processing"}, "2348": {"path": "/paddlevideo/loader/dataset/frame.py:159-177", "hash": "c084dba0e1af602b61693c9e98b02345", "title": "Retry Corrupted Video Data Preparation"}, "2349": {"path": "/paddlevideo/loader/dataset/ms_tcn_dataset.py", "hash": "859e25ba5373595c10f89bafee143957", "title": "MS-TCN Dataset Loader"}, "2350": {"path": "/paddlevideo/loader/dataset/ms_tcn_dataset.py:1-38", "hash": "2f7f6c6af539436a5b04dee5f4a626df", "title": "MS-TCN Dataset Registration"}, "2351": {"path": "/paddlevideo/loader/dataset/ms_tcn_dataset.py:39-68", "hash": "c31dee3baf78e3d4e59aac5ee2a6fdeb", "title": "MS-Tcn Dataset Initialization"}, "2352": {"path": "/paddlevideo/loader/dataset/ms_tcn_dataset.py:69-95", "hash": "7315cce1a9a6fc1105b0f4e8fddac6ee", "title": "Video Feature and Label Dataset Loader"}, "2353": {"path": "/paddlevideo/loader/dataset/ms_tcn_dataset.py:97-110", "hash": "efc502005b1116b23bce91112a4eb4c6", "title": "Video Dataset Label Loading Function"}, "2354": {"path": "/paddlevideo/loader/dataset/msrvtt.py", "hash": "9b1972e6ea256145cf949c47f8a0feb9", "title": "MSRVTT Dataset Preparation"}, "2355": {"path": "/paddlevideo/loader/dataset/msrvtt.py:1-31", "hash": "f253d07dabf5fa1bf5cffd078a5ba75d", "title": "Python Script: LMDB & PaddleLNPTok"}, "2356": {"path": "/paddlevideo/loader/dataset/msrvtt.py:32-67", "hash": "b2cb8f0b58ad15bc93c6b6da6ad02902", "title": "MSR-VTT Dataset Loader"}, "2357": {"path": "/paddlevideo/loader/dataset/msrvtt.py:68-93", "hash": "dfe6c17146aeb3860b5cdc53c5452eb4", "title": "Video Caption Tokenization with BertTokenizer"}, "2358": {"path": "/paddlevideo/loader/dataset/msrvtt.py:94-120", "hash": "7e9e5a63923dae146c5a7bacac768806", "title": "Video Data Processing and Loader"}, "2359": {"path": "/paddlevideo/loader/dataset/msrvtt.py:121-142", "hash": "0e7cf8deb980d74c2e67a03892731784", "title": "Image Box Resizing and Feature Concatenation"}, "2360": {"path": "/paddlevideo/loader/dataset/msrvtt.py:143-163", "hash": "8d7a26a8092e69f637bb582f7249e018", "title": "MSRVTT Dataset Loading and Feature Extraction"}, "2361": {"path": "/paddlevideo/loader/dataset/msrvtt.py:165-187", "hash": "15d5504809fc2382ef736d77bbda68ce", "title": "Padding and Conversion for Dataset"}, "2362": {"path": "/paddlevideo/loader/dataset/msrvtt.py:188-220", "hash": "2199d9239198064597257c3eb6c12618", "title": "Data Preparation in MSR-VTT Dataset"}, "2363": {"path": "/paddlevideo/loader/dataset/oxford.py", "hash": "43c790407dfc0d8e648cdff21955dd73", "title": "MonoDataset: PaddleVideo Oxford Dataset"}, "2364": {"path": "/paddlevideo/loader/dataset/oxford.py:1-37", "hash": "571d2cc2812df583ce321c65cfdcbb95", "title": "Creating MonoDataset for PaddleVideo"}, "2365": {"path": "/paddlevideo/loader/dataset/oxford.py:39-62", "hash": "6dfda28527b22fa26333e97240a24d6f", "title": "Oxford Dataset Loader"}, "2366": {"path": "/paddlevideo/loader/dataset/skeleton.py", "hash": "7af4cd74f60b5a2d874c3a8235f1327c", "title": "SkeletonDataset: Action Recognition Loader"}, "2367": {"path": "/paddlevideo/loader/dataset/skeleton.py:1-34", "hash": "6ab0aa395f41b2c6a9b5516b7fc14155", "title": "Skeleton Dataset: Action Recognition Loader"}, "2368": {"path": "/paddlevideo/loader/dataset/skeleton.py:35-55", "hash": "38544bbf9e24b971d3c7ff20020a0fa8", "title": "Skeleton Data Loader Class"}, "2369": {"path": "/paddlevideo/loader/dataset/skeleton.py:56-78", "hash": "b7ccecd3815d14e14637e67f340d2cfe", "title": "Skeleton DataLoader"}, "2370": {"path": "/paddlevideo/loader/dataset/slowfast_video.py", "hash": "cf3232c0c91a7234e000882913e17500", "title": "SF Video Dataset: PaddleVideo's Action Recognition"}, "2371": {"path": "/paddlevideo/loader/dataset/slowfast_video.py:1-31", "hash": "ba1e3266e04db515d50b62c50343bed0", "title": "SlowFast Video Dataset"}, "2372": {"path": "/paddlevideo/loader/dataset/slowfast_video.py:32-64", "hash": "7927952a5c093d4fa3aaf0a308814773", "title": "SlowFast Video Dataset"}, "2373": {"path": "/paddlevideo/loader/dataset/slowfast_video.py:65-87", "hash": "6b3c9799602ab4047ae07125918c7174", "title": "Random Seed and Index Loading"}, "2374": {"path": "/paddlevideo/loader/dataset/slowfast_video.py:88-112", "hash": "8c48ab964b59af1e7bfca52eca181414", "title": "Resilient Video Dataset Processing"}, "2375": {"path": "/paddlevideo/loader/dataset/slowfast_video.py:113-137", "hash": "ef42aa2939a20ea5da10575ba2d68ead", "title": "Retry and Logging Video Loader"}, "2376": {"path": "/paddlevideo/loader/dataset/slowfast_video.py:138-143", "hash": "8c259d9d49aff1cb34fe4b1f7746ff3d", "title": "Size of Dataset Calculator"}, "2377": {"path": "/paddlevideo/loader/dataset/ucf101_skeleton.py", "hash": "2b107e035abb4b7929cf3ef2a93e8cc1", "title": "UCF101 Skeleton Dataset PaddleVideo Loader"}, "2378": {"path": "/paddlevideo/loader/dataset/ucf101_skeleton.py:1-35", "hash": "98faf73c53c8f3e67f5593d77fabffef", "title": "UCF101 Skeleton Dataset Loader"}, "2379": {"path": "/paddlevideo/loader/dataset/ucf101_skeleton.py:36-66", "hash": "aa314b9a1fb4c9bbbdb105a75910c553", "title": "UCF101 Skeleton Annotation Loader"}, "2380": {"path": "/paddlevideo/loader/dataset/ucf101_skeleton.py:67-89", "hash": "9840cf1c2744fbf36e2125305efdd6ad", "title": "UCf101 Skeleton Dataset Preparation"}, "2381": {"path": "/paddlevideo/loader/dataset/ucf24_dataset.py", "hash": "396cbcb1e55c7a39a3c1794cac34ef6c", "title": "Ucf24Dataset Class for PaddleVideo"}, "2382": {"path": "/paddlevideo/loader/dataset/ucf24_dataset.py:1-30", "hash": "b33ece26e28f7bbe768c7e35b193afee", "title": "UCF24 Dataset Python Class"}, "2383": {"path": "/paddlevideo/loader/dataset/ucf24_dataset.py:31-59", "hash": "c7bb89a470032d476c2cd93a5e583e05", "title": "Ucf24Dataset: Video Data Loader"}, "2384": {"path": "/paddlevideo/loader/dataset/ucf24_dataset.py:60-76", "hash": "340143c019c5e7f7074182754eb376ef", "title": "UCF24 Dataset Preparation and Conversion"}, "2385": {"path": "/paddlevideo/loader/dataset/video.py", "hash": "afd63647d4fa7f3a725e388c2ede37b7", "title": "Video Dataset Loader"}, "2386": {"path": "/paddlevideo/loader/dataset/video.py:1-31", "hash": "55e40944fb9a83b272c3781434d90be0", "title": "VideoDataset: Loading and Transforming Raw Videos"}, "2387": {"path": "/paddlevideo/loader/dataset/video.py:32-57", "hash": "5291e4be761c70cb32cea2ad34ebbe95", "title": "Video Loader Class Initialization"}, "2388": {"path": "/paddlevideo/loader/dataset/video.py:58-80", "hash": "2914c458f2e0192a43d3902f39b38d33", "title": "Video Dataset Preparer"}, "2389": {"path": "/paddlevideo/loader/dataset/video.py:81-95", "hash": "d6f1a55e44be37ad2e7f262bec9e12b8", "title": "Robust Video Loading and Testing"}, "2390": {"path": "/paddlevideo/loader/pipelines/__init__.py", "hash": "c80a5807780d3dc5e01c5e4421fef368", "title": "Video Processing Pipelines"}, "2391": {"path": "/paddlevideo/loader/pipelines/__init__.py:1-20", "hash": "c79221f81d0429cc1e680a5ac376ac87", "title": "Pipeline Initialization in PaddleVideo"}, "2392": {"path": "/paddlevideo/loader/pipelines/__init__.py:21-38", "hash": "a7cf4082ac287c0fe68a11c9ddb0f04c", "title": "PaddleVideo Pipelines"}, "2393": {"path": "/paddlevideo/loader/pipelines/__init__.py:39-55", "hash": "1b8fc3f3f6a2853751c54292729d847f", "title": "Customizable PaddleVideo Pipelines"}, "2394": {"path": "/paddlevideo/loader/pipelines/__init__.py:56-56", "hash": "d9c239db287380391a4b887498fd023e", "title": "Empty Code Alert"}, "2395": {"path": "/paddlevideo/loader/pipelines/anet_pipeline.py", "hash": "6eafb8d603d1e9d1f6d526a99d32e957", "title": "PaddleVideo: IoU-based Feature Extraction"}, "2396": {"path": "/paddlevideo/loader/pipelines/anet_pipeline.py:1-32", "hash": "d2590645397863832521bae7f31d2d01", "title": "PaddleVideo Feature Data Loader"}, "2397": {"path": "/paddlevideo/loader/pipelines/anet_pipeline.py:33-62", "hash": "6580dd17e6dca23452dc27b777f4e576", "title": "Temporal Matching Windows Generator"}, "2398": {"path": "/paddlevideo/loader/pipelines/anet_pipeline.py:63-90", "hash": "54f9f2259969e68254abb74f70c89e8f", "title": "Anchors Intersection Calculator"}, "2399": {"path": "/paddlevideo/loader/pipelines/anet_pipeline.py:91-115", "hash": "794e498e1487a1a8892aa2dff955905e", "title": "Ground Truth Initialization in Video Pipeline"}, "2400": {"path": "/paddlevideo/loader/pipelines/anet_pipeline.py:116-140", "hash": "d0bd33bce6ee4e086a64420b43f6ef1c", "title": "Intersection Over Union Calculation for Anchor Boxes"}, "2401": {"path": "/paddlevideo/loader/pipelines/anet_pipeline.py:141-150", "hash": "ce01b5fb034f28ff2896bfe2a053431b", "title": "Annotating IOU Maps"}, "2402": {"path": "/paddlevideo/loader/pipelines/augmentations.py", "hash": "e7bfe2e6bb3e7939723463bdfcc5e3b5", "title": "Enhanced PaddleVideo Loader with Augmentation"}, "2403": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1-34", "hash": "548268937c767bfc2e40c17b99bed85e", "title": "Scaling Images with PaddleVideo Loader"}, "2404": {"path": "/paddlevideo/loader/pipelines/augmentations.py:35-61", "hash": "a707733c84ea8e6eca5ee3392a604598", "title": "Resize Image Class"}, "2405": {"path": "/paddlevideo/loader/pipelines/augmentations.py:62-88", "hash": "2994b8870e4a34c1515769aff2547ccd", "title": "Resizing Images in PaddleVideo Pipeline"}, "2406": {"path": "/paddlevideo/loader/pipelines/augmentations.py:89-108", "hash": "0066180b4d0b468132251e4423eb6251", "title": "Resizing Image with Aspect Ratio Preservation"}, "2407": {"path": "/paddlevideo/loader/pipelines/augmentations.py:109-138", "hash": "c08fdeed1adee6790ed7e77ce152003c", "title": "Image Augmentation Pipeline Defined"}, "2408": {"path": "/paddlevideo/loader/pipelines/augmentations.py:139-164", "hash": "435fef1c324c9de096762eff45b25075", "title": "Random Crop Augmentation in PaddleVideo"}, "2409": {"path": "/paddlevideo/loader/pipelines/augmentations.py:165-197", "hash": "3efce07732a6c7fac9f74d04a5ee16f9", "title": "Random Resizing and Cropping Pipeline"}, "2410": {"path": "/paddlevideo/loader/pipelines/augmentations.py:198-219", "hash": "81cc9d51681e68726058d9f5a0be24cf", "title": "Random Crop Generator"}, "2411": {"path": "/paddlevideo/loader/pipelines/augmentations.py:220-249", "hash": "f76d03acae5b820a821f8ee3cdec61d9", "title": "Image Cropper for PaddleVideo"}, "2412": {"path": "/paddlevideo/loader/pipelines/augmentations.py:250-276", "hash": "93bc321a8f4cdbc2a374e191a0507be1", "title": "Center Cropping Image Class"}, "2413": {"path": "/paddlevideo/loader/pipelines/augmentations.py:277-297", "hash": "515a05a43d5a7c733f9feb4fd9713d34", "title": "Center Crop Images in Augmentations"}, "2414": {"path": "/paddlevideo/loader/pipelines/augmentations.py:298-325", "hash": "03ba993de4c1f28ab3bc5b183bdac0bb", "title": "MultiScaleCrop: Flexible Image Augmentation"}, "2415": {"path": "/paddlevideo/loader/pipelines/augmentations.py:326-360", "hash": "eeb822872bcb49d00d8b07b191c5c85a", "title": "Multi-Scale Image Cropper"}, "2416": {"path": "/paddlevideo/loader/pipelines/augmentations.py:361-384", "hash": "5d1166a576fae5903857feea6a79cf79", "title": "Random Crop with Grid Offsets"}, "2417": {"path": "/paddlevideo/loader/pipelines/augmentations.py:385-405", "hash": "5ee665c3195516b9e67ab31fcabd9434", "title": "Random Cropping for Image Augmentation"}, "2418": {"path": "/paddlevideo/loader/pipelines/augmentations.py:406-440", "hash": "9b4e47b75bd37e36edc12aca02abc021", "title": "Random Flip Image Augmentation Pipeline"}, "2419": {"path": "/paddlevideo/loader/pipelines/augmentations.py:441-473", "hash": "a98ff29c4e69c81f9835cb0f71f3e55c", "title": "Random Image Flipping and Brightness Adjustment"}, "2420": {"path": "/paddlevideo/loader/pipelines/augmentations.py:474-508", "hash": "880f9b7c36c2c9def3744accd234a2e1", "title": "Random Image Augmentations in PaddleVideo"}, "2421": {"path": "/paddlevideo/loader/pipelines/augmentations.py:509-546", "hash": "ba3aa6f4acd340c3c2a24fba4a4a6ba3", "title": "Random Saturation and Hue Pipeline Transforms"}, "2422": {"path": "/paddlevideo/loader/pipelines/augmentations.py:547-577", "hash": "0fa32f56c4d9a116d39956afb082171b", "title": "Gamma and Color Jitter Augmentation in PaddleVideo"}, "2423": {"path": "/paddlevideo/loader/pipelines/augmentations.py:578-611", "hash": "ee21c79ad8f79736e7c9166da512a75a", "title": "Random Gamma Adjustment Pipeline"}, "2424": {"path": "/paddlevideo/loader/pipelines/augmentations.py:612-638", "hash": "d4275dd1a63b4e42040490418658b9cc", "title": "Image to NumpyArray Transpose Class"}, "2425": {"path": "/paddlevideo/loader/pipelines/augmentations.py:639-665", "hash": "179e981ff99c33fbd08b5cfbc22d764c", "title": "Normalization Class in PaddleVideo's Loader Pipelines"}, "2426": {"path": "/paddlevideo/loader/pipelines/augmentations.py:667-693", "hash": "b7c7bea6051bffc2cb6667f0f6a3bd54", "title": "Image Normalization Class"}, "2427": {"path": "/paddlevideo/loader/pipelines/augmentations.py:694-722", "hash": "a74f33922883d93c880fcb4dd5445dbf", "title": "Image Normalization and Scaling Pipeline"}, "2428": {"path": "/paddlevideo/loader/pipelines/augmentations.py:724-749", "hash": "0ad6de646f875c90c2483af010071c28", "title": "Jitter Resize Image Sequence Function"}, "2429": {"path": "/paddlevideo/loader/pipelines/augmentations.py:750-774", "hash": "fd0c2eb7782b8d894a3386388864efd8", "title": "Resize Image Pipeline"}, "2430": {"path": "/paddlevideo/loader/pipelines/augmentations.py:777-805", "hash": "8f5c83c9534177748e910f6502cf0456", "title": "MultiCenterCrop Class: Image Cropping Operations"}, "2431": {"path": "/paddlevideo/loader/pipelines/augmentations.py:807-834", "hash": "d5eef1f92d1ffd056f97e5ddf90f1f24", "title": "Image Cropping Augmentations in PyAV"}, "2432": {"path": "/paddlevideo/loader/pipelines/augmentations.py:835-865", "hash": "b7cef974bc83b5b043dd09fcd653d66e", "title": "MultiCrop Pipeline for Paddle Tensor"}, "2433": {"path": "/paddlevideo/loader/pipelines/augmentations.py:866-891", "hash": "aeffa5dae39978b7282ec7cc33d0e4ae", "title": "Random Crop Augmentation Class"}, "2434": {"path": "/paddlevideo/loader/pipelines/augmentations.py:892-914", "hash": "6af6d0bb75deb3b2a2f0d26f550dfae8", "title": "Image Size Check and Crop Generation"}, "2435": {"path": "/paddlevideo/loader/pipelines/augmentations.py:915-944", "hash": "4a8b646b7e95391e776b81aa5c5f34bb", "title": "Crop Offsets Calculator"}, "2436": {"path": "/paddlevideo/loader/pipelines/augmentations.py:946-975", "hash": "a983b804c5d461d1a7cbf9b0be4ab111", "title": "GroupFullResSample Pipeline"}, "2437": {"path": "/paddlevideo/loader/pipelines/augmentations.py:977-1007", "hash": "e47bab9612f462fd050f611c60009463", "title": "Image Augmentation via Crops and Flips"}, "2438": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1008-1037", "hash": "8c32da9316bc6a4bf146741828176332", "title": "10-Crop Image Class"}, "2439": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1038-1069", "hash": "579393f042aeceafad7c1ecd149a0c38", "title": "UniformCrop Pipeline for Image Sampling"}, "2440": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1070-1099", "hash": "0165d8fccc541480e24b4bcf9d1645f3", "title": "Image Offset Determination for Cropping"}, "2441": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1100-1127", "hash": "bb5855edbdfd390e5274d2b9b40bc686", "title": "Image Augmentation Pipeline"}, "2442": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1128-1156", "hash": "47655206156ee740c051f2add7cea72b", "title": "Image Augmentation for PaddleVideo"}, "2443": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1157-1193", "hash": "aceaf9db61d135386f81e9635c70b1b9", "title": "Color Jitter Augmentation"}, "2444": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1194-1227", "hash": "6f56dc5deb5331041d0da4b68c117e09", "title": "ColorFlipAugmenter"}, "2445": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1228-1257", "hash": "ea67e59be8aa02a41c3f6acef2aea4e2", "title": "Image Augmentation Pipeline"}, "2446": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1258-1294", "hash": "0aa07295e7c4f4c316d06685ed57e955", "title": "YowoAug: Versatile Image Augmentation"}, "2447": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1295-1322", "hash": "1b3764c65421e1428e8f7d0d1a796f2b", "title": "Image Augmentation and Detection Functions"}, "2448": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1323-1353", "hash": "c8ef3d47db1508951b91813a34e6de05", "title": "Resizing and Normalizing Bounding Boxes"}, "2449": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1354-1390", "hash": "bd3f3255e64e4fbc7009f8d2ebacb4cb", "title": "Bounding Box Jitter Augmentation"}, "2450": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1391-1419", "hash": "a5a469c2707a8b2ea831a57ac8d144fe", "title": "Image Augmentation and Label Manipulation"}, "2451": {"path": "/paddlevideo/loader/pipelines/augmentations.py:1420-1427", "hash": "505be0de691e21d66d680cd44b3028a6", "title": "Image Resizing and Conversion Augmentation"}, "2452": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py", "hash": "13797dcc144d7371e5950813faee4e15", "title": "AVA Dataset Image Augmentation and Resizing in PaddleVideo"}, "2453": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:1-34", "hash": "8724ded58914bfe587aed115595da8d3", "title": "AVA Image Augmentations in PaddleVideo"}, "2454": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:35-64", "hash": "412e094a80fa46e7fe5c0194ff30b976", "title": "Properly Initializing Lazy Operations"}, "2455": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:65-96", "hash": "629dc6bf06dca92d8851c47121d68062", "title": "AVA Image Augmentation Functions"}, "2456": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:97-130", "hash": "8f15054c32c4141ff89f5a22efe88312", "title": "Imresize: Scaling Images with Flexibility"}, "2457": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:131-160", "hash": "94149ecc6b87f4209a655c3425fd7691", "title": "Image Resizing Function for CV2 and Pillow"}, "2458": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:161-193", "hash": "5695a3872fdec6bd21912a9d7ea6755b", "title": "EntityBoxCrop Scale Class"}, "2459": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:194-224", "hash": "61ef8998345496ca6ae258c2272c3fac", "title": "Cropping Object Detection Proposals"}, "2460": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:225-249", "hash": "f14d96a624baf9a56384733f811b9bea", "title": "Horizontal Flipping of Entity Boxes"}, "2461": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:250-284", "hash": "14c59a656cdc6c03907c3d27d61e1e7b", "title": "Resizing Image Pipeline Augmentation"}, "2462": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:286-303", "hash": "20c5f1a6c2dd235104f689680f3fec77", "title": "Image Augmentation Function in PaddleVideo"}, "2463": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:304-334", "hash": "c45518869608b9a2173295ff6e434e26", "title": "Initialize Resize Augmentation Object"}, "2464": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:335-363", "hash": "ca78f1d4ef45c493cb77f0927e54d9ee", "title": "Image Resizing Augmentation"}, "2465": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:364-393", "hash": "ec76ca7bc9f97332294285c378fd7e0b", "title": "Random Rescaling Image Augmentation"}, "2466": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:395-423", "hash": "96a1c3aa55f14e344232e7bec3926f5a", "title": "Resize Augmentation Transform"}, "2467": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:424-455", "hash": "f0baf6b3df8717a8e9aba72d199448f7", "title": "Rescale Augmentation for PaddleVideo"}, "2468": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:456-487", "hash": "e44ee0f0b7e4eaf05eebc05336172972", "title": "Image Resizing and Cropping in PaddleVideo"}, "2469": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:488-517", "hash": "9a63ea0e20914d085dfcd4e6e69d9e38", "title": "Random Cropping Augmentation"}, "2470": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:519-544", "hash": "a1665cbc9f336448eadd01f2e33fc6a4", "title": "Crop Quadruple Adjustment"}, "2471": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:546-571", "hash": "8a2c61e8a507b875131f4988e2926d2d", "title": "Augmentations for Video Frames"}, "2472": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:572-609", "hash": "0b4ca83df92049a8ef21de905adbae12", "title": "In-Place Flipping and Image Negation"}, "2473": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:610-631", "hash": "0bec591115787cdcdb7892e1d17614e8", "title": "Flip Augmentation in PaddleVideo"}, "2474": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:632-660", "hash": "6100b357ac63aa08bdcd41ece518c054", "title": "Flip Augmentation for Images"}, "2475": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:661-693", "hash": "0868a0c37a316f677f4d57eab33b947f", "title": "Image Augmentation Class"}, "2476": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:696-720", "hash": "5f9dcaa6e7bfc66531adcc00378965f8", "title": "Normalize Image Augmentation"}, "2477": {"path": "/paddlevideo/loader/pipelines/augmentations_ava.py:722-749", "hash": "79ed8b8c45f0fc45781c48f711f14a4a", "title": "AVA Image Normalization Augmentation Pipeline"}, "2478": {"path": "/paddlevideo/loader/pipelines/compose.py", "hash": "d1dff462d80b23d18ca4ae63aba9e2fb", "title": "Flexible Transformation Composition"}, "2479": {"path": "/paddlevideo/loader/pipelines/decode.py", "hash": "07ed6a0da55fed7e1471a2b192f19a6b", "title": "TimeSformer Video Decoder Pipeline"}, "2480": {"path": "/paddlevideo/loader/pipelines/decode.py:1-32", "hash": "61dbba05035d57d7b4c466941646c030", "title": "Video Clip Processing Pipeline"}, "2481": {"path": "/paddlevideo/loader/pipelines/decode.py:33-69", "hash": "48cf456c5a394de0f675e3dccba9d222", "title": "MP4 Decoder Class for Frame Extraction"}, "2482": {"path": "/paddlevideo/loader/pipelines/decode.py:70-98", "hash": "77d50b933deaa25bc57f3cda92c3f9da", "title": "Video Decoder Pipeline"}, "2483": {"path": "/paddlevideo/loader/pipelines/decode.py:99-125", "hash": "34bfc65b5153d2b41bbc2389ad12844a", "title": "Video Duration Check and Decoding Indices"}, "2484": {"path": "/paddlevideo/loader/pipelines/decode.py:127-150", "hash": "f862d4a93e1926a3c28168de4f185434", "title": "Seek, Decode, Filter Frames"}, "2485": {"path": "/paddlevideo/loader/pipelines/decode.py:151-177", "hash": "4decf9f2490903afbbb63e46dc1d4869", "title": "Decode and Sort Video Frames"}, "2486": {"path": "/paddlevideo/loader/pipelines/decode.py:178-222", "hash": "bc0d6e593da87ad772c7b5dcc812b868", "title": "Pipeline Classes for Data Decoding"}, "2487": {"path": "/paddlevideo/loader/pipelines/decode.py:223-249", "hash": "bb17944ebfa567edab16227224d3b690", "title": "Preparing Data for Model in PaddleVideo Loader"}, "2488": {"path": "/paddlevideo/loader/pipelines/decode.py:250-275", "hash": "6472f0459e9efd50ff9cc3da51cc6ff0", "title": "Video Feature Pad and Dequantize"}, "2489": {"path": "/paddlevideo/loader/pipelines/decode.py:276-310", "hash": "b53d3230dcf932629982beb5a3133a85", "title": "ActionFeatureDecoder: Feature Decoding Class"}, "2490": {"path": "/paddlevideo/loader/pipelines/decode.py:311-338", "hash": "e1bba14a39dafb24921269b059e68875", "title": "Data Preprocessing for PaddlePaddle Video Pipeline"}, "2491": {"path": "/paddlevideo/loader/pipelines/decode.py:339-347", "hash": "1e606df02604ac9b410b53bf49c6447f", "title": "Pad and Concatenate Feature Data"}, "2492": {"path": "/paddlevideo/loader/pipelines/decode_image.py", "hash": "c1e64c0b8ce0651857922dc76fbeabb7", "title": "Decoding Images with PaddleVideo"}, "2493": {"path": "/paddlevideo/loader/pipelines/decode_image.py:1-37", "hash": "9af8e70277101796c94d44ca6b6e2792", "title": "PaddleVideo Image Decoder Pipeline"}, "2494": {"path": "/paddlevideo/loader/pipelines/decode_image.py:38-66", "hash": "ca4d677423f7f4adccf6ce5953a247e0", "title": "Image Decoding Pipeline Class"}, "2495": {"path": "/paddlevideo/loader/pipelines/decode_image.py:67-89", "hash": "002f9f3cfcdf9ba0534362a3df9d45f2", "title": "Decode Image Pipeline Methods"}, "2496": {"path": "/paddlevideo/loader/pipelines/decode_image.py:91-116", "hash": "3ff85b82ef0a445fce49f391c20b1e0d", "title": "Depth Image Resizer"}, "2497": {"path": "/paddlevideo/loader/pipelines/decode_image.py:117-149", "hash": "aa678514723b0d13ced6a8fac1c4ae17", "title": "Image Decoding and Organization"}, "2498": {"path": "/paddlevideo/loader/pipelines/decode_image.py:150-179", "hash": "097764e33d7423211913504a8526684b", "title": "Decode Image Pipeline: Setup and Side Detection"}, "2499": {"path": "/paddlevideo/loader/pipelines/decode_image.py:180-206", "hash": "201ec6955c04b90a662dcd2c456bd2e4", "title": "Pipeline for Decoding Images in PaddleVideo"}, "2500": {"path": "/paddlevideo/loader/pipelines/decode_sampler.py", "hash": "d0a710bc329d307946f9ff09de4b76cc", "title": "Video Decoder Pipeline: Load, Decode, Clip"}, "2501": {"path": "/paddlevideo/loader/pipelines/decode_sampler.py:1-30", "hash": "12cb99d2c716cc9af95bad759b6d5442", "title": "Fast Decoding and Sampling with DecodeSampler"}, "2502": {"path": "/paddlevideo/loader/pipelines/decode_sampler.py:31-55", "hash": "591bdffeaac5070bd3fc622dbfd4ebeb", "title": "Video Frame Sampler Class Initialization"}, "2503": {"path": "/paddlevideo/loader/pipelines/decode_sampler.py:57-81", "hash": "214f98c5539df68bd7ffe409a462d5fb", "title": "MP4 Decoder with Short Cycle Adjustment"}, "2504": {"path": "/paddlevideo/loader/pipelines/decode_sampler.py:82-93", "hash": "5ca6dc495cfb1b2e1b574f1c1194267b", "title": "Decode Image Frames Pipeline"}, "2505": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py", "hash": "6da97e8db8c8d73c0b339526dabb3fab", "title": "MRI Frame Decoder and Sampler"}, "2506": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:1-36", "hash": "cf2557dfad507d73940d1bd481aed31e", "title": "SFMRI Decoder and Sampler"}, "2507": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:37-64", "hash": "4c3cc29682bf527e863a5d71cde73d73", "title": "MRI Frame Segmenter"}, "2508": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:65-94", "hash": "2b7caf4c9b7a1ad5f58e73476c114f3e", "title": "MRI Sampler Decode Pipeline"}, "2509": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:95-115", "hash": "ca12508ce219016359b828322bd5a7f7", "title": "Video Sampling Frame Handler"}, "2510": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:116-135", "hash": "a168a9ff7e9d5898a741dee1100c54ec", "title": "Sampling Indices Calculator"}, "2511": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:136-157", "hash": "495464a919b785b231096526d93ab159", "title": "Randomly Selecting Frames Offsets"}, "2512": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:158-180", "hash": "908e779db21837ca4338b3cff28f3619", "title": "Frame Index Assignment in MRI Decode Pipeline"}, "2513": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:181-203", "hash": "0f4d265a2de1036abdc16cf591b72e4b", "title": "Generate Offsets for TSM"}, "2514": {"path": "/paddlevideo/loader/pipelines/decode_sampler_MRI.py:204-224", "hash": "06000da7f31c19c006bd0b08530b4164", "title": "Calculate Segment Offsets for 's' and 'f' Frames"}, "2515": {"path": "/paddlevideo/loader/pipelines/mix.py", "hash": "e57c0a9f56bb8e50edcd4cab5a8be81d", "title": "VideoMix: Augmented Image Classification with Controlled Mixup and Cutmix"}, "2516": {"path": "/paddlevideo/loader/pipelines/mix.py:1-34", "hash": "2ffecbbbbbe92b2d6c89d2ac29b05a05", "title": "Mixup Class for PaddleVideo"}, "2517": {"path": "/paddlevideo/loader/pipelines/mix.py:35-70", "hash": "efc498922847c8b23ff92a6e0006f155", "title": "Cutmix: A Mixup Operator for Images"}, "2518": {"path": "/paddlevideo/loader/pipelines/mix.py:72-103", "hash": "5645f8631db884a54bd36bf564e6bd5a", "title": "CutMix and MixUp Video Data Augmentation"}, "2519": {"path": "/paddlevideo/loader/pipelines/mix.py:104-116", "hash": "d0c60f3f99a019c605aaa86b00f48310", "title": "Random Mixup or Cutmix for Paddle Video"}, "2520": {"path": "/paddlevideo/loader/pipelines/multimodal.py", "hash": "66c2b3d3ace9c46f8e68eef2e4c40bc9", "title": "Multimodal PaddleVideo Pipeline Expansion"}, "2521": {"path": "/paddlevideo/loader/pipelines/multimodal.py:1-35", "hash": "8301a42b060eb3fce1bd629094ee3af7", "title": "Feature Padding Class in PaddlePaddle Video Analysis"}, "2522": {"path": "/paddlevideo/loader/pipelines/multimodal.py:36-59", "hash": "a626cf7ee547b44fa8314b1cb7338896", "title": "Multimodal Paddle Video Loader"}, "2523": {"path": "/paddlevideo/loader/pipelines/multimodal.py:60-81", "hash": "007b743573fb4d7da92597fd1dbe1071", "title": "Multimodal Data Preprocessing"}, "2524": {"path": "/paddlevideo/loader/pipelines/multimodal.py:82-113", "hash": "a8f7bd8ab5e3814569ded7f48757bde8", "title": "Random Caption Selector Pipeline"}, "2525": {"path": "/paddlevideo/loader/pipelines/multimodal.py:114-151", "hash": "34c1541fd0dcd5b0423c7c6d4197028b", "title": "Random Labeling and Masking in Multimodal Pipeline"}, "2526": {"path": "/paddlevideo/loader/pipelines/multimodal.py:152-175", "hash": "a3203991c4929a9a8cc7ca7ca57ade89", "title": "Multimodal Data Loader for TensorFlow"}, "2527": {"path": "/paddlevideo/loader/pipelines/multimodal.py:176-201", "hash": "e50d5922388859316ef5bbfab6c183ba", "title": "Masking Tokens for LM Tasks"}, "2528": {"path": "/paddlevideo/loader/pipelines/multimodal.py:202-225", "hash": "ba394a6cee3eca1c25f34ecece726d9f", "title": "Token Masking in PaddleVideo"}, "2529": {"path": "/paddlevideo/loader/pipelines/multimodal.py:226-255", "hash": "723c93b1b0046a6d8c8d20ef6981414c", "title": "Randomizing Functions in Multimodal Pipeline"}, "2530": {"path": "/paddlevideo/loader/pipelines/multimodal.py:256-285", "hash": "9e49257cacde5bf0dbdf2b3cf6f37a7b", "title": "Random Masking Function"}, "2531": {"path": "/paddlevideo/loader/pipelines/multimodal.py:286-308", "hash": "92f27f698dc17ea2e8408ca37c3bcb72", "title": "Multimodal Pipeline: BERT-based Feature Concatenation"}, "2532": {"path": "/paddlevideo/loader/pipelines/multimodal.py:309-333", "hash": "38257caa51ebdf842bab84b3104ba5d0", "title": "Preparing Input for Multimodal Pipeline"}, "2533": {"path": "/paddlevideo/loader/pipelines/multimodal.py:334-359", "hash": "ae330c6474504f623e1e48653325dc37", "title": "Zero-Padding Sequences to Max Length"}, "2534": {"path": "/paddlevideo/loader/pipelines/multimodal.py:360-380", "hash": "73e97bc99d5776fdaefdabbdd0e767ab", "title": "Multimodal Pipeline: Feature Extraction"}, "2535": {"path": "/paddlevideo/loader/pipelines/sample.py", "hash": "e96144cc0657890b2365cf992a6d39cd", "title": "Efficient Frame Sampling with PaddleVideo"}, "2536": {"path": "/paddlevideo/loader/pipelines/sample.py:1-38", "hash": "48223a254a88b5388887546203589a0d", "title": "Python PaddleVideo Image Processing Pipeline"}, "2537": {"path": "/paddlevideo/loader/pipelines/sample.py:39-66", "hash": "9cbf02849bff686f233720b89fe8b768", "title": "Sampler Frame Selection"}, "2538": {"path": "/paddlevideo/loader/pipelines/sample.py:67-96", "hash": "f6b0f8f53672cad51b325e23bd22c821", "title": "Image Format Converter Class"}, "2539": {"path": "/paddlevideo/loader/pipelines/sample.py:97-119", "hash": "355ce3f8662d36654a604bfa3d7c1b8c", "title": "Video Decoding Pipeline with Multiple Backends"}, "2540": {"path": "/paddlevideo/loader/pipelines/sample.py:120-144", "hash": "f2bae25aa356aafe47e43e9fb914c3ea", "title": "Video Frame Sampler: Handles Dense and Non-Dense Scenarios"}, "2541": {"path": "/paddlevideo/loader/pipelines/sample.py:145-171", "hash": "dc69f8a1532b2f48d8fa0eb8e1e2e22e", "title": "Clip Offsets Calculator"}, "2542": {"path": "/paddlevideo/loader/pipelines/sample.py:172-199", "hash": "92d28c1ace1b072a81bfb07deb4215f2", "title": "Video Frame Sampling Algorithm"}, "2543": {"path": "/paddlevideo/loader/pipelines/sample.py:200-223", "hash": "6d92ea5e1cb667cd84d312b3150dc652", "title": "Video Frame Sampler Algorithm"}, "2544": {"path": "/paddlevideo/loader/pipelines/sample.py:224-245", "hash": "6fa7b126e4e0935bdddcb6676a499d6f", "title": "Sampling Position Determination Algorithm"}, "2545": {"path": "/paddlevideo/loader/pipelines/sample.py:246-268", "hash": "247306142fc2442bc0b0cd661378fba8", "title": "Indexing Frames by Duration"}, "2546": {"path": "/paddlevideo/loader/pipelines/sample.py:270-292", "hash": "6ac440435b574f7daf99e14f3832a24b", "title": "Random Frame Sampler"}, "2547": {"path": "/paddlevideo/loader/pipelines/sample.py:293-327", "hash": "d41f74cf04e7c83ca5e4e73d101cfc7d", "title": "Video Sampler Class for PyTorch"}, "2548": {"path": "/paddlevideo/loader/pipelines/sample.py:328-358", "hash": "fe650a7f86f8a2bed44ef5946ea6cd8b", "title": "Video Image Sampler in Paddle Video Pipeline"}, "2549": {"path": "/paddlevideo/loader/pipelines/sample.py:359-382", "hash": "6d826ac04edf6dae978df15f52401874", "title": "Video Sample Indexing Algorithm"}, "2550": {"path": "/paddlevideo/loader/pipelines/sample_ava.py", "hash": "e91a11440a5fc241db709a490d3116e5", "title": "SampleAVA Pipeline for PaddleVideo"}, "2551": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:1-35", "hash": "775db9745a59205217a7c21bada98d04", "title": "PaddleVideo: Frame Sampler"}, "2552": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:36-61", "hash": "a803107a19fd623efe83353f2ac2f91e", "title": "AVA Frame Sampling Initialization"}, "2553": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:62-82", "hash": "e52c62c97ff51f68fb5b42ee5560c764", "title": "Clip Offset Calculator"}, "2554": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:83-107", "hash": "66efe74c8097be70c95a9dc93fb0f2b9", "title": "AVA Video Sampler"}, "2555": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:108-129", "hash": "c7f717e3ac8d2db4a06e588be0e2b2dd", "title": "Wrap-Around Frame Index Handling"}, "2556": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:130-166", "hash": "9fc85f8e778242000bc81ae1881ae6e6", "title": "Abstract Class for Storage Backends"}, "2557": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:167-190", "hash": "644d69db3b17c0dc4f8a7d2b33728e27", "title": "Registering Backends: SampleAVA Pipeline Code"}, "2558": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:191-225", "hash": "7af58b2b803028af1c297025b2331800", "title": "FileClient: Handling File Operations and Pillow Image Conversion"}, "2559": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:226-247", "hash": "facbe8b65b7be6c98649661f3419ae56", "title": "Pillow Image to Numpy Array Converter"}, "2560": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:248-270", "hash": "f5f8e839f136099fb0ff4e53c3ad9c47", "title": "Image Conversion to Numpy Array"}, "2561": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:271-301", "hash": "7485fce1eaab46de1cae999100411b0b", "title": "Pipeline for Decoding Frames in Sample_AVA.py"}, "2562": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:303-326", "hash": "a560e86c6e9147fc2025fb24a5e57cf2", "title": "Resizing and Scaling Pipeline"}, "2563": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:327-354", "hash": "5255c6d99baa8e0de41736cdd51e02f1", "title": "SampleAVAFrames Class Overview"}, "2564": {"path": "/paddlevideo/loader/pipelines/sample_ava.py:355-374", "hash": "f7f56a23dd566af9d2dcdf27279124c0", "title": "AVA Sample Frame Indexer"}, "2565": {"path": "/paddlevideo/loader/pipelines/sample_ucf24.py", "hash": "2c4dfebf632d691b8d7b853a114a324e", "title": "UCF24 Frame Sampler"}, "2566": {"path": "/paddlevideo/loader/pipelines/sample_ucf24.py:1-33", "hash": "b1afe9d9b1291fb4881d1f23257a8a3a", "title": "Video Sampler Class: SamplerUCF24"}, "2567": {"path": "/paddlevideo/loader/pipelines/sample_ucf24.py:34-65", "hash": "cff97457829bd1b1e44f280cbe7a7dc0", "title": "Video Clip Pipeline Creation"}, "2568": {"path": "/paddlevideo/loader/pipelines/sample_ucf24.py:66-69", "hash": "138d2eeae7bb05f5f5bf4b03d9644ab4", "title": "Keyframe Indexer"}, "2569": {"path": "/paddlevideo/loader/pipelines/segmentation.py", "hash": "b4617809da5e4dfec194445c86c20e8f", "title": "PaddleVideo: Enhanced Segmentation and Transformation"}, "2570": {"path": "/paddlevideo/loader/pipelines/segmentation.py:1-32", "hash": "2efbbeed6024866f6cf1ed0bad579da8", "title": "PaddleVideo Segmentation Pipeline Code"}, "2571": {"path": "/paddlevideo/loader/pipelines/segmentation.py:33-65", "hash": "880ecf608c49d4c3902d65ae26c66be1", "title": "Multi-Scale Image Segmentation Function"}, "2572": {"path": "/paddlevideo/loader/pipelines/segmentation.py:67-92", "hash": "8b646c06f82bce95a2b3728ffa919449", "title": "Image Resizing and Flipping Pipeline"}, "2573": {"path": "/paddlevideo/loader/pipelines/segmentation.py:93-124", "hash": "a5e38a6bc0139ee8e9eba03a30390408", "title": "MultiNorm Image Preprocessing"}, "2574": {"path": "/paddlevideo/loader/pipelines/segmentation.py:125-130", "hash": "780e88e70888605b04e9a2757d6cdea9", "title": "Image Normalization and Transposition"}, "2575": {"path": "/paddlevideo/loader/pipelines/segmentation_pipline.py", "hash": "45f9ab88ea44e60757e7680dffb042c9", "title": "Segmentation Sampler Python Class"}, "2576": {"path": "/paddlevideo/loader/pipelines/segmentation_pipline.py:1-35", "hash": "c3b0fff5597e13470623b02b8c4368bd", "title": "Segmentation Sampler Python Pipeline"}, "2577": {"path": "/paddlevideo/loader/pipelines/segmentation_pipline.py:36-40", "hash": "e06cf98749d8f3c370f0296f4278949c", "title": "Segmentation Pipeline Code Snippet"}, "2578": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py", "hash": "0c6078a6f6584c6a9b93bd56364ce1c3", "title": "Skeleton Pipeline for PaddleVideo"}, "2579": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1-34", "hash": "cf1ce62eb6a3d0a4f30dbe7994575520", "title": "Skeleton Pipeline Registration"}, "2580": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:36-68", "hash": "cc10108b2989770eabb157d9b1addc8a", "title": "Lazy Operation Initialization"}, "2581": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:69-101", "hash": "0d98dcf84a2c2f7fe5a180056fcfd9ea", "title": "Skeleton Pipeline: Auto-Padding and Feature Extraction"}, "2582": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:102-133", "hash": "886d30a6f7f094ba7b86471c41b015c3", "title": "Skeleton Pipeline Data Padding"}, "2583": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:134-170", "hash": "debaec96d7168a9b5d89fcf7b0f88317", "title": "Skeleton Pipeline Classes"}, "2584": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:173-202", "hash": "4a89fb1c92a28089d718d4558a28d24e", "title": "Random Rotation Skeleton Class"}, "2585": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:204-229", "hash": "f53caf25ccc6e44e0124006f1a15feb9", "title": "Random Rotation Applier"}, "2586": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:230-265", "hash": "bc0899fedc2f147d54fd73742257e600", "title": "Skeleton Pipeline Class for Cropping"}, "2587": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:266-286", "hash": "a13ca9fc6ef9ea60c1b071de6e4357e7", "title": "Randomly Cropped and Biased Skeleton Data Processing"}, "2588": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:287-316", "hash": "03d78abdca7d11f96a7e04935584cfd1", "title": "Skeleton Data Transformation for Video Analysis"}, "2589": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:317-344", "hash": "34e80164a644a1bc1cc58d944c1cd4dc", "title": "Skeleton Pipeline for PaddleVideo"}, "2590": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:345-372", "hash": "c618b23f40b4c29a4b51055f0acd25f2", "title": "Training Clip Sampler"}, "2591": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:373-401", "hash": "57f9faee2cb1d60609c089d8fe6bfac6", "title": "Skeleton Clip Index Determination"}, "2592": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:402-427", "hash": "362f978bb6d2bf6fd20debb3cfcf2163", "title": "Random Frame Index Selection"}, "2593": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:428-459", "hash": "06b1a49a60b638d5f611a53a42a24af0", "title": "Skeleton Pipeline Class for PaddleVideo"}, "2594": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:460-493", "hash": "aee15f2de0e3280ad38b5c27bfe610fa", "title": "PoseDecode Class Loads Pose Keypoints"}, "2595": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:494-528", "hash": "521cff006703d2076b2ed01c630a2a92", "title": "PoseCompact: Compact Keypoint Representation"}, "2596": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:529-546", "hash": "e74b967f49d7f8079d12dc43ebc416a7", "title": "Expand Bounding Boxes in Skeleton Pipeline"}, "2597": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:548-585", "hash": "f1e84a40f190de10f5d96ed5d5def92b", "title": "Skeleton Pipeline Class"}, "2598": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:587-611", "hash": "ffa733326c2aeac7a702a4be7dee2b47", "title": "Bounding Box Adjustment for Skeleton Pipeline"}, "2599": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:613-640", "hash": "b0bf72e2253e89a1a7dd1f3ba3d19f27", "title": "Crop-Based Skeleton Detection"}, "2600": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:641-669", "hash": "ee9fce904b6e2b862fe3e09331125e6c", "title": "Cropping Bounding Boxes in Skeleton Pipeline"}, "2601": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:670-693", "hash": "54288f10e51e69f8cbb54cd5d4177959", "title": "Random Resized Crop Pipeline V2"}, "2602": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:694-719", "hash": "2fef9ab9a0b797a21b77df39b84ac496", "title": "Initialize Class for Cropping Bounding Box"}, "2603": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:720-741", "hash": "6eae779f2359f685bcdc67349eb46cc3", "title": "Random Crop Bounding Box Generator"}, "2604": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:742-766", "hash": "aaa5fd2c845f3b27fa050c308d87dd1f", "title": "Random Crop with Aspect Ratios"}, "2605": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:767-791", "hash": "0b1078d15581f0324c38480d71e00f5b", "title": "Crop Quadruple Adjustment for Skeleton Pipeline"}, "2606": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:792-815", "hash": "2a2bd0485fc129fd9d6e64a7a19864c2", "title": "Image Cropping and Keypoints Extraction"}, "2607": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:816-843", "hash": "3b4d0252485182df66e360dac411722a", "title": "Skeleton Pipeline for PaddleVideo"}, "2608": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:844-880", "hash": "d27bcff26be0a60e1b6e6078d58748f5", "title": "CenterCrop_V2 Pipeline and is\\_seq\\_of Function"}, "2609": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:881-909", "hash": "27af2f4c09a583e4d32772777b392b61", "title": "CenterCrop Augmentation Class"}, "2610": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:910-936", "hash": "32ed08979bd1d9951cb8dcc32b9d0bb4", "title": "Update Image Shape and Crop Coordinates"}, "2611": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:937-957", "hash": "efa922b9645f9d5496a31a55d7cf2379", "title": "Handling Flip Operation in Skeleton Pipeline"}, "2612": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:958-984", "hash": "dfcb46b740835043e2c65094ac307b43", "title": "Flip_V2 Pipeline Registration and Functionality"}, "2613": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:985-1006", "hash": "e9308737203900f05aedd65cc7e58945", "title": "SkeletonPipeline: Direction-Based Keypoint Flipping"}, "2614": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1007-1034", "hash": "3f9b174776e404d07a15be2086fad7d7", "title": "Skeleton Pipeline Image and Keypoints Flipping"}, "2615": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1036-1065", "hash": "1d88d695b771c669773029d3e399f649", "title": "Horizontal Flip Augmentation in PaddleVideo"}, "2616": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1066-1090", "hash": "8d1bd9a3b563bea78206166f4a061a71", "title": "Flip and Flip Labels in Skeleton Pipeline"}, "2617": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1091-1117", "hash": "595e7be903800d12e5eefee0aa4785ee", "title": "SkeletonPipeline: Flip and Register"}, "2618": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1119-1144", "hash": "f9a31106731d99261eba19d47184cfa9", "title": "Image Data Formatting Class"}, "2619": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1145-1169", "hash": "9c07978e5b3a57ded21a0270f9885e25", "title": "SkeletonPipeline: Image Processing and Reshaping"}, "2620": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1170-1197", "hash": "d476b189108056a7725a342a2a2db39c", "title": "Image Data Converter: NHWC/NCHW/NPTCHW with Collapse Option"}, "2621": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1198-1220", "hash": "a8e3f022378c96fdf1b62c940ecb6e23", "title": "Collect Pipeline Class"}, "2622": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1221-1238", "hash": "628b2c9059ce564e5e1b1ff3235a7d5e", "title": "Default Image Data Loading Parameters"}, "2623": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1239-1275", "hash": "84136e9b5764375a566448c1acf926f2", "title": "Skeleton Pipeline Class"}, "2624": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1276-1294", "hash": "d68298b2fc172904ffe6bdec0deac53d", "title": "GeneratePoseTarget: Heatmap Generator"}, "2625": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1295-1318", "hash": "5a70d0eedf53b044f9e8202e77b7167b", "title": "Skeleton Pipeline Initialization"}, "2626": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1319-1349", "hash": "b41b98058845d2946d284915c61bc0d1", "title": "SkeletonPipeline Heatmap Generation"}, "2627": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1350-1375", "hash": "adf6a29dde94e2ab86ed4d2b58f09184", "title": "Gaussian Kernel Patch Heatmap Generation"}, "2628": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1377-1398", "hash": "64f10a4e281ad7c106ef82f13a138a11", "title": "Pseudo Heatmap Generation"}, "2629": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1399-1427", "hash": "c0c560754f899171faceb8f80ce9c9bc", "title": "Keypoint Distance Calculator"}, "2630": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1429-1453", "hash": "8ecabbaa09a15f6871aef3801aae3fc1", "title": "Gaussian Kernel Heatmap Dominant Point Calculator"}, "2631": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1455-1483", "hash": "8b4c1b312a91f207152c54df573a17ce", "title": "Generate Heatmaps for Keypoints and Limbs"}, "2632": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1484-1517", "hash": "2aaddd2227e46f1d2aa22cdc6da2ed79", "title": "Pseudo Heatmap Generator for Skeleton Sequences"}, "2633": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1518-1547", "hash": "75c14245313a5015744d4aa1247a09d6", "title": "Heatmap Generator from Keypoints"}, "2634": {"path": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1548-1554", "hash": "4dbdf3bebe73a6fb49780eaa395e50fa", "title": "Skeleton Pipeline Formatting"}, "2635": {"path": "/paddlevideo/loader/registry.py", "hash": "427b6d09fb7379ed2157da934047955e", "title": "PaddleVideo Registry Definition"}, "2636": {"path": "/paddlevideo/metrics/ActivityNet/__init__.py", "hash": "0270f824442a5b01503b600f1cd8ac40", "title": "Public API Added for ANETproposal"}, "2637": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py", "hash": "9e35f7d43b19c34993650ce1896effcc", "title": "ActivityNet Proposal Metrics"}, "2638": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:1-29", "hash": "3830cb8af9974328636764da8294b2ca", "title": "ActivityNet Metrics: AR@N & AUC"}, "2639": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:31-54", "hash": "cac2eb8d5061ec87b2fcd5f2510f8280", "title": "Initializing Class with Files and Defaults"}, "2640": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:55-77", "hash": "46fefb644a7385731bd8d55644735239", "title": "Blocked Video Metrics Script"}, "2641": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:79-102", "hash": "0674aca243e45b186266c8fba0c260e9", "title": "Read Ground Truth JSON and Return DataFrame"}, "2642": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:103-130", "hash": "4cd3cd74f5dd2b4e9ebb9bdab0c753b3", "title": "Proposal JSON Parser"}, "2643": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:132-158", "hash": "40b63921394aff41514882c244d6ce86", "title": "ActivityNet Proposal Evaluation Metrics"}, "2644": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:159-182", "hash": "c4f57a7c571e5ccaaf901fa55c474fc3", "title": "ActivityNet Proposal Metric"}, "2645": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:183-202", "hash": "f91461ffb1b5fc043abe3078ccef33a3", "title": "Average Recall Calculator"}, "2646": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:203-231", "hash": "7a97c81f8804afaa80c007cd46cb5292", "title": "Max Average Proposals Per Video"}, "2647": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:232-255", "hash": "f1d313e28cb1852d17d57ac752c5df6a", "title": "Exception Handling for Proposals and Ground Truth"}, "2648": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:257-278", "hash": "ecf3d48cd313f7c319ee09823820c74b", "title": "Average Recall Calculator"}, "2649": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:279-298", "hash": "a9e5c5242f1f4b153ad1e47cff359ac2", "title": "Threshold-Based True Positives Calculation"}, "2650": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:299-324", "hash": "2349a1e75e66794711d476d029d13e1c", "title": "Efficient Video Metrics Calculation"}, "2651": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:325-349", "hash": "9bf31be6e8cf325aea6e860db6067e44", "title": "TIOU Calculation Function"}, "2652": {"path": "/paddlevideo/metrics/ActivityNet/anet_prop.py:350-359", "hash": "6d5a9680ea911a7eb8cadc5ec89d786f", "title": "IoU Calculation for Segment Intersection"}, "2653": {"path": "/paddlevideo/metrics/__init__.py", "hash": "6a954e46472a837fd5dd1762ba8995e9", "title": "PaddleVideo Metrics Library"}, "2654": {"path": "/paddlevideo/metrics/__init__.py:1-25", "hash": "dc3f4e7557448feb9010b41deeea43ba", "title": "Video Metric Suite"}, "2655": {"path": "/paddlevideo/metrics/__init__.py:26-36", "hash": "f8b63dad51c7f6757c83185fd3c946be", "title": "Comprehensive Metric Import for PaddleVideo"}, "2656": {"path": "/paddlevideo/metrics/ava_evaluation/README.md", "hash": "f4d2521494de8a8b63ecfa0288fb9d12", "title": "AVA Evaluation Metrics in PaddleVideo"}, "2657": {"path": "/paddlevideo/metrics/ava_evaluation/metrics.py", "hash": "1f2182ce45889bb95e2c9e70e246b26a", "title": "AVA Metrics Calculation"}, "2658": {"path": "/paddlevideo/metrics/ava_evaluation/metrics.py:1-30", "hash": "9f11b1ce1e96d02156242490be812b5f", "title": "Precision and Recall Metrics Function"}, "2659": {"path": "/paddlevideo/metrics/ava_evaluation/metrics.py:32-58", "hash": "5231aee6105f555809a46accf60ea65e", "title": "AVA Evaluation Array Validation"}, "2660": {"path": "/paddlevideo/metrics/ava_evaluation/metrics.py:59-88", "hash": "5e6ea6a8ee6fa5fa3820411929ab8ba5", "title": "Average Precision and Recall Calculation"}, "2661": {"path": "/paddlevideo/metrics/ava_evaluation/metrics.py:89-111", "hash": "052a31eb858dfe3b49f8d6513cca6dba", "title": "Validate and Concatenate Precision-Recall Arrays"}, "2662": {"path": "/paddlevideo/metrics/ava_evaluation/metrics.py:112-137", "hash": "0bb057142e294672b0f5dc268a4536f8", "title": "Average Precision and CorLoc Metric"}, "2663": {"path": "/paddlevideo/metrics/ava_evaluation/metrics.py:138-143", "hash": "fc850b0166c6cd8a5c4d5da032e56555", "title": "Average Class Precision"}, "2664": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_list.py", "hash": "3596e3bea0593ddafd613ed41b8e50b3", "title": "Validating Bounding Box Coordinates"}, "2665": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:1-26", "hash": "6f51b11d05146524ad776691aa931f9e", "title": "BoxList Class for Bounding Boxes"}, "2666": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:28-52", "hash": "fbc489886a2c19f71ecaef661e39eda7", "title": "Numpy Box List Class"}, "2667": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:54-81", "hash": "b0491ae796be435f33099f2319abe8d9", "title": "Box Collection Manager: Count, Retrieve, and Add Data"}, "2668": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:82-117", "hash": "8245674d79ee5298fddcbadbdc1cd47a", "title": "Numpy Box List Class"}, "2669": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:118-138", "hash": "42c1dd5a90a5c166265719de810f0fcf", "title": "Valid Box Check"}, "2670": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_ops.py", "hash": "6a54e93b875a763b5cf4bda29dbaf1ba", "title": "Numpy Box Operations for IoU"}, "2671": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_ops.py:1-29", "hash": "d2f9334e13ed2ac24e0594a11de319b3", "title": "Bounding Box Operations for Numpy Arrays"}, "2672": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_ops.py:31-57", "hash": "db84fb56e0e85aa493929537b174c418", "title": "Box Area and Intersection Calculations"}, "2673": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_ops.py:58-90", "hash": "d1e492195a83fd2f8ff9a06d1f36a357", "title": "Pairwise IOU/IOA Computation for Box Collections"}, "2674": {"path": "/paddlevideo/metrics/ava_evaluation/np_box_ops.py:91-98", "hash": "ef868be27e75d09b3c411bdee231b58c", "title": "Pairwise IoU Calculation for Bounding Boxes"}, "2675": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py", "hash": "3264d2f809b20af661f43df242c38021", "title": "AVA Object Detection Evaluation"}, "2676": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:1-21", "hash": "119877ede59583de119a05b0f366f6c6", "title": "PaddleVideo Object Detection Evaluation"}, "2677": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:22-58", "hash": "d10ef18168383130744beac0267f9b8f", "title": "Object Detection Evaluator Class"}, "2678": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:59-86", "hash": "e95f522aa341a832af1b29ff37914f5d", "title": "AVA Object Detection Evaluation Metric"}, "2679": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:87-120", "hash": "a8625f55fe89585dd0e195efcadfa03f", "title": "Object Detection Evaluator: Ava Metrics"}, "2680": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:121-139", "hash": "b5d11964d49233446e747fa5e11a438d", "title": "Object Detection Evaluation Class"}, "2681": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:140-160", "hash": "2b13ba11ef661bdadcfd7b0f77f46e9a", "title": "Object Detection Evaluation Module"}, "2682": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:161-179", "hash": "c7ce0e8dde7f5e57b614b438dc2d0431", "title": "Validating Groundtruth Image Addition"}, "2683": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:180-198", "hash": "3d05134d80f2d1bd924315223c46a5ef", "title": "Checking Existing Image in Object Detection Evaluation"}, "2684": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:199-219", "hash": "4d1722b93c4ad651f0e310bba7809986", "title": "Ground Truth Difficulty Check"}, "2685": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:220-236", "hash": "1d984dc9f6aa12e468e6873a690c7a42", "title": "Single Image Detection Evaluation"}, "2686": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:237-259", "hash": "71693f9330a32aafeca71a99e4afc522", "title": "Detection Class Retrieval and Mask Validation"}, "2687": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:260-290", "hash": "26f2f3c6cef5abccdb5b39e687b51b40", "title": "AVA Object Detection Evaluation"}, "2688": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:291-315", "hash": "a91b92af7cc1701f863ef2a4e5371460", "title": "Mean Average Precision Calculator"}, "2689": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:316-338", "hash": "946320c45521d5514ed3b01693ddfe60", "title": "Object Detection Metrics Calculation"}, "2690": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:339-375", "hash": "70f629e5b801fc0338a24cebfb871e9d", "title": "PaddleVideo Object Detection Evaluation"}, "2691": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:376-402", "hash": "42ac52b15276fe54ad0310f60b527531", "title": "Object Detection Evaluation Setup"}, "2692": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:404-430", "hash": "924057516908778baa78e861e07b01bb", "title": "Object Detection Evaluation Functions"}, "2693": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:432-447", "hash": "b86e7aa4dc8c1315838bf439651bde32", "title": "AVA Object Detection Evaluation"}, "2694": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:448-467", "hash": "f0f8ea09dbe40677e2870854eae0a776", "title": "Add Ground Truth Data to Database"}, "2695": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:468-493", "hash": "a65ba8f0e1b609f7eff48d262c78da13", "title": "Single Image Evaluation Function"}, "2696": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:494-516", "hash": "1d0384e216c79cce1fbaf43b7133ae32", "title": "Create Numpy Array from Detection Masks"}, "2697": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:518-536", "hash": "962c93358ccae61a33d25ea632e6c0ec", "title": "Ground Truth Init for Object Detection"}, "2698": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:537-561", "hash": "be36ef6babd8e45d91cd960d648df3b6", "title": "PaddleVideo: Object Detection Metrics Calculation"}, "2699": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:562-583", "hash": "976bc5a4022f1ec2c68eb6b358d02b2d", "title": "Ground Truth Update for Object Detection"}, "2700": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:584-605", "hash": "15f5cf82114fa12c4874e5bb6bf59aed", "title": "Object Detection Evaluation Metrics"}, "2701": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:606-629", "hash": "283c38db9c7e0dafeb11599397d94d6f", "title": "AVA-Based Object Detection Evaluation"}, "2702": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:630-651", "hash": "017d6553af81e89009acc2dd138f4682", "title": "Object Detection Evaluation Metrics"}, "2703": {"path": "/paddlevideo/metrics/ava_evaluation/object_detection_evaluation.py:652-658", "hash": "2dd8b73625e85fe3825d034c568c4d33", "title": "Object Detection Metrics Calculator"}, "2704": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py", "hash": "1997401b8c0a7ffbf8d3760581e8c6a8", "title": "AVA Performance Metrics in PaddleVideo"}, "2705": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:1-20", "hash": "e4f7b4602590dac17ba3be4e8768e08f", "title": "Single Image AVA Evaluation"}, "2706": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:21-53", "hash": "23a3c0cb26b0a55a0c0bda5db3f00aae", "title": "Single Image Detection Metrics Evaluator"}, "2707": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:54-73", "hash": "d502d3818d8f686150bf5da03fe998bf", "title": "AVA Evaluation: True Positives, False Positives, and Ignored Detections"}, "2708": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:74-91", "hash": "612c979731201397a0f5a26908e94e16", "title": "AVA Metric Calculation"}, "2709": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:92-115", "hash": "4d251a5e2b18f0687d23b59456ef7947", "title": "Invalid Detection Box Removal for Object Evaluation"}, "2710": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:116-143", "hash": "ad1964a8c021d5906760cb257cef9fda", "title": "Per-Image AVA Evaluation"}, "2711": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:144-161", "hash": "6ca7396509a1e92b237fd4d57c123520", "title": "AVA Metrics: Per-Image Evaluation"}, "2712": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:162-183", "hash": "e0c2f822edf21bcc0192aea0eca7cddb", "title": "Checking and Storing Masks for AVA Evaluation"}, "2713": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:184-202", "hash": "4f163fbfd90c62393ee2e589cca16840", "title": "Per-Class Array Extraction"}, "2714": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:203-228", "hash": "26f609a06033269c662a04798ba4c0e4", "title": "Per-Image AVA Evaluation"}, "2715": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:229-249", "hash": "dd1806953f1450187381f4f69d5afd7f", "title": "Intersection Metrics: IoU and IoA"}, "2716": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:250-276", "hash": "aee100fed4d8244330fe22ba929c612a", "title": "Per-Image AVA Evaluation Labeling"}, "2717": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:277-295", "hash": "cca9f03519357fe4b5c1fdd02d1f879d", "title": "Difficult Box Evaluation"}, "2718": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:296-322", "hash": "e2ebcab5eaa91ac01a62bb42131c807f", "title": "True Positive Detection via IoU and Scores"}, "2719": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:323-344", "hash": "ef809d341a3fffa2bd6cd0c8b405e622", "title": "AVA Per-Image Evaluation"}, "2720": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:345-371", "hash": "b68c02569eb5aeec2d60ea2581cbd9eb", "title": "Class-Specific Array Retriever"}, "2721": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:372-392", "hash": "d9711057d2b9b381390bed9e2c2b7a7b", "title": "AVA Metrics Function"}, "2722": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:393-421", "hash": "3eda8828e90a291bdd2de4b6235810fd", "title": "Class-Specific Results Extraction and Invalid Box Removal"}, "2723": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:422-443", "hash": "d99beb397e3c0009cc4eae1a02ba3816", "title": "Filter and Slice Input Arrays"}, "2724": {"path": "/paddlevideo/metrics/ava_evaluation/per_image_evaluation.py:444-452", "hash": "01008177cbdb311510cd78b889098f38", "title": "Bounding Boxes and Scores"}, "2725": {"path": "/paddlevideo/metrics/ava_evaluation/standard_fields.py", "hash": "c495fddcb51e1dfe1876081872b8ef92", "title": "Standard Fields for AVA Evaluation"}, "2726": {"path": "/paddlevideo/metrics/ava_evaluation/standard_fields.py:1-26", "hash": "e10be32f96e0250a7a9933d24371aa4f", "title": "Standard Object Detection Fields"}, "2727": {"path": "/paddlevideo/metrics/ava_evaluation/standard_fields.py:27-46", "hash": "766a895b229c1530ee5f57084dad9e5a", "title": "Standard Fields for AVA Evaluation"}, "2728": {"path": "/paddlevideo/metrics/ava_evaluation/standard_fields.py:47-66", "hash": "49c1db15dea29e1854841976599e8d2f", "title": "AVA Evaluation Dictionary Defined"}, "2729": {"path": "/paddlevideo/metrics/ava_evaluation/standard_fields.py:67-86", "hash": "ef6bbc8af474726a6157e277c1050d0e", "title": "Standard AWA Field Definitions"}, "2730": {"path": "/paddlevideo/metrics/ava_evaluation/standard_fields.py:89-113", "hash": "96c36ceaed1ef5a3160f9ddece712776", "title": "Standard Video Object Detector Naming Conventions"}, "2731": {"path": "/paddlevideo/metrics/ava_evaluation/standard_fields.py:114-115", "hash": "93a1d41d0803b4aa247c17b45a03eda1", "title": "Standard Fields: Detection Metrics"}, "2732": {"path": "/paddlevideo/metrics/ava_metric.py", "hash": "f003e9d72cba4848b475f6a0edd07fcc", "title": "AVAMetric: PaddleVideo's Metric for Video Object Detection"}, "2733": {"path": "/paddlevideo/metrics/ava_metric.py:1-34", "hash": "cf35d782f526be7719cf6fab55e23b3f", "title": "AVAMetric: PaddleVideo Metric"}, "2734": {"path": "/paddlevideo/metrics/ava_metric.py:35-60", "hash": "d77a12377b4335c7aa061433b3ac431c", "title": "Video Metrics Initialization in PaddlePaddle"}, "2735": {"path": "/paddlevideo/metrics/ava_metric.py:61-90", "hash": "0760b8005ec394a8bd4122803b90a728", "title": "AVA Metrics Calculation and Logging Class"}, "2736": {"path": "/paddlevideo/metrics/ava_metric.py:92-92", "hash": "22be346acf5f8d463ed179b31d7eae6f", "title": "Class Method Returns Record List"}, "2737": {"path": "/paddlevideo/metrics/ava_utils.py", "hash": "3617204fb1ab28b433c6e173214bfe14", "title": "AVA Metrics Utilities for Video Object Detection"}, "2738": {"path": "/paddlevideo/metrics/ava_utils.py:1-31", "hash": "ab735f28535b4bfc057a2caaf8a03b04", "title": "AVA Metrics Evaluation Utilities"}, "2739": {"path": "/paddlevideo/metrics/ava_utils.py:32-64", "hash": "555db02ba40c2346588333d18563e69b", "title": "CSV Results Conversion Functions"}, "2740": {"path": "/paddlevideo/metrics/ava_utils.py:66-97", "hash": "3fd44ef430a94fd93b25123e094c15ad", "title": "Utility Functions for Video Analysis"}, "2741": {"path": "/paddlevideo/metrics/ava_utils.py:99-120", "hash": "3088bdcead2890ec1e82ed9ae8b2c33b", "title": "CSV to Dictionaries: AVA Metrics"}, "2742": {"path": "/paddlevideo/metrics/ava_utils.py:122-147", "hash": "d180a298640899bb3409181d60a10eb4", "title": "CSV Object Detection Results Merger"}, "2743": {"path": "/paddlevideo/metrics/ava_utils.py:149-181", "hash": "0f43571f4e7b0a9f5800a06b6f0e40ad", "title": "Excluding Images and Labelmap without Protocol Buffers"}, "2744": {"path": "/paddlevideo/metrics/ava_utils.py:182-210", "hash": "7df7e95ee5250090d39363f264f00686", "title": "Mean Average Precision for AVA Evaluation"}, "2745": {"path": "/paddlevideo/metrics/ava_utils.py:211-240", "hash": "e2a79632d12a4706ff561869e6563965", "title": "AVA Proposal Generation"}, "2746": {"path": "/paddlevideo/metrics/ava_utils.py:241-265", "hash": "2fe967d06cea07a8507520a3e43c4366", "title": "Average Recall and mAP Calculation"}, "2747": {"path": "/paddlevideo/metrics/ava_utils.py:266-286", "hash": "58b67a0887f57ac4d4e5d408e946526e", "title": "Single Image Pascal Evaluator Addition"}, "2748": {"path": "/paddlevideo/metrics/ava_utils.py:287-320", "hash": "508bdb76d31d4aed5cb529938898ffba", "title": "AVA Metrics Code Snippet"}, "2749": {"path": "/paddlevideo/metrics/ava_utils.py:323-357", "hash": "70eebbd7788eb01d382bfef501bf14e5", "title": "Collecting Results Across GPUs"}, "2750": {"path": "/paddlevideo/metrics/ava_utils.py:358-384", "hash": "e71802067a35cc49e0adeb9021fd3d10", "title": "AVA Evaluation Utils"}, "2751": {"path": "/paddlevideo/metrics/ava_utils.py:385-394", "hash": "f36b2a0750a2b99f5b176585f12968e5", "title": "Mean Average Precision Computation Code"}, "2752": {"path": "/paddlevideo/metrics/base.py", "hash": "1d9e08910c08f6a2a6a8f71e804e5b1d", "title": "PaddleVideo Metrics Base Class"}, "2753": {"path": "/paddlevideo/metrics/base.py:1-31", "hash": "9baa105e92338b3f573b74c1e5e19f4e", "title": "PaddleVideo Metrics Base Class Initialization"}, "2754": {"path": "/paddlevideo/metrics/base.py:33-52", "hash": "3c83471a1f603b972399f7f9ff439c7a", "title": "All-Gather and Concatenation Function"}, "2755": {"path": "/paddlevideo/metrics/bmn_metric.py", "hash": "85711ed6b2e42c607f5423085d1bc87f", "title": "BMN Metric for Paddle Video"}, "2756": {"path": "/paddlevideo/metrics/bmn_metric.py:1-32", "hash": "94b30cca892d0bef8e8e2ec8006885c8", "title": "Intersection over Union Calculation Code"}, "2757": {"path": "/paddlevideo/metrics/bmn_metric.py:33-63", "hash": "47b41a2b062fe7ee0bc5dbab893996de", "title": "Bounding Box Metrics Calculation"}, "2758": {"path": "/paddlevideo/metrics/bmn_metric.py:65-98", "hash": "6d249192a8a66cfec153ebabfec52568", "title": "BMN Metric: Object Detection Algorithm"}, "2759": {"path": "/paddlevideo/metrics/bmn_metric.py:99-127", "hash": "42f8f9840d29146a7a85c605f0d396b1", "title": "Initializing BMN Metric Class in PaddleVideo"}, "2760": {"path": "/paddlevideo/metrics/bmn_metric.py:128-156", "hash": "07b2a94594a0bf5168144bacf7f4e316", "title": "Class Variables and Metrics Initialization"}, "2761": {"path": "/paddlevideo/metrics/bmn_metric.py:157-182", "hash": "2b09ac4567a01518978e5a201469bc54", "title": "Boundary Detection Score Vector List Generation"}, "2762": {"path": "/paddlevideo/metrics/bmn_metric.py:183-206", "hash": "731e1f0bbc0ee8985e5d14bc9689b028", "title": "Post-Process Video Metrics Calculation"}, "2763": {"path": "/paddlevideo/metrics/bmn_metric.py:207-229", "hash": "16c4c4e8163fca2ed761d5ce17999537", "title": "Parallel Video Processing with bmn_post_Processing"}, "2764": {"path": "/paddlevideo/metrics/bmn_metric.py:230-256", "hash": "f508563769c5b97341ed9f022fcf6fdc", "title": "Parallel Video Processing with Multiprocessing"}, "2765": {"path": "/paddlevideo/metrics/bmn_metric.py:257-282", "hash": "0c06e10b8f22393d44730ea71344794b", "title": "Soft NMS Processing"}, "2766": {"path": "/paddlevideo/metrics/bmn_metric.py:283-304", "hash": "3d1d8a1a80a8626ffe241fd7e6d9f687", "title": "Calculate Metrics with ANETproposal"}, "2767": {"path": "/paddlevideo/metrics/build.py", "hash": "a358e2f5d18276139017e2df56bf08cb", "title": "Building Metrics with Apache License"}, "2768": {"path": "/paddlevideo/metrics/center_crop_metric.py", "hash": "3ea7e1390eac18ad559928d6cb1ad318", "title": "Center Crop Metric: PaddleVideo's Batch-Aware Class"}, "2769": {"path": "/paddlevideo/metrics/center_crop_metric.py:1-31", "hash": "a50c5c147e3896bdd9d7ba31385515d7", "title": "CenterCrop Metric Registration"}, "2770": {"path": "/paddlevideo/metrics/center_crop_metric.py:32-55", "hash": "9fca7238830c7c5f2917e9c0800ec57d", "title": "Batch-Initializing Metric for Multi-GPU Data"}, "2771": {"path": "/paddlevideo/metrics/center_crop_metric.py:56-79", "hash": "786f1356a03dc186ddaeb7f8dbadf446", "title": "Batch Processing Metric"}, "2772": {"path": "/paddlevideo/metrics/center_crop_metric_MRI.py", "hash": "961eaf76db5adc723e0f8f76ea3c60b0", "title": "Top-1/5 Accuracy Tracker"}, "2773": {"path": "/paddlevideo/metrics/center_crop_metric_MRI.py:1-33", "hash": "57ce59859113cd76cccf5c651db8611c", "title": "CenterCropMetric_MRI: Video Metric Class"}, "2774": {"path": "/paddlevideo/metrics/center_crop_metric_MRI.py:34-60", "hash": "d121ecf19865522c7454628bbdf961a8", "title": "Top-1/5 Accuracy Calculator"}, "2775": {"path": "/paddlevideo/metrics/center_crop_metric_MRI.py:61-61", "hash": "1b0a0709fdfa6c5881d12b814d0fab6c", "title": "Mean of Top-1 Accuracy"}, "2776": {"path": "/paddlevideo/metrics/depth_metric.py", "hash": "9a1b4f8d8e1441757a7b8268da8085b2", "title": "DepthMetric: Distributed Batch Processing"}, "2777": {"path": "/paddlevideo/metrics/depth_metric.py:1-34", "hash": "4bf0f160ce23b808075b501ee0ad5b43", "title": "Depth Metric: Distributed Computing"}, "2778": {"path": "/paddlevideo/metrics/depth_metric.py:35-57", "hash": "764ed528aaf28eea14df0710ca145988", "title": "Distributed All-Reduce Metrics Averaging"}, "2779": {"path": "/paddlevideo/metrics/depth_metric.py:58-77", "hash": "8bc2a5ca2b1436111f07420f96bdaeaf", "title": "Batch Processing and Metric Accumulation"}, "2780": {"path": "/paddlevideo/metrics/msrvtt_metric.py", "hash": "cd373e941ad00646bf78f8a8ba7bb818", "title": "MSR-VTT Metrics Computation"}, "2781": {"path": "/paddlevideo/metrics/msrvtt_metric.py:1-31", "hash": "789ac39b7dce364509b77bb878738f16", "title": "MSRVTT Metric Initialization"}, "2782": {"path": "/paddlevideo/metrics/msrvtt_metric.py:32-56", "hash": "0effc52f070411a97b93852cc5a04015", "title": "MSR-VTT Rank Metrics Calculator"}, "2783": {"path": "/paddlevideo/metrics/msrvtt_metric.py:57-62", "hash": "076fcf90b2e995befac29db89ba77eb9", "title": "MSRVTT Metric Accumulator"}, "2784": {"path": "/paddlevideo/metrics/multi_crop_metric.py", "hash": "e54bc81b2bbe99db2c87fb98e2e84171", "title": "Multi-Crop Metric in PaddleVideo"}, "2785": {"path": "/paddlevideo/metrics/multi_crop_metric.py:1-35", "hash": "68af44846195a615fe2102049edce01f", "title": "MultiCrop Metric: PaddleVideo Class"}, "2786": {"path": "/paddlevideo/metrics/multi_crop_metric.py:36-61", "hash": "241679c8a2aa523211583883125a8e5f", "title": "Multi-Crop Metric Initialization"}, "2787": {"path": "/paddlevideo/metrics/multi_crop_metric.py:62-83", "hash": "0ca2bb7a19e230dbeea0a4a9f8c26b15", "title": "Multi-Crop Ensemble Metric"}, "2788": {"path": "/paddlevideo/metrics/multi_crop_metric.py:84-104", "hash": "c4392530943d3e5587687ae58b0b692c", "title": "Multi-Crop Metric Calculation"}, "2789": {"path": "/paddlevideo/metrics/multi_crop_metric.py:105-108", "hash": "a6fd9fc7d83fac8cb8b398a7e967610a", "title": "Multi-Crop Metric Average Accuracy Logging"}, "2790": {"path": "/paddlevideo/metrics/recall.py", "hash": "dc0ebb076210ec5e15297eca4edade46", "title": "Paddle Video Recall Metrics Calculation"}, "2791": {"path": "/paddlevideo/metrics/recall.py:1-27", "hash": "c701156b0a43f569e3dac0cc37d72736", "title": "PaddleRecall: Object Detection Recall Calculator"}, "2792": {"path": "/paddlevideo/metrics/recall.py:29-62", "hash": "28fb53c75a39211b5f30fcba32b35d47", "title": "Precision-Recall Curve Calculation"}, "2793": {"path": "/paddlevideo/metrics/recall.py:64-84", "hash": "cb11171bef0fae4751bb44a71f6c64bc", "title": "Object Detection Recall Calculator"}, "2794": {"path": "/paddlevideo/metrics/registry.py", "hash": "df96b61f43a6063fd36b4ec66ff63de9", "title": "Registry-Based Metrics Management"}, "2795": {"path": "/paddlevideo/metrics/segmentation_metric.py", "hash": "cc3baa4548149e4a7979a7c2ae529943", "title": "Label Change Detection Metric"}, "2796": {"path": "/paddlevideo/metrics/segmentation_metric.py:1-35", "hash": "769e6aecd931f1358818625850caddac", "title": "Segmentation Metric Function"}, "2797": {"path": "/paddlevideo/metrics/segmentation_metric.py:36-57", "hash": "7b277b0d1dc994a3ac42bfb3359a59a1", "title": "Segmentation Score Calculator"}, "2798": {"path": "/paddlevideo/metrics/segmentation_metric.py:58-91", "hash": "ea10763a94b38cb3eb84a6ea7f981b9e", "title": "Segmentation Metric: Labeling and Distance Calculation"}, "2799": {"path": "/paddlevideo/metrics/segmentation_metric.py:92-126", "hash": "e1102702ca11126753ec11d1743a419e", "title": "Levenstein Distance for Video Segmentation"}, "2800": {"path": "/paddlevideo/metrics/segmentation_metric.py:128-161", "hash": "ec235f7ebab22cad166778066373b395", "title": "Segmentation Metric: Precision, Recall, F1"}, "2801": {"path": "/paddlevideo/metrics/segmentation_metric.py:162-191", "hash": "c1e4ca0fb704718ba88ec32bb443bf4e", "title": "Refining Object Detection Proposals"}, "2802": {"path": "/paddlevideo/metrics/segmentation_metric.py:192-230", "hash": "cf28309fa121daf755db64382e9af7b0", "title": "Average Recall Calculation for Video Segmentation"}, "2803": {"path": "/paddlevideo/metrics/segmentation_metric.py:231-264", "hash": "26ead2af1e4b4af9bb2a75e4026d7a50", "title": "Segmentation Metric Initialization"}, "2804": {"path": "/paddlevideo/metrics/segmentation_metric.py:265-295", "hash": "a2bb5163f5b654b10177fad5ffa5f7be", "title": "Accuracy Calculation via Segmentation"}, "2805": {"path": "/paddlevideo/metrics/segmentation_metric.py:296-330", "hash": "b48f7816e0d784c57dcb7fd78ef3710f", "title": "Segmentation Metrics Accumulation"}, "2806": {"path": "/paddlevideo/metrics/segmentation_metric.py:331-356", "hash": "9079930823437473b2514afba1a8b82a", "title": "Segmentation Metrics Calculator"}, "2807": {"path": "/paddlevideo/metrics/segmentation_metric.py:358-385", "hash": "fedd9d20baae84b1ff156f4cfbce746b", "title": "Segmentation Metric Calculator"}, "2808": {"path": "/paddlevideo/metrics/segmentation_metric.py:386-389", "hash": "e1e5363e9e346736b7493fead5ed22a2", "title": "Initialize Proposal Metrics List"}, "2809": {"path": "/paddlevideo/metrics/skeleton_metric.py", "hash": "36030e3b8d5b889bdc7ed01b4b45e618", "title": "SkeletonMetric: PaddleVideo's Skeleton-Based Metric Tool"}, "2810": {"path": "/paddlevideo/metrics/skeleton_metric.py:1-38", "hash": "f186f301073b5eb6920d1847c12687ff", "title": "Skeleton Metric Calculator"}, "2811": {"path": "/paddlevideo/metrics/skeleton_metric.py:39-65", "hash": "2a5ac263d90ff3ee29764899253c8f48", "title": "Metrics Tracking Class"}, "2812": {"path": "/paddlevideo/metrics/skeleton_metric.py:66-88", "hash": "76b8cdf90efdd64282869c8bb803fa1d", "title": "Accuracy Calculator"}, "2813": {"path": "/paddlevideo/metrics/skeleton_metric.py:89-96", "hash": "0c79bf0b7ff3bbdd9c0ea469ca1ffb46", "title": "Save Values to File: Skeleton Metric Logging"}, "2814": {"path": "/paddlevideo/metrics/transnetv2_metric.py", "hash": "c25f88b14f22c9dc6eebb75f2f77d5b4", "title": "TransNetV2 Metric Calculator"}, "2815": {"path": "/paddlevideo/metrics/transnetv2_metric.py:1-34", "hash": "b3ec9ed345f302a5daa7f87cd58bfbf8", "title": "Predictions to Scenes: Identifying Scene Changes"}, "2816": {"path": "/paddlevideo/metrics/transnetv2_metric.py:35-57", "hash": "1a81d85ea59bb73a3b34d9ef92d7d837", "title": "Transnet V2 Metric Conversion"}, "2817": {"path": "/paddlevideo/metrics/transnetv2_metric.py:58-80", "hash": "2ba3e9cb23aa5891afd03847277f64f0", "title": "TransNet V2 Metric Calculation"}, "2818": {"path": "/paddlevideo/metrics/transnetv2_metric.py:81-120", "hash": "29f867d8def7ff10ba52464fab4e3cfe", "title": "Transnetv2 Metric Calculator"}, "2819": {"path": "/paddlevideo/metrics/transnetv2_metric.py:121-152", "hash": "6474954f70fac29d28de0a85a249938f", "title": "TransNetV2 Metric Calculation"}, "2820": {"path": "/paddlevideo/metrics/transnetv2_metric.py:153-174", "hash": "64ecb25dfa39362a3a69500810d05c5a", "title": "Machine Learning Metric Calculator"}, "2821": {"path": "/paddlevideo/metrics/ucf24_utils.py", "hash": "2157170f291aa52e6d4853b80dca73b4", "title": "UCF24 Metrics: PaddleVideo Utility Functions"}, "2822": {"path": "/paddlevideo/metrics/ucf24_utils.py:1-33", "hash": "8f83d13f2d62d07bf3fdd4117da47480", "title": "Average Precision Metrics in UCF101 Dataset"}, "2823": {"path": "/paddlevideo/metrics/ucf24_utils.py:34-81", "hash": "56cdf272548b1f75432ee2807c74e198", "title": "Bounding Box Converter Utilities"}, "2824": {"path": "/paddlevideo/metrics/ucf24_utils.py:82-122", "hash": "ac3dea98ba843de71b1a709216743f82", "title": "Absolute Bounding Box Conversion and Visualization"}, "2825": {"path": "/paddlevideo/metrics/ucf24_utils.py:123-148", "hash": "fa8b0d8fb42db92ba237c57f9df8f418", "title": "Draw Text Box Around Rectangle"}, "2826": {"path": "/paddlevideo/metrics/ucf24_utils.py:149-165", "hash": "4de895be70e37614469bc971bbb7e88b", "title": "Ucf24Metrics Constructor"}, "2827": {"path": "/paddlevideo/metrics/ucf24_utils.py:166-181", "hash": "213e25c9bd8b71fc986db1f1e1149f58", "title": "BoundingBox Class Definition"}, "2828": {"path": "/paddlevideo/metrics/ucf24_utils.py:183-207", "hash": "b83d900e14098f6403bf30137d7c15eb", "title": "Relative to Absolute Bounding Box Conversion"}, "2829": {"path": "/paddlevideo/metrics/ucf24_utils.py:208-232", "hash": "41304ae0094f57f3d303728020d12ce2", "title": "Bounding Box Class for Image Formats"}, "2830": {"path": "/paddlevideo/metrics/ucf24_utils.py:233-266", "hash": "be2c8a317365d979ac4d82c54a957914", "title": "Detection Result Class with Compare Method"}, "2831": {"path": "/paddlevideo/metrics/ucf24_utils.py:268-294", "hash": "ac24812e6083d1467f47257736b8bac8", "title": "Bounding Box Comparison and Cloning"}, "2832": {"path": "/paddlevideo/metrics/ucf24_utils.py:297-332", "hash": "59e6afd2737173b80708494702ab59b1", "title": "Bounding Box Collection Class"}, "2833": {"path": "/paddlevideo/metrics/ucf24_utils.py:333-359", "hash": "cad22b93369cb4aaecad9932a7842728", "title": "Bounding Box Utilities"}, "2834": {"path": "/paddlevideo/metrics/ucf24_utils.py:360-380", "hash": "9d1ec6c440e702988eae342c2c600cb4", "title": "Pascal VOC Metrics Calculation"}, "2835": {"path": "/paddlevideo/metrics/ucf24_utils.py:381-397", "hash": "1f25f6730ff578263eb625d94c17c417", "title": "Class Metrics List"}, "2836": {"path": "/paddlevideo/metrics/ucf24_utils.py:398-422", "hash": "12b72114ab3dd25ea9b81532dd467432", "title": "Detection Metrics Initialization and Sorting"}, "2837": {"path": "/paddlevideo/metrics/ucf24_utils.py:423-445", "hash": "65182bdc7393a8e801474b0b51cf2aad", "title": "Detection Metrics Calculation"}, "2838": {"path": "/paddlevideo/metrics/ucf24_utils.py:446-465", "hash": "667fb1e97d7a481ab207a186d781dfa4", "title": "Precision, Recall, Average Precision Calculation"}, "2839": {"path": "/paddlevideo/metrics/ucf24_utils.py:466-495", "hash": "cfc804b7d4dada4a9c2deeb87d58c0dd", "title": "Calculate Average Precision for Classes"}, "2840": {"path": "/paddlevideo/metrics/ucf24_utils.py:496-523", "hash": "caa052cd196d1b8565a5eea5f75f8dcd", "title": "Interpolated Average Precision Calculation"}, "2841": {"path": "/paddlevideo/metrics/ucf24_utils.py:524-553", "hash": "641e154e93431fb71f847a1191545158", "title": "Calculating AP, AUC, and IoU in Video Metrics"}, "2842": {"path": "/paddlevideo/metrics/ucf24_utils.py:554-583", "hash": "e11d308d637b2c4c64bb32faa4bd56bf", "title": "Bounding Box Intersection Utility"}, "2843": {"path": "/paddlevideo/metrics/ucf24_utils.py:584-617", "hash": "b01d038dde77f5e284c1b52754d1296f", "title": "Bounding Box Intersection and Union Calculation"}, "2844": {"path": "/paddlevideo/metrics/ucf24_utils.py:618-648", "hash": "689bfc6c7bacd37750eca4b5c5316828", "title": "Validate Image Size and Coordinate Type Functions"}, "2845": {"path": "/paddlevideo/metrics/ucf24_utils.py:649-680", "hash": "2bc35449f2ceac4b8cb13230689083b6", "title": "Bounding Box Reader Function"}, "2846": {"path": "/paddlevideo/metrics/ucf24_utils.py:681-711", "hash": "828521da23a92b44cc6f81cf20752a6a", "title": "Bounding Box Analyzer"}, "2847": {"path": "/paddlevideo/metrics/ucf24_utils.py:712-743", "hash": "a0b46170c985b74b40a07d17963ae654", "title": "Mean Average Precision Calculator"}, "2848": {"path": "/paddlevideo/metrics/ucf24_utils.py:744-772", "hash": "53986650f001acb684a35d1d2a30559b", "title": "Average Precision Calculation"}, "2849": {"path": "/paddlevideo/metrics/ucf24_utils.py:773-783", "hash": "b45d64bedcd6d6b15c401d66096b9212", "title": "Mean Average Precision Calculator"}, "2850": {"path": "/paddlevideo/metrics/vos_metric.py", "hash": "915a8759484e2e5ef33f0869381073e5", "title": "VOS Metric: Video Object Segmentation"}, "2851": {"path": "/paddlevideo/metrics/vos_metric.py:1-38", "hash": "62eda92996aa477431934c9849c2bf53", "title": "VOS Metric: PaddleVideo Segmentation"}, "2852": {"path": "/paddlevideo/metrics/vos_metric.py:39-68", "hash": "200b31defdeca55bf28f4e16a0ba0ed4", "title": "VOS Metric Class Initialization"}, "2853": {"path": "/paddlevideo/metrics/vos_metric.py:69-91", "hash": "99ab5eec36253eac7628ecaff2875012", "title": "Data Loading and Processing Loop"}, "2854": {"path": "/paddlevideo/metrics/vos_metric.py:93-113", "hash": "3a2e0d9c42608d86e2ce09b8397a34d4", "title": "Prepare Data for Video Object Detection Model"}, "2855": {"path": "/paddlevideo/metrics/vos_metric.py:115-129", "hash": "f1be161f171716b96d7aecacb46b8eab", "title": "Introducing New Labels in VOS Metric"}, "2856": {"path": "/paddlevideo/metrics/vos_metric.py:131-147", "hash": "e8380516825c6b1c32f561e898a01711", "title": "Average Max Prediction"}, "2857": {"path": "/paddlevideo/metrics/vos_metric.py:149-168", "hash": "0cb7def920d404e362d76f262c64b2d1", "title": "Frame-wise Mask Updating and Timing"}, "2858": {"path": "/paddlevideo/metrics/vos_metric.py:169-191", "hash": "12ff7e0c1c3831f4bee116459e773a33", "title": "Average Time per Frame Calculator"}, "2859": {"path": "/paddlevideo/metrics/vos_metric.py:192-209", "hash": "ffda2c06adcac07ac0ecaca236fafa4e", "title": "Flip and Save Mask Tensor"}, "2860": {"path": "/paddlevideo/metrics/vos_metric.py:210-222", "hash": "d5b679eb56f5acc8bdb7e72e4a9d8e01", "title": "Unknown Variable Range Identification"}, "2861": {"path": "/paddlevideo/metrics/vos_metric.py:223-236", "hash": "cf513ebb9c2f6bedcb32d5f885507c61", "title": "Consecutive Integers Range"}, "2862": {"path": "/paddlevideo/metrics/vos_metric.py:237-250", "hash": "0a2d4661faa1494e3dae1431ca6859a5", "title": "Frame Metrics Analysis"}, "2863": {"path": "/paddlevideo/metrics/vos_metric.py:251-272", "hash": "ce5736294af41c423d5a5d0924b2671e", "title": "Masking and Saving Images in PaddleVideo Metrics"}, "2864": {"path": "/paddlevideo/metrics/vos_metric.py:273-276", "hash": "771f0b745f83fe03c9a184900e806ed8", "title": "Metrics Calculation Class Zip Savior"}, "2865": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py", "hash": "41aadc62c802f8fcdc4267be85ef557d", "title": "Average Precision Calculator for VOD"}, "2866": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:1-23", "hash": "2f02e25004c76d711a83db8d544f1f83", "title": "Interpolated Average Precision Calculator"}, "2867": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:25-55", "hash": "a35e75c835d69b4261b9b5f97f665ebe", "title": "Average Precision Calculator for Long Lists"}, "2868": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:57-86", "hash": "07ab196c211ee40a6b43b96f0626efcb", "title": "Average Precision Calculator Class"}, "2869": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:87-108", "hash": "fb9cab3f4d396b62ca789bce97a170ed", "title": "Average Precision Calculator"}, "2870": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:109-134", "hash": "f230c6ba4def426c0691906f666417a5", "title": "Average Precision Calculator"}, "2871": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:136-166", "hash": "6f58dc07af8cb38188b90ce5fc61ef44", "title": "Non-Interpolated Average Precision Calculator"}, "2872": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:168-192", "hash": "cc6778d11aea92ab1e3edf1381b90876", "title": "Non-Interpolated Average Precision Calculator"}, "2873": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:193-220", "hash": "32ff75ab9498acb3cb5ed8c5ce61e943", "title": "Non-Interpolated Average Precision Calculator"}, "2874": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:221-256", "hash": "506ea1b5420db66da24bff18b2ecb7a5", "title": "Average Precision Calculator"}, "2875": {"path": "/paddlevideo/metrics/youtube8m/average_precision_calculator.py:257-274", "hash": "cf50a45f26bc42e41054c14df54c7691", "title": "Normalized Predictions for Average Precision"}, "2876": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py", "hash": "02429df6c99f35dcd61f8564dfbcb3f4", "title": "Paddlevideo Metrics Evaluation Utility"}, "2877": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:1-29", "hash": "6ba64c18b0159b6415daec92ef65f97c", "title": "Eval Util for Model Metrics"}, "2878": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:32-60", "hash": "a749d663a39c044a19963e816a717668", "title": "Video-level Annotation Precision"}, "2879": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:61-90", "hash": "88ee4e53916e83bf6ea5aa7d17167814", "title": "Video Average Precision Calculator"}, "2880": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:91-116", "hash": "42b217af7d7b320cadfe13731c1e73d7", "title": "Global Average Precision Calculation"}, "2881": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:117-137", "hash": "259858e9971ced1b918f07f44441dca6", "title": "Top-k Triplet Prediction Evaluation"}, "2882": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:138-167", "hash": "3484d024d6ab08d3b961e0280c0bb6c3", "title": "Top-K Prediction Evaluation Metrics"}, "2883": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:169-193", "hash": "5812363db00851131bddfb5e14a2d737", "title": "HitOneMetric: Evaluating Metrics in Video Prediction Task"}, "2884": {"path": "/paddlevideo/metrics/youtube8m/eval_util.py:194-205", "hash": "aa6284061eaa228dd7b47c8fcd3a5ae1", "title": "Calculating Gap in YouTube8m Evaluation"}, "2885": {"path": "/paddlevideo/metrics/youtube8m/mean_average_precision_calculator.py", "hash": "3a6b52474e0f8fc1b0ef29272e8d9fc1", "title": "Mean Average Precision Calculator"}, "2886": {"path": "/paddlevideo/metrics/youtube8m/mean_average_precision_calculator.py:1-27", "hash": "cc511a80842322b8b997ba14ce6fff30", "title": "Mean Average Precision Calculator"}, "2887": {"path": "/paddlevideo/metrics/youtube8m/mean_average_precision_calculator.py:28-59", "hash": "a6761286bf12f710723f2473bc33f1e6", "title": "Binary Classification Dataset Generation"}, "2888": {"path": "/paddlevideo/metrics/youtube8m/mean_average_precision_calculator.py:60-80", "hash": "70f1d4ba19f0ed433c69a2a07198faf3", "title": "Mean Average Precision Calculator for Video Classification"}, "2889": {"path": "/paddlevideo/metrics/youtube8m/mean_average_precision_calculator.py:81-112", "hash": "3a58d9388b273aa2da74b4c2aa9c1fcb", "title": "Mean Average Precision Calculator"}, "2890": {"path": "/paddlevideo/metrics/youtube8m/mean_average_precision_calculator.py:113-114", "hash": "a736d8805b15e5b715f26733c4294cdc", "title": "Mean Average Precision Calculator"}, "2891": {"path": "/paddlevideo/metrics/yowo_metric.py", "hash": "7c0e54f1c7d0481a9c7bff57bf53be76", "title": "YOWO Metric Integration in PaddleVideo"}, "2892": {"path": "/paddlevideo/metrics/yowo_metric.py:1-30", "hash": "d53bcb6c7ac6a890b3a6ff894dda3d2e", "title": "YOWOMetric: PaddleVideo Metrics"}, "2893": {"path": "/paddlevideo/metrics/yowo_metric.py:31-62", "hash": "1d53a2b1c96df648d435eda21733e10b", "title": "BMN Metrics Initialization and Update"}, "2894": {"path": "/paddlevideo/metrics/yowo_metric.py:63-82", "hash": "0f345694c671f8e25c72442650bb6718", "title": "YOLOv5 Box Metrics Accumulator"}, "2895": {"path": "/paddlevideo/modeling/__init__.py", "hash": "488966a787e392178e2b8543857b5772", "title": "Video Recognition Modeling in PaddleVideo"}, "2896": {"path": "/paddlevideo/modeling/__init__.py:1-22", "hash": "3d751e0507daeeefbf85a20d6bb13105", "title": "PaddleVideo Modeling Library"}, "2897": {"path": "/paddlevideo/modeling/__init__.py:23-37", "hash": "d90466a4e75e22f691d9df1d19e4ec38", "title": "Initializing PaddleVideo Models and Functions"}, "2898": {"path": "/paddlevideo/modeling/assigners/__init__.py", "hash": "b84c04f109097502374e3de072b6161f", "title": "Importing MaxIoUAssignerAVA in PaddleVideo"}, "2899": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py", "hash": "4bc679cc0efdb7df18b1405f90605397", "title": "MaxIOUAssignerAVA: Assigning Results Efficiently"}, "2900": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py:1-27", "hash": "1646824dbf7c1b4c3e2e7338b9a0610f", "title": "Max IoU Assigner AVA Class"}, "2901": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py:28-49", "hash": "7a8c5854ee2f3ea1352f9fc773ddb8f1", "title": "MaxIoUAssignerAVA Initialization"}, "2902": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py:50-75", "hash": "8b9bd9c31f2ef8a68068ba0c931470ee", "title": "Max IOU Assigner: Assigning GT Boxes"}, "2903": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py:76-93", "hash": "e8e26cce699dee0caf2d33f22aec707e", "title": "Max IoU Assigner"}, "2904": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py:94-109", "hash": "d1977482b366ef6a5ecdcf327375519a", "title": "Max IOU Assigner Algorithm"}, "2905": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py:110-126", "hash": "7bcf4f22ab1f730c928fbadc100a7ea7", "title": "Max IOU Assigner: AVA Dataset Handling"}, "2906": {"path": "/paddlevideo/modeling/assigners/max_iou_assigner_ava.py:127-148", "hash": "cbad570eaa675dcecea0e27a7f26a71b", "title": "Max IOU Assigner Implementation"}, "2907": {"path": "/paddlevideo/modeling/backbones/__init__.py", "hash": "e23df3fde12adb8739fd070328e85b88", "title": "Versatile Backbone Models in PaddleVideo"}, "2908": {"path": "/paddlevideo/modeling/backbones/__init__.py:1-27", "hash": "bc17074d4cf04323d788071bc1bcb773", "title": "Backbone Models Initialization in PaddleVideo"}, "2909": {"path": "/paddlevideo/modeling/backbones/__init__.py:28-55", "hash": "85d40b2dbb2e4e247d3f9fe343c3c437", "title": "PaddleVideo Backbone Models"}, "2910": {"path": "/paddlevideo/modeling/backbones/__init__.py:56-60", "hash": "fbeb11233a6ed72a3f2f192782528d2e", "title": "PaddleVideo Backbones List"}, "2911": {"path": "/paddlevideo/modeling/backbones/actbert.py", "hash": "6868ab9c78271cb980934dc163c8d96b", "title": "Multimodal BERT Embeddings for Video Action Recognition"}, "2912": {"path": "/paddlevideo/modeling/backbones/actbert.py:1-32", "hash": "0da4c8a154f652e9d5e532ad4de17370", "title": "PaddlePaddle BertEmbeddings Class"}, "2913": {"path": "/paddlevideo/modeling/backbones/actbert.py:33-52", "hash": "f6167c5a10c1bf90e5fa85ba4d3639a1", "title": "ActBERT Embeddings Initialization"}, "2914": {"path": "/paddlevideo/modeling/backbones/actbert.py:53-75", "hash": "8508f305bf5abc4ad9ca7bcb8fa63b62", "title": "ActBert: Video Action Recognition Backbone"}, "2915": {"path": "/paddlevideo/modeling/backbones/actbert.py:76-100", "hash": "27045e1f4524435a9f11a3f9aa9972f2", "title": "Bert Self-Attention and Embedding Layers"}, "2916": {"path": "/paddlevideo/modeling/backbones/actbert.py:101-123", "hash": "4d2230a96135f66e2b7930f9b58db21e", "title": "BertSelfAttention Class Definition"}, "2917": {"path": "/paddlevideo/modeling/backbones/actbert.py:124-144", "hash": "401783c08483e2c4a9d4272086706a40", "title": "Multi-Head Attention in ACT-BERT"}, "2918": {"path": "/paddlevideo/modeling/backbones/actbert.py:146-169", "hash": "516a7b040a7649397d45ba0ef830bce2", "title": "BertSelfOutput Layer Implementation"}, "2919": {"path": "/paddlevideo/modeling/backbones/actbert.py:170-192", "hash": "3e66128fc157f6162117135e8daf4dc6", "title": "ActBert: Transformer Backbone Model"}, "2920": {"path": "/paddlevideo/modeling/backbones/actbert.py:193-219", "hash": "4ce208b9f79524877d15c74678f43c1c", "title": "Attention-Based Transformer with Dropout"}, "2921": {"path": "/paddlevideo/modeling/backbones/actbert.py:220-246", "hash": "b963a7a280dcfe446ecb66cbdcdb9351", "title": "BertEntAttention: Vision Attention Class"}, "2922": {"path": "/paddlevideo/modeling/backbones/actbert.py:247-267", "hash": "0af87eb02d10fa64c49a32321bdb9448", "title": "Self-Attention Layers in ACTBERT"}, "2923": {"path": "/paddlevideo/modeling/backbones/actbert.py:268-299", "hash": "91f6cae682855dde6c490a7466cfc01d", "title": "Attention Mechanism for Vision and Text"}, "2924": {"path": "/paddlevideo/modeling/backbones/actbert.py:300-321", "hash": "5fdef2334285520932dbe311eea0a0a0", "title": "Multi-Head Attention Operation in ActBERT"}, "2925": {"path": "/paddlevideo/modeling/backbones/actbert.py:322-342", "hash": "247cd7c7fcc31e9ce2e58f0d95b0d0ef", "title": "Dropout-based Attention Scoring in ActBERT"}, "2926": {"path": "/paddlevideo/modeling/backbones/actbert.py:343-361", "hash": "206d2f979f233a9f40e205802350ac8e", "title": "Multi-scale Context Fusion in ActBERT"}, "2927": {"path": "/paddlevideo/modeling/backbones/actbert.py:363-381", "hash": "6c0d16d57d500a4f38fba2cf55cf2e2b", "title": "Cross-Attention in Transformers"}, "2928": {"path": "/paddlevideo/modeling/backbones/actbert.py:382-409", "hash": "0324b9057e289628cf0d5e526d22c64c", "title": "BertEntOutput: Layer Normalization and Dropout"}, "2929": {"path": "/paddlevideo/modeling/backbones/actbert.py:410-440", "hash": "004a5a04d4724ab3ae3d8b830c8904dc", "title": "Attention-Based Bert Layer with Dropout"}, "2930": {"path": "/paddlevideo/modeling/backbones/actbert.py:441-461", "hash": "3053dc4dab5104d84ab0c5ae1046d4e9", "title": "Bert Layer and Connection Layer Classes"}, "2931": {"path": "/paddlevideo/modeling/backbones/actbert.py:462-487", "hash": "b318be98785bb70dfb5057e2b4984306", "title": "BertConnectionLayer Initialization"}, "2932": {"path": "/paddlevideo/modeling/backbones/actbert.py:488-512", "hash": "f7f3c5b7b5336ece47d32829d80253a2", "title": "ActBERT Input Streams Model"}, "2933": {"path": "/paddlevideo/modeling/backbones/actbert.py:513-539", "hash": "5ccbd2d95009116baf564dd1bbeb7f11", "title": "Compute Layer Outputs for ActBert Pathways"}, "2934": {"path": "/paddlevideo/modeling/backbones/actbert.py:540-576", "hash": "d3768e90a4d154ad869199e50399627d", "title": "BertEncoder: Initializing BERT Encoder Parameters"}, "2935": {"path": "/paddlevideo/modeling/backbones/actbert.py:577-594", "hash": "a11d0cf26247deb0f77595da57609992", "title": "ACT Bert Layer Initialization"}, "2936": {"path": "/paddlevideo/modeling/backbones/actbert.py:595-622", "hash": "390c0f1859130aab834a47746c442a27", "title": "ActBERT: Multimodal Model for Text, Vision, and Action Embeddings"}, "2937": {"path": "/paddlevideo/modeling/backbones/actbert.py:623-645", "hash": "701ae7d374bb6f89d0f4de985df60610", "title": "Initializing Encoder Layers in ActBERT Model"}, "2938": {"path": "/paddlevideo/modeling/backbones/actbert.py:647-669", "hash": "db74773ac87ad2310a98f6f23a50fac7", "title": "Multi-Modal Embedding with Attention Probs"}, "2939": {"path": "/paddlevideo/modeling/backbones/actbert.py:670-693", "hash": "f9f0921d3cfed8612001abe2903146be", "title": "ActBERT Encoder Layers"}, "2940": {"path": "/paddlevideo/modeling/backbones/actbert.py:695-729", "hash": "656c4876d61ec18972c255e67cbd4a90", "title": "ActBert Pooler Class and Model Initialization"}, "2941": {"path": "/paddlevideo/modeling/backbones/actbert.py:730-759", "hash": "a92fa2016e3abb4677a08855e2ed49f2", "title": "Customized Bert Model Initialization"}, "2942": {"path": "/paddlevideo/modeling/backbones/actbert.py:760-775", "hash": "80f970dd467326a29798858e9456b668", "title": "ACTBERT: Multi-modal Action Model Initiation"}, "2943": {"path": "/paddlevideo/modeling/backbones/actbert.py:776-800", "hash": "c7a01c9ce07bc213c28f164d9dea49e5", "title": "ActBERT Model: Encoding Text, Action, and Visual Features"}, "2944": {"path": "/paddlevideo/modeling/backbones/actbert.py:801-819", "hash": "48a0849453a67cf70935f208da4c8bb1", "title": "Mask Generation for ActBERT"}, "2945": {"path": "/paddlevideo/modeling/backbones/actbert.py:820-838", "hash": "439d0e21ccbb3bd418d0bdc8b6db5fb6", "title": "ACTBERT Extended Mask Creation"}, "2946": {"path": "/paddlevideo/modeling/backbones/actbert.py:839-865", "hash": "18247f82a70c14144562dbbdce7981bc", "title": "Multimodal ACTBERT Backbone Encoding"}, "2947": {"path": "/paddlevideo/modeling/backbones/actbert.py:866-892", "hash": "27fbe39f4a3a2ec18a7f4b709a597825", "title": "BERT Prediction Heads: Transform and Classes"}, "2948": {"path": "/paddlevideo/modeling/backbones/actbert.py:893-909", "hash": "47296f887c6b1cbac796cd29f4158c94", "title": "BertLMPredictionHead Initialization"}, "2949": {"path": "/paddlevideo/modeling/backbones/actbert.py:910-937", "hash": "2ea52f96071119c4e8d951ce2902b092", "title": "Attention and Feedforward in BERT"}, "2950": {"path": "/paddlevideo/modeling/backbones/actbert.py:938-956", "hash": "bc24dba75be517628bdb518d768b6cbc", "title": "BertPreTrainingHeads Class Initialization"}, "2951": {"path": "/paddlevideo/modeling/backbones/actbert.py:957-986", "hash": "07d102fb8cefd77770875a692ed1792f", "title": "Multi-Modal ACT-BERT Model"}, "2952": {"path": "/paddlevideo/modeling/backbones/actbert.py:987-1018", "hash": "e9b36157b48b1254e5ca3c79f9be1d70", "title": "Custom ACT-BERT Backbone Model for Multi-Modality"}, "2953": {"path": "/paddlevideo/modeling/backbones/actbert.py:1019-1034", "hash": "18964dbc2212b0fdc2adf937cdff7c36", "title": "ActBERT Input Parameters"}, "2954": {"path": "/paddlevideo/modeling/backbones/actbert.py:1035-1047", "hash": "43bf1835e40fbc7da8cec0055dab8ca4", "title": "Fixed BertLayer Parameters"}, "2955": {"path": "/paddlevideo/modeling/backbones/actbert.py:1048-1058", "hash": "a398bb6137bd244772b6d176ae4081f3", "title": "Transformer Model Default Parameters"}, "2956": {"path": "/paddlevideo/modeling/backbones/actbert.py:1059-1092", "hash": "9e7c573ffb8192880e187a80133e7937", "title": "Initialize ActBert Model"}, "2957": {"path": "/paddlevideo/modeling/backbones/actbert.py:1093-1116", "hash": "2019b29f5a0deee118c2f6d4bb1756f9", "title": "ActBERT Model Initialization"}, "2958": {"path": "/paddlevideo/modeling/backbones/actbert.py:1117-1137", "hash": "57bfd678e702fffda36aa6990f4584b1", "title": "ActBERT Input Layout"}, "2959": {"path": "/paddlevideo/modeling/backbones/actbert.py:1138-1158", "hash": "b59dea233adfd2192b6ae64ee289456a", "title": "ActBERT Function: Multimodal Prediction and Sequence Relationship"}, "2960": {"path": "/paddlevideo/modeling/backbones/adds.py", "hash": "37a2febfef9dfc56aef7fed1e0f389b0", "title": "PaddleVideo: Enhanced Modeling Backbones"}, "2961": {"path": "/paddlevideo/modeling/backbones/adds.py:1-30", "hash": "54f52d8306dc94f279ebc0155ace07ff", "title": "PaddlePaddle Backbones Registration"}, "2962": {"path": "/paddlevideo/modeling/backbones/adds.py:31-67", "hash": "b357e332304dc55ee759c91465389a57", "title": "Depth Prediction and Feature Extraction Functions"}, "2963": {"path": "/paddlevideo/modeling/backbones/adds.py:68-104", "hash": "526bf54fda523ad880d1244864553bf1", "title": "Transpose Conv with BatchNorm and Activation"}, "2964": {"path": "/paddlevideo/modeling/backbones/adds.py:105-151", "hash": "e7c2c24414313e018c7f03863edb5e30", "title": "Transformation Matrix Conversion"}, "2965": {"path": "/paddlevideo/modeling/backbones/adds.py:152-188", "hash": "16e6e974d0a2c7d1095be58785cc71c7", "title": "Rotation Operations on 3D Vectors"}, "2966": {"path": "/paddlevideo/modeling/backbones/adds.py:189-231", "hash": "3848705d7a802a58281f561dbb3ff202", "title": "Efficient Disparity Smoothness Loss Calculation"}, "2967": {"path": "/paddlevideo/modeling/backbones/adds.py:232-264", "hash": "d84c81d9ed3beb2fa69a2c480eb42697", "title": "ResNet Model with Multi-Input Images"}, "2968": {"path": "/paddlevideo/modeling/backbones/adds.py:265-294", "hash": "4c0fb660db2a370353f8150ecde52963", "title": "ResNet Model Creation Code"}, "2969": {"path": "/paddlevideo/modeling/backbones/adds.py:295-330", "hash": "b846b747d774fc5af344446efe3a10ff", "title": "Conv3x3 and Depth Backprojection"}, "2970": {"path": "/paddlevideo/modeling/backbones/adds.py:331-355", "hash": "c5b7b42e5b080a9757333d894dd15525", "title": "PaddleVideo Backbone Parameter Initialization"}, "2971": {"path": "/paddlevideo/modeling/backbones/adds.py:357-385", "hash": "e3d8b4a9ae284c1ccbd02b502b309519", "title": "Camera Projection in Project3D"}, "2972": {"path": "/paddlevideo/modeling/backbones/adds.py:386-417", "hash": "3f4ff089649ce7d16b25d703da2ff8fb", "title": "SSIM Loss Calculator from Pixel Coords"}, "2973": {"path": "/paddlevideo/modeling/backbones/adds.py:419-441", "hash": "14ad50be90168c9ea956687206763d6a", "title": "Multi-Input ResNet Model in PaddleVideo"}, "2974": {"path": "/paddlevideo/modeling/backbones/adds.py:442-466", "hash": "90b3e0f0db8302b93f9018180ae84014", "title": "ConvBN Layer Initialization"}, "2975": {"path": "/paddlevideo/modeling/backbones/adds.py:467-497", "hash": "4215d3cf191d5ae6fd104325ef74e7bf", "title": "ConvBN Layer Custom Class"}, "2976": {"path": "/paddlevideo/modeling/backbones/adds.py:498-528", "hash": "0d015a98a046d9468166df78f855c2c4", "title": "BasicBlock Class Definition"}, "2977": {"path": "/paddlevideo/modeling/backbones/adds.py:529-563", "hash": "13d18aa58b8278058673b03a96e55df5", "title": "ResNet V1.5 Bottleneck Layer Definition"}, "2978": {"path": "/paddlevideo/modeling/backbones/adds.py:564-597", "hash": "2a7d8491eadeb6c228fbe664a2dfb573", "title": "Bottleneck Convolutional Neural Network"}, "2979": {"path": "/paddlevideo/modeling/backbones/adds.py:599-631", "hash": "9bfbf5a82349c05eed460e19c6199e0d", "title": "DepthDecoder Class Definition"}, "2980": {"path": "/paddlevideo/modeling/backbones/adds.py:633-660", "hash": "0dc206bc2d110e3db4d85ae442a7e8d5", "title": "Decoder Convolutional Network Architecture"}, "2981": {"path": "/paddlevideo/modeling/backbones/adds.py:661-686", "hash": "283d92a398c0011e4a5b06b35bc19e37", "title": "Convolutional PoseDecoder Layer"}, "2982": {"path": "/paddlevideo/modeling/backbones/adds.py:688-725", "hash": "41a1063a56b8338f371f2f271c6b2425", "title": "ResNet Encoder with Adds Convolution"}, "2983": {"path": "/paddlevideo/modeling/backbones/adds.py:726-753", "hash": "cb5a462ed2e64f2411990b385e8167d6", "title": "ResNet Backbone Creation and Checks"}, "2984": {"path": "/paddlevideo/modeling/backbones/adds.py:754-776", "hash": "108895d00bd1965a66d9e53b609cf538", "title": "Shared Encoders and Decoder Backbone"}, "2985": {"path": "/paddlevideo/modeling/backbones/adds.py:777-797", "hash": "2057e3d08c1250dab9380506d18342a9", "title": "Convolutional Layers with Batch Normalization"}, "2986": {"path": "/paddlevideo/modeling/backbones/adds.py:798-817", "hash": "2ecb5a4722d9091c9f7b90d4c9b9efc9", "title": "Normalizing Image Input for Day Encoder"}, "2987": {"path": "/paddlevideo/modeling/backbones/adds.py:818-834", "hash": "a0147e1413c1e959697b860cfb7b063b", "title": "Day-Night Encoder Convolutions"}, "2988": {"path": "/paddlevideo/modeling/backbones/adds.py:835-861", "hash": "608cd0efb87b9bf7bdd38590e49793fd", "title": "Day-Night Model Features Extraction"}, "2989": {"path": "/paddlevideo/modeling/backbones/adds.py:862-889", "hash": "8edd777de943b977a71f51c2ff386250", "title": "Resnet Encoder Pypaddle Module"}, "2990": {"path": "/paddlevideo/modeling/backbones/adds.py:890-917", "hash": "571fa446968b68e091d4710d7826f6cc", "title": "ResNet Backbone Model with Multi-Image Inputs"}, "2991": {"path": "/paddlevideo/modeling/backbones/adds.py:918-949", "hash": "d0afb98cf1c72399756689f8d8da8c1e", "title": "ADDS Depth Estimation Network"}, "2992": {"path": "/paddlevideo/modeling/backbones/adds.py:950-972", "hash": "60a3e6b19ecb697223cea50b1a11d921", "title": "Model Initialization and Configuration"}, "2993": {"path": "/paddlevideo/modeling/backbones/adds.py:973-996", "hash": "382ab51041003217b59077d7b6abe267", "title": "Backbone Model for Pose Estimation Init"}, "2994": {"path": "/paddlevideo/modeling/backbones/adds.py:997-1019", "hash": "cc428eede3aa05f67c70bda302a7f1ce", "title": "Day-Night Backbone Model with Depth Feature Extraction"}, "2995": {"path": "/paddlevideo/modeling/backbones/adds.py:1020-1044", "hash": "7ee599a07d25d64b80e37b016de6a651", "title": "Handling Dict and Non-Dict Model Inputs"}, "2996": {"path": "/paddlevideo/modeling/backbones/adds.py:1046-1074", "hash": "ad49c8f9b8fcae7b7ce13c8d00be5c5d", "title": "Night/Day Pose Prediction Function"}, "2997": {"path": "/paddlevideo/modeling/backbones/adds.py:1075-1096", "hash": "7da278c6f7a74770b661892d63f94769", "title": "Calculates Camera Transformation Parameters"}, "2998": {"path": "/paddlevideo/modeling/backbones/adds.py:1097-1122", "hash": "c096162ac31211fcf153efcd4476044e", "title": "Depth Estimation with Displacement Interpolation"}, "2999": {"path": "/paddlevideo/modeling/backbones/adds.py:1123-1142", "hash": "caae6da4b2669a9a4ab0148a09e6ceb2", "title": "Grid Sampling and Masking for Night Scenes"}, "3000": {"path": "/paddlevideo/modeling/backbones/adds.py:1143-1146", "hash": "143d48df8a8fd2827a78374e748c6f43", "title": "Selecting Input Data from Dictionary"}, "3001": {"path": "/paddlevideo/modeling/backbones/agcn.py", "hash": "0b54af11c1f610dc2760f1d3b1fe6a8a", "title": "Adaptive Graph Convolutional Networks (AGCN) Backbone"}, "3002": {"path": "/paddlevideo/modeling/backbones/agcn.py:1-27", "hash": "557de042d709c02e868cdda422bced99", "title": "PaddlePaddle GCN Class Definition"}, "3003": {"path": "/paddlevideo/modeling/backbones/agcn.py:28-57", "hash": "6176ffe51f2db643bc2eac4ab0637a48", "title": "3D Spatio-Temporal Convolutional Block"}, "3004": {"path": "/paddlevideo/modeling/backbones/agcn.py:58-84", "hash": "c961c4ef76bdc214f7a008fb73ce66d0", "title": "GCN-TCN Residual Block Init."}, "3005": {"path": "/paddlevideo/modeling/backbones/agcn.py:87-110", "hash": "e0bc0e63fdce09ea465f61f8c9bfaa98", "title": "Adaptive Graph Convolutional Network (AGCN) Improvement"}, "3006": {"path": "/paddlevideo/modeling/backbones/agcn.py:111-128", "hash": "52d780627df6f634c342b78521a65529", "title": "AGCN Backbone: Custom Normalization and Pooling"}, "3007": {"path": "/paddlevideo/modeling/backbones/agcn2s.py", "hash": "f98dd76b978a59f05a7c78dd066c3974", "title": "AGCN2S Graph Convolutions in PaddlePaddle"}, "3008": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:1-32", "hash": "84d9835404acf4a0813b5b73694f17c5", "title": "Temporal Convolutional Network Layer in PaddlePaddle"}, "3009": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:33-65", "hash": "d384cb3dcf8c610e4c36e580832795ba", "title": "AGCN Unit: Learning Spatio-Temporal Features"}, "3010": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:66-91", "hash": "6cdd6e828bd983a8a8ad49bb157b6fa7", "title": "AGCN2S Neural Network Backbone Definition"}, "3011": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:92-121", "hash": "fedfd07ca74a92cf3a7a34859b7e95a7", "title": "AGCN-TS: Temporal Series Modeling with GCN and TCN"}, "3012": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:122-144", "hash": "7eaa96b064b7d5e7afc887037150b7c1", "title": "Graph Class for NTURGB+D Dataset"}, "3013": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:146-176", "hash": "4b4f0681a029ce9f324dcedf49dd07c2", "title": "Adjacency Matrix Conversion Functions"}, "3014": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:177-212", "hash": "a7cc97c44a2ec264e23a89785ced10f4", "title": "Graph Convolutional Neural Network Layer (GCNN)"}, "3015": {"path": "/paddlevideo/modeling/backbones/agcn2s.py:213-229", "hash": "0376efd3716dbc9bc090cef16517bd73", "title": "AGCN2S Transformation Layers"}, "3016": {"path": "/paddlevideo/modeling/backbones/asrf.py", "hash": "a6ac6d4ea530091babd6e7926db93a66", "title": "ASRF: PaddleVideo Backbone Initiation"}, "3017": {"path": "/paddlevideo/modeling/backbones/asrf.py:1-30", "hash": "10a23849463d44042eef2cfccebc29e5", "title": "Asrf Backbone Model Registration"}, "3018": {"path": "/paddlevideo/modeling/backbones/asrf.py:33-65", "hash": "f3b40ded48a39e51144827bfafaffbd4", "title": "ASRF: Customizable Convolutional Backbone for CV"}, "3019": {"path": "/paddlevideo/modeling/backbones/asrf.py:66-75", "hash": "df236668f0758c13b7c79742c1aa8c5e", "title": "ASRF Backbone Initialization and Forward Method"}, "3020": {"path": "/paddlevideo/modeling/backbones/bmn.py", "hash": "a4fcecf0864fa2a7522c54e021154e06", "title": "BMN Backbone for Paddle Video"}, "3021": {"path": "/paddlevideo/modeling/backbones/bmn.py:1-28", "hash": "b7604968084b7bf64eb305e7706ca415", "title": "Boundary-Matching Pair Mask Generator"}, "3022": {"path": "/paddlevideo/modeling/backbones/bmn.py:29-53", "hash": "7042f3bf6cd9dcf606e7c7e3bbbb695f", "title": "Generating Sample Masks for Boundary-Matching Maps"}, "3023": {"path": "/paddlevideo/modeling/backbones/bmn.py:54-77", "hash": "e60959713a58d0492f61f75fc70cfcb4", "title": "Video Frame Mask Generation Code"}, "3024": {"path": "/paddlevideo/modeling/backbones/bmn.py:78-103", "hash": "9b2426cd9be2608d066aa6d3b2555f50", "title": "BMN Layer for Temporal Action Proposal Generation"}, "3025": {"path": "/paddlevideo/modeling/backbones/bmn.py:104-137", "hash": "9c5f27497475b308bf24b2241e179a61", "title": "BMN: Backbone Model with ConvLayers"}, "3026": {"path": "/paddlevideo/modeling/backbones/bmn.py:138-163", "hash": "440629d4c8292ef85882bdbae17ed896", "title": "Conv1D Block for BMN Model"}, "3027": {"path": "/paddlevideo/modeling/backbones/bmn.py:164-189", "hash": "3d4933abd2c3a98ae244ca8f21e782f8", "title": "Initializing TEM and PEM Modules in Backbone Network"}, "3028": {"path": "/paddlevideo/modeling/backbones/bmn.py:190-215", "hash": "78ec95979958789f1b0282aab49b912a", "title": "BMN Backbone Model Initialization"}, "3029": {"path": "/paddlevideo/modeling/backbones/bmn.py:216-246", "hash": "f9818fcc7daf9d04ef24086b8cf22014", "title": "2D Conv Layers for BMSN Backbone"}, "3030": {"path": "/paddlevideo/modeling/backbones/bmn.py:247-283", "hash": "a89c4846306b97df44d5ebef96d5a908", "title": "Video Analysis Backbone Model: BMN"}, "3031": {"path": "/paddlevideo/modeling/backbones/bmn.py:284-290", "hash": "7adeb2f0caaf01b50f8f9da2e33a8811", "title": "Convolutional Neural Network Backbone"}, "3032": {"path": "/paddlevideo/modeling/backbones/cfbi.py", "hash": "84c90cd16331c8b71ceed8e73577c267", "title": "CFBI Model: FPN-DeepLab Backbone"}, "3033": {"path": "/paddlevideo/modeling/backbones/cfbi.py:1-28", "hash": "4a21cd57b7e93c73a12eb0dbda8bcc62", "title": "FPN Layer Definition"}, "3034": {"path": "/paddlevideo/modeling/backbones/cfbi.py:29-54", "hash": "aaaef5ff7967d1a7b51d9d1b4a8bafaa", "title": "CFBI Backbone Model Architecture"}, "3035": {"path": "/paddlevideo/modeling/backbones/cfbi.py:56-84", "hash": "8ba487a6e65fd33a91235454e5a03109", "title": "CFBI: DeepLab-FPN Backbone Model"}, "3036": {"path": "/paddlevideo/modeling/backbones/cfbi.py:85-88", "hash": "7a2820fdc97c10a36f54efddf7f98586", "title": "CFBI: Multi-scale Feature Extraction"}, "3037": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py", "hash": "b68c1109349ce09a20a84bb36db023e9", "title": "Introducing CTRGCN Backbone for Video Models"}, "3038": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:1-31", "hash": "a8421e8c3b26ab466801827268cc9434", "title": "CtrGCN Backbone Setup"}, "3039": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:32-66", "hash": "d45bc2277c55afbbe9a4be1d46c1e01e", "title": "Defining CTRGC: Convolutional Layer"}, "3040": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:67-93", "hash": "b174ec5fde322ed7d6b0f37095eba9a5", "title": "Convolutional Temporal RGPN Backbone"}, "3041": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:94-127", "hash": "4ae33295f2dd4f2311a30ea6c8e5d4a2", "title": "Temporal Convolution Backbone"}, "3042": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:128-155", "hash": "846834dad40ef9ab2c0d4b828ad3a7e6", "title": "MultiScale Temporal Conv Layer"}, "3043": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:156-182", "hash": "1cd25c9c14ee85cbae8548b0ba24cc8d", "title": "Conv-Temporal RGN Backbone: Video Analysis Model"}, "3044": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:183-211", "hash": "7c5d41cc7ee843633abb88f0c0c16495", "title": "Conv-Temporal Residual Group Convolutional Network Backbone"}, "3045": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:212-250", "hash": "c76eae6db565ab8e0199ebb4b32ce210", "title": "Temporal and Graph Convolutional Network Units"}, "3046": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:251-276", "hash": "7276eaa21d2ae732017b7c0dd7893ff7", "title": "CTRGC Model Initialization"}, "3047": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:277-306", "hash": "a9d6c6429842af5ea03692abde04b9c8", "title": "Adaptive CTR GCN Initialization"}, "3048": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:307-335", "hash": "928b69c27f0be9ddf63ea0097393440e", "title": "TCN-GCN Unit Definition"}, "3049": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:336-363", "hash": "feb494348367103baf0ad536625382a1", "title": "CTRGCN: Residual Graph Convolutional Network"}, "3050": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:364-397", "hash": "af76f6b7f946fa8619ba3cf805c037d5", "title": "Generating Adjacency Matrices for CTRGCN"}, "3051": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:398-426", "hash": "e5a21f04ca69da7da88a2999235678d1", "title": "CTRGCN: Skeleton Action Model"}, "3052": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:427-455", "hash": "618d77923142bca0b283412dfaa1b24f", "title": "CTRGCN: TCN-GCN Model Initialization"}, "3053": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:456-477", "hash": "c3bec9e7555de459dc04bd322b0f06c1", "title": "Deep TCN-GCN Architecture for CTRGCN Model"}, "3054": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:478-511", "hash": "28c7091e7c30fe9c87c9f73007a76fb3", "title": "TCN-GCN Neural Network Model"}, "3055": {"path": "/paddlevideo/modeling/backbones/ctrgcn.py:512-514", "hash": "f7179ec1a463768b18f189f553df4e66", "title": "Final Neural Network Layer 10 Application"}, "3056": {"path": "/paddlevideo/modeling/backbones/darknet.py", "hash": "306a8cd8fc576d602d1837e2810029e2", "title": "Darknet Backbone with ConvBNLayer"}, "3057": {"path": "/paddlevideo/modeling/backbones/darknet.py:1-32", "hash": "2996a471779b51ac4472914ac90a90f4", "title": "Darknet ConvBN Layer Definition"}, "3058": {"path": "/paddlevideo/modeling/backbones/darknet.py:33-61", "hash": "9ae3475fa49503d39dfc32304d2dd356", "title": "Darknet Convolutional Block with BN and Leaky ReLU"}, "3059": {"path": "/paddlevideo/modeling/backbones/darknet.py:62-92", "hash": "9a2721de8e247fccea94289cb3d0d490", "title": "Darknet Backbone with ConvBNLayer and MaxPooling"}, "3060": {"path": "/paddlevideo/modeling/backbones/darknet.py:93-115", "hash": "f7955b6f2e7fbccb98b95416544d457f", "title": "Darknet Layer Transpose Dimensions"}, "3061": {"path": "/paddlevideo/modeling/backbones/darknet.py:116-129", "hash": "0f07b10fa1cb3b02656a22711d5d4864", "title": "Darknet Backbone: ConvBNLayer Sequence"}, "3062": {"path": "/paddlevideo/modeling/backbones/darknet.py:130-150", "hash": "b5126b14fa295c902c32c19570c55b88", "title": "Darknet Neural Network Backbone Design"}, "3063": {"path": "/paddlevideo/modeling/backbones/darknet.py:151-165", "hash": "5cbcab83c0edb6cb905e5d693f397fab", "title": "Darknet Convolutional Branching"}, "3064": {"path": "/paddlevideo/modeling/backbones/deeplab.py", "hash": "93dbc83efd62dc5f1c026d8d500d49f9", "title": "DeepLab Network Construction"}, "3065": {"path": "/paddlevideo/modeling/backbones/deeplab.py:1-33", "hash": "3b645ceb7e148d1455afd9c795488f68", "title": "Fixed Batch Normalization Layer"}, "3066": {"path": "/paddlevideo/modeling/backbones/deeplab.py:34-59", "hash": "ba3187ee65a81a2b0ad90a06d0614552", "title": "DeepLab Bottleneck Layer Initialization"}, "3067": {"path": "/paddlevideo/modeling/backbones/deeplab.py:60-86", "hash": "2c0909b89d0b76fb0414eaa00931ead1", "title": "Bottleneck Conv Neuron Layer for DeepLab"}, "3068": {"path": "/paddlevideo/modeling/backbones/deeplab.py:87-130", "hash": "f5769a2ab73a8014995e860ce2e45a16", "title": "ResNet: Residual Blocks with Conv and BatchNorm"}, "3069": {"path": "/paddlevideo/modeling/backbones/deeplab.py:131-152", "hash": "911951e1e520bbf4384eeadebe11807b", "title": "DeepLab Model Creation with Conv Layers and BatchNorm"}, "3070": {"path": "/paddlevideo/modeling/backbones/deeplab.py:153-176", "hash": "1bea05aa65ab2cf8e502fac6b8751c49", "title": "DeepLab Backbone Classification Layer Design"}, "3071": {"path": "/paddlevideo/modeling/backbones/deeplab.py:177-207", "hash": "3058ac7b63898556c86be5c9a0bb1372", "title": "DeepLab Module Creation Function"}, "3072": {"path": "/paddlevideo/modeling/backbones/deeplab.py:208-240", "hash": "64ac081dc8580ed0bf07debf1966b647", "title": "DeepLab ConvNet Function"}, "3073": {"path": "/paddlevideo/modeling/backbones/deeplab.py:241-269", "hash": "ec86c2916e5caa90de47dd0ed8156937", "title": "DeepLab ASPP Model Extraction"}, "3074": {"path": "/paddlevideo/modeling/backbones/deeplab.py:270-307", "hash": "21a6ef848333d30346313e7b99365acc", "title": "DeepLab ASPP Module Initialization"}, "3075": {"path": "/paddlevideo/modeling/backbones/deeplab.py:308-330", "hash": "0a432fbbabd38ec6882aaaf0389c57c6", "title": "Dynamic ASPP Modules in DeepLab Backbone"}, "3076": {"path": "/paddlevideo/modeling/backbones/deeplab.py:332-363", "hash": "7da09401b65b148753681e6127abd6c4", "title": "DeepLab Backbone for Image Segmentation"}, "3077": {"path": "/paddlevideo/modeling/backbones/deeplab.py:364-395", "hash": "f50ebd3329a0beaf9a4d6d1a569ec4cd", "title": "DeepLab Decoder Class"}, "3078": {"path": "/paddlevideo/modeling/backbones/deeplab.py:396-426", "hash": "af3ee85468de0d0d6b8818ed00192b2d", "title": "DeepLab Model for Segmentation"}, "3079": {"path": "/paddlevideo/modeling/backbones/deeplab.py:427-454", "hash": "24e128e0bdd5344ef13ac5dcb2731d71", "title": "DeepLab Model Implementation"}, "3080": {"path": "/paddlevideo/modeling/backbones/movinet.py", "hash": "a302bfecfee2f2ecd3e604c080380d0d", "title": "MoViNet: Mobile Video Analysis Model"}, "3081": {"path": "/paddlevideo/modeling/backbones/movinet.py:1-27", "hash": "8b9cbe75f2d2e65a613bcb77e13335ad", "title": "MOViNet Configuration"}, "3082": {"path": "/paddlevideo/modeling/backbones/movinet.py:28-55", "hash": "dd33540272c41527352f7bf57762e06e", "title": "MobileNetV2 Architecture Defined"}, "3083": {"path": "/paddlevideo/modeling/backbones/movinet.py:56-94", "hash": "39705352fffe0a3b19a938abbfcab294", "title": "Conv2dBNActivation Layer for MoviNet"}, "3084": {"path": "/paddlevideo/modeling/backbones/movinet.py:95-121", "hash": "e7cc68013aca91f573e26c8c6bc59213", "title": "Convolutional Neural Network Layers with Batch Normalization"}, "3085": {"path": "/paddlevideo/modeling/backbones/movinet.py:122-147", "hash": "f4b0621c7111350fdbe82bc6f5ed6d90", "title": "Conv3D Layer Creation"}, "3086": {"path": "/paddlevideo/modeling/backbones/movinet.py:148-177", "hash": "a92cd17d060b0b723d3eb58f53af0ebd", "title": "ConvBlock3D: Causal Convolutional Module"}, "3087": {"path": "/paddlevideo/modeling/backbones/movinet.py:178-196", "hash": "408112b914bf28884f91a5467d3ec22e", "title": "Conv Type Check and Initialization"}, "3088": {"path": "/paddlevideo/modeling/backbones/movinet.py:197-216", "hash": "bbb4975ea6a56064dc9ede43575d3b10", "title": "Defining Conv Layers in Movinet Backbone"}, "3089": {"path": "/paddlevideo/modeling/backbones/movinet.py:217-238", "hash": "fb354d010d2a3138ff4591bf46d8aca6", "title": "Convolutional Video Backbone"}, "3090": {"path": "/paddlevideo/modeling/backbones/movinet.py:239-269", "hash": "58ec4e14fe27bcf5624398b2fa5f1f34", "title": "Temporal Causal Average Pooling 3D"}, "3091": {"path": "/paddlevideo/modeling/backbones/movinet.py:270-296", "hash": "fca960d149ec066fa3935c31891cae19", "title": "CausalModule: Cumulative Sum and Activation Control"}, "3092": {"path": "/paddlevideo/modeling/backbones/movinet.py:297-322", "hash": "316d42da22ac811dc22f5cf7d291725a", "title": "SqueezeExcitation Layer Class"}, "3093": {"path": "/paddlevideo/modeling/backbones/movinet.py:323-347", "hash": "988591b8f3b8c54e9240804dd398e5a5", "title": "Scale-Aware Spatial Pyramid Pooling"}, "3094": {"path": "/paddlevideo/modeling/backbones/movinet.py:350-382", "hash": "68faea4af3cdc76d8f6d6313a5cb770c", "title": "BasicBneck Neural Network Layer"}, "3095": {"path": "/paddlevideo/modeling/backbones/movinet.py:383-404", "hash": "97181d9978a3b91eb56a442a7486658c", "title": "3D ConvBlock for MoviNet Backbone"}, "3096": {"path": "/paddlevideo/modeling/backbones/movinet.py:405-427", "hash": "6114d1b97d9584ebc415a187d8928232", "title": "ConvBlock3D Creation: Stride, Channels and Causal Convolution"}, "3097": {"path": "/paddlevideo/modeling/backbones/movinet.py:428-464", "hash": "c45048016d029d5ada75c7fe639418e6", "title": "MoViNet: Video Backbone Model"}, "3098": {"path": "/paddlevideo/modeling/backbones/movinet.py:465-487", "hash": "7d796eb9a9e404d934bd32ce08f80588", "title": "MOViNet Model Definition"}, "3099": {"path": "/paddlevideo/modeling/backbones/movinet.py:488-510", "hash": "2c20e56cc6cf1802f3372a61d13fb423", "title": "MOViNet Customizable Model Creation"}, "3100": {"path": "/paddlevideo/modeling/backbones/movinet.py:511-539", "hash": "37197c7571972487a8d871063d9e7743", "title": "MoviNet 3D CNN Backbone"}, "3101": {"path": "/paddlevideo/modeling/backbones/movinet.py:541-572", "hash": "17d78086e0c95c271ea233ae202a775d", "title": "MoviNet Backbone Class"}, "3102": {"path": "/paddlevideo/modeling/backbones/movinet.py:573-574", "hash": "92b55d206590d1a1b81e94b3f61ae34f", "title": "Movinet 3D Causal Instance Generation"}, "3103": {"path": "/paddlevideo/modeling/backbones/ms_tcn.py", "hash": "2be430f8aab90780090ae870946e9d0a", "title": "Kaiming Uniform Initialization for MSTCN Backbone"}, "3104": {"path": "/paddlevideo/modeling/backbones/ms_tcn.py:1-32", "hash": "8e48f220f89e292b615af45b9e36aca2", "title": "MS TCN Initialization"}, "3105": {"path": "/paddlevideo/modeling/backbones/ms_tcn.py:34-68", "hash": "94b1cbe68270fbc75b2039edcecba130", "title": "Kaiming Uniform Initialization in MS-TCN"}, "3106": {"path": "/paddlevideo/modeling/backbones/ms_tcn.py:69-100", "hash": "9a7b4686b501d693a919410af1544b7b", "title": "SingleStage MS-TCN Model"}, "3107": {"path": "/paddlevideo/modeling/backbones/ms_tcn.py:101-132", "hash": "065eb70e24c8f0ead3e32b3d6190b1dc", "title": "Dilated Residual Layers in MSTCN Backbone"}, "3108": {"path": "/paddlevideo/modeling/backbones/ms_tcn.py:133-154", "hash": "25c9ba4d1825a7f638812b505c74f725", "title": "MS TCN Model Initialization"}, "3109": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py", "hash": "b619a08a8910a5bbe2b51642fc1785fb", "title": "MobileNetV2 Backbones for PaddlePaddle"}, "3110": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:1-30", "hash": "a6184ad59b1da63a24dc29b2b890d950", "title": "MobileNetV2 Backbone Code"}, "3111": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:32-58", "hash": "97b8470cf5c3812187a4ca9403bc941c", "title": "PaddlePaddle MobileNetV2: ConvBNLayer"}, "3112": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:59-85", "hash": "8c6079e3e79f7db1e18cd497ff7febfb", "title": "Inverted Residual Unit Class"}, "3113": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:86-103", "hash": "553eb9d8ee736c1aae931e1a958adbe5", "title": "Initializing and Defining Convolutional Layers in PPTSM-MV2 Backbone"}, "3114": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:105-132", "hash": "5b11cc0138b8b967ef6927f40b6eb9f4", "title": "Inverted Residual Blocks for PPTSM MV2"}, "3115": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:133-151", "hash": "4f12277b699b50b83cca69a54ed173fe", "title": "PPTSM_MV2 Residual Units Creation"}, "3116": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:152-187", "hash": "3f5c25af2b26fc415185310dd4bc64e7", "title": "PPTSM-MV2 and MobileNet Model"}, "3117": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:188-207", "hash": "e71f6b5556366690400370aa469e62f1", "title": "PPTSM-MV2 Backbone Initialization"}, "3118": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:208-232", "hash": "f16f33d73f184689874f7e02251865b7", "title": "PPTSM-MV2 Backbone Implementation"}, "3119": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:233-266", "hash": "a189744ec4b3c7388c6ae1be48a10ae5", "title": "PPTSM MobileNetV2 Model Initialization"}, "3120": {"path": "/paddlevideo/modeling/backbones/pptsm_mv2.py:267-282", "hash": "47da330f2155df56e2971632a9b49b7e", "title": "Scaled MobileNet Functions in PaddleVideo"}, "3121": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py", "hash": "c6e5fad6c599ff54486a4f4cac6730a1", "title": "PPTSM-Mv3 Backbone in PaddleVideo"}, "3122": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:1-28", "hash": "55a66790711897340dd9dff546463169", "title": "PaddleVideo: PPTSM-MV3 Backbone"}, "3123": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:30-52", "hash": "df20a3a621c4fd8718fb090311f23e86", "title": "MobileNetV3 Backbones: Stages and URLs"}, "3124": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:53-79", "hash": "71581279dd38439337dbcb5867e0c83e", "title": "PPTSM-Mv3 Backbone Versions"}, "3125": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:80-118", "hash": "bd48aa71ad51a0c6621a745ce16a72ca", "title": "MobileNetV3: Custom PyTorch Layer Definition"}, "3126": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:119-142", "hash": "fc0869b151975b92f71f0a94e43ba282", "title": "Configurable MobileNetV3 Model Function"}, "3127": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:143-168", "hash": "1f27175ece3fc1e9f764fb4e87146cf9", "title": "PPTSM-MV3 Backbone Architecture"}, "3128": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:169-194", "hash": "dc2606dfed9c34b02b203586208f82f2", "title": "PPTSM-MV3 Model Architecture"}, "3129": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:195-222", "hash": "398d930db9eb10f3a94085760215d965", "title": "PPTSM_MV3 Neural Network Model"}, "3130": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:223-258", "hash": "fb15e58f1a346619cd987d2fadf6df8a", "title": "ConvBNLayer: Video Classification Backbone"}, "3131": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:259-292", "hash": "5af576bda3bef2e1b3f79c1ac5354e06", "title": "ResidualUnit: Expand Conv Layer"}, "3132": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:293-312", "hash": "aa72f0cafbdf6e22a47bf2d2472bf55c", "title": "PPTSM_MV3 Block Design"}, "3133": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:314-348", "hash": "b7fa75f34540333339ed3ddafa28281c", "title": "PPTSM-MV3 Backbone: Temporal Shifting and SE Module"}, "3134": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:349-376", "hash": "6aa1d879936095c0ca510f6ee69d9c8c", "title": "Convolutional Neural Network Layer for PPTSM-MobileNetV3_small_x1_0"}, "3135": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:377-405", "hash": "08e8419605406c05cfd46380c1053fd2", "title": "Create MobileNetV3 Models via PaddlePaddle"}, "3136": {"path": "/paddlevideo/modeling/backbones/pptsm_mv3.py:406-408", "hash": "3b5f01d2aafab4c70f964b97ad7af48e", "title": "PPTSM-MV3 Backbone Instance Creation"}, "3137": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py", "hash": "b3cecb1c76ffe9b7b7320a2c84959f49", "title": "PPTSMv2 Video Backbone Python Module"}, "3138": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:1-27", "hash": "3e1b67e30314798bf7f101c986890306", "title": "PaddlePaddle Neural Network Backbone Module"}, "3139": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:29-64", "hash": "6b904833b4d4eebdad99c4c2a2a32ddb", "title": "PPLCNetV2 Backbone for Video Processing"}, "3140": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:65-96", "hash": "38cce59157e9164479cb0b4ec1f72f03", "title": "PPTSMV2: ConvBN Encoder with Attention"}, "3141": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:97-127", "hash": "fec8f26c22eccd90e5819abbc3c890a3", "title": "P3-SE Module: Conv2D, BatchNorm2D, ReLU, SEModule"}, "3142": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:128-161", "hash": "be91ce732a74dbf5daf28182da378b1c", "title": "Depthwise Separable Conv Layer Initialization"}, "3143": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:162-185", "hash": "d76e6b3cf8ec64bd2b43d7097a4c938e", "title": "PPTSM Backbone Model Initialization"}, "3144": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:186-209", "hash": "9cdff6b625075b1daf1475281e5a0633", "title": "Downsample Convolution Layer with SE Module"}, "3145": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:210-238", "hash": "c27b1c5dd0443acb2b514840cb509c04", "title": "PPTSM_v2 Backbone: Convolutional Deep Learning Model"}, "3146": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:239-269", "hash": "d3eefdeafa8cbd7683879e31b4cfd31d", "title": "PPTSM_V2 Backbone Implementation"}, "3147": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:270-303", "hash": "6390adc8b9e7b90b374066e5632abac5", "title": "PPTSM_v2_LCNet: A Backbone Neural Network"}, "3148": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:304-324", "hash": "fc79f52e1b50e9806f7043381ced1478", "title": "PPTSM-v2 Backbone Model: DepthwiseSeparable Stages"}, "3149": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:325-347", "hash": "93d29ef72beae8a88dbc1c96f9ff8709", "title": "PPTSM_V2 Backbone: PaddleVideo Model"}, "3150": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:348-372", "hash": "c723b7d83de5874e98ba9f7842570683", "title": "PPTSM_v2 Backbone: Weights and Efficiency"}, "3151": {"path": "/paddlevideo/modeling/backbones/pptsm_v2.py:373-405", "hash": "45207241f8894efdbeff4e55cee03c36", "title": "PPTSM_v2 Backbone: Video Analysis Model"}, "3152": {"path": "/paddlevideo/modeling/backbones/resnet.py", "hash": "2f26a0393ce97a8f274b46e0f7450d31", "title": "Dynamic ResNet Backbone Model"}, "3153": {"path": "/paddlevideo/modeling/backbones/resnet.py:1-34", "hash": "b572888cc977d360f81f2cc2eb573820", "title": "ConvBN Layer Class in ResNet"}, "3154": {"path": "/paddlevideo/modeling/backbones/resnet.py:35-58", "hash": "9c21811cdc30489005645fd30de15638", "title": "ConvBNLayer Custom Layer"}, "3155": {"path": "/paddlevideo/modeling/backbones/resnet.py:59-89", "hash": "3e16305b2805b104f8c77b7881f555c2", "title": "ResNet Module with BN and Activation"}, "3156": {"path": "/paddlevideo/modeling/backbones/resnet.py:90-111", "hash": "41354287fcb88509e9afad16350c67a6", "title": "ResNet Backbone: ConvBNLayer Creation"}, "3157": {"path": "/paddlevideo/modeling/backbones/resnet.py:112-143", "hash": "1eac3842e1f9895ffa70330bdda2f4d1", "title": "ResNet Block Creation in PyTorch"}, "3158": {"path": "/paddlevideo/modeling/backbones/resnet.py:144-178", "hash": "c9b218dcdf40e47d47f60eab827c5f84", "title": "ResNet Backbone Model Definition"}, "3159": {"path": "/paddlevideo/modeling/backbones/resnet.py:179-208", "hash": "2c96f267d3ae2467058e615f6e941ca0", "title": "ResNet Class Definition"}, "3160": {"path": "/paddlevideo/modeling/backbones/resnet.py:210-229", "hash": "beeebbcd94b2ed8b45e608fd73cffbd9", "title": "Dynamic ResNet Bottleneck Blocks"}, "3161": {"path": "/paddlevideo/modeling/backbones/resnet.py:230-252", "hash": "71e5dbe942f1a61d8eb55732cd760fce", "title": "Defining ResNet Model Layers"}, "3162": {"path": "/paddlevideo/modeling/backbones/resnet.py:253-268", "hash": "da9cc39e247eafd6b06d12f5293b9997", "title": "Pretrained ResNet Loading Path"}, "3163": {"path": "/paddlevideo/modeling/backbones/resnet.py:270-283", "hash": "e4a44513b9f7bdd645acae88ee7ea168", "title": "ResNet Forward Function Definition"}, "3164": {"path": "/paddlevideo/modeling/backbones/resnet3d.py", "hash": "295e9fdcfa348450a8b64f8b96f57dcf", "title": "3D ResNet Model in PaddleVideo"}, "3165": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:1-37", "hash": "71afc249d8df392d2dfa51a241c55694", "title": "Simplifying ConvNet Layers with ConvBNLayer"}, "3166": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:38-56", "hash": "43a105317fd5807d314801124ccb99d0", "title": "Extended Conv2D Layer for ResNet3D"}, "3167": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:57-89", "hash": "2dda73b02268924cf5289e056daba22f", "title": "3D ConvBN Layer Definition"}, "3168": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:90-115", "hash": "e63969981e0433b09559f6e2f66eaa24", "title": "Bottleneck3D Class Definition"}, "3169": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:116-140", "hash": "a223f417566331ef6a118bdc4b2e264e", "title": "ResNet3D Block Configurations"}, "3170": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:141-171", "hash": "28eef9576bb878cb38e7775807ef6b76", "title": "Initializing 3D ResNet Backbone Model"}, "3171": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:172-198", "hash": "36f2ea91399c3aa9bc08cc42f4675491", "title": "Dilated 3D ResNet Conv Layers"}, "3172": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:199-239", "hash": "6cc91ad1ec008d0da4d21afc2d7efeb0", "title": "ResNet3D Block Definition"}, "3173": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:242-263", "hash": "b740566d67abeb1afcc0fde5233d2add", "title": "Customizable ResNet 3D Backbone"}, "3174": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:264-282", "hash": "304ff74b54b6dd438fce2c242c765db6", "title": "ResNet3D Backbone Parameters"}, "3175": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:283-302", "hash": "b88c224f2c6476484702685137777dd0", "title": "ResNet3D Parameters and Architecture Settings"}, "3176": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:303-331", "hash": "fdd0190e1f3696f6e49b33060510e4de", "title": "ResNet3D Backbone: 3D Deep Learning Model"}, "3177": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:332-357", "hash": "f89bf5fe1d03f80edc0a166e0754f102", "title": "ResNet3D Model Initializer"}, "3178": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:358-387", "hash": "53863e4358f9ea8393a10a32cbdebfd5", "title": "Configuring ResNet3D Model Attributes"}, "3179": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:388-412", "hash": "eb1d5c82f597ab513c6c3acb8ab7405b", "title": "ResNet3D Layer Function"}, "3180": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:414-440", "hash": "cb6f6b0a535094ccad9bfe98bdce3ba8", "title": "Creating ResNet3D Residual Layers"}, "3181": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:441-457", "hash": "ece5aca85f65d6175cf08b5d4614ffec", "title": "Customizable ResNet3D Backbone Model"}, "3182": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:458-481", "hash": "a50f507149f972cdeae3b9c11a8099bb", "title": "ResNet3D Residual Layer Creation"}, "3183": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:482-509", "hash": "ebc2e91a3a6886a6504e10062363e879", "title": "Customizable ResNet3D Architecture"}, "3184": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:510-537", "hash": "cb6b0d0f75e9bdef79cfadff47565990", "title": "3D Conv Resnet Inflation"}, "3185": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:538-561", "hash": "1722c487c3072bad9ba662840b8ede96", "title": "Inflating 2D ConvNet to 3D ResNet3D"}, "3186": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:562-586", "hash": "4c99e9e62d6398f1c1c4252c3f5c49ae", "title": "ResNet3D Param Loading & Stem Layer Creation"}, "3187": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:587-620", "hash": "6cf295c803457a4e2b55df196accce40", "title": "ResNet3D: Convolutional and Pooling Layers"}, "3188": {"path": "/paddlevideo/modeling/backbones/resnet3d.py:621-641", "hash": "f552cbf0a939457312bbb5e44971d5f1", "title": "ResNet-3D Backbone Model Training"}, "3189": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py", "hash": "410dc3eeb473b70d31aeb1f3daff9d2a", "title": "Slowfast ResNet3d Backbone"}, "3190": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:1-30", "hash": "ea3a89034fd73b161dc13d7ab598039f", "title": "Slowfast ResNet3d: Reduced Fast Pathway"}, "3191": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:31-60", "hash": "25150af0b60afe1eee0b1a7ba369a5d6", "title": "ResNet3D: Slowfast Residual Layer"}, "3192": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:62-79", "hash": "2b21a6e3153447dd9a78422534e5c626", "title": "Defining Residual Module with Parameters"}, "3193": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:80-98", "hash": "7cecba1e78d9d9288184bb45f6d31e92", "title": "Build Residual Layers"}, "3194": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:100-129", "hash": "685ae30ee2a4cc586da717785f5f83c2", "title": "Downsampling Block for ResNet3D"}, "3195": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:130-157", "hash": "cabaf2c3cad6d659db9309cb93ed1b62", "title": "Resnet3D Backbone Creation in PaddleVideo"}, "3196": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:158-180", "hash": "4d2c54b404048a38e93fca7b79b7e23a", "title": "Loading and Resizing 2D Model Parameters"}, "3197": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:181-210", "hash": "b1d8dec33a4796416a67151731ec2708", "title": "ResNet3D Slow Only Pad Extension"}, "3198": {"path": "/paddlevideo/modeling/backbones/resnet3d_slowonly.py:211-214", "hash": "6ffd2191f5b2589534d2ff7af82e52c8", "title": "Resnet3D Slow-Only Strides and Dilations"}, "3199": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py", "hash": "76c37b1130688600443295b080a853c5", "title": "SlowFast: Video Recognition Backbone"}, "3200": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:1-33", "hash": "f8a1e7e7ed7646603b2f872c67cb60c2", "title": "ResNet SlowFast Backbone Initiation"}, "3201": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:34-66", "hash": "cc779de0a2eac28a1d110cb2b3098968", "title": "BottleneckTransform: Tx1x1, 1x3x3, Variable Kernel Sizes"}, "3202": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:67-87", "hash": "d8c780f5eec69bfe4eded094f8d36529", "title": "BottleneckTransform Class Definition"}, "3203": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:88-113", "hash": "5fcee0b7059041f21f1ca0f3c56cb4b5", "title": "Conv3D Layer for ResNet_SlowFast Backbone"}, "3204": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:114-139", "hash": "43e484311b1e3bad43aef502d0633073", "title": "3D Convolutional Layer with Batch Normalization"}, "3205": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:140-180", "hash": "ff4a279a571c2697d6138ef6b724bb3f", "title": "SlowFast ResNet Blocks"}, "3206": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:181-198", "hash": "462deefe8effcdddd10633f96816c0c7", "title": "Defining ResNet Bottleneck Arguments"}, "3207": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:199-237", "hash": "68113f9e36b662a83ade48a29f3c43fa", "title": "ResBlock Class for Deep Neural Networks"}, "3208": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:238-260", "hash": "713dd3b84d75f55c764f06fd9724402c", "title": "ResNet SlowFast Backbone Model"}, "3209": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:261-294", "hash": "1fa470895861cf878b111d8806e54134", "title": "SlowFast ResNet Stage"}, "3210": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:295-312", "hash": "46a056c4878dbad9869e0d3ce512fa32", "title": "ResStage Class Constructor"}, "3211": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:313-330", "hash": "ae48aab8439ae24443970625bb139ac6", "title": "ResStage Class for Residual Block"}, "3212": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:331-372", "hash": "66c001f807055d847fac7d9930e1df2c", "title": "ResNet SlowFast Model Initialization"}, "3213": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:373-404", "hash": "9226bc9be204e7606b9e86e1c77043d6", "title": "Slow-Fast ResNet Backbone with Pathways"}, "3214": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:405-432", "hash": "1906c4d12e8dd29178a876b05f7896bc", "title": "ResNet Basic Stem Module Definition"}, "3215": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:433-466", "hash": "0c18017c67ff0b7492777e034827cc2b", "title": "SlowFast 3D Stem Module"}, "3216": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:467-492", "hash": "7dcd535fadba37d8356d47294694f60f", "title": "Resnet Slowfast Model Initialization"}, "3217": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:494-518", "hash": "68b7fb814a680b3d09bd549b24f94429", "title": "ResNet SlowFast Stem and Fusion"}, "3218": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:519-544", "hash": "ab19eadaaa2f971b089565aea22a2820", "title": "FuseFastToSlow Convolutional Layer"}, "3219": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:545-572", "hash": "a2f07245be6af7cdaf768a21d4467b6f", "title": "ResNetSlowFast Model in PaddlePaddle"}, "3220": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:574-607", "hash": "b641571102a81ad9b829cee061c0b409", "title": "ResNetSlowFast: Video Recognition Architecture"}, "3221": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:608-632", "hash": "7ae10a70ce42148f2a30eea05d96d056", "title": "SlowFast Model Construction"}, "3222": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:633-657", "hash": "30b6433e3b123f1db2e2d840390ca518", "title": "SlowFast ResNet Backbone Initialization"}, "3223": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:659-678", "hash": "1a38dd45254193be69982e83119304f4", "title": "ResStage Configuration in ResNet SlowFast"}, "3224": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:679-704", "hash": "079e644ed52e59a8110b949c570fca96", "title": "ResNet SlowFast Model Architecture"}, "3225": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:705-733", "hash": "3669b4a77022aa248754be03b4159c11", "title": "ResNet SlowFast Layer Definitions"}, "3226": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:734-762", "hash": "c87a465cca62b8c6fe17995d4fca50d8", "title": "SlowFast ResNet Feature Extraction"}, "3227": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:763-788", "hash": "fc88d7de3dab4905a5f383bdc81eba75", "title": "ResNet Slowfast Model: Initialization and Forwarding"}, "3228": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast.py:790-795", "hash": "87ca4374c685dc76a0c8b1a4fbd8dc9c", "title": "ResNet SlowFast Final Layer"}, "3229": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py", "hash": "b1c36e6e8ccfc3f2e1246a2c9e153707", "title": "ResNet SlowFast MRI Model"}, "3230": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:1-33", "hash": "a29162cca09d08d1c98a150447f69332", "title": "PaddleVideo Backbone Initialization"}, "3231": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:34-66", "hash": "2965f7bd419469367527eb4518212205", "title": "BottleneckTransform: Temporal Conv Layers"}, "3232": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:67-87", "hash": "ac01a4f8467ac421b1ef98222482e160", "title": "BottleneckTransform Class in ResNet SlowFast MRI Model"}, "3233": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:88-113", "hash": "2ab2a09349f840e4a0fca6620178067e", "title": "Initiating 3D ConvLayers with BatchNorm and Stride"}, "3234": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:114-139", "hash": "c5f1d489fa7c0613eeb1529f95e3b011", "title": "Conv3D Layer with BN in Resnet-Slowfast MRI"}, "3235": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:140-180", "hash": "7150b7b2bf5021e7fc14f92ea9d4e673", "title": "SlowFast MRI ResNet Model"}, "3236": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:181-198", "hash": "d3c8b4b774e95e02b44cb66b84b9c0a5", "title": "Define ResNet Bottleneck"}, "3237": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:199-237", "hash": "c1ed6033ff1840dcc9da3a89f35e9957", "title": "ResBlock with Skip Connection"}, "3238": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:238-260", "hash": "11024f390083c7e62a522597168a1822", "title": "ResNet SlowFast MRI Model with BN & BottleneckTransform"}, "3239": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:261-294", "hash": "531b8228768565204840acfa3b757168", "title": "ResStage for 3D ResNet SlowFast Networks"}, "3240": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:295-312", "hash": "f16a3445572e456fcd2dee597d729cc1", "title": "ResStage Initialization"}, "3241": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:313-330", "hash": "383945abf6564556a95bf8a2bcaf94a1", "title": "ResStage Initialization: Resnet Slowfast MRI Backbone"}, "3242": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:331-372", "hash": "a168a89ece0e9b8cfbf20c95ab2c11f4", "title": "ResNet-SlowFast MRI Construction"}, "3243": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:373-404", "hash": "724c9c69304d9c43c284db48ecd362ca", "title": "SlowFast ResNet Backbone Initiation"}, "3244": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:405-432", "hash": "55b23715450e0f9cb5f58e9b207b1dfe", "title": "ResNetBasicStem: Kernel, Stride, Padding"}, "3245": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:433-466", "hash": "b567f5bc5f9a46b03ee90e668f823427", "title": "SlowFast Video Stem Module"}, "3246": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:467-492", "hash": "bb6959c2dcc98909cd4445a8629da8d6", "title": "Resnet Slowfast MRI Backbone"}, "3247": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:494-518", "hash": "6926cb4b286809ce1c3fe91a4e1d900b", "title": "ResNet SlowFast MRI Fusion"}, "3248": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:519-544", "hash": "7952982f5a9afee1ea74b5b49278185d", "title": "FuseFastToSlow Initialization"}, "3249": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:545-572", "hash": "bd9012942a29cdedf39aef8190a73521", "title": "ResNetSlowFast_MRI: Fusion Conv Layer"}, "3250": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:574-607", "hash": "3183c0f524499ed9494e7ecd14408f5b", "title": "ResNetSlowFast_MRI Model Initialization"}, "3251": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:608-632", "hash": "0534a0e51e0e4d1c1ae5dec0f705ed47", "title": "SlowFast Model Architecture"}, "3252": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:633-657", "hash": "052a1453087e58ab92dab2664cc21e3c", "title": "ResNet SlowFast MRI Backbone"}, "3253": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:659-678", "hash": "e0fcfeae7461d84ad9183f045107d545", "title": "Defining ResStage Layer Parameters"}, "3254": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:679-704", "hash": "351a00b914e73b4fbf4443d67063e7f6", "title": "ResNet SlowFast Model Initialization"}, "3255": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:705-733", "hash": "ac0e2c75db1d6e5239c71654d1b6dfcc", "title": "ResNet SlowFast MRI Model Initialization"}, "3256": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:734-762", "hash": "8162ee531c3162e3a292a04a48162304", "title": "ResNet SlowFast MRI Video Analysis Model"}, "3257": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:763-793", "hash": "32e623172ac947470296d31d6a381489", "title": "SlowFast 3D ResNet Model Initialization"}, "3258": {"path": "/paddlevideo/modeling/backbones/resnet_slowfast_MRI.py:794-796", "hash": "5a7d58f4971b403060a810a79625913b", "title": "SlowFast ResNet Fusion Layer"}, "3259": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py", "hash": "df7a018f1375f44c2e4c9fee4f666457", "title": "ResNet-TSM Backbone Update"}, "3260": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:1-30", "hash": "9a169b61f713b7417bf53a682e9ff7dd", "title": "ConvBNLayer: Combining Conv2D and BatchNorm2D"}, "3261": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:31-53", "hash": "df6acc03ec4023c61e0560c41c2bb6a1", "title": "Custom ConvBNLayer Class Definition"}, "3262": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:54-84", "hash": "4acdd29f187fb086afa9d2f155d2aa49", "title": "BottleneckBlock: Conv, BatchNorm, Activation"}, "3263": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:85-108", "hash": "c1851a9e1800073a79390a5151563972", "title": "BottleneckBlock Class Definition"}, "3264": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:109-134", "hash": "735bb8638185e33e0f3ec188d02d5517", "title": "TSM Backbone: Layer Initialization"}, "3265": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:135-164", "hash": "9a67fe609aa52d2526b5d91451c67766", "title": "Temporal Shift ResNet Backbone"}, "3266": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:165-202", "hash": "f9989c26be1d901c46929ae79517c895", "title": "Residual TSM Block: Alleviating Vanishing Gradients"}, "3267": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:203-241", "hash": "f9b31503ac41862c9383609c9b9f5223", "title": "ResNet TSM Backbone Model: Flexible Depths"}, "3268": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:242-273", "hash": "f9d3639c0cd0499577dc739dc41dbb28", "title": "ResNet-TSM Backbone Configuration"}, "3269": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:274-293", "hash": "5aca1583caa34c3fe1dfc0ca49828d33", "title": "ResNet TSM Bottleneck Blocks Creation"}, "3270": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:294-316", "hash": "e58bafc7602c6e0bcdfa25ea59cf8ddd", "title": "ResNet TSM Backbone Initialization"}, "3271": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:317-332", "hash": "99906c7b9e5b16f668a6378d592b1ee9", "title": "Initializing ResNet TSM Backbone Parameters"}, "3272": {"path": "/paddlevideo/modeling/backbones/resnet_tsm.py:333-353", "hash": "ed95d1825c76306ab6ace510aea0b7ae", "title": "ResNet TSM Forward Function"}, "3273": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py", "hash": "c00200559d1e7db7c30351f6ead8e5e0", "title": "ResNet-TSM MRI Backbone"}, "3274": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:1-32", "hash": "d80fb03775940a4bffdbd1ef2d3e092a", "title": "Convolutional Batch Normalization Layer"}, "3275": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:33-58", "hash": "7269412985591c20082a1050ca1c400d", "title": "ConvBNLayer Class Definition"}, "3276": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:59-83", "hash": "577d08ed9c6786de8bca38aff93e0000", "title": "ResNet-D: Pooling and Convolution Initialization"}, "3277": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:84-112", "hash": "0fc947bd602d2e28e60d31cda5885303", "title": "ResNetTSM_MRI Backbone Design"}, "3278": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:113-134", "hash": "ed038f4e4b5d0e976ea1699682110369", "title": "ResNet-D Branch Creation"}, "3279": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:136-166", "hash": "ce155ee4ea52deac2dcb58f1e00de1ba", "title": "ResNet-TSM Backbone with Temporal Shifts"}, "3280": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:167-200", "hash": "b4a87ad67626cf635ebc0919e8f4fc0d", "title": "ResNet TSM Backbone with BN and Leaky ReLU"}, "3281": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:201-229", "hash": "528cfcfcb1adf5a02c731b78ca24e9ed", "title": "ResNetTSM_MRI Class Initialization"}, "3282": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:230-252", "hash": "35f0360cdfd0d88fffdef9f7eeba6266", "title": "ResNet-TSM Backbone in PaddleVideo"}, "3283": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:253-271", "hash": "a0b9b4e0acb2c8c0fdd94e1fe4a61a58", "title": "Dynamic BottleneckBlock Naming"}, "3284": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:272-294", "hash": "a7e8af26df2d96d4af312d811c68ccf4", "title": "Dynamic ResNet TSM Backbone Creation"}, "3285": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:295-311", "hash": "4e8a168cb399726e5990366053666861", "title": "Initializing Backbone Neural Network"}, "3286": {"path": "/paddlevideo/modeling/backbones/resnet_tsm_MRI.py:313-327", "hash": "3bbb03125c5acc8a5a56023f643b2776", "title": "Convolutional Layer Iterations"}, "3287": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py", "hash": "e1017f39d02cdbb8829e92c3062ea769", "title": "ResNet-TSN Model for PaddlePaddle"}, "3288": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:1-29", "hash": "782b7c9700b57db24014c32aec6d443b", "title": "ResNet-TSN Backbone Model Initialization"}, "3289": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:31-58", "hash": "ea167b3a5ad2412bc719f5ab9b742649", "title": "ConvBNPoolingLayer Class Definition"}, "3290": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:59-89", "hash": "d917b851e25b4ee26da543c6d6b34c5a", "title": "Resnet_TSN Backbone Model Definition"}, "3291": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:90-111", "hash": "618268671dd14fc68e16e6ff753bc2c7", "title": "BottleneckBlock: ResNet's Core Layer"}, "3292": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:112-144", "hash": "4565859aa43e5748904266485e4144c8", "title": "ResNet TSN Backbone with Conv and Shortcut Connection"}, "3293": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:145-167", "hash": "5cb940aa6a90638126e0609e9dbec78f", "title": "Defining BasicBlock for ResNet TSN MRI Model"}, "3294": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:168-202", "hash": "cf240e13e8ab5877f14d96792a3abba3", "title": "ResNetTSN_MRI Backbone Definition"}, "3295": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:204-232", "hash": "73761d62be0420ce7c44eb5e65e21bfe", "title": "ResNet TSN Backbone Initialization"}, "3296": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:233-253", "hash": "cf9a7f589fd9f3b45bb0bafb9cf3a2c9", "title": "ResNet TSN Model with Multiple Branch Inputs"}, "3297": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:254-275", "hash": "8163c78e1c2c2fd5aab9e41441c286d4", "title": "ResNet-TSN Bottleneck Block Initialization"}, "3298": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:276-294", "hash": "5739ef37916729ac772bfa365206d732", "title": "ResNet TSN Model Creation"}, "3299": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:295-311", "hash": "ed948e335a362c75c1e256f9e9f040aa", "title": "ResNet TSN Backbone Weight Initialization"}, "3300": {"path": "/paddlevideo/modeling/backbones/resnet_tsn_MRI.py:313-331", "hash": "bff3cc81ea81525cd1f6bb3cc3dd9fea", "title": "Initializing and Checking Model Path"}, "3301": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py", "hash": "b1c1965060841beb75ba9c1b9623c33a", "title": "TSM ResNet Backbone for Temporal Segment Networks"}, "3302": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:1-31", "hash": "324bc8e91cc152daaab465c3bf4696f6", "title": "TSM ResNet Backbone Imports"}, "3303": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:32-54", "hash": "63f6a7f8da6dbb7b328dd6c00f0a2da8", "title": "ConvBNLayer: Combined Conv2D and BatchNorm2D Layers"}, "3304": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:55-78", "hash": "61416475f94a7b6901e302d3b928e0d0", "title": "ResNet-D Tweak ConvBN Layer"}, "3305": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:79-105", "hash": "cc1b6412a25bc6f6162a090f30a0af4f", "title": "Tweakable Convolutional Neural Network with Batch Normalization"}, "3306": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:106-132", "hash": "cca61b09bc716aee0988db3591cf6043", "title": "BottleneckBlock in ResNet-TSM"}, "3307": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:133-159", "hash": "602154f1982a3d9fba6ef88fd537c0a3", "title": "Resnet TSM Backbone: Forward Method"}, "3308": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:160-192", "hash": "9ba0d0c63bad533275b225b512a78547", "title": "Temporal Shifted ResNet Backbone"}, "3309": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:193-217", "hash": "1f9aa2d312ab5e1ceb2a97197bade0fe", "title": "ResNet TSM Block Definition"}, "3310": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:218-253", "hash": "2d989f2db9613c9e72a507541b62af20", "title": "ResNet TSM Backbone Model Init & Forward"}, "3311": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:254-279", "hash": "00e39f971dd6f95704f9327df9a4b55b", "title": "ResNet Model Depth Customization"}, "3312": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:280-301", "hash": "85d74f23dab55cb6eaa1d77436f306cb", "title": "TSM-ResNet Backbone with Tweaks"}, "3313": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:302-322", "hash": "f3dbae556575bccdf6cf993347500a50", "title": "ResNet Block Assignment Algorithm"}, "3314": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:323-339", "hash": "48f4ffe62901d60669c20cb894b71179", "title": "ResNet TSM Backbone Weights Init"}, "3315": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsm.py:340-362", "hash": "844fbf7cf3eb27202406abd4fe0b8b2f", "title": "Backbone Weights Initialization"}, "3316": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py", "hash": "f27398edca1352044711ba1e1def3961", "title": "ResNet TSN Model Backbones: PaddleVideo"}, "3317": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:1-29", "hash": "9ae6665e5256851f16c943f909e0ec08", "title": "ResNet Tweaks TSN Model Backbone"}, "3318": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:31-58", "hash": "32d20b89ba6e43b2dc71b58e020cfc88", "title": "Tailored ResNet Backbone with Pooling"}, "3319": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:59-89", "hash": "7f729f77290427564f6458c77a0b043a", "title": "ResNet-TSN Tweaks Backbone"}, "3320": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:90-111", "hash": "f4ad77f8136334bab88485ee5cec900f", "title": "Bottleneck Block: ResNet Parameter Reduction"}, "3321": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:112-144", "hash": "d9b0bdc7d70dd75139fa604f18e74263", "title": "ResNet Block Implementation"}, "3322": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:145-167", "hash": "f082a8720c0d058dc0dd00168b8d24af", "title": "BasicBlock Convolutional Layers and BatchNorm"}, "3323": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:168-203", "hash": "583278b3266af5064dd347b19f97d0bd", "title": "ResNetTweaksTSN Backbone: Convolution, Shortcut, and ReLU"}, "3324": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:204-232", "hash": "a8e738c65db825d78a4ce6b69a5840fe", "title": "ResNet Backbone Configurations"}, "3325": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:233-254", "hash": "9df72be5a8fc2f3d9b1146264f390ce8", "title": "First Layer ResNet Backbone Definition"}, "3326": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:255-276", "hash": "4b2a1ed083bed6b390c97719e8230271", "title": "ResNet-TSN Backbone Code"}, "3327": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:277-296", "hash": "d783dfb92fbe7be4b05c5722205e3d7a", "title": "Dynamic ResNet Tweaks for TSN"}, "3328": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:297-314", "hash": "7fb38e7b0a9b1b7ff08d6d0962cf7a89", "title": "Pre-Trained Weights Initialization in ResNet Backbone"}, "3329": {"path": "/paddlevideo/modeling/backbones/resnet_tweaks_tsn.py:315-328", "hash": "e0945651f520fdea379578d1659f93f4", "title": "ResNet Tweaks TSN Initialization"}, "3330": {"path": "/paddlevideo/modeling/backbones/resnext101.py", "hash": "0d7563caca06db964e53ce7a0fcdd480", "title": "ResNeXt-101 in PaddlePaddle"}, "3331": {"path": "/paddlevideo/modeling/backbones/resnext101.py:1-31", "hash": "6916baf0b107458101302ba2d89497a6", "title": "ConvBNLayer Class in PaddlePaddle"}, "3332": {"path": "/paddlevideo/modeling/backbones/resnext101.py:32-55", "hash": "75c93aebcfea165ccc58d5f7c18a14b8", "title": "ConvBNLayer Initialization"}, "3333": {"path": "/paddlevideo/modeling/backbones/resnext101.py:56-82", "hash": "356cdf29637ca2a5ca86127b27e5f571", "title": "ResNeXt101 Bottleneck Block and Downsampling"}, "3334": {"path": "/paddlevideo/modeling/backbones/resnext101.py:83-122", "hash": "c7fc05fa04552941b236a329aba7bdc8", "title": "ResNeXt Model Definition"}, "3335": {"path": "/paddlevideo/modeling/backbones/resnext101.py:123-148", "hash": "e35a35a62d5fbbca04b6a20ea36bbe0f", "title": "ResNext101 Backbone Architecture"}, "3336": {"path": "/paddlevideo/modeling/backbones/resnext101.py:149-176", "hash": "d1f3521390699ee4cfda1c947ae99a3a", "title": "ResNeXt-101 Model Implementation"}, "3337": {"path": "/paddlevideo/modeling/backbones/resnext101.py:177-187", "hash": "d04a5057bb510e6de0af0cf64bf21f8b", "title": "ResNext101: Constructing and Applying Layers"}, "3338": {"path": "/paddlevideo/modeling/backbones/stgcn.py", "hash": "f564cebceac268c66fb3977da4d482bd", "title": "STGCN: Skeleton-based Action Recognition Backbone"}, "3339": {"path": "/paddlevideo/modeling/backbones/stgcn.py:1-37", "hash": "43805073d93a8529c3d48c5bd9c68401", "title": "STGCN Backbone Definition"}, "3340": {"path": "/paddlevideo/modeling/backbones/stgcn.py:38-80", "hash": "89ece095569cf9c677af6b185fc72e77", "title": "Graph Hopping and Normalization"}, "3341": {"path": "/paddlevideo/modeling/backbones/stgcn.py:81-104", "hash": "fdb0f7da4e63ff4f5a59cbf5a87f3f78", "title": "Hop Distance Initialization in ST-GCN"}, "3342": {"path": "/paddlevideo/modeling/backbones/stgcn.py:105-120", "hash": "82e63e11b5506c2be6747b9fbb45beb4", "title": "Node Initialization in STGCN and COCO Keypoint Backbones"}, "3343": {"path": "/paddlevideo/modeling/backbones/stgcn.py:121-143", "hash": "7d16f48635f2c16ad5d5d83cdbd2bff8", "title": "Adjacency Matrix Initialization for STGCN"}, "3344": {"path": "/paddlevideo/modeling/backbones/stgcn.py:144-174", "hash": "703822fea14d8ae57d5b08c4cbca3667", "title": "ConvTemporalGraphical Layer Initialization in STGCN"}, "3345": {"path": "/paddlevideo/modeling/backbones/stgcn.py:175-209", "hash": "fbc469e4eaf9661c78ed0a26a5697da8", "title": "Temporal Graph Convolutions in STGCN"}, "3346": {"path": "/paddlevideo/modeling/backbones/stgcn.py:210-251", "hash": "c51c8efabb4eba54ab47a35742dae631", "title": "STGCN Model: Spatial and Temporal Processing"}, "3347": {"path": "/paddlevideo/modeling/backbones/stgcn.py:251-278", "hash": "07dc4b981729502cae16f9a00e4e7f43", "title": "Skeleton Action Recognition with STGCN"}, "3348": {"path": "/paddlevideo/modeling/backbones/stgcn.py:279-300", "hash": "6873eb5551ee14111d37dff15c743950", "title": "ST-GCN Block Initialization"}, "3349": {"path": "/paddlevideo/modeling/backbones/stgcn.py:301-327", "hash": "de921dd57ce01c14dfe572ffe559c05d", "title": "StGCN Edge Importance Initialization"}, "3350": {"path": "/paddlevideo/modeling/backbones/stgcn.py:328-343", "hash": "d1c88eca206df1f2d5fb54aa82e9ea4c", "title": "ST-GCN Pooling and Reshaping"}, "3351": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py", "hash": "b516fc69528e2b134eeb7b840a81eb5d", "title": "Swin Transformer 3D Backbone in PaddleVideo"}, "3352": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:1-33", "hash": "a1eb32272963f0b5e110eb0f6d1f8417", "title": "Swin Transformer Stochastic Depth"}, "3353": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:34-64", "hash": "232738576c71b8acafaa53b52de83c95", "title": "Stochastic Depth DropPath Layer"}, "3354": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:65-99", "hash": "174392b3293daaeb37bd16c22e544a04", "title": "Defining Swin Transformer Layer"}, "3355": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:100-137", "hash": "af53d162a1535c8085da766abc98e486", "title": "Swin Transformer Window Rearrangement"}, "3356": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:138-161", "hash": "4b15885733e802c6b90ce13212f513d4", "title": "Window-based Multi-Head Self Attention with Relative Position Bias"}, "3357": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:162-185", "hash": "7ec1f82c25cfbe31f9b5dcc647e77bf8", "title": "Swin Transformer Self-Attention Initialization"}, "3358": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:186-204", "hash": "0275bd3467f5abe5830c41e2560e688e", "title": "Swin Transformer: Relative Position Encoding"}, "3359": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:205-232", "hash": "4e32b34c957d81c4ac04a5dd0d4be8e3", "title": "Swin Transformer Backbone Initialization"}, "3360": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:233-261", "hash": "21d07bba4a7a9b43cbd1bab8034136f2", "title": "Swin Transformer Block 3D Implementation"}, "3361": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:262-282", "hash": "438a747abd84a81503589143c9ae9913", "title": "Swin Transformer Backbone Initialization"}, "3362": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:283-307", "hash": "46b06f39a563ae54bc20ef66b7098909", "title": "Swin Transformer Backbone Initialization"}, "3363": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:308-330", "hash": "0f04445a026a546034852e46e0830eaf", "title": "Swin Transformer Backbone Initialization"}, "3364": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:331-353", "hash": "283d9509465f1aa29e03ac7e77433763", "title": "Swin Transformer: Cyclic Shift and Windowed Self-Attention"}, "3365": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:354-390", "hash": "f71cc1322cf5837f6d2d27e7433105b2", "title": "Swin Transformer Forward Pass"}, "3366": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:391-426", "hash": "6fcbaed527f0519a157789e69aa6852c", "title": "Swin Transformer Image Backbone"}, "3367": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:427-443", "hash": "f86955aa2354d5bc840cec7a0e1156e8", "title": "Swin Transformer Attention Mask Generation"}, "3368": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:444-464", "hash": "aef4fddf6299aae015e683d401be169b", "title": "Customizable Swin Transformer Layer"}, "3369": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:464-493", "hash": "a714d26f8156733980ce51537c88a007", "title": "Swin Transformer 3D Block Definition"}, "3370": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:494-522", "hash": "89f56b7cab1d60c6a04897f04b7538a7", "title": "Swin Transformer Block for PaddleVideo"}, "3371": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:523-551", "hash": "a42c695b9e44366f7251c1bba6c857e9", "title": "Video Patch Embedding for Swin Transformer"}, "3372": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:553-581", "hash": "0358895b1c6be023d0b0a1e55c8f230b", "title": "Swin Transformer Backbone Initialization"}, "3373": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:582-604", "hash": "32503e43ac42ef30bf0b097b2241b04b", "title": "Swin Transformer 3D Backbone: Paddle Video"}, "3374": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:605-627", "hash": "aad844096d8ac1728893cdd18c4d0664", "title": "Swin Transformer Initialization Parameters"}, "3375": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:628-659", "hash": "a8a4da3d59d4cef4a9c8dac61e826b3e", "title": "Swin Transformer Model Initialization"}, "3376": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:660-687", "hash": "ee3634586cd5ffb03fb3270c90f4be05", "title": "Swin Transformer Backbone Initialization"}, "3377": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:689-720", "hash": "cf40c652cd018d3ed9ef42cc3f0c7eaa", "title": "Swin Transformer Initialization"}, "3378": {"path": "/paddlevideo/modeling/backbones/swin_transformer.py:721-742", "hash": "6c33f9aa3216fbf69cac4401c8aa512f", "title": "Swin Transformer Layer Processing"}, "3379": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py", "hash": "b438a9d1f817b38cc9308e17df0bc136", "title": "Shift-ViT: Versatile Image Processing Backbone"}, "3380": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:1-37", "hash": "39670b02fae73dee6d7d509d2f741cf8", "title": "Shifted Vision Transformer Backbone"}, "3381": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:38-65", "hash": "4ac59c9cea14eb517a69601f8afe4142", "title": "Stochastic Depth Drop Path Implementation"}, "3382": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:66-104", "hash": "acef93c443550140e63ed11579065fc0", "title": "Self-Attention Mechanism Implementation"}, "3383": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:105-138", "hash": "b33362025e710e066cdd046c15686b47", "title": "Self-Attention Module: TOShift-ViT Class"}, "3384": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:139-164", "hash": "a58da9ef4603dacc22a733ec27236025", "title": "Object Initialization in Toshift_VIT Model"}, "3385": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:165-186", "hash": "907137db33c26c1a044f8c5621c2eba2", "title": "Temporal Attention Initialization"}, "3386": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:187-213", "hash": "20fba74ec232916ea6dbe09181a56f79", "title": "Token-Shifting ViT Model Initialization"}, "3387": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:214-245", "hash": "2f021115cf6e846b0c50686e21333831", "title": "ToshiftVIT: Custom Backbone for Vision Transformer Model"}, "3388": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:246-278", "hash": "0cc6fd9582bbea1791656f200446459a", "title": "TokenShift Vision Transformer Class"}, "3389": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:279-305", "hash": "b6050c5828f6aaf28c213516fc5e859e", "title": "Toshift ViT Class Initialization"}, "3390": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:306-330", "hash": "abfee8739a36af65df8768616d820f97", "title": "Transformer Backbone Model Setup"}, "3391": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:331-360", "hash": "14db32bd076093b3f3eb6279636f91df", "title": "Toshift_VIT Model Initialization"}, "3392": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:361-386", "hash": "b59b77b4293bbf266de088c3207dad43", "title": "TOShiftViT: Initializing and Processing Features"}, "3393": {"path": "/paddlevideo/modeling/backbones/toshift_vit.py:387-413", "hash": "0dfda89d206e34a8cce52f8786dfd1f6", "title": "Positional Embedding and Attention Blocks"}, "3394": {"path": "/paddlevideo/modeling/backbones/transnetv2.py", "hash": "3e7d2ce68cd321e11745707718ccce63", "title": "OctConv3D Enhances TransNetV2 Backbone"}, "3395": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:1-28", "hash": "1849c11df70650ec580ba8d1708f7574", "title": "OctConv3D Layer Creation"}, "3396": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:30-43", "hash": "ff35a8cb4c2a4968c64acb84fd61aa21", "title": "Interleaved 3D Convolutional Paths for TransNetV2"}, "3397": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:44-58", "hash": "401d7db53a139d6dbb910eb89ed39e00", "title": "TransNetV2: Conv, Upsample, Downsample Backbone"}, "3398": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:60-90", "hash": "88d12da63c635f4fb9610390d2e5084e", "title": "TransNetV2: Versatile Transformation Functions"}, "3399": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:91-104", "hash": "86f2a8dc25cc65fef2931a4ca9cdf23c", "title": "TransNetV2 Backbone Conv Layers"}, "3400": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:105-131", "hash": "e3d3cdcde22dbcc269bd409cbbf0a0a3", "title": "TransnetV2: Configurable Conv3D Backbone"}, "3401": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:132-150", "hash": "aa8bedc88183a8579f2d4c8f5f8872d7", "title": "TransNetV2 Model Definition"}, "3402": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:151-179", "hash": "6433d11242a70b8b6b66bedbcf6b348b", "title": "Stacked DDCNNV2: Neural Network Layer"}, "3403": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:181-207", "hash": "cfe5e0e80982454d0528e0cc6be7bd82", "title": "TransNetV2 Backbone Initialization"}, "3404": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:208-232", "hash": "080854f6a821506864983f16a76428aa", "title": "Stochastic Depth ResNet Block"}, "3405": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:234-260", "hash": "cd8a328137db1212426e22f92c680751", "title": "TransNetV2 Layer Sequence"}, "3406": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:261-282", "hash": "d7a72f4b38075b5c15661c1908bf9abf", "title": "TransNetV2 Backbone Initialization"}, "3407": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:283-307", "hash": "52fb2d0d55f5c88e2397744895272121", "title": "FrameSimilarity Layer Initialization"}, "3408": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:309-330", "hash": "b12048f4a339fc5ae68f1617190d4ba6", "title": "TransNetV2 Model Initialization and Similarity Calculation"}, "3409": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:331-346", "hash": "2a90096dc59d7d2009e4d1c1ae635a44", "title": "Tensor Indices and Regression"}, "3410": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:347-364", "hash": "d20fcecfda35a2050afe0f277b3437be", "title": "TransNetV2 Conv3D Model"}, "3411": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:365-390", "hash": "0c1e9c14ed98fb8e06178afdef6ad09f", "title": "TransnetV2 Frame Concatenation"}, "3412": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:391-411", "hash": "36ec74cb9991ddb709333eeb700bd715", "title": "Color Histograms in TransnetV2"}, "3413": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:412-429", "hash": "392806c3e69e4fac69b9724a9c9dc4b2", "title": "Video Frame Histogram Comparison"}, "3414": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:430-446", "hash": "5c96067017fedd0db232034012518ed2", "title": "TransNetV2 Lookup Operation"}, "3415": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:449-473", "hash": "91d59d86aab44d36781b571728bbb939", "title": "TransNetV2: Shot Transition Detection Model"}, "3416": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:473-484", "hash": "ffa2108ee65aaf803b5ad1bfd4fc35bc", "title": "TransNetV2 ResNet Features Initialization"}, "3417": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:485-508", "hash": "9fcbecc776eb56706faa9135346ea395", "title": "TransNetv2 Backbone Initialization"}, "3418": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:510-526", "hash": "e298e21c299ae507e36acd02fc4cf1c0", "title": "TransNetV2 Neural Network Model Initialization"}, "3419": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:527-548", "hash": "a9e859e5595b9f65daa8d1b5168d87cd", "title": "TransNetV2 Model Architecture"}, "3420": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:549-571", "hash": "5172989db6b799a17edac1ccf6c26014", "title": "TransNetV2 Feature Extraction and Pooling"}, "3421": {"path": "/paddlevideo/modeling/backbones/transnetv2.py:572-581", "hash": "c0477aa5c70e6ef5259986b60107eee6", "title": "Transnetv2 Classification"}, "3422": {"path": "/paddlevideo/modeling/backbones/vit.py", "hash": "c76d4a70f0ca56ce2f979f3482eebe23", "title": "Vision Transformer Backbone in PaddleVideo"}, "3423": {"path": "/paddlevideo/modeling/backbones/vit.py:1-37", "hash": "408b0eb1f17f36a7341bbc268c73d71b", "title": "Drop Path Functions in PaddleVideo"}, "3424": {"path": "/paddlevideo/modeling/backbones/vit.py:38-65", "hash": "ff869156b066cd6c5f001503b93c5366", "title": "Stochastic Depth Dropout Paths for Vision Transformers"}, "3425": {"path": "/paddlevideo/modeling/backbones/vit.py:66-104", "hash": "6e874695a2ecb3800bf33d25718ad130", "title": "Vision Transformer Backbone: MLP & Attention"}, "3426": {"path": "/paddlevideo/modeling/backbones/vit.py:105-138", "hash": "1d13b50b60f0b6e09f1b731e4e5def86", "title": "Multi-Head Attention Layer Initialization"}, "3427": {"path": "/paddlevideo/modeling/backbones/vit.py:139-166", "hash": "bff04c7bfbb0d0fa8baf3d95379a0ec3", "title": "Vision Transformer Initializer"}, "3428": {"path": "/paddlevideo/modeling/backbones/vit.py:167-185", "hash": "4cb61d83cd9a5549bbdb78e9634d6f75", "title": "Vision Transformer Backbone Initialization"}, "3429": {"path": "/paddlevideo/modeling/backbones/vit.py:186-210", "hash": "64c21f79e69612dad4f2f8352536579a", "title": "VI Forward Method"}, "3430": {"path": "/paddlevideo/modeling/backbones/vit.py:211-235", "hash": "51283af92e4a8245b4152d36a988b56d", "title": "Spatial Attention in Vision Transformer Model"}, "3431": {"path": "/paddlevideo/modeling/backbones/vit.py:236-267", "hash": "fbc95e2d04846c209c67d153a989eec3", "title": "Vision Transformer Backbone: Averaging and Patch Embedding"}, "3432": {"path": "/paddlevideo/modeling/backbones/vit.py:268-298", "hash": "6eda2e04e8a97f799aa2f32b297dcee8", "title": "VisionTransformer: Paddle Video Backbone"}, "3433": {"path": "/paddlevideo/modeling/backbones/vit.py:299-327", "hash": "e920126bcde00906a3bb031d984e1571", "title": "Initialize ViT Backbone Model Parameters"}, "3434": {"path": "/paddlevideo/modeling/backbones/vit.py:328-350", "hash": "3aae59338b35bd29fcf9f1c61c2dbbe3", "title": "Initializing Vision Transformer Components"}, "3435": {"path": "/paddlevideo/modeling/backbones/vit.py:351-379", "hash": "2c0ce9caf48e93a75c4580ef3baf72cf", "title": "Vision Transformer Model Initialization"}, "3436": {"path": "/paddlevideo/modeling/backbones/vit.py:380-405", "hash": "4c7ef97b01afb5cc66e07c29579eb994", "title": "Vision Transformer Forward Initialization"}, "3437": {"path": "/paddlevideo/modeling/backbones/vit.py:406-430", "hash": "117a5075ec3714ab6a7a632f3c3853f2", "title": "Relative Position Embeddings in Vision Transformer Model"}, "3438": {"path": "/paddlevideo/modeling/backbones/vit.py:431-455", "hash": "67c775000dedca37bf529cb2f4effedc", "title": "VIT Time Embedding and Attention Processing"}, "3439": {"path": "/paddlevideo/modeling/backbones/vit.py:456-465", "hash": "6044521cdc323aa7d06df568ed79f510", "title": "Vit Model Frame Averaging Embeddings"}, "3440": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py", "hash": "a548272c7d6b08482a90b78c5d10df21", "title": "VisionTransformer_tweaks: Time-Based Feature Modification"}, "3441": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:1-32", "hash": "163a0037b25c37a6632cb1f8dcfda775", "title": "VisionTransformer_tweaks Model"}, "3442": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:35-69", "hash": "78352dc8e36e1346ef26cb25a3d04bc9", "title": "Dropout and Bounding Box Functions"}, "3443": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:70-107", "hash": "8ace0dc760c31b91ed452f0a3a2215af", "title": "Vit Tweak: Mlp Class with DropPath"}, "3444": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:108-144", "hash": "0401902aa6b16a647ab6f29097bbc013", "title": "Multi-Head Self-Attention Layer for Transformers"}, "3445": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:145-178", "hash": "191644ca105916df53648c86415e00fa", "title": "Attention Block Class with QKV Decomposition"}, "3446": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:179-202", "hash": "6b722b6f674b8db929e19361d8ea469e", "title": "Dynamic Norm Layer Instantiation"}, "3447": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:203-221", "hash": "1dd8e532402098aaf473db917d76023a", "title": "Temporal Attention Module Initialization"}, "3448": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:223-247", "hash": "afdd811a27dcf7e98c719f834abc51f9", "title": "Flexible ViT Backbone with MLP and Attention Types"}, "3449": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:248-271", "hash": "0086b93679364518612178f754ffddbc", "title": "Spatial Attention in ViT Models"}, "3450": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:273-302", "hash": "11c9d5308350dd7336516a92f9b3ba90", "title": "PatchEmbed Class in PaddleVideo Library"}, "3451": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:303-331", "hash": "63acd61c3f3ecb4c9eb0f76cddf1d5a8", "title": "Vision Transformer with Patch Input"}, "3452": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:332-360", "hash": "25b329afe0081ad6b0180838891a034b", "title": "Vit Model Initialization"}, "3453": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:361-384", "hash": "0e89cbbaa0a22e51f56928484a67e76f", "title": "Initializing Transformer Embeddings"}, "3454": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:385-414", "hash": "d3e20fec384349febb7c119899ebf086", "title": "Transformer Model Customization"}, "3455": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:415-441", "hash": "cb06972d145661ed99980ac66175e4ee", "title": "Initializing Backbone Network Parameters"}, "3456": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:442-464", "hash": "60855cda21ff7311d108d7fb6dfe8e17", "title": "Transformer Model Forward Pass: Positional Embedding Reshaping"}, "3457": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:465-487", "hash": "b7ca73dab6fe4bfcc7d31a35dd659447", "title": "Vit Tweaks: Position & Time Embeddings"}, "3458": {"path": "/paddlevideo/modeling/backbones/vit_tweaks.py:488-515", "hash": "875fdb7c9204895c5bb0fe1223694a0a", "title": "Dynamic Frame Averaging for Vision Transformers"}, "3459": {"path": "/paddlevideo/modeling/backbones/yowo.py", "hash": "6d813eb363bbe30b4d86f2d5f8860de7", "title": "YOWO Video Backbone for Paddle"}, "3460": {"path": "/paddlevideo/modeling/backbones/yowo.py:1-28", "hash": "ac8f79947a7d1b74b8f9eca5ce085236", "title": "CAM Module: PaddleVideo Backbone Custom Layer"}, "3461": {"path": "/paddlevideo/modeling/backbones/yowo.py:29-53", "hash": "0d1a96e0efd74d43e31eb4b4d8145603", "title": "Channel-wise Attention CFAMPBlock"}, "3462": {"path": "/paddlevideo/modeling/backbones/yowo.py:54-79", "hash": "b15f2e6b60845f1f5e55e0a7896a3772", "title": "YOWO Backbone: ConvLayers, BN, ReLU, CAM_Module"}, "3463": {"path": "/paddlevideo/modeling/backbones/yowo.py:80-108", "hash": "5c26f0be612429a40fa78e5f816ef574", "title": "YOWO Model Initialization"}, "3464": {"path": "/paddlevideo/modeling/backbones/yowo.py:109-129", "hash": "1c8e90f5d0b9a72fccdfbfa11df2c7e7", "title": "YOLOv5 Backbone Loading Weights"}, "3465": {"path": "/paddlevideo/modeling/backbones/yowo.py:130-150", "hash": "9fa2c93e462f148bb07d56e9b41acc19", "title": "YOWO Model Loading and Processing"}, "3466": {"path": "/paddlevideo/modeling/bbox_utils.py", "hash": "1eb491813fff5a32cb1eae9cbac785f7", "title": "Bounding Box Utilities"}, "3467": {"path": "/paddlevideo/modeling/bbox_utils.py:1-30", "hash": "2a73114bd0d84dfde2d5219f8eac6993", "title": "Bounding Box Delta Calculator"}, "3468": {"path": "/paddlevideo/modeling/bbox_utils.py:31-63", "hash": "7c1b9f6e26a9e5c855fa3f46557b737a", "title": "Weighted Bounding Box Differential Conversion"}, "3469": {"path": "/paddlevideo/modeling/bbox_utils.py:65-102", "hash": "22e54b8f788c0470e3fd4047a09b39cd", "title": "Bounding Box Utilities"}, "3470": {"path": "/paddlevideo/modeling/bbox_utils.py:103-139", "hash": "93d47f796fe21906e485498b12b3a16c", "title": "Bounding Boxes Filters and Overlaps Calculation"}, "3471": {"path": "/paddlevideo/modeling/bbox_utils.py:140-176", "hash": "22a59432756f7f35e6782e664f7a6b75", "title": "Grid and YOLO Box Utilities"}, "3472": {"path": "/paddlevideo/modeling/bbox_utils.py:177-204", "hash": "f8be8d60697747632f78c3351d40e48a", "title": "Bounding Box Utilities"}, "3473": {"path": "/paddlevideo/modeling/bbox_utils.py:205-237", "hash": "7bda48665388a7e7affdcb5cd5ca38b5", "title": "Bounding Box IoU Calculator"}, "3474": {"path": "/paddlevideo/modeling/bbox_utils.py:238-268", "hash": "510bc42ed7e2b00ef6d99ae4d3442190", "title": "Intersection Over Union Calculator for Bounding Boxes"}, "3475": {"path": "/paddlevideo/modeling/bbox_utils.py:269-304", "hash": "69eac5d5a3497a69cb90ee2547cd6db1", "title": "Rotated Bounding Box Conversion"}, "3476": {"path": "/paddlevideo/modeling/bbox_utils.py:305-339", "hash": "63d645cc81c60f97c93978715a50119a", "title": "Bounding Box Regression Computation"}, "3477": {"path": "/paddlevideo/modeling/bbox_utils.py:340-378", "hash": "d7325d30b52547b54f022d6d99e6da35", "title": "Delta BBox Calculator"}, "3478": {"path": "/paddlevideo/modeling/bbox_utils.py:379-417", "hash": "ff92e35e48ebc7662a7c0ed08a77ad22", "title": "Decoding Bounding Boxes in Paddle Video"}, "3479": {"path": "/paddlevideo/modeling/bbox_utils.py:418-447", "hash": "c602fe8c7dea13ca1fb1b98648254d99", "title": "Bounding Box Dimensions and Angle Calculator"}, "3480": {"path": "/paddlevideo/modeling/bbox_utils.py:448-475", "hash": "4a4f68045c9d4d210ed43f52440e014e", "title": "Find Best Begin Point in Coordinates"}, "3481": {"path": "/paddlevideo/modeling/bbox_utils.py:476-503", "hash": "1bc8dc77e5d310147d21104a3e9c60a7", "title": "Rotated Rectangle to Polygon Conversion"}, "3482": {"path": "/paddlevideo/modeling/bbox_utils.py:504-528", "hash": "9835ef8fc487bbf5a103b3c4465accb4", "title": "Rotating Rectangles to Polygons"}, "3483": {"path": "/paddlevideo/modeling/builder.py", "hash": "432511b5183f421d54cc0ecbdaa26b7e", "title": "Video Model Builder with Paddle"}, "3484": {"path": "/paddlevideo/modeling/builder.py:1-19", "hash": "1669a9d36b0d8fd7b265ef111097b3ab", "title": "Video Object Detection Model Builder"}, "3485": {"path": "/paddlevideo/modeling/builder.py:22-73", "hash": "8618aaa75ac267357e95266674533d2e", "title": "Model Builder Functions"}, "3486": {"path": "/paddlevideo/modeling/builder.py:74-116", "hash": "d439be6fb4327f79c3bac31be9fae7cd", "title": "Dynamically Building Paddle Video Components"}, "3487": {"path": "/paddlevideo/modeling/builder.py:117-127", "hash": "367a6276d74ebb3ebc37a50f08f976bd", "title": "Framework-Based Model Builder"}, "3488": {"path": "/paddlevideo/modeling/framework/__init__.py", "hash": "d49482c4dcead0a03cb3aefe8d39b3f6", "title": "PaddleVideo Framework Base Classes"}, "3489": {"path": "/paddlevideo/modeling/framework/__init__.py:1-24", "hash": "7e305ff962e1f8983d8d7c805ffff655", "title": "PaddleVideo Framework Base Classes"}, "3490": {"path": "/paddlevideo/modeling/framework/__init__.py:25-28", "hash": "97213dbae08d7f28284ca6f7f1fe2cf0", "title": "Model Classes in PaddleVideo Framework"}, "3491": {"path": "/paddlevideo/modeling/framework/detectors/__init__.py", "hash": "74d69ae58b26f238cf2cf4a52e30933d", "title": "Detector Imports in PaddleVideo"}, "3492": {"path": "/paddlevideo/modeling/framework/detectors/base.py", "hash": "cbdfde8ee2714d2022f05e905dad6857", "title": "Abstract BaseDetector Class"}, "3493": {"path": "/paddlevideo/modeling/framework/detectors/base.py:1-36", "hash": "1a1b462fae43ab6b14ce12fdc4165783", "title": "Base Detector Class: Foundation for Detection Models"}, "3494": {"path": "/paddlevideo/modeling/framework/detectors/base.py:37-51", "hash": "78af2c1b9ee31995ed603dd4a19a8f13", "title": "Abstract Base Classes for ML Training, Validation, and Testing"}, "3495": {"path": "/paddlevideo/modeling/framework/detectors/fast_rcnn.py", "hash": "995c0920fe164fdca7fbf01f5ac940e4", "title": "Fast R-CNN Detector"}, "3496": {"path": "/paddlevideo/modeling/framework/detectors/fast_rcnn.py:1-30", "hash": "fca462237f532a3cebc98d4f3dc5fa50", "title": "Fast R-CNN Detector"}, "3497": {"path": "/paddlevideo/modeling/framework/detectors/fast_rcnn.py:31-34", "hash": "5a95b7228206c205e13f8982a18f8829", "title": "Fast RCNN Detector Builder"}, "3498": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py", "hash": "4a436e3a42ab688dcb93bf11a51eb687", "title": "Two-Stage Slowfast Detector"}, "3499": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py:1-32", "hash": "995e8abd8351d5a038cd1b66642e5cc3", "title": "Two-Stage Detector Base Class"}, "3500": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py:33-64", "hash": "eb4a046d83796722acdec9b2b29b0577", "title": "Two-Stage Object Detector Class"}, "3501": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py:66-91", "hash": "ddef4a084e2def9405e69f65266996af", "title": "Two-Stage Detector Feature Extraction and Loss Computation"}, "3502": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py:92-124", "hash": "4a4f16803a1559b2b8f7689bd33fb7ae", "title": "SlowFast Model Detectors: Val, Test, Infer"}, "3503": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py:125-152", "hash": "5d52e1edda180f25665886c2a7895558", "title": "Two-Stage Detector Data Retrieval"}, "3504": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py:153-176", "hash": "0b899b997adff404d829a4f0925b1f37", "title": "Two-Stage Detector: GT Bounding Boxes Generation"}, "3505": {"path": "/paddlevideo/modeling/framework/detectors/two_stage.py:178-186", "hash": "8bd3f18946bfd6950df46e331a75871a", "title": "Selecting Entity IDs with Paddle's Index Select"}, "3506": {"path": "/paddlevideo/modeling/framework/estimators/__init__.py", "hash": "4d6dd35e01f8874e14c1ce9f539d10a7", "title": "Estimators Import and Definition"}, "3507": {"path": "/paddlevideo/modeling/framework/estimators/base.py", "hash": "542f6746ef6bcf445680ee009e28a944", "title": "PaddleVideo BaseEstimator Class"}, "3508": {"path": "/paddlevideo/modeling/framework/estimators/base.py:1-34", "hash": "9567eb47ee9c89ecbf73794c1f8865f8", "title": "BaseEstimator: PaddleVideo's Estimator Foundation"}, "3509": {"path": "/paddlevideo/modeling/framework/estimators/base.py:35-66", "hash": "bd9178c299fbd0c650e96fc7b6a487f2", "title": "Versatile Estimator Framework"}, "3510": {"path": "/paddlevideo/modeling/framework/estimators/base.py:67-82", "hash": "63038ac9856cabe6c130e5a2f83008c2", "title": "Abstract Methods for Model Validation"}, "3511": {"path": "/paddlevideo/modeling/framework/estimators/depth_estimator.py", "hash": "c5ab2f35918c01f76881ee9ee7afa13a", "title": "DepthEstimator: Feature Extraction and Loss Metrics"}, "3512": {"path": "/paddlevideo/modeling/framework/estimators/depth_estimator.py:1-31", "hash": "e9a1512a1fc55fe0e21cc9a52648b649", "title": "DepthEstimator: Framework for Feature Extraction"}, "3513": {"path": "/paddlevideo/modeling/framework/estimators/depth_estimator.py:32-58", "hash": "6b241c504e96a2e43926623cbed9125f", "title": "Depth Estimator Steps: Train, Validate, Test, Infer"}, "3514": {"path": "/paddlevideo/modeling/framework/estimators/depth_estimator.py:59-59", "hash": "b74c9a1fcc3531c44f51d48e92b7dec0", "title": "Depth Estimator Results"}, "3515": {"path": "/paddlevideo/modeling/framework/localizers/__init__.py", "hash": "2e9f2c432aca496aa9d1249d5bce9364", "title": "PaddleVideo Localizers: Handling Video Localization Tasks"}, "3516": {"path": "/paddlevideo/modeling/framework/localizers/base.py", "hash": "e5ec47c319c94a025edfb590989c5993", "title": "Localization Model Base Class (Python)"}, "3517": {"path": "/paddlevideo/modeling/framework/localizers/base.py:1-27", "hash": "04b5021c52bede6c08ba0fb219f7bf50", "title": "Base Class for Localization Models"}, "3518": {"path": "/paddlevideo/modeling/framework/localizers/base.py:28-56", "hash": "0719a456a7f6130fadd3aca7007d54ca", "title": "Localizer Model Initialization"}, "3519": {"path": "/paddlevideo/modeling/framework/localizers/base.py:58-74", "hash": "26d325c8400d5fa9f99effce415bb1d3", "title": "Abstract Classes for Model Steps"}, "3520": {"path": "/paddlevideo/modeling/framework/localizers/bmn_localizer.py", "hash": "4310de76da1da7ee89afcc44f8b3759c", "title": "BMN Localizer Model for PaddleVideo"}, "3521": {"path": "/paddlevideo/modeling/framework/localizers/bmn_localizer.py:1-36", "hash": "76eb9dca1647809b36f22b3ecef89d0e", "title": "BMNLocalizer: PaddleVideo's Localization Framework"}, "3522": {"path": "/paddlevideo/modeling/framework/localizers/bmn_localizer.py:37-69", "hash": "a282cc9666cff1dc7b4e10234b6b34ca", "title": "BMN Localizer: Training, Testing, Inferring"}, "3523": {"path": "/paddlevideo/modeling/framework/localizers/yowo_localizer.py", "hash": "160109cbcd5687b25197f81fd3b0c6c9", "title": "YOWO Localizer Evaluation"}, "3524": {"path": "/paddlevideo/modeling/framework/localizers/yowo_localizer.py:1-33", "hash": "9a63e9a69e42867c7724c1aeab5d7110", "title": "YOWO Localizer Class: PaddleVideo"}, "3525": {"path": "/paddlevideo/modeling/framework/localizers/yowo_localizer.py:34-67", "hash": "8e43173b3be367041e8d059fd8125eb3", "title": "Model Training and Validation Process"}, "3526": {"path": "/paddlevideo/modeling/framework/localizers/yowo_localizer.py:68-90", "hash": "4dfcf237c9e7d2149de26e67c482f4db", "title": "Non-Maximum Suppression and Precision Calculation"}, "3527": {"path": "/paddlevideo/modeling/framework/localizers/yowo_localizer.py:91-125", "hash": "9549755e1497945f55e84cbb1be9f3c2", "title": "YOLOv3 Localizer Metrics Calculator"}, "3528": {"path": "/paddlevideo/modeling/framework/localizers/yowo_localizer.py:126-147", "hash": "8652bdc3ba23c929ba1371ea477b2987", "title": "YOWO Localizer Evaluation: Precision, Recall, F-Score"}, "3529": {"path": "/paddlevideo/modeling/framework/localizers/yowo_localizer.py:149-161", "hash": "fb118b9272a8a2654e7892ed14651a89", "title": "YOWO Localizer Functions"}, "3530": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py", "hash": "bfd609ca9c7b5e7486b5ccfea57d2a01", "title": "YOWO Utils: Non-Max Suppression and Tensor Movement"}, "3531": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:1-36", "hash": "81e65b633220ba59e7710cc486090d0e", "title": "YOWO Localizers: Truths Length & NMS"}, "3532": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:37-67", "hash": "8bb9b5d2a1cfbb681e39ded4a518b00d", "title": "Functional Definitions for Bounding Boxes"}, "3533": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:68-94", "hash": "44b5fd6b05da6ea2163aee830f09edeb", "title": "Box Regression via Reshaping and Sigmoid"}, "3534": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:96-122", "hash": "c999fd6586965e8fc54de0491e0a5ec5", "title": "YOLOv2 Bounding Box Processing"}, "3535": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:123-153", "hash": "4898fc30c21ee470c6257a68b23fd8fd", "title": "YOLO Bounding Box Extractor"}, "3536": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:154-178", "hash": "73bd6c07816f417b8e3889d8cd08cc73", "title": "YOLO Object Detection Utilities"}, "3537": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:179-213", "hash": "4fc87ce334a37ae4aa963b18e7234b66", "title": "Intersection-Over-Union Calculator"}, "3538": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:214-241", "hash": "9eae82f4b1cb058e894545e6c0707c9b", "title": "Intersection Over Union Code"}, "3539": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:244-268", "hash": "882e1193aae713b79068d0150da1ab5b", "title": "YOLO Localizer Ground Truth Builder"}, "3540": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:269-288", "hash": "f1f497f1f527b6dd2413c2d4d208b931", "title": "IoU Calculation for YoWo Localizers"}, "3541": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:289-315", "hash": "17f927d886761fb64547112fbff82521", "title": "IoU-Based Masking for Bounding Box Confidences"}, "3542": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:316-338", "hash": "3e2ad226e82d6fec29625fd8a264bd3f", "title": "YOLO Anchor Box Selection"}, "3543": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:340-357", "hash": "0e4d063f1ce69d716427323cb6442d81", "title": "Object Localization Metric"}, "3544": {"path": "/paddlevideo/modeling/framework/localizers/yowo_utils.py:358-359", "hash": "0a56a06a90c434a7f18729605a7b8dd2", "title": "Localizers Framework Functions"}, "3545": {"path": "/paddlevideo/modeling/framework/multimodal/__init__.py", "hash": "16e7ede9cfcb091a61695a433e4542d1", "title": "Multimodal Model Initialization"}, "3546": {"path": "/paddlevideo/modeling/framework/multimodal/actbert.py", "hash": "0af35f36994c2a91a8dead5e3b0a16a3", "title": "Introducing ActBert: Multimodal Model Training"}, "3547": {"path": "/paddlevideo/modeling/framework/multimodal/actbert.py:1-27", "hash": "f5899f7de5a08fd93a845ca488a06c98", "title": "ActBert: Multimodal Model Framework"}, "3548": {"path": "/paddlevideo/modeling/framework/multimodal/actbert.py:28-46", "hash": "eb2ab6a430aef7ed347c6aacc366235e", "title": "ActBert Dataset Train and Val Steps"}, "3549": {"path": "/paddlevideo/modeling/framework/multimodal/actbert.py:47-64", "hash": "bc11af1fc51ee84d436ff6db24c9b75f", "title": "Multimodal ACT-BERT Model"}, "3550": {"path": "/paddlevideo/modeling/framework/multimodal/base.py", "hash": "1f8ab578f31cc44de34c93a94367910c", "title": "Multimodal Base Class for PaddleVideo"}, "3551": {"path": "/paddlevideo/modeling/framework/multimodal/base.py:1-32", "hash": "398ac04aae0d84d1b7576dd38037cc0a", "title": "Multimodal Base Class for PaddleVideo"}, "3552": {"path": "/paddlevideo/modeling/framework/multimodal/base.py:33-63", "hash": "f962038917c4f2f29b108d316c47e6c1", "title": "Multimodal Base Class with Selectable Step Functions"}, "3553": {"path": "/paddlevideo/modeling/framework/multimodal/base.py:65-81", "hash": "bc615f7c65319e237596891b9892e639", "title": "Abstract Methods for Validation, Testing, and Inference"}, "3554": {"path": "/paddlevideo/modeling/framework/partitioners/__init__.py", "hash": "9706e51cb51c8bbcaff3c7d46aad7ec8", "title": "PaddleVideo Partitioner Initialization"}, "3555": {"path": "/paddlevideo/modeling/framework/partitioners/base.py", "hash": "b12171257da0c516ebeafdc2f0a00b61", "title": "BaseModelPartitioner: PaddleVideo's Modeling Framework"}, "3556": {"path": "/paddlevideo/modeling/framework/partitioners/base.py:1-27", "hash": "891eeced2764f40573ef0d33d3502940", "title": "Python Base Partitioner Class for PaddleVideo"}, "3557": {"path": "/paddlevideo/modeling/framework/partitioners/base.py:28-55", "hash": "babffbaf165f5b72fe6d3b81aad8b244", "title": "Partitioned Model Initialization"}, "3558": {"path": "/paddlevideo/modeling/framework/partitioners/base.py:56-84", "hash": "ff61a4d3bb1badcbe950560d65189e4f", "title": "Base Model Partitioner Class"}, "3559": {"path": "/paddlevideo/modeling/framework/partitioners/transnetv2_partitioner.py", "hash": "1b52da32dddedad198e15ef9e15a2bc5", "title": "TransNetV2 Partitioner in PaddleVideo"}, "3560": {"path": "/paddlevideo/modeling/framework/partitioners/transnetv2_partitioner.py:1-32", "hash": "ca7c9e4964ee0959310270f0f2bd54a6", "title": "TransNetV2 Partitioner for PaddleVideo"}, "3561": {"path": "/paddlevideo/modeling/framework/partitioners/transnetv2_partitioner.py:33-54", "hash": "001629ec2b99c9e826e0104f77a0cb80", "title": "TransNetV2 Partitioner Loss Metrics"}, "3562": {"path": "/paddlevideo/modeling/framework/partitioners/transnetv2_partitioner.py:55-68", "hash": "5be6e179da11bb81bc528d38fb9e9469", "title": "TransnetV2 Partitioner Methods"}, "3563": {"path": "/paddlevideo/modeling/framework/recognizers/__init__.py", "hash": "f00bf8d794a8c50aaf356e7716dcf297", "title": "PaddleVideo Recognizers: Action & Motion"}, "3564": {"path": "/paddlevideo/modeling/framework/recognizers/__init__.py:1-23", "hash": "88c96cc42fe9b23590c21b51d7cd61d0", "title": "PaddleVideo Recognizers: A Versatile Toolkit"}, "3565": {"path": "/paddlevideo/modeling/framework/recognizers/__init__.py:25-30", "hash": "6575e4b81f36d1dcff2b7d76c06824fe", "title": "PaddleVideo Recognizer Models"}, "3566": {"path": "/paddlevideo/modeling/framework/recognizers/base.py", "hash": "87bd61d7e664633212c7a6a9aecfa2cb", "title": "Base Recognizer Model in PaddleVideo"}, "3567": {"path": "/paddlevideo/modeling/framework/recognizers/base.py:1-33", "hash": "acf2a27498e11e141ce3c4605a980427", "title": "Base Recognizer Class: Override Train, Valid, Test Steps"}, "3568": {"path": "/paddlevideo/modeling/framework/recognizers/base.py:34-66", "hash": "17dd47ff9cff4a55cbddb92c41a09120", "title": "Initialize and Train Model's Head"}, "3569": {"path": "/paddlevideo/modeling/framework/recognizers/base.py:67-81", "hash": "8d9745a49b0cbb2c4c951998d78f76d9", "title": "Abstract Base Recognizer Steps in PaddleVideo"}, "3570": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer1d.py", "hash": "28efe264f754e49622d7b8ba41c53ebc", "title": "1D Recognizer Model in PaddleVideo"}, "3571": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer1d.py:1-29", "hash": "fb6d0be018e373c206e280ddc8b50396", "title": "1D Recognizer Model Framework in PaddleVideo"}, "3572": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer1d.py:30-61", "hash": "4ad7be8e2f9093dae0c2de154ab75cf8", "title": "1D Recognizer Model Processing Image and Audio Data"}, "3573": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer1d.py:62-91", "hash": "fa24583216596690f9aec569f142d5ff", "title": "1D Recognizer Model Framework"}, "3574": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer1d.py:93-111", "hash": "fe823c1191d815f90137b78bb01bdcf0", "title": "Shared Implementation in Validating, Testing, and Inferring Steps"}, "3575": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer2d.py", "hash": "e6cdba583a0043f48446e18ad905b818", "title": "2D Video Recognizer in PaddleVideo"}, "3576": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer2d.py:1-27", "hash": "fec983d0706190c97bf9074358b5c119", "title": "2D Recognizer Model Framework in PaddleVideo"}, "3577": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer2d.py:28-60", "hash": "cdeaa6c74cca5ce4e85fe9ca3cf5b5fa", "title": "Video Analysis Recognizer2D Model"}, "3578": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer2d.py:60-69", "hash": "81949ad652723c8d49ffbbad137391ad", "title": "Recognizer2D Class and Methods: Forward Net and Infer Step"}, "3579": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3d.py", "hash": "f18d123d3bfc63ba0d696b749da24354", "title": "Recognizer3D: 3D Object Recognition Framework"}, "3580": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3d.py:1-33", "hash": "691508594c5da66b4991d9c8892fc609", "title": "3D Recognizer Framework in PaddleVideo"}, "3581": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3d.py:34-64", "hash": "010581b320ebd5c756bad73528758b6f", "title": "Training and Validation Steps in 3D Recognizer Model"}, "3582": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3d.py:66-93", "hash": "2377a47bc3341f0043bf7a5ee2f73469", "title": "Reshape Input for ResNet3dSlowOnly"}, "3583": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3dMRI.py", "hash": "57b8b2e1589049872840cfb9fc302345", "title": "3D Recognizer Model in PaddleVideo"}, "3584": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3dMRI.py:1-31", "hash": "a111a274dc01d959d30afab201a33309", "title": "3D MRI Recognizer Framework"}, "3585": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3dMRI.py:32-65", "hash": "124260c888336561acd5fb509e9060ef", "title": "3D MRI Recognizer Model Training and Testing"}, "3586": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer3dMRI.py:66-81", "hash": "5cb52f5e0497ab27bf3bef6cb76e492a", "title": "Dual Test/Infer Steps in Recognizer3D MRI Model"}, "3587": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py", "hash": "5ea9dd786f7dca9ccebbb509bfdcc366", "title": "Recognizer Distillation in PaddleVideo"}, "3588": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:1-34", "hash": "7c943f774171e5e019db600cd30cedb5", "title": "Recognizer Distillation Layer for PaddleVideo"}, "3589": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:35-60", "hash": "f595a20998203c7d1a49618c94e002f7", "title": "Distillation Model Initialization"}, "3590": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:61-85", "hash": "f7fbc6c12861130fe6fe2b80061ca956", "title": "Distillation Recognizer Model Initialization"}, "3591": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:86-114", "hash": "842cd7f75c9acf70054a881301df2fc7", "title": "Distillation Recognizer Framework"}, "3592": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:116-136", "hash": "38b544effbcccc2331f384c76311b010", "title": "Distillation Recognizer Loss Calculation"}, "3593": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:137-165", "hash": "7a51104811e2fa84116f6f4d8493cf7e", "title": "Training Step and Recognizer Distillation"}, "3594": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:167-193", "hash": "e95bd3ca5d93db6cf2e45af44dbc61fd", "title": "Distillation Recognizer Class"}, "3595": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:195-224", "hash": "ddba3abca9223c0adeca36b00b59694e", "title": "Evaluating Student Model in Image Recognition"}, "3596": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerDistillation.py:225-231", "hash": "7943604882b0857a01814cc9ba0d9bd7", "title": "Selecting and Applying Model"}, "3597": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerMRI.py", "hash": "d694e080a32b5624e83c1a554c3ec535", "title": "2D Image Classifier with PaddleVideo's RecognizerMRI"}, "3598": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerMRI.py:1-27", "hash": "b474c3acb56c78223374723247eb69b5", "title": "PaddleVideo: RecognizerMRI Framework"}, "3599": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerMRI.py:28-59", "hash": "e32f873677f0e265d1294dc1c0aaab83", "title": "Image Classification Model Definition"}, "3600": {"path": "/paddlevideo/modeling/framework/recognizers/recognizerMRI.py:60-76", "hash": "6065a096715c2b1e4e0fb0da6dd9adb5", "title": "Testing Steps without Head Loss"}, "3601": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_gcn.py", "hash": "d9c7bf9bc838d87918547f0f3675f88b", "title": "GCN Recognizer Model Framework"}, "3602": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_gcn.py:1-33", "hash": "abe7c09dda29e16f30d1796a861fa1ea", "title": "GCN Recognizer Model Framework"}, "3603": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_gcn.py:34-66", "hash": "cfa10fac94afa8724a4e49bc9a9de7ab", "title": "RecognizerGCN: Image Classification Model"}, "3604": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_gcn.py:67-87", "hash": "71a5cbc82176b956cf9eeb3e655f5216", "title": "GCN Recognizer Model with Test and Infer Steps"}, "3605": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_movinet_frame.py", "hash": "e0b2dd9c4b3defc77a842ec5e6d73c78", "title": "MoViNet Recognizer Framework"}, "3606": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_movinet_frame.py:1-33", "hash": "77ad568b5621c91737800dfa713a8d91", "title": "MoViNet Frame Recognizer Class"}, "3607": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_movinet_frame.py:34-57", "hash": "fd0bb6cd2d9e5f2edf91cba32e608200", "title": "Training and Validation Steps in Recognizer"}, "3608": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_movinet_frame.py:58-78", "hash": "95579ca288a54230ff94ab674fbf945b", "title": "Model's Forward, Test, and Infer Steps"}, "3609": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer.py", "hash": "f882ae128808665c2a12c89357697094", "title": "Transformer-Based Recognizer Model"}, "3610": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer.py:1-31", "hash": "67ed64365bb234950eb25d6a471ba2c0", "title": "Transformer-Based Recognizer Framework"}, "3611": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer.py:33-62", "hash": "097207192256865824a31d86ac09c24f", "title": "Training, Validation, Testing Steps in Recognizer Transformer"}, "3612": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer.py:63-86", "hash": "b57d83a7799f255738c36403ea268c0c", "title": "Multi-View Image Inference Model"}, "3613": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer.py:87-98", "hash": "4003abce501babe5332315a2604997bf", "title": "Averaging Method for Recognizer Transformer"}, "3614": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer_MRI.py", "hash": "7d982b2acc16e3ce873d6e6be5bcdfc3", "title": "Recognizer-Transformer MRI Model Code"}, "3615": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer_MRI.py:1-32", "hash": "5ddcb09c062f38721723a1e440923c21", "title": "RecognizerTransformer_MRI Model Definition"}, "3616": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer_MRI.py:33-63", "hash": "bb4f33c0e491ec4c211e6ce38bfac30a", "title": "Recognizer Transformer Image Classifier"}, "3617": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer_MRI.py:65-89", "hash": "ab5eb1965ab7a7463cbcb2d15ccf0aaf", "title": "Average-View Model Inference"}, "3618": {"path": "/paddlevideo/modeling/framework/recognizers/recognizer_transformer_MRI.py:90-104", "hash": "f95b391fecbd9a96cbddfdffd609b377", "title": "Combining Scores in Recognizer Transformer"}, "3619": {"path": "/paddlevideo/modeling/framework/segment/__init__.py", "hash": "e8b235c791b00b096fb4ee3cc5bf81a2", "title": "PaddleVideo Segment Models"}, "3620": {"path": "/paddlevideo/modeling/framework/segment/base.py", "hash": "a0560f0c7726e7f962384b92e97af38a", "title": "Semi-Video Object Segmentation Base Class"}, "3621": {"path": "/paddlevideo/modeling/framework/segment/base.py:1-29", "hash": "ce321359973aac51bb5524e797e5c2c6", "title": "Abstract Base Class for Semi-Video Object Segmentation"}, "3622": {"path": "/paddlevideo/modeling/framework/segment/base.py:30-57", "hash": "7ddade8e35f3f9d58d537e2497bc54e7", "title": "Segment Model Initialization and Forward Pass"}, "3623": {"path": "/paddlevideo/modeling/framework/segment/base.py:58-90", "hash": "48aaeea3786c7f0439b85da4723e4024", "title": "Abstract Class for Model Training Phases"}, "3624": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py", "hash": "e88dfb54fd64b0dd9a32f286ffeda48c", "title": "CFBI Model for AI Segmentation"}, "3625": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:1-30", "hash": "6c2c6799efd19e4ee3ccddef66fee0d4", "title": "CFBI Model Python Class"}, "3626": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:31-56", "hash": "664c7a59e89d8f49face423863dc7384", "title": "CFBI Framework Testing"}, "3627": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:57-84", "hash": "57e8be59a380245223c5b29a5982dea5", "title": "PaddleVideo CFBI Else Block"}, "3628": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:85-108", "hash": "3d16e2663ef4a1583f29a11ad415d284", "title": "Segmentation Head Initialization"}, "3629": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:109-127", "hash": "6af60fde61459db547327599920c409f", "title": "Resizing CFBI in PaddleVideo"}, "3630": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:128-144", "hash": "ecd05783b0a8da6f7b4b997f2c196894", "title": "Preparing Frame Embeddings for Attention and Loss Calculation"}, "3631": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:145-164", "hash": "f5d13eab6e7b59d782a789d680bc995c", "title": "Distance Bias Assignment for Frame Sequences"}, "3632": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:165-184", "hash": "d2a195c752c1e2e8406b4499828a49c5", "title": "NotImplementedError Handler"}, "3633": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:185-200", "hash": "9991c900e946ed8cab50b6f10e60f1e0", "title": "Global Matching Evaluation in CFBI Model"}, "3634": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:201-216", "hash": "8b453f365f35b2578a3f9b58d72545d8", "title": "Preparing Input for Local Matching Function"}, "3635": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:217-237", "hash": "80074bea902c3fde52ce98ffe6bd6a8f", "title": "Global/Local Background Subtraction for Image Segmentation"}, "3636": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:238-256", "hash": "ba1d9a6d563f95b4215a739a544fba4e", "title": "Video Segmentation Model Code"}, "3637": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:257-279", "hash": "af0d2bebdefaf1f249c8f5b1a75c62be", "title": "CFBI Attention Calculation"}, "3638": {"path": "/paddlevideo/modeling/framework/segment/cfbi.py:280-286", "hash": "3e78e916165eeb1ae690b1ae248557d7", "title": "Append and Pass for Attention Model"}, "3639": {"path": "/paddlevideo/modeling/framework/segment/utils.py", "hash": "497e15db17786182646ee5ae62a6223d", "title": "PaddleVideo Framework for Object Segment Matching"}, "3640": {"path": "/paddlevideo/modeling/framework/segment/utils.py:1-31", "hash": "c0cc8d91db604453246ced342838737a", "title": "Foreground to Background Distance Conversion"}, "3641": {"path": "/paddlevideo/modeling/framework/segment/utils.py:32-68", "hash": "3f7dc16213e97778465ca73c95cad07e", "title": "Pairwise L2 Distance Matrix Calculator"}, "3642": {"path": "/paddlevideo/modeling/framework/segment/utils.py:69-92", "hash": "0dc1dfe8e6f3c9fad785c9992e45db32", "title": "Pairwise Distance Computation and Feature Extraction"}, "3643": {"path": "/paddlevideo/modeling/framework/segment/utils.py:93-113", "hash": "9d9ea24dbdc859f67fb669f0decbb6ae", "title": "Nearest Neighbor Features Calculator"}, "3644": {"path": "/paddlevideo/modeling/framework/segment/utils.py:114-138", "hash": "525fafd395f1a2f3cfb5209951fbdeff", "title": "Query-Reference Frame Feature Computation"}, "3645": {"path": "/paddlevideo/modeling/framework/segment/utils.py:139-167", "hash": "bfa506e19548fb3bac0b4df9129d5eb3", "title": "Global Matching with Embedding Chunks"}, "3646": {"path": "/paddlevideo/modeling/framework/segment/utils.py:168-186", "hash": "df49b94353a60cc8462281100848d967", "title": "Nearest Neighbor Distance Calculator"}, "3647": {"path": "/paddlevideo/modeling/framework/segment/utils.py:187-209", "hash": "2a781d43b4b01d2cfc6d5d504b1ad5ff", "title": "Spatial Pyramid Pooling Point Padding"}, "3648": {"path": "/paddlevideo/modeling/framework/segment/utils.py:210-230", "hash": "6f5196a57c504eb288c1f781f7848524", "title": "Segmentation Method in PaddleVideo Library"}, "3649": {"path": "/paddlevideo/modeling/framework/segment/utils.py:231-257", "hash": "3f182156b1f010e5b60ee5f4b4b6358d", "title": "Nearest Neighbor Video Segment Matching"}, "3650": {"path": "/paddlevideo/modeling/framework/segment/utils.py:258-277", "hash": "50b1a6ec33ad1720ed2f1589af07a974", "title": "Distance to Nearest Neighbor Calculator"}, "3651": {"path": "/paddlevideo/modeling/framework/segment/utils.py:278-299", "hash": "ce45741ef3b1393666fa33edfe4b54d0", "title": "Atrous Tensor Matching Function"}, "3652": {"path": "/paddlevideo/modeling/framework/segment/utils.py:300-318", "hash": "891402125ce07de2c526421bd24efe59", "title": "Image Segmentation Atrous Rate Code"}, "3653": {"path": "/paddlevideo/modeling/framework/segment/utils.py:320-338", "hash": "ebf38e5c8a2f6ed84bd6f26741d4737e", "title": "Concatenate and Pad Embeddings"}, "3654": {"path": "/paddlevideo/modeling/framework/segment/utils.py:339-356", "hash": "8d51670269b7ee742e055f2564590727", "title": "Embedding Reshaper"}, "3655": {"path": "/paddlevideo/modeling/framework/segment/utils.py:357-375", "hash": "3154c480d8c863951e25fe2a8bc5ada0", "title": "Atrous Spatial Pyramid Pooling Padder"}, "3656": {"path": "/paddlevideo/modeling/framework/segment/utils.py:376-394", "hash": "dc05a70d8a6977a27b8c96741513a269", "title": "Flattened Embeddings Conversion"}, "3657": {"path": "/paddlevideo/modeling/framework/segment/utils.py:395-415", "hash": "a57dbfe21dac58547a52967bb1068630", "title": "Feature Selection and Reshaping for Segment Matching"}, "3658": {"path": "/paddlevideo/modeling/framework/segment/utils.py:416-442", "hash": "5eef61da1b434782f5c9a8a9161226b7", "title": "Pairwise L2 Distance Nearest Neighbor Features"}, "3659": {"path": "/paddlevideo/modeling/framework/segment/utils.py:443-464", "hash": "b757c8522e7c829c0dc0faaad9c36d2c", "title": "Downsampling with Bilinear Interpolation"}, "3660": {"path": "/paddlevideo/modeling/framework/segment/utils.py:465-492", "hash": "2da581c56596518b1f1fc73eed414e5a", "title": "Atrous Dilation Pairwise Distance Calculation"}, "3661": {"path": "/paddlevideo/modeling/framework/segment/utils.py:493-513", "hash": "3902f2ec1b1d4adf794b691a45d1c668", "title": "Pairwise L2 Distance Compute Function"}, "3662": {"path": "/paddlevideo/modeling/framework/segment/utils.py:514-537", "hash": "b192741c54fce49a9180e0aa37dabb5f", "title": "Downsizing and Padding Tensors"}, "3663": {"path": "/paddlevideo/modeling/framework/segment/utils.py:539-566", "hash": "054b65ee6b2c2dd5080678abff41204b", "title": "Distance Calculator for Frame Embeddings"}, "3664": {"path": "/paddlevideo/modeling/framework/segment/utils.py:567-584", "hash": "a520cab335bbf72d0381d1ebc7e942f3", "title": "Nearest Neighbor Video Segmentation"}, "3665": {"path": "/paddlevideo/modeling/framework/segment/utils.py:585-609", "hash": "c9f1d434fa8d52a82b07a0e4258c504d", "title": "Parallel Nearest Neighbor Calculation"}, "3666": {"path": "/paddlevideo/modeling/framework/segment/utils.py:610-635", "hash": "4b00d078ed4df7d55eb3c5847c026635", "title": "Pairwise Distance Calculator"}, "3667": {"path": "/paddlevideo/modeling/framework/segment/utils.py:637-662", "hash": "6a1a0846e2d9c8fb76802a8dbd07c535", "title": "Atrous Spatial Pyramid Pooling in PaddlePaddle"}, "3668": {"path": "/paddlevideo/modeling/framework/segment/utils.py:663-684", "hash": "1f8e02a2559ebb6143657b4476cd5ab4", "title": "Image Segmentation with Distance Matrix"}, "3669": {"path": "/paddlevideo/modeling/framework/segment/utils.py:685-709", "hash": "c5f23d19670afcdaea34fdc7d2a757b9", "title": "Attention Heads Calculator"}, "3670": {"path": "/paddlevideo/modeling/framework/segment/utils.py:710-736", "hash": "012b4c92ac73b78d29efcf302a444700", "title": "Attention Head Evaluation"}, "3671": {"path": "/paddlevideo/modeling/framework/segment/utils.py:737-754", "hash": "4c20b3affc9ab8f56a1c2e92315325c0", "title": "Total Head Calculation with Stability"}, "3672": {"path": "/paddlevideo/modeling/framework/segmenters/__init__.py", "hash": "84720a22568b454d78570812ff4885cc", "title": "PaddleVideo Segmenter Modules"}, "3673": {"path": "/paddlevideo/modeling/framework/segmenters/asrf.py", "hash": "2c6c3ba13ba3c982786b73d20a1b9639", "title": "ASRF Segmentation Model in PaddleVideo"}, "3674": {"path": "/paddlevideo/modeling/framework/segmenters/asrf.py:1-33", "hash": "7e189d4dda23d8c064b10fb64e3d73b2", "title": "ASRF: PaddleVideo Segmenter Model"}, "3675": {"path": "/paddlevideo/modeling/framework/segmenters/asrf.py:34-67", "hash": "48bcbfb8f15be7695903268f2b20e564", "title": "Segmentation Model Training Code"}, "3676": {"path": "/paddlevideo/modeling/framework/segmenters/asrf.py:69-100", "hash": "0914e42ec1b2c02631d34a965d03eee4", "title": "ASRF Model Validation Step"}, "3677": {"path": "/paddlevideo/modeling/framework/segmenters/asrf.py:101-129", "hash": "407932551cf071e6ced64fd14e3bb490", "title": "ASRF Segmentation Model Inference"}, "3678": {"path": "/paddlevideo/modeling/framework/segmenters/asrf.py:130-143", "hash": "a4eb4042150f8dd54290d8f6f19c296d", "title": "Forward Pass and Sigmoid Application"}, "3679": {"path": "/paddlevideo/modeling/framework/segmenters/base.py", "hash": "ef455dfd5240fa7a2b29e96e46fa5d88", "title": "BaseSegmenter: Foundation for PaddleVideo Segmenters"}, "3680": {"path": "/paddlevideo/modeling/framework/segmenters/base.py:1-30", "hash": "c3d53cbed71982a888d363248b81ac1d", "title": "BaseSegmenter: Foundation for All Segmenters"}, "3681": {"path": "/paddlevideo/modeling/framework/segmenters/base.py:32-63", "hash": "12042e4c8d98b1693b0b15eb42ad1a4b", "title": "Segmenter Base Class Init"}, "3682": {"path": "/paddlevideo/modeling/framework/segmenters/base.py:64-99", "hash": "152307638c62e0f76ebf2b94bda2aca3", "title": "Trainable Segmenter Base Class"}, "3683": {"path": "/paddlevideo/modeling/framework/segmenters/base.py:100-100", "hash": "d23bac234f663a671d44802b96010000", "title": "NotImplementedError in Base Segmenter"}, "3684": {"path": "/paddlevideo/modeling/framework/segmenters/ms_tcn.py", "hash": "ce778e99471f4b5431757041068f53ce", "title": "MS-TCN Video Segmentation Tool"}, "3685": {"path": "/paddlevideo/modeling/framework/segmenters/ms_tcn.py:1-33", "hash": "c67db889536cc475144e88679fe5860f", "title": "MS-TCN Video Segmenter"}, "3686": {"path": "/paddlevideo/modeling/framework/segmenters/ms_tcn.py:34-70", "hash": "595aa0fdb789fd0e6f3f1051a8d1a4d0", "title": "MS-TCN Segmenter Training and Validation"}, "3687": {"path": "/paddlevideo/modeling/framework/segmenters/ms_tcn.py:72-101", "hash": "03d30d1f9e40a7023468953618d7f1da", "title": "MS-TCN Model: Train, Test, and Infer Functions"}, "3688": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py", "hash": "189ea9ac00e66401b1aba144023078ec", "title": "Gaussian Smoothing in PaddlePaddle"}, "3689": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:1-30", "hash": "a48b826fb16b9aeff7931d38791a5a65", "title": "Gaussian Smoothing in PaddlePaddle"}, "3690": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:31-62", "hash": "64f1cb2f355206f59b94432f3fc5fa28", "title": "Gaussian Kernel Initialization and Application"}, "3691": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:63-95", "hash": "1d31cbc04070ae3396fbb36ce4e0bf6c", "title": "1D Convolution and Argrelmax Functions for Image Processing"}, "3692": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:97-146", "hash": "54d8103e4aaab63b98b8db1cd909e3df", "title": "Tensor Conversion Functions"}, "3693": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:149-176", "hash": "5eb52370ac1e5053ab45ee80f2e0f52b", "title": "Boundary-Based Action Segmentation"}, "3694": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:177-203", "hash": "cf0eac81fb2fde7b5d9dfc026dfac6d3", "title": "Majority Class Action Segmentation"}, "3695": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:204-242", "hash": "8a4d9ba05198313b24a6cfccc02efa80", "title": "Smoothing and Relabeling Functions"}, "3696": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:243-270", "hash": "413d8b8367b44e773d25e830da844889", "title": "ASRF Post-Processing for Action Segmentation"}, "3697": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:271-301", "hash": "78233ac8db297db218db7bcdd3a824d4", "title": "Tensor Fan-In/Out and Refinement Function"}, "3698": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:302-335", "hash": "d2897532974c2dc6898e136a354222b2", "title": "Neural Network Weight Initialization Code"}, "3699": {"path": "/paddlevideo/modeling/framework/segmenters/utils.py:336-343", "hash": "064edf5e1b1d7e970fbc3cd55023f4cc", "title": "Initialize Weights and Biases for Neural Network Layer"}, "3700": {"path": "/paddlevideo/modeling/heads/__init__.py", "hash": "7a0e36dc6b9dcff4a4dd4333d6eaf407", "title": "Importing Video Heads from PaddleVideo"}, "3701": {"path": "/paddlevideo/modeling/heads/__init__.py:1-25", "hash": "349392f1597ee247a5d3d66ec6ee03d5", "title": "Importing PaddleVideo Heads"}, "3702": {"path": "/paddlevideo/modeling/heads/__init__.py:26-49", "hash": "476acb972e05f6108931983936b6d01c", "title": "Versatile Video Heads Import"}, "3703": {"path": "/paddlevideo/modeling/heads/adds_head.py", "hash": "8ef3a0eda00742eaa08c953b245cc26f", "title": "AddsHead: Object Detection in PaddleVideo"}, "3704": {"path": "/paddlevideo/modeling/heads/adds_head.py:1-33", "hash": "e0b58fb5570c14b298febc678ea729b2", "title": "AddsHead Class Definition"}, "3705": {"path": "/paddlevideo/modeling/heads/adds_head.py:34-62", "hash": "aff9ccc22d3a0f8b92fdfdc28364a7e2", "title": "AddsHead: Initialization and Forward Pass"}, "3706": {"path": "/paddlevideo/modeling/heads/adds_head.py:63-95", "hash": "44b2902e96508beff09982ad5ad9411e", "title": "AddsHead: Compute Error Metrics"}, "3707": {"path": "/paddlevideo/modeling/heads/adds_head.py:96-117", "hash": "224adee361ffcb654f99baf6d9039f65", "title": "Multi-GPU Tensor Averaging"}, "3708": {"path": "/paddlevideo/modeling/heads/adds_head.py:118-144", "hash": "a604d2b45124844162f941e756c1f1ab", "title": "Error Metrics in Depth Prediction"}, "3709": {"path": "/paddlevideo/modeling/heads/adds_head.py:146-146", "hash": "7cd3ab5af0463b1117ddcf036b5ebbeb", "title": "Metrics for Regression Models"}, "3710": {"path": "/paddlevideo/modeling/heads/agcn2s_head.py", "hash": "8542a224b4593d99658eaac21e4a8761", "title": "AGCN2s Head: PaddleVideo's Versatile Model Component"}, "3711": {"path": "/paddlevideo/modeling/heads/agcn2s_head.py:1-32", "hash": "1e521fdb4e7f64dd25b1cfa3a8198655", "title": "AGCN2s Head Class in PaddleVideo"}, "3712": {"path": "/paddlevideo/modeling/heads/agcn2s_head.py:33-56", "hash": "c23ef34f9d51f84335372fee6e09774d", "title": "Agcn2sHead: Initialize Linear Layer and Reshape"}, "3713": {"path": "/paddlevideo/modeling/heads/agcn2s_head.py:57-59", "hash": "ad339d46ae161a8e6c883da80e0eba26", "title": "Average-Then-FC Aggregation"}, "3714": {"path": "/paddlevideo/modeling/heads/asrf_head.py", "hash": "df95e21baa757ae34d65dba8826f0066", "title": "ASRF Head: Action Recognition and Metrics"}, "3715": {"path": "/paddlevideo/modeling/heads/asrf_head.py:1-32", "hash": "49f61ca50d5b3d3a5f5cfd291f851ce3", "title": "ASRF Head: PaddleVideo Modeling"}, "3716": {"path": "/paddlevideo/modeling/heads/asrf_head.py:34-63", "hash": "45eb25b4cfed7be627d84915f3cbb5f1", "title": "ASRF Head Model Initialization"}, "3717": {"path": "/paddlevideo/modeling/heads/asrf_head.py:64-98", "hash": "fbb50ce57e1f173e0255d3972ebe1e50", "title": "ASRF Head Model: Forward Pass and Weights Init"}, "3718": {"path": "/paddlevideo/modeling/heads/asrf_head.py:100-136", "hash": "0912b504e69eaeda3bab8f092843a066", "title": "ASRF Head and F1 Score Calculation"}, "3719": {"path": "/paddlevideo/modeling/heads/asrf_head.py:137-170", "hash": "433903a8154e16171a8be4ef23565cda", "title": "ASRF Head: Labels and Levenshtein Distance"}, "3720": {"path": "/paddlevideo/modeling/heads/asrf_head.py:171-200", "hash": "fd20b004a3d9f12d7db0568af7da248f", "title": "Edit Score Calculation with Levenshtein Distance"}, "3721": {"path": "/paddlevideo/modeling/heads/asrf_head.py:201-212", "hash": "c4ff7771783aa50b091d27273b2d8565", "title": "ASRF Head: Calculating Metrics"}, "3722": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py", "hash": "2997780b8291d981c8fdb52e132ea5b1", "title": "LSTM Attention Mechanism for PaddleVideo"}, "3723": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:1-32", "hash": "0b3537589eacd92fc06a3fb74ee4732e", "title": "Attention LSTM Head: PaddleVideo's Neural Network Component"}, "3724": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:33-53", "hash": "add5aa2e2d67c22c54a731dafe6b267a", "title": "Bi-directional LSTM Attention Head for Video Classification"}, "3725": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:54-74", "hash": "47c26f0e1b2f42ccae3e62eb84dac556", "title": "Bidirectional LSTM Attention Head"}, "3726": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:75-95", "hash": "e6d68c45f6bd5ddb2eb92b144b2f9ae8", "title": "Attention LSTM Head in PaddleVideo"}, "3727": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:96-120", "hash": "0b1b85f759901357569614d5acd8ab6a", "title": "Attention LSTM Head"}, "3728": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:121-144", "hash": "44812590752788eaff419cf1bf7627a2", "title": "Attention LSTM Sequence Modeling Head"}, "3729": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:145-173", "hash": "e6097307d934cc41edad8fafd1fefab7", "title": "Attention LSTM Head Metrics"}, "3730": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:174-195", "hash": "17662b44d750ec1567db55aff04d5feb", "title": "Bidirectional LSTM Attention Mechanism for Multimodal Fusion"}, "3731": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:196-221", "hash": "9942f201e7b4980594e12059b3e97963", "title": "Attention-based LSTM Head in PaddleVideo"}, "3732": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:222-244", "hash": "b02af59130430792c510571c461eb5c3", "title": "Bi-directional LSTM Attention Head"}, "3733": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:245-267", "hash": "eae3c44c4ef69d188e86bcc414ba51fb", "title": "LSTM-based Attention Pooling for Neural Networks"}, "3734": {"path": "/paddlevideo/modeling/heads/attention_lstm_head.py:268-288", "hash": "c8201d17241b30ee21043e3b14ab4925", "title": "LSTM Attention Head with Loss and Metrics"}, "3735": {"path": "/paddlevideo/modeling/heads/base.py", "hash": "37064db3837c3920a65a7d12ca7ea477", "title": "PaddleVideo Classification Head: Versatile, Distributed"}, "3736": {"path": "/paddlevideo/modeling/heads/base.py:1-34", "hash": "5f8b63777c3c06713be561bf1d49de5a", "title": "Base Head Initializer: Initialize Weights for Subclasses"}, "3737": {"path": "/paddlevideo/modeling/heads/base.py:35-65", "hash": "7e6d40f745bf0fab1e5430b23d7fd7bf", "title": "PaddleVideo Classification Head Base"}, "3738": {"path": "/paddlevideo/modeling/heads/base.py:67-91", "hash": "cff327b7e16576f52fe150d2d2dd453b", "title": "Loss, Accuracy Calculator"}, "3739": {"path": "/paddlevideo/modeling/heads/base.py:92-113", "hash": "ed8dec5d7561bdd691673a9b6fd301d1", "title": "Mix-up Loss for MRI Classification"}, "3740": {"path": "/paddlevideo/modeling/heads/base.py:114-143", "hash": "816d6c2aedafa39ffea5677898fd64b1", "title": "Classification Loss Function"}, "3741": {"path": "/paddlevideo/modeling/heads/base.py:144-164", "hash": "83b222edbd2af11cdbb3a6d73201c6f1", "title": "Uniform Hard/Soft Loss Calculation"}, "3742": {"path": "/paddlevideo/modeling/heads/base.py:165-178", "hash": "62c5d3cd59b99a64f19c2474f1557239", "title": "Average Metrics Across Devices"}, "3743": {"path": "/paddlevideo/modeling/heads/bbox_head.py", "hash": "f9237353026c5a3e54e7289dc3868b48", "title": "BBoxHeadAVA: Box Detection and Evaluation"}, "3744": {"path": "/paddlevideo/modeling/heads/bbox_head.py:1-32", "hash": "3534cbdb22ad3d9c51027308116a7559", "title": "BBoxHeadAVA: Simple RoI Head with Pooling Options"}, "3745": {"path": "/paddlevideo/modeling/heads/bbox_head.py:33-61", "hash": "e54f2ca85e57e04bf5ba85751178d917", "title": "Class BBoxHeadAVA Initialization"}, "3746": {"path": "/paddlevideo/modeling/heads/bbox_head.py:62-83", "hash": "a1243715a75ebaadb34db02e7c75fe53", "title": "BBoxHead Model Initialization"}, "3747": {"path": "/paddlevideo/modeling/heads/bbox_head.py:85-106", "hash": "1d31ab148be850e10c0d3c87d5ba9855", "title": "Bbox Head Classification and Debug Image Init"}, "3748": {"path": "/paddlevideo/modeling/heads/bbox_head.py:107-126", "hash": "c238413e3b2c45dbff38ebd3914c0e6c", "title": "BBox Head Generator in PaddleVideo"}, "3749": {"path": "/paddlevideo/modeling/heads/bbox_head.py:128-152", "hash": "befe3713036d5ed1c5dacad18fe806ea", "title": "PaddleVideo Bbox Head Labeling and Comparison"}, "3750": {"path": "/paddlevideo/modeling/heads/bbox_head.py:153-171", "hash": "02716709c251af6be307a4b8827a2215", "title": "Multi-Label Recall and Precision Calculation"}, "3751": {"path": "/paddlevideo/modeling/heads/bbox_head.py:172-195", "hash": "2627fa986ea65b965a8692617b9d4620", "title": "BBox Head: Recall and Precision Calculation"}, "3752": {"path": "/paddlevideo/modeling/heads/bbox_head.py:196-218", "hash": "c17c37ca731bfd7dc36c6dd057879b5e", "title": "Bounding Box Heads: Accuracy and Loss Calculation"}, "3753": {"path": "/paddlevideo/modeling/heads/bbox_head.py:219-225", "hash": "5a41a1ac68021e4baa6876c4bc6a4a0f", "title": "Calculating BBox Scores in PaddleVideo Model"}, "3754": {"path": "/paddlevideo/modeling/heads/cfbi_head.py", "hash": "19295a2196d3be73fa69e8da45844e40", "title": "Multi-Input Collaborative Ensembler Network"}, "3755": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:1-32", "hash": "5cbbf0217b762a04d7b4c551ce1722e6", "title": "IA_Gate Layer Class Definition"}, "3756": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:33-65", "hash": "1564fbcbe8bdd339c3833b71a7125902", "title": "GCT Layer Definition and Initialization"}, "3757": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:66-95", "hash": "5ed32602fc417116d1df340592e34714", "title": "PaddleVideo's CFBI Head"}, "3758": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:96-119", "hash": "2351a8324a824e9e59421d551cd7f10a", "title": "CFBI Head: BatchNorm-ConvNet with ReLU"}, "3759": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:120-160", "hash": "2c729e70dd6b308e859f09eb484adc38", "title": "Convolutional Feature Fusion Head (CFBI)"}, "3760": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:161-193", "hash": "513bc98ed904a243f31c9a83891bc739", "title": "Convolutional Feature Fusion Block and ASPP Module"}, "3761": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:195-218", "hash": "28237bc7909541707db76ba1c5e8f6b1", "title": "ASPP Modules with Global Pooling in CFBI Head"}, "3762": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:220-251", "hash": "6114bb450f93cf4f259f9d64e0b8f86c", "title": "CFBI Head: Deep Feature Extraction and Aggregation"}, "3763": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:254-279", "hash": "a84fa2e26d49115f53326fdd703069d3", "title": "CollaborativeEnsemblerMS Class in PaddleVideo"}, "3764": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:281-306", "hash": "cd93887a252495daa16932626afba923", "title": "Multi-Stage Transformer Layer Initialization"}, "3765": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:308-332", "hash": "da9e845e49c863f8fa6d95dfd9b8aee2", "title": "Feature Extraction and Fusion Model Components"}, "3766": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:333-360", "hash": "90ffcce88afa2c3ae9c88d046f575ae2", "title": "Neural Network Architecture for CV Task"}, "3767": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:361-401", "hash": "422b34a5524a5f5e654c087eb0d5d471", "title": "Instance Segmentation Network Architecture with ASPP Module"}, "3768": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:402-433", "hash": "f3e94d097486c1fdc5b10bde90e09216", "title": "Convolutional Feature Binding IA Head"}, "3769": {"path": "/paddlevideo/modeling/heads/cfbi_head.py:435-448", "hash": "dad61005c9eceb4e1b1d30d74467874f", "title": "Augmented Background Logit Fusion"}, "3770": {"path": "/paddlevideo/modeling/heads/ctrgcn_head.py", "hash": "386f241bedb6eefd0e427e95e299be37", "title": "CTR-GCN Neural Network Head"}, "3771": {"path": "/paddlevideo/modeling/heads/ctrgcn_head.py:1-32", "hash": "8685a894e7d06ed864c235c0b7305456", "title": "CTR-GCN Head in PaddleVideo"}, "3772": {"path": "/paddlevideo/modeling/heads/ctrgcn_head.py:34-63", "hash": "45338577704a81b75c59a7d9e49dfe62", "title": "Neural Network Head Constructor with Dropout"}, "3773": {"path": "/paddlevideo/modeling/heads/ctrgcn_head.py:65-65", "hash": "469fa94828181561c4a21cf83c014cd1", "title": "FC Layer in CTRGCN Head"}, "3774": {"path": "/paddlevideo/modeling/heads/i3d_head.py", "hash": "787acd934c8e2485dfedbeaa39ecbb57", "title": "I3D Classification Head in PaddleVideo"}, "3775": {"path": "/paddlevideo/modeling/heads/i3d_head.py:1-31", "hash": "6de47f800601953380c89cc39bac31ec", "title": "I3D Head: Classification for PaddleVideo"}, "3776": {"path": "/paddlevideo/modeling/heads/i3d_head.py:32-59", "hash": "4cca39c61e0f1c6995e671e55224c837", "title": "I3D Head Class Constructor"}, "3777": {"path": "/paddlevideo/modeling/heads/i3d_head.py:60-91", "hash": "3c5da8ef43c89b581abe72175ea371ec", "title": "I3D Head: Feature Processing and Classification"}, "3778": {"path": "/paddlevideo/modeling/heads/i3d_head.py:92-95", "hash": "b3519cdaec142a96e175d22d5bf7e2af", "title": "Output Layer for PaddleVideo Classification"}, "3779": {"path": "/paddlevideo/modeling/heads/movinet_head.py", "hash": "fd4a4637458892a759578e567f7aa23e", "title": "MoViNetHead: Custom Head for Video Classification"}, "3780": {"path": "/paddlevideo/modeling/heads/ms_tcn_head.py", "hash": "ac4225305eff267ec80e86e29283bc0a", "title": "MS-TCN Head: Loss Calculation"}, "3781": {"path": "/paddlevideo/modeling/heads/ms_tcn_head.py:1-33", "hash": "2b38514f6bbe6a7832fa4068e1d940bb", "title": "MS-TCN Head: CrossEntropy and MSE Losses"}, "3782": {"path": "/paddlevideo/modeling/heads/ms_tcn_head.py:34-68", "hash": "f99a173d7ea5e36907871ab0f43e7eb0", "title": "MS-TCN Head: Loss and F1 Score Calculation"}, "3783": {"path": "/paddlevideo/modeling/heads/ms_tcn_head.py:69-105", "hash": "79a6b610568788891493fc01af8970aa", "title": "F1 Score Calculation and Label Extraction Algorithm"}, "3784": {"path": "/paddlevideo/modeling/heads/ms_tcn_head.py:106-137", "hash": "b952a96f66c0cae7ca3b195694d3e754", "title": "Edit Score Calculation Functions"}, "3785": {"path": "/paddlevideo/modeling/heads/ms_tcn_head.py:138-165", "hash": "c53db36308edb252f7893422f347c38d", "title": "F-score Calculator for Labeled Sequences"}, "3786": {"path": "/paddlevideo/modeling/heads/pptimesformer_head.py", "hash": "5db56e6fef45fa2021ca381e287711b0", "title": "PaddlePaddle TimeSformer Head"}, "3787": {"path": "/paddlevideo/modeling/heads/pptimesformer_head.py:1-30", "hash": "52f069299f69ebd485962307ca512d18", "title": "Introducing ppTimeSformerHead Class"}, "3788": {"path": "/paddlevideo/modeling/heads/pptimesformer_head.py:31-58", "hash": "f96ceedc5e775508a0888b7a80257aaf", "title": "PPTimesformerHead: Paddle Video Model Class"}, "3789": {"path": "/paddlevideo/modeling/heads/pptimesformer_head.py:59-74", "hash": "cdc21d18271d28737bfb0e5d3fdfe848", "title": "PPTimesformer Head Definition"}, "3790": {"path": "/paddlevideo/modeling/heads/pptsm_head.py", "hash": "d815fc9a525f12763be5f0d14bf9af3e", "title": "PaddlePaddle Video: PPTSMHead Initialization"}, "3791": {"path": "/paddlevideo/modeling/heads/pptsm_head.py:1-31", "hash": "e18be863a92905feb4ca09db6dbfc39a", "title": "ppTSMHead: PaddleVideo Registry Class"}, "3792": {"path": "/paddlevideo/modeling/heads/pptsm_head.py:32-58", "hash": "26d5a4e0ce88090cd215d89a2b1e70b0", "title": "PPTSM Head Initialization"}, "3793": {"path": "/paddlevideo/modeling/heads/pptsm_head.py:59-87", "hash": "ecc653049729258ad0ac89b2722fefad", "title": "PPTSM Head Initialization"}, "3794": {"path": "/paddlevideo/modeling/heads/pptsm_head.py:88-92", "hash": "530aa2b0ec8126772a39369909a9ba4c", "title": "PaddleVideo's PptsmHead FC Function"}, "3795": {"path": "/paddlevideo/modeling/heads/pptsn_head.py", "hash": "987c38f13c37dc0bbf27866190a270ef", "title": "PaddlePaddle PP-TSN Head Classification"}, "3796": {"path": "/paddlevideo/modeling/heads/pptsn_head.py:1-30", "hash": "23af7c74394c1e0910acdba8b7730179", "title": "Python PP-TSN Head Implementation"}, "3797": {"path": "/paddlevideo/modeling/heads/pptsn_head.py:31-54", "hash": "7818ff5c9f40719261c0c500b0909e6f", "title": "Adaptive Pooling PPTSN Head"}, "3798": {"path": "/paddlevideo/modeling/heads/pptsn_head.py:56-84", "hash": "9111a3c7bef36dc0b11da620a4350d2a", "title": "PaddlePaddle Classification Head Code"}, "3799": {"path": "/paddlevideo/modeling/heads/pptsn_head.py:85-103", "hash": "58f43449132426469bca8ce96c26a3ae", "title": "PPTSN Head Processing"}, "3800": {"path": "/paddlevideo/modeling/heads/roi_extractor.py", "hash": "33990fc44ccd2bcf8636b1c7bfaa24b6", "title": "RoIAlign: Region Feature Alignment"}, "3801": {"path": "/paddlevideo/modeling/heads/roi_extractor.py:1-31", "hash": "19b7ca545bf9fb355141b9598d9ea77f", "title": "RoIAlign: Feature Alignment Tool"}, "3802": {"path": "/paddlevideo/modeling/heads/roi_extractor.py:32-53", "hash": "b221d88f1a1d9b5330ea22ce8d8a5c6c", "title": "ROI Alignment with PaddlePaddle"}, "3803": {"path": "/paddlevideo/modeling/heads/roi_head.py", "hash": "4ad51b2ae316c0542fb62dac54795e6a", "title": "ROI Head for Object Detection"}, "3804": {"path": "/paddlevideo/modeling/heads/roi_head.py:1-29", "hash": "0edbd3f114dd6edccc3b3ac806890184", "title": "Bounding Box to Detection Results Converter"}, "3805": {"path": "/paddlevideo/modeling/heads/roi_head.py:30-59", "hash": "d5146cb636ece616d226c4c34496d4a7", "title": "NMS-Based Bounding Box Filtering"}, "3806": {"path": "/paddlevideo/modeling/heads/roi_head.py:60-93", "hash": "1ab9958834151b73f681ac553c73fa38", "title": "PaddlePaddle RoI Head Class"}, "3807": {"path": "/paddlevideo/modeling/heads/roi_head.py:94-114", "hash": "5b1f64b769bd9382a22ad59ce38304c5", "title": "Bbox Head Initialization and Feature Extraction"}, "3808": {"path": "/paddlevideo/modeling/heads/roi_head.py:115-134", "hash": "800707b11c5a44606274117ddf2d5070", "title": "ROI Head: Bbox Loss Calculation and Assignment"}, "3809": {"path": "/paddlevideo/modeling/heads/roi_head.py:135-158", "hash": "ecf4c9d7ce9fdcc15d55e040ed31b95d", "title": "RoI Head BBox Prediction Functions"}, "3810": {"path": "/paddlevideo/modeling/heads/roi_head.py:159-177", "hash": "26a2c768fbb45fa29ecd3ec409f9961c", "title": "Detect Bboxes Without Augmentation"}, "3811": {"path": "/paddlevideo/modeling/heads/single_straight3d.py", "hash": "9cbfb8cebb39b11227958311b2bf9975", "title": "Single Straight 3D ROI Extractor"}, "3812": {"path": "/paddlevideo/modeling/heads/single_straight3d.py:1-28", "hash": "eb478a5275e1a78926014308569b1fbf", "title": "SingleRoIExtractor3D: RoI Extractor for 3D Features"}, "3813": {"path": "/paddlevideo/modeling/heads/single_straight3d.py:29-55", "hash": "c889f95ba01d8fa56feb4258cd5cb4d7", "title": "3D Head Feature Extraction"}, "3814": {"path": "/paddlevideo/modeling/heads/single_straight3d.py:56-79", "hash": "23bfa60f0f7c998bff9525762ee45aca", "title": "Spatio-Temporal Feature Extraction and ROI Pooling"}, "3815": {"path": "/paddlevideo/modeling/heads/slowfast_head.py", "hash": "a89efdfa957537ca710abe439859fd74", "title": "SlowFast 3D Head Initialization"}, "3816": {"path": "/paddlevideo/modeling/heads/slowfast_head.py:1-30", "hash": "af7596ee359c82f614ed4b6d606033cf", "title": "SlowFast Head: PaddleVideo ResNeXt 3D Projection"}, "3817": {"path": "/paddlevideo/modeling/heads/slowfast_head.py:31-56", "hash": "7c72119b924e24a529cc3d67159bba80", "title": "SlowFast_Head: Concatenating Multi-Pathway Classifier"}, "3818": {"path": "/paddlevideo/modeling/heads/slowfast_head.py:57-83", "hash": "b68ae62cd818f669a9167102da6ae170", "title": "Initializing SlowFast Head Model Parameters"}, "3819": {"path": "/paddlevideo/modeling/heads/slowfast_head.py:84-113", "hash": "325e112fb20162f0ab952a2cee301ee1", "title": "SlowFast Head Model Initialization"}, "3820": {"path": "/paddlevideo/modeling/heads/slowfast_head.py:114-137", "hash": "80822321a533a4d2d921e6e50f723355", "title": "SlowFast Head: Pooling and Dropout Operations"}, "3821": {"path": "/paddlevideo/modeling/heads/stgcn_head.py", "hash": "e4df9fc01a835f963337097e37f7d39c", "title": "STGCN Head Initialization and Forward Pass"}, "3822": {"path": "/paddlevideo/modeling/heads/stgcn_head.py:1-32", "hash": "6ee61791a4679a3558c0458b1bc6569a", "title": "STGCN Head: PaddlePaddle's Video Modeling Class"}, "3823": {"path": "/paddlevideo/modeling/heads/stgcn_head.py:33-50", "hash": "b7485b7c63f9c81714097f0f9b77f879", "title": "Convolutional STGCN Head"}, "3824": {"path": "/paddlevideo/modeling/heads/timesformer_head.py", "hash": "49c9f82bda568463bb26f1a8f4b83c7e", "title": "TimeSformer Head: TimeSformer's Model Head"}, "3825": {"path": "/paddlevideo/modeling/heads/timesformer_head.py:1-29", "hash": "3da3b9642d00a4bd3a3c23d911f8b42b", "title": "TimeSformer Head Class"}, "3826": {"path": "/paddlevideo/modeling/heads/timesformer_head.py:30-60", "hash": "383b6239d6130a3fde64845574392bfd", "title": "TimeSformer Head: PaddlePaddle's Dynamic Initialization"}, "3827": {"path": "/paddlevideo/modeling/heads/timesformer_head.py:61-70", "hash": "acf77cc1674e99bf0422f8865fa5054e", "title": "Fully Connected Layer with Dropout Clarification"}, "3828": {"path": "/paddlevideo/modeling/heads/token_shift_head.py", "hash": "dd3c9a896ad1dd0e99bb38bd69affb6f", "title": "TokenShiftHead: Paddle's Classification Framework"}, "3829": {"path": "/paddlevideo/modeling/heads/token_shift_head.py:1-30", "hash": "6eff9dac6f9cbe9fa94a634e9a7dc48f", "title": "TokenShiftHead: Transformer Classification Task Head"}, "3830": {"path": "/paddlevideo/modeling/heads/token_shift_head.py:31-60", "hash": "eedb60d205d528c6d64af374b60ec073", "title": "Initializing Token Shift Head Parameters"}, "3831": {"path": "/paddlevideo/modeling/heads/token_shift_head.py:61-79", "hash": "bd02a8d3773e1eb8787a2375095e6c24", "title": "TokenShiftHead: Classification Scores for Each Frame"}, "3832": {"path": "/paddlevideo/modeling/heads/transnetv2_head.py", "hash": "0f5d585b500e1ed3bd876e9db74487f4", "title": "TransNetV2Head: Loss and F1 Score in Computer Vision"}, "3833": {"path": "/paddlevideo/modeling/heads/transnetv2_head.py:1-29", "hash": "dbbaedcf623519a8c344a70164cccee8", "title": "TransNetV2Head: CV Model Base Class"}, "3834": {"path": "/paddlevideo/modeling/heads/transnetv2_head.py:30-45", "hash": "48f28be9bf4d1e121ad81071e3084cb3", "title": "TransnetV2 Head: Loss and F1 Score Calculation"}, "3835": {"path": "/paddlevideo/modeling/heads/tsm_head.py", "hash": "3631d54cf25af541978aa6584cf4abde", "title": "TSM Head: PaddleVideo's Temporal Segment Network"}, "3836": {"path": "/paddlevideo/modeling/heads/tsm_head.py:1-33", "hash": "d9fee9bb3a31c95410e3499fbc2983e5", "title": "TSM Head Class"}, "3837": {"path": "/paddlevideo/modeling/heads/tsm_head.py:34-57", "hash": "e981e974e14750d4e0654f924db79982", "title": "TSM Head: PyTorch Class Initialization"}, "3838": {"path": "/paddlevideo/modeling/heads/tsm_head.py:58-89", "hash": "f0b494929e7bc13bf10614f13d36fa5d", "title": "TSM Head Initialization"}, "3839": {"path": "/paddlevideo/modeling/heads/tsm_head.py:90-99", "hash": "b0d5e36e0da4013c6f30008f90bafc3d", "title": "Temporal Segment Network Head Score Averaging"}, "3840": {"path": "/paddlevideo/modeling/heads/tsn_head.py", "hash": "ed0423612cb96dea2651accb3af11357", "title": "TSN Head: Image Classification in PaddleVideo"}, "3841": {"path": "/paddlevideo/modeling/heads/tsn_head.py:1-30", "hash": "77d4da21a18c3b4f20e275e57679b60c", "title": "TSN Head: Image Classification Model"}, "3842": {"path": "/paddlevideo/modeling/heads/tsn_head.py:31-63", "hash": "8d7e7aebb4aec836ecb9385316afb7e4", "title": "TSN Head Initialization"}, "3843": {"path": "/paddlevideo/modeling/heads/tsn_head.py:64-93", "hash": "192c53b686c9caeac3a86967bf897948", "title": "TSN Head: Average Pooling and Classification"}, "3844": {"path": "/paddlevideo/modeling/losses/__init__.py", "hash": "f61640bbd74cfe81d8569d855246f600", "title": "Comprehensive Losses for PaddleVideo"}, "3845": {"path": "/paddlevideo/modeling/losses/__init__.py:1-26", "hash": "f34b998f0c7bca3d7767589f4b63ec07", "title": "Extensive Loss Functions for PaddleVideo"}, "3846": {"path": "/paddlevideo/modeling/losses/__init__.py:27-29", "hash": "423d62feecd711ef9d9661062a07cf2a", "title": "Loss Functions for PaddleVideo"}, "3847": {"path": "/paddlevideo/modeling/losses/actbert_loss.py", "hash": "6df5e98f142dafac115756a39ac1604a", "title": "ActBert Loss Functions"}, "3848": {"path": "/paddlevideo/modeling/losses/actbert_loss.py:1-32", "hash": "b94cfb9dffdcf5cb201ae021812b38d6", "title": "ActBertLoss: Custom Loss for ActBert Model"}, "3849": {"path": "/paddlevideo/modeling/losses/actbert_loss.py:33-50", "hash": "aaf30a8d16328a89219949fdda85e186", "title": "ActBert Loss: Visual Classification with KLDivLoss"}, "3850": {"path": "/paddlevideo/modeling/losses/actbert_loss.py:51-75", "hash": "8cf69c4f9b970c6994880b7d6bc3f8b8", "title": "Multi-Loss Calculation in ActBERT Model"}, "3851": {"path": "/paddlevideo/modeling/losses/asrf_loss.py", "hash": "d33700d7ad66223e82feebc5c2cc8369", "title": "Custom Loss Functions for Video Modeling"}, "3852": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:1-32", "hash": "625cc67dd6b859ffecf3882aa15f668e", "title": "TMSE Loss: Temporal MSE for Action Segmentation"}, "3853": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:33-66", "hash": "452685c4044c89af4d0c659d1d032741", "title": "ASRF and Temporal MSE Loss Functions"}, "3854": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:67-92", "hash": "651f3d0254476926640215569401638f", "title": "Gaussian-weighted MSE Loss in Paddle"}, "3855": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:94-126", "hash": "0962cc3b8d1ba515701dbe8fb3f7724b", "title": "ASRF and Focal Loss Calculations"}, "3856": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:128-167", "hash": "dc2ed5da22c9d0bc7c967505c3c1f213", "title": "Action Segmentation Loss: Flexible Implementations"}, "3857": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:168-198", "hash": "493d84379741396286fb3ceaa091f2c5", "title": "Initialize Loss Functions and Weights"}, "3858": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:200-221", "hash": "12c7cc54485146b357c19ddcefe81ec0", "title": "ASRF Loss: CrossEntropy with Class Weights"}, "3859": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:222-248", "hash": "67fee7fc6d6b4886191f9fbe1cdc520b", "title": "Adjustable Sensitivity Ranking Fusion Loss"}, "3860": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:250-291", "hash": "2a86a423d54927263ebcecbce9bd613c", "title": "Boundary Regression Loss Function Combination"}, "3861": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:292-321", "hash": "489b41bbb0c022cc730e46a1730195f9", "title": "Positive Weight Calculator"}, "3862": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:322-359", "hash": "8551e37f098a314872414c247026d0f2", "title": "Multicriterion ASR Loss Function"}, "3863": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:360-373", "hash": "765c6e45b455ef565d96c60b9dfb6ef7", "title": "Initialize ActionSegmentationLoss Object"}, "3864": {"path": "/paddlevideo/modeling/losses/asrf_loss.py:374-401", "hash": "c32d531e658c441e6532d2488fca8f02", "title": "Custom Loss Function for Video Modeling Framework"}, "3865": {"path": "/paddlevideo/modeling/losses/base.py", "hash": "2db2a4be2ecb18fc8460926d6258f304", "title": "PaddlePaddle Loss Base Class"}, "3866": {"path": "/paddlevideo/modeling/losses/base.py:1-31", "hash": "adc80ba40f2a0eca6b8891b4c12e6d95", "title": "Base Loss Function in PaddlePaddle"}, "3867": {"path": "/paddlevideo/modeling/losses/base.py:32-49", "hash": "a15a273f35f2605c4ede1dae032efe62", "title": "Weighted Loss Initialization and Forward Pass"}, "3868": {"path": "/paddlevideo/modeling/losses/bmn_loss.py", "hash": "ff73d098f17f4851c450bb36764b6372", "title": "BMN Loss for PaddleVideo"}, "3869": {"path": "/paddlevideo/modeling/losses/bmn_loss.py:1-32", "hash": "aca797ce49351053042921a339d55d6b", "title": "BMN Loss Function for PaddleVideo"}, "3870": {"path": "/paddlevideo/modeling/losses/bmn_loss.py:33-55", "hash": "8059995d2425393437cd8b9ddba2df3a", "title": "Binary Mask Network Loss"}, "3871": {"path": "/paddlevideo/modeling/losses/bmn_loss.py:56-77", "hash": "bf02a920eefc3aac3333c505f134133e", "title": "Bi-directional Masked Object Detection Loss"}, "3872": {"path": "/paddlevideo/modeling/losses/bmn_loss.py:78-101", "hash": "9a9ada15455bcc24a76c697f1a134cfc", "title": "Uniform Mask Multiplication and Ratio Calculation"}, "3873": {"path": "/paddlevideo/modeling/losses/bmn_loss.py:102-126", "hash": "7b8acfcc30686af0577022b4e42ae27e", "title": "BMN Loss Calculation"}, "3874": {"path": "/paddlevideo/modeling/losses/bmn_loss.py:127-147", "hash": "c2e19224db25651cc03f528ac016d0e2", "title": "Forward Function: BMN Loss Calculation"}, "3875": {"path": "/paddlevideo/modeling/losses/bmn_loss.py:149-155", "hash": "d94dd662e2bbb79ec49661795c3045af", "title": "BMN Loss Calculation: PEM & TEAM Detection"}, "3876": {"path": "/paddlevideo/modeling/losses/cross_entropy_loss.py", "hash": "68bf4de77eff03950a8751c492f8738a", "title": "CrossEntropy Loss Function in PaddlePaddle"}, "3877": {"path": "/paddlevideo/modeling/losses/cross_entropy_loss.py:1-30", "hash": "9a1bb154ed274edb939c94662b16c67d", "title": "Custom Cross Entropy Loss in PaddlePaddle"}, "3878": {"path": "/paddlevideo/modeling/losses/cross_entropy_loss.py:31-36", "hash": "bc7f6c7f17042cac9df3d8919c2a560e", "title": "Calculate CrossEntropy Loss in Paddle"}, "3879": {"path": "/paddlevideo/modeling/losses/depth_loss.py", "hash": "94194edd127d30f4cd325266f2f96b33", "title": "Depth Loss Calculation for PaddleVideo"}, "3880": {"path": "/paddlevideo/modeling/losses/depth_loss.py:1-29", "hash": "8458f5a75cb4739dce9e614979b46cdb", "title": "Smoothness Loss Function"}, "3881": {"path": "/paddlevideo/modeling/losses/depth_loss.py:30-67", "hash": "4f0f3df184c134d3810091b4d168f60a", "title": "Depth Loss: DiffLoss and MSE for Disparity Estimation"}, "3882": {"path": "/paddlevideo/modeling/losses/depth_loss.py:68-104", "hash": "4f50cf05b517ef3cdcdc236ccd52cdd8", "title": "Structured Loss Functions for PaddlePaddle"}, "3883": {"path": "/paddlevideo/modeling/losses/depth_loss.py:106-137", "hash": "0f0abfbb3b9209f330868cb0c0c582b9", "title": "SSIM Loss Calculation in ADDSLoss"}, "3884": {"path": "/paddlevideo/modeling/losses/depth_loss.py:138-173", "hash": "7e19625ac425e8211893a864101befb5", "title": "Scale-Based Depth Loss Calculation"}, "3885": {"path": "/paddlevideo/modeling/losses/depth_loss.py:174-197", "hash": "f1504cc4e4cfbae5b26795d276bbbb42", "title": "Depth Loss Computation Algorithm"}, "3886": {"path": "/paddlevideo/modeling/losses/depth_loss.py:199-223", "hash": "271659957241546a16783bfb4b7d3dfb", "title": "Depth Loss Calculation"}, "3887": {"path": "/paddlevideo/modeling/losses/depth_loss.py:225-250", "hash": "98c67927da903e7836f9a2c586fd9bab", "title": "Computing Day-Night Losses for Video"}, "3888": {"path": "/paddlevideo/modeling/losses/depth_loss.py:251-276", "hash": "7bcb76e448f6c699dfadbe4f2d2b1fc1", "title": "Depth and Reconstruction Losses in Day-Night Scenes"}, "3889": {"path": "/paddlevideo/modeling/losses/depth_loss.py:278-290", "hash": "504522f06bd08d92a7d5f61b43e20f40", "title": "Depth Loss Update"}, "3890": {"path": "/paddlevideo/modeling/losses/distillation_loss.py", "hash": "3e56305826ba0d63f91b6ad3a3318a61", "title": "Distillation & KL Divergence Losses"}, "3891": {"path": "/paddlevideo/modeling/losses/distillation_loss.py:1-30", "hash": "d94481369c0a27fa95d06d4cdf5f036c", "title": "Distillation Entropy Loss Class"}, "3892": {"path": "/paddlevideo/modeling/losses/distillation_loss.py:31-60", "hash": "c1f88ee0a3f36da348be06542d6a9843", "title": "Distillation-Aware CrossEntropy Loss with Weighted Average"}, "3893": {"path": "/paddlevideo/modeling/losses/distillation_loss.py:61-79", "hash": "c0efe085d2a7e1bc02ef185efded4d6b", "title": "Kullback-Leibler Divergence Loss Class"}, "3894": {"path": "/paddlevideo/modeling/losses/transnetv2_loss.py", "hash": "8f1862da4f0453e0051af28d54862648", "title": "TransNetV2 Loss Calculation"}, "3895": {"path": "/paddlevideo/modeling/losses/transnetv2_loss.py:1-28", "hash": "ef943971c6dbde4166946012d3ba089b", "title": "TransNetV2 Loss Calculator"}, "3896": {"path": "/paddlevideo/modeling/losses/transnetv2_loss.py:30-54", "hash": "bda5798196c7c724c78c5f999a779c3e", "title": "TransNetV2 Loss Function"}, "3897": {"path": "/paddlevideo/modeling/losses/transnetv2_loss.py:56-56", "hash": "c06362f66c8157a0a6864689f7d9211c", "title": "TransNetV2 Total Loss Calculation"}, "3898": {"path": "/paddlevideo/modeling/losses/yowo_loss.py", "hash": "1c9fd70d7a5631d5a61c305a09dc8666", "title": "YOLO Loss Functions in PaddleVideo"}, "3899": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:1-31", "hash": "03fcb46914151ac11319969d3cdd010b", "title": "Focal Loss: Focusing on Hard Examples"}, "3900": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:33-55", "hash": "17375f075fdf6bd88abf6425a262801c", "title": "Focal Loss with Alpha, Gamma, and Size Average"}, "3901": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:56-87", "hash": "ccbb72dc9c456c4c0fe8e23717b588cc", "title": "Yowo Loss Function: GPU Optimized and Customizable"}, "3902": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:88-112", "hash": "86ec0f111e466048dddb8bd90c9962f1", "title": "Region Loss with Focal Loss and Threshold"}, "3903": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:113-137", "hash": "550636ebffdd5caad40180e620d6b85c", "title": "Sigmoid Transformation for YOLO Anchors"}, "3904": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:138-155", "hash": "f7cc9cbf5b8d076b2e314e05659d9397", "title": "YOLOv5 Loss Assignment"}, "3905": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:156-169", "hash": "9712965b8836d42507b345034a278d1e", "title": "Prepare Data for Object Detection Training"}, "3906": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:170-181", "hash": "a141d80ccbbe92f2f94c73fb77b3a4d7", "title": "Anchor Width-Height Assignments for YOWO Loss"}, "3907": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:183-199", "hash": "fec5ddbe85fcebcdbd5f0f1299d0abcf", "title": "YOLOv3 Loss Calculation in PaddleVideo"}, "3908": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:199-210", "hash": "2b11946efd7abb17bf25db8aa4a8f5fe", "title": "YOLO Loss Setup"}, "3909": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:211-237", "hash": "34a67a50ec21f4a1562d876e48d78914", "title": "GPU Variables Loss Calculation"}, "3910": {"path": "/paddlevideo/modeling/losses/yowo_loss.py:238-249", "hash": "c928b5e938a77a74db6570d31f7ae10c", "title": "YOWO Loss: Coordinate and Classification"}, "3911": {"path": "/paddlevideo/modeling/registry.py", "hash": "a4bdd3d8401ddf8b5a60c92bc22492da", "title": "Efficient Model Registry Organization"}, "3912": {"path": "/paddlevideo/modeling/registry.py:1-27", "hash": "ae9386e7a49df56a03ee08c5bf71e9bc", "title": "Model Registry Organization"}, "3913": {"path": "/paddlevideo/modeling/registry.py:28-31", "hash": "61db931447ef50230d42bd44c6fdda68", "title": "Model Registries for Paddle Video"}, "3914": {"path": "/paddlevideo/modeling/samplers/__init__.py", "hash": "f71e47fc8c9e9869c372a360431983bd", "title": "Importing RandomSampler Class and Licensing Information"}, "3915": {"path": "/paddlevideo/modeling/samplers/random_sampler.py", "hash": "ba79d15c6f2bb6948ebc136aacede585", "title": "Random Sampler for Bbox Sampling"}, "3916": {"path": "/paddlevideo/modeling/samplers/random_sampler.py:1-28", "hash": "e23700cd98671582d4a4b1e7340982e6", "title": "Random Sampling Class Definition"}, "3917": {"path": "/paddlevideo/modeling/samplers/random_sampler.py:29-55", "hash": "210c9338346983c783dc54a872d0c58f", "title": "Initializing Sampler Bounding Boxes"}, "3918": {"path": "/paddlevideo/modeling/samplers/random_sampler.py:56-92", "hash": "549fe38951bec250d526f8e8587ee5e2", "title": "RandomSampler: Randomly Sampling Bounding Boxes"}, "3919": {"path": "/paddlevideo/modeling/samplers/random_sampler.py:93-114", "hash": "fa2262bec46b4f314e90269ac4859bd6", "title": "Random Sampler for Imbalanced Classes"}, "3920": {"path": "/paddlevideo/modeling/samplers/random_sampler.py:115-139", "hash": "5f03a4fcbecbc29ea1b0b0007bf9afb9", "title": "Random Sampler: Positive and Negative Sample Selection"}, "3921": {"path": "/paddlevideo/modeling/samplers/random_sampler.py:140-146", "hash": "be5ab46709d9accf65fe071d25493f3b", "title": "Zero-Check Random Sampler"}, "3922": {"path": "/paddlevideo/modeling/weight_init.py", "hash": "228286f83524ae8e3e67808f5d744faf", "title": "Weight Initialization in PaddlePaddle"}, "3923": {"path": "/paddlevideo/modeling/weight_init.py:1-36", "hash": "12230ca790b64fcbfc5bc9149d76f85d", "title": "Weight Initialization for PaddlePaddle Layers"}, "3924": {"path": "/paddlevideo/modeling/weight_init.py:37-66", "hash": "6f4f37410b80207f3aa125c7d5f62bd9", "title": "Truncated Normal Weight Initialization"}, "3925": {"path": "/paddlevideo/modeling/weight_init.py:68-98", "hash": "8aaf662e76ad966b356f712de2bac498", "title": "Truncated Gaussian Tensor Weight Init"}, "3926": {"path": "/paddlevideo/modeling/weight_init.py:99-130", "hash": "6e8cb481f11c114f48bede00df617ac8", "title": "Convolutional Layer Weight Initialization"}, "3927": {"path": "/paddlevideo/modeling/weight_init.py:131-156", "hash": "ce1ebba0dc8551c8339cff6212cc95a9", "title": "Neural Network Weight Initialization"}, "3928": {"path": "/paddlevideo/modeling/weight_init.py:157-157", "hash": "a673ec052d80914639ecba2760975d77", "title": "Initialize Tensor with Values"}, "3929": {"path": "/paddlevideo/solver/__init__.py", "hash": "2d1b6e1c8e3481d93693e2f673e1fc8c", "title": "Solver Package Imports"}, "3930": {"path": "/paddlevideo/solver/custom_lr.py", "hash": "4f640bf9207ef966562c2f3d0c4bf430", "title": "Custom Learning Rate Schedulers for PaddleVideo"}, "3931": {"path": "/paddlevideo/solver/custom_lr.py:1-31", "hash": "686b84282932ffb07f680f8219c5dad6", "title": "Custom Warmup-Cosine Decay LR Scheduler"}, "3932": {"path": "/paddlevideo/solver/custom_lr.py:32-54", "hash": "cf46af48f50f2a31f782a40e4c3d502b", "title": "Cosine Annealing Learning Rate Scheduler"}, "3933": {"path": "/paddlevideo/solver/custom_lr.py:55-80", "hash": "086b6b40ce1ea25cfb77ecfac5db98e6", "title": "Custom Learning Rate Scheduler for PaddleVideo"}, "3934": {"path": "/paddlevideo/solver/custom_lr.py:81-106", "hash": "dcca060978c0d8a1f4998a7d6a31a719", "title": "Custom Learning Rate Scheduler with Warmup and Decay"}, "3935": {"path": "/paddlevideo/solver/custom_lr.py:107-133", "hash": "21325b18356de39934720c7896193fe5", "title": "Customizable Piecewise Decay Learning Rate Scheduler"}, "3936": {"path": "/paddlevideo/solver/custom_lr.py:134-158", "hash": "0ed1cf81201096fd592cb6eaccec3825", "title": "Custom Learning Rate Scheduler"}, "3937": {"path": "/paddlevideo/solver/custom_lr.py:159-188", "hash": "a6552ca371a951367850a4475d47ecca", "title": "Warmup Custom Learning Rate Policy"}, "3938": {"path": "/paddlevideo/solver/custom_lr.py:189-222", "hash": "7fa78593dbf67ad5822ae3f1e10dee7d", "title": "Customizable Warmup Cosine Decay Learning Rate Scheduler"}, "3939": {"path": "/paddlevideo/solver/custom_lr.py:223-249", "hash": "4245b2eacad56153e37a41b4ff287824", "title": "Custom Learning Rate Scheduler"}, "3940": {"path": "/paddlevideo/solver/custom_lr.py:251-282", "hash": "e309e4ad28f0560e04d2604a120b14e5", "title": "Custom Learning Rate Scheduler"}, "3941": {"path": "/paddlevideo/solver/custom_lr.py:283-305", "hash": "2c621c295ff96bd575678a3832cd884e", "title": "Custom Learning Rate Scheduler"}, "3942": {"path": "/paddlevideo/solver/custom_lr.py:306-332", "hash": "b5e104c85c5212105dc4f6599cbff87e", "title": "Custom Warmup Adjust Decay Scheduler"}, "3943": {"path": "/paddlevideo/solver/custom_lr.py:333-338", "hash": "dbfb50baffc9658e1ab898032d8eef23", "title": "Custom Warmup Learning Rate"}, "3944": {"path": "/paddlevideo/solver/lr.py", "hash": "4241bb08f9afbd56f380f0724d6d23fa", "title": "Learning Rate Scheduler Builder"}, "3945": {"path": "/paddlevideo/solver/lr.py:1-28", "hash": "9c0d92047f388c7204eed6460ce207e6", "title": "Learning Rate Scheduler Builder"}, "3946": {"path": "/paddlevideo/solver/lr.py:30-52", "hash": "4643f4c5d126b65f9a72f6742b3503cb", "title": "Custom Learning Rate Scheduler"}, "3947": {"path": "/paddlevideo/solver/optimizer.py", "hash": "762f7825b6d2acb832cb3bd56e5c2e3e", "title": "Python Optimizer Configurations"}, "3948": {"path": "/paddlevideo/solver/optimizer.py:1-31", "hash": "881b23097c1591c6ac710f277337ebb4", "title": "Building PaddleVideo's Optimizer"}, "3949": {"path": "/paddlevideo/solver/optimizer.py:32-63", "hash": "d8fa03bd06e71bca8e47928680b93975", "title": "Optimizer Configuration and Learning Rate Scheduler"}, "3950": {"path": "/paddlevideo/solver/optimizer.py:64-85", "hash": "3c59d078a1b3ef862c183535f0772063", "title": "AMP-Aware Optimizer Function"}, "3951": {"path": "/paddlevideo/solver/optimizer.py:86-109", "hash": "409522bce5a252b5db3628c80c292506", "title": "L1-L2 Weight Decay Optimizer Config"}, "3952": {"path": "/paddlevideo/solver/optimizer.py:110-133", "hash": "58a1390ccb4c6ab2bed48b05c2483ddf", "title": "Multi-Precision Learning Rate Scheduler"}, "3953": {"path": "/paddlevideo/solver/optimizer.py:134-136", "hash": "1812c20346fc34e19f0ac1fd0fe7e4f3", "title": "Optimizer Factory Function"}, "3954": {"path": "/paddlevideo/tasks/__init__.py", "hash": "329e7e606d1f77433b28213d93548337", "title": "PaddleVideo Tasks Initialization"}, "3955": {"path": "/paddlevideo/tasks/test.py", "hash": "857bf5660755efbab95696e2fba42300", "title": "Parallel Testing with PaddlePaddle"}, "3956": {"path": "/paddlevideo/tasks/test.py:1-32", "hash": "8395e2179a873b01a27e7e025025b314", "title": "Parallel PaddlePaddle Model Testing"}, "3957": {"path": "/paddlevideo/tasks/test.py:34-61", "hash": "d753f7a43c27abec9211d10d97ba5a7f", "title": "Model Initialization and Configuration"}, "3958": {"path": "/paddlevideo/tasks/test.py:62-90", "hash": "3df5791ddb8019f575605e9e7acedfb0", "title": "Model Evaluation Loop"}, "3959": {"path": "/paddlevideo/tasks/train.py", "hash": "9d53805884dfb657b53da1a3dc3fcde9", "title": "Distributed Training with PaddlePaddle Fleet API"}, "3960": {"path": "/paddlevideo/tasks/train.py:1-27", "hash": "cf36ab1402539e12740170fced0f0c5f", "title": "Video Task Training Framework"}, "3961": {"path": "/paddlevideo/tasks/train.py:28-51", "hash": "5d1e2a40e2a50d6be8a271b3f52dbc0d", "title": "Training Model with PaddleVideo"}, "3962": {"path": "/paddlevideo/tasks/train.py:52-75", "hash": "96683855e51a4a52d4fd8620a9f1c2ba", "title": "Gradient Accumulation for Distributed PaddlePaddle Training"}, "3963": {"path": "/paddlevideo/tasks/train.py:76-96", "hash": "5555b80473927042bd3b5b94a7828244", "title": "Global Batch Size Configuration"}, "3964": {"path": "/paddlevideo/tasks/train.py:97-124", "hash": "661ffc460bcc3a156811709a7ee25451", "title": "Static Model Conversion for Training and Validation"}, "3965": {"path": "/paddlevideo/tasks/train.py:125-150", "hash": "cb1495d28ba861f7dc15e6dc48d9746c", "title": "Training PaddleVideo with Datasets and Optimizers"}, "3966": {"path": "/paddlevideo/tasks/train.py:151-172", "hash": "f548bf11474f9f74973ed8ac87201ce3", "title": "Training Mode Checker and Handler"}, "3967": {"path": "/paddlevideo/tasks/train.py:173-204", "hash": "7b9d6dd792ec3f462dfbf9648cd9168b", "title": "Efficient Model Training with Paddle's DataParallel"}, "3968": {"path": "/paddlevideo/tasks/train.py:206-229", "hash": "672602f36e2a855189f129c8fc6caa08", "title": "Efficient AMP Training and Gradient Scaling"}, "3969": {"path": "/paddlevideo/tasks/train.py:230-253", "hash": "935d943f1a04ec0f9c75f132d8cd80b5", "title": "Gradient Descent and Backward Pass in Train.py"}, "3970": {"path": "/paddlevideo/tasks/train.py:254-277", "hash": "706376b3cb35db1c3c8b26a76a856ff3", "title": "Gradient Clearing & Optimizer Progress"}, "3971": {"path": "/paddlevideo/tasks/train.py:278-306", "hash": "b4aaba6ed977b63074dce84599c0f3b3", "title": "PaddleVideo Model Training and Evaluation"}, "3972": {"path": "/paddlevideo/tasks/train.py:307-330", "hash": "1f646f0c85d53e317a088ffaac47fafd", "title": "Training Model in PaddleVideo"}, "3973": {"path": "/paddlevideo/tasks/train.py:331-351", "hash": "cb9ad2409c6a6199eb16f9157795f184", "title": "Evaluate Dataset and Log Performance Metrics"}, "3974": {"path": "/paddlevideo/tasks/train.py:352-373", "hash": "10c6921f2c61776ee5e4f8fe40425add", "title": "Parallel Update: PreciseBN Accuracy Check"}, "3975": {"path": "/paddlevideo/tasks/train.py:374-395", "hash": "3820f2415da224fd9e6f9d362008bead", "title": "Precise Batch Normalization and Validation in Deep Learning"}, "3976": {"path": "/paddlevideo/tasks/train.py:396-417", "hash": "d826ca20169188b0009dae01d744b924", "title": "Saving Best Model and Metric Logging"}, "3977": {"path": "/paddlevideo/tasks/train.py:418-426", "hash": "45a6daf9bbe1413b8c89b1b1794244de", "title": "Periodic Model Saving"}, "3978": {"path": "/paddlevideo/tasks/train_dali.py", "hash": "23c7f192dacdeecd7765410ab90606cb", "title": "Train DALI with PaddleVideo"}, "3979": {"path": "/paddlevideo/tasks/train_dali.py:1-25", "hash": "20dd3826eb3e717c3d057a0f701ed1ae", "title": "PaddleVideo: TSN-Dali Dataset Loading and Preparation"}, "3980": {"path": "/paddlevideo/tasks/train_dali.py:26-63", "hash": "531bf4ed5bf29af9a79963fcdc1c1eb4", "title": "DALI Initialization and Training for TSN Model"}, "3981": {"path": "/paddlevideo/tasks/train_dali.py:64-88", "hash": "f4b78a3093149ac1d60b2a82dc72c754", "title": "Model Training Pipeline with Resume and Finetuning"}, "3982": {"path": "/paddlevideo/tasks/train_dali.py:89-116", "hash": "b1b9983cde6953cb302060102d9eca11", "title": "Training Model with Backpropagation"}, "3983": {"path": "/paddlevideo/tasks/train_dali.py:117-141", "hash": "67a29e5adecc73155d1d86f1775fb82d", "title": "Train DALI: Batch Normalization and Saving Progress"}, "3984": {"path": "/paddlevideo/tasks/train_dali.py:143-143", "hash": "3062cff0adc1046da7e3572938717bc8", "title": "Model Training Completion Logged"}, "3985": {"path": "/paddlevideo/tasks/train_multigrid.py", "hash": "3eaa4757a1b4e5682f42caa554028f0d", "title": "Training Multigrid Models in PaddleVideo"}, "3986": {"path": "/paddlevideo/tasks/train_multigrid.py:1-27", "hash": "0b37f54321906c2757b36b5d4cfa8b24", "title": "Setting Up PaddleVideo Environment"}, "3987": {"path": "/paddlevideo/tasks/train_multigrid.py:28-50", "hash": "23d9e6310435da93cfbc2f9d3c50541b", "title": "Multigrid Data Loader Construction"}, "3988": {"path": "/paddlevideo/tasks/train_multigrid.py:51-77", "hash": "b64afbffac8cf4e9680074e1b9665b98", "title": "Adjust Batch Size for Multigrid Training"}, "3989": {"path": "/paddlevideo/tasks/train_multigrid.py:78-110", "hash": "86653a60abc315ea318fa6aaf0b83086", "title": "Training PaddleVideo Model with DataLoaders and Parallelization"}, "3990": {"path": "/paddlevideo/tasks/train_multigrid.py:111-146", "hash": "8ab554c556bcc2702489442759bb1687", "title": "Multigrid Training Initialization"}, "3991": {"path": "/paddlevideo/tasks/train_multigrid.py:148-179", "hash": "685a9e041d389fde78008ee5272d1e72", "title": "Multigrid Model Training Setup"}, "3992": {"path": "/paddlevideo/tasks/train_multigrid.py:181-210", "hash": "b7f6481faf20e37400c72124b2c602b4", "title": "Multi-grid Training Optimizer Construction"}, "3993": {"path": "/paddlevideo/tasks/train_multigrid.py:211-235", "hash": "e5a80b2fbb9206064dd11ec470677650", "title": "Training Multigrid Models"}, "3994": {"path": "/paddlevideo/tasks/train_multigrid.py:236-262", "hash": "c5dc615569a2c7d8eda328c0c9044579", "title": "Adaptive Learning Rate Optimization"}, "3995": {"path": "/paddlevideo/tasks/train_multigrid.py:264-288", "hash": "8c44c2823b837cb420e79793328b2590", "title": "Batch-wise Evaluation and Logging"}, "3996": {"path": "/paddlevideo/tasks/train_multigrid.py:290-313", "hash": "fd268207e0cdde5bf175f00a8bbc4032", "title": "Batch Normalization & Performance Logging"}, "3997": {"path": "/paddlevideo/tasks/train_multigrid.py:314-335", "hash": "88f18dd9a636cbbd853a58d71609e837", "title": "Automatic Model Saving and Evaluation in PaddleVideo"}, "3998": {"path": "/paddlevideo/utils/__init__.py", "hash": "11a097247079a44b22b703aec2640924", "title": "PaddleVideo Utils: Imports, Build, Save & Load"}, "3999": {"path": "/paddlevideo/utils/build_utils.py", "hash": "f83a439f771717559e12a420144707b5", "title": "Build Utility Function"}, "4000": {"path": "/paddlevideo/utils/config.py", "hash": "506a810492d0ed734b0ae4f298f185c3", "title": "Config Management Utilities"}, "4001": {"path": "/paddlevideo/utils/config.py:1-34", "hash": "081a6b736cce947e6d1429e43321992e", "title": "Config Handling and Setup"}, "4002": {"path": "/paddlevideo/utils/config.py:35-67", "hash": "4022140bd21023dd723cb7f4de2de755", "title": "Config Parsing and Dict Visualization Functions"}, "4003": {"path": "/paddlevideo/utils/config.py:68-109", "hash": "bb6898eb4f3d327070968a9a0257cee8", "title": "Config Manipulation Functions"}, "4004": {"path": "/paddlevideo/utils/config.py:110-139", "hash": "f9f0c5f4a99dab4875f6f31790034f1f", "title": "Recursive Config Override Function"}, "4005": {"path": "/paddlevideo/utils/config.py:140-170", "hash": "c2ce69eac999f798ff005e7fae7959b6", "title": "Config Utilities: Load, Update and Display"}, "4006": {"path": "/paddlevideo/utils/config.py:171-174", "hash": "90381d7e083d83d183502c07e13e1429", "title": "Verify and Print Config"}, "4007": {"path": "/paddlevideo/utils/dist_utils.py", "hash": "e0dab607c4f876623c7a502c5b5bdf99", "title": "Distributed Computing Utilities"}, "4008": {"path": "/paddlevideo/utils/logger.py", "hash": "60ca93f2ed075ed2c8be2ee2f0a09be9", "title": "Colorful Logging for PaddleVideo"}, "4009": {"path": "/paddlevideo/utils/multigrid/__init__.py", "hash": "6bd1017c23601b2bedd5aa0ed1d2fb37", "title": "Multigrid Scheduler Imports"}, "4010": {"path": "/paddlevideo/utils/multigrid/batchnorm_helper.py", "hash": "c4b921d84e56deff8a46d4e475c22d8b", "title": "Batch Normalization for PyTorch Multigrid"}, "4011": {"path": "/paddlevideo/utils/multigrid/batchnorm_helper.py:1-36", "hash": "8a0c7742dc20618ed0e2db695dc283aa", "title": "Sub-BatchNorm Helper"}, "4012": {"path": "/paddlevideo/utils/multigrid/batchnorm_helper.py:37-64", "hash": "ff0578366203b7e9d585bf407c1773f4", "title": "Multi-Split Batch Normalization"}, "4013": {"path": "/paddlevideo/utils/multigrid/batchnorm_helper.py:65-85", "hash": "0970c30911caeba522749ef1f527fe9b", "title": "BatchNorm Layer Initialization"}, "4014": {"path": "/paddlevideo/utils/multigrid/batchnorm_helper.py:86-108", "hash": "efcb91d2540d04c52487d83e6964851c", "title": "BatchNorm3D Instantiation and Aggregation"}, "4015": {"path": "/paddlevideo/utils/multigrid/batchnorm_helper.py:109-135", "hash": "e46826068279ddb36edf33c32fcdaa7d", "title": "Batch Normalization Helper Class"}, "4016": {"path": "/paddlevideo/utils/multigrid/batchnorm_helper.py:136-142", "hash": "79a7bacc1e74d7ac165c1dfb91d6e533", "title": "BatchNorm Multiplication and Normalization"}, "4017": {"path": "/paddlevideo/utils/multigrid/interval_helper.py", "hash": "f7417c6c47a0b94e17eb6437ca8e4d83", "title": "Multigrid Evaluation Function"}, "4018": {"path": "/paddlevideo/utils/multigrid/multigrid.py", "hash": "774a1b519d4323554603eccb7ecb045b", "title": "Multigrid Schedule Management"}, "4019": {"path": "/paddlevideo/utils/multigrid/multigrid.py:1-25", "hash": "debf935fcb21ae49a1c64c14b36e07ca", "title": "Multigrid Scheduling Class Definition"}, "4020": {"path": "/paddlevideo/utils/multigrid/multigrid.py:26-50", "hash": "521c09731da649f24a468f66a68b6dc5", "title": "Multi-Grid Training Schedule Initialization"}, "4021": {"path": "/paddlevideo/utils/multigrid/multigrid.py:51-74", "hash": "87c22fc3b93aad620ba07c727e975853", "title": "Long Cycle Shape Update Function"}, "4022": {"path": "/paddlevideo/utils/multigrid/multigrid.py:75-94", "hash": "64840b86141cc3eaf324f2dbcda12f07", "title": "Multigrid Configuration and Update Settings"}, "4023": {"path": "/paddlevideo/utils/multigrid/multigrid.py:95-115", "hash": "7fb342ac0529e51e1ac0e150b6160509", "title": "Multigrid Configuration Checker"}, "4024": {"path": "/paddlevideo/utils/multigrid/multigrid.py:116-141", "hash": "7bfb45395989787469d83cb87a2a2a74", "title": "Multi-Grid Training Schedule Calculator"}, "4025": {"path": "/paddlevideo/utils/multigrid/multigrid.py:142-169", "hash": "6ef53bdcbbf5e8d0d1cba98d06653cf9", "title": "Multigrid Training Schedule in PaddleVideo"}, "4026": {"path": "/paddlevideo/utils/multigrid/multigrid.py:171-191", "hash": "480d50b79aa057b43433012888274fde", "title": "Multigrid Iteration Calculator"}, "4027": {"path": "/paddlevideo/utils/multigrid/multigrid.py:193-224", "hash": "32d792c440fbc55e35fce33ed2ed64cb", "title": "Multigrid Learning Rate Scheduler"}, "4028": {"path": "/paddlevideo/utils/multigrid/multigrid.py:225-233", "hash": "36fb1d3065fb0a7acd2d497aa5b3ba3a", "title": "Schedule-Based Shape Iterator"}, "4029": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py", "hash": "7e7911e27a34cd2515dc83e6d14163da", "title": "Ensuring State Dict Consistency in PaddleVideo"}, "4030": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:1-31", "hash": "e067ccbd2ddfaae72ad03b237ed47f44", "title": "Converting Sub-BN to Normal BN Parameters"}, "4031": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:32-58", "hash": "a2ebecc290c42d76873d77343ee50c96", "title": "Sub-BN Conversion for Checkpoint Loading"}, "4032": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:59-81", "hash": "cd83f56e0160e37af6770184dbdd6a30", "title": "Shape Comparison and Concatenation"}, "4033": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:82-103", "hash": "1d2276455240da6525bc4842e30f8bd0", "title": "Modify Optimizer State Dict Keys"}, "4034": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:104-135", "hash": "598034f34bec4e5594af2b05a4292fd4", "title": "Compare Optimizer and Model Parameters"}, "4035": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:136-163", "hash": "fcdc1ac8bd290c69660be432034c4eab", "title": "Update BN/Sub-BN Key Names"}, "4036": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:164-190", "hash": "72d25c1c3217ef4db50fce9c19164a62", "title": "Save and Load Helper Functions"}, "4037": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:191-216", "hash": "aadce11faa449cb23f46be4a31b8915e", "title": "Checkpoint Loader and Shape Comparison"}, "4038": {"path": "/paddlevideo/utils/multigrid/save_load_helper.py:217-237", "hash": "055c11a050505d1fc71d5b1fdc24ac85", "title": "Loading Weights and Optimizer State: SaveLoadHelper"}, "4039": {"path": "/paddlevideo/utils/multigrid/short_sampler.py", "hash": "55d4472ff6cf99d6e3d2985d936bf83b", "title": "Efficient Distributed Video Data Loading"}, "4040": {"path": "/paddlevideo/utils/multigrid/short_sampler.py:1-28", "hash": "0e8aed59128b16fa21e162d1b509c38b", "title": "Distributed ShortSampler for Dynamic Batch Sizing"}, "4041": {"path": "/paddlevideo/utils/multigrid/short_sampler.py:29-51", "hash": "733fb814c88e238cc39c75364c85b7fa", "title": "MultiGrid Initializer"}, "4042": {"path": "/paddlevideo/utils/multigrid/short_sampler.py:52-79", "hash": "5747af55730f75085350f3e223415544", "title": "Multigrid Sampler Initialization"}, "4043": {"path": "/paddlevideo/utils/multigrid/short_sampler.py:80-102", "hash": "0088c62515ecb39b1c1f7fb71727c47d", "title": "Balanced Subsampling with Modulo Handling"}, "4044": {"path": "/paddlevideo/utils/multigrid/short_sampler.py:103-130", "hash": "5d3e69e7dbdee27649557a2cb85b8b99", "title": "Dynamic Batch Sampler"}, "4045": {"path": "/paddlevideo/utils/multigrid/short_sampler.py:131-146", "hash": "412580f6e641b14d3dfcbff1ef864cfc", "title": "Efficient Video Sampler for PaddleVideo"}, "4046": {"path": "/paddlevideo/utils/precise_bn.py", "hash": "b862a992ff15e89aeec0112e55991b99", "title": "Precise Batch Normalization Acceleration"}, "4047": {"path": "/paddlevideo/utils/precise_bn.py:1-34", "hash": "1947e5c3b17259bac45fd6f86fa8b2b6", "title": "Precise Batch Normalization: Accuracy and Efficiency Boost"}, "4048": {"path": "/paddlevideo/utils/precise_bn.py:35-56", "hash": "efc2d580a4c68756a712b6fcdd9e7c6f", "title": "Precise BN Stats Recomputation"}, "4049": {"path": "/paddlevideo/utils/precise_bn.py:58-83", "hash": "789ee22f0724f880e1f884e702b99f31", "title": "Accurate Batch Normalization Update"}, "4050": {"path": "/paddlevideo/utils/precise_bn.py:84-94", "hash": "c6df7d9431553361fbf1bcb560397fb9", "title": "Accurate Batch Normalization Update"}, "4051": {"path": "/paddlevideo/utils/profiler.py", "hash": "54486a0418777b38ee758c526958dbd2", "title": "PaddleVideo Profiler: Performance Analysis and Optimization"}, "4052": {"path": "/paddlevideo/utils/profiler.py:1-29", "hash": "c584cb9c2164cfad6b7de74ec3f76280", "title": "PaddleVideo Profiler Module Init"}, "4053": {"path": "/paddlevideo/utils/profiler.py:30-53", "hash": "a86b0b1d419869daa79c27adaeddd117", "title": "Profiler Options Class"}, "4054": {"path": "/paddlevideo/utils/profiler.py:54-77", "hash": "4c6d9e1fa7d9e5893867dafa8282b298", "title": "Python Profiler: Option Parser and Batch Range"}, "4055": {"path": "/paddlevideo/utils/profiler.py:79-105", "hash": "7004dc7ea2ae9e15d4bcc9803ff673a3", "title": "Operator-Level Timing Profiler with PaddlePaddle"}, "4056": {"path": "/paddlevideo/utils/profiler.py:106-128", "hash": "4849e235de5a04ea59ff802482b05480", "title": "Profiler Object Initialization"}, "4057": {"path": "/paddlevideo/utils/record.py", "hash": "89d9c54c6141558972e55576091c0ff9", "title": "Efficient Training Metrics Recording"}, "4058": {"path": "/paddlevideo/utils/record.py:1-32", "hash": "561a1659f637bea7da2bacb51ba1ca1f", "title": "Record Builder and Logger Setup"}, "4059": {"path": "/paddlevideo/utils/record.py:33-48", "hash": "c7b973de2e925fb4393ad07a345e3626", "title": "Averaging Metrics in PaddleVideo Record"}, "4060": {"path": "/paddlevideo/utils/record.py:49-65", "hash": "f6b20ae30ae072ad5a43cafca3dbe014", "title": "Conditional Metric Addition"}, "4061": {"path": "/paddlevideo/utils/record.py:67-105", "hash": "7c55fc16a894d704cbb9139b23073315", "title": "Record Dictionary with AverageMeter Objects"}, "4062": {"path": "/paddlevideo/utils/record.py:106-136", "hash": "a81494e7362391ed4dd7ac1fee63ec43", "title": "Batch Logging and Metrics Calculation"}, "4063": {"path": "/paddlevideo/utils/record.py:137-155", "hash": "c70c6ef3e023b070ad47583dc796cd7c", "title": "Training Progress Logger"}, "4064": {"path": "/paddlevideo/utils/record.py:157-168", "hash": "cfa8224ed6475d43cf1e3e82d0f24474", "title": "Mean Metric String Calculation and Formatting"}, "4065": {"path": "/paddlevideo/utils/registry.py", "hash": "37f5a552289064dfc46330490dcf80ac", "title": "Registry Class for Object Mapping and Registration"}, "4066": {"path": "/paddlevideo/utils/save_load.py", "hash": "59c047b941ff6607e7522e136183b37e", "title": "Model Save and Load in PaddlePaddle"}, "4067": {"path": "/paddlevideo/utils/save_load.py:1-30", "hash": "37116fb1a09f01012e93a998394c83ee", "title": "Swin Model Transfer in PaddleVideo"}, "4068": {"path": "/paddlevideo/utils/save_load.py:31-61", "hash": "140d4956535b0425335a7053afb06eb6", "title": "Ensuring Model State Consistency"}, "4069": {"path": "/paddlevideo/utils/save_load.py:62-82", "hash": "23169d296a5b59e716276d071dd6591c", "title": "Loading Weights for Position Bias"}, "4070": {"path": "/paddlevideo/utils/save_load.py:83-105", "hash": "49e51abc0e01236c07df66e993c17d7b", "title": "Model Parameter Transformation for ViT Models"}, "4071": {"path": "/paddlevideo/utils/save_load.py:106-126", "hash": "2444073049a4a318e541f3482fa8f616", "title": "Adjusting Positional Embeddings for Patch Count"}, "4072": {"path": "/paddlevideo/utils/save_load.py:127-147", "hash": "cba65dccf2e0d87f62d7eee066d7f24a", "title": "Loading Weights: Model Shape Check and Progress Bar"}, "4073": {"path": "/paddlevideo/utils/save_load.py:148-172", "hash": "164181959af7aaf52dae2ebe28dbb62b", "title": "ResNet18 Weight Adaptation"}, "4074": {"path": "/paddlevideo/utils/save_load.py:173-197", "hash": "b1dc759c94f720a4f11cb1432a47b42a", "title": "Dynamic Weights Loading with Progress Updates"}, "4075": {"path": "/paddlevideo/utils/save_load.py:198-226", "hash": "edadf6c942c8c9723397e306bd556dee", "title": "Load Pre-trained Model Parameters"}, "4076": {"path": "/paddlevideo/utils/save_load.py:227-248", "hash": "f2733dfcb841f22a097ab13eacd2058e", "title": "Model Weights and Dictionary Loading"}, "4077": {"path": "/paddlevideo/utils/save_load.py:249-282", "hash": "e227ae94f75902b36862117cbd8c55c5", "title": "Save and Load Utilities"}, "4078": {"path": "/paddlevideo/utils/save_load.py:283-289", "hash": "75b9a3073324075c8e36ed75a41dd897", "title": "Save and Load Functions with Paddle"}, "4079": {"path": "/paddlevideo/version.py", "hash": "6ca7d799557f98e977461c1e4bfd1c3e", "title": "PaddleVideo Version Info"}, "4080": {"path": "/run.sh", "hash": "3d75e2aa31ca5441cc8ca54480a39215", "title": "PaddlePaddle: Train, Test, Export, Infer"}, "4081": {"path": "/run.sh:1-18", "hash": "25aef41f81dff63c299afd070f61dd8a", "title": "Distributed CUDA Training with 8 GPUs"}, "4082": {"path": "/run.sh:20-36", "hash": "e03ccab9a96164ec05eeb7eca65ffc2a", "title": "PaddlePaddle Video Recognition Training Script"}, "4083": {"path": "/run.sh:38-54", "hash": "d2da813149fd3a81ff9fe8f121449839", "title": "Distributed Deep Learning Training with PaddlePaddle"}, "4084": {"path": "/run.sh:54-74", "hash": "b5661db9a9f4810ee9679abf9a3dc57f", "title": "Distributed Deep Learning Training and Testing Script"}, "4085": {"path": "/run.sh:76-89", "hash": "0781e4d439704f76f0336f00ea3f8fad", "title": "PaddleVideo Test and Inference Guide"}, "4086": {"path": "/setup.py", "hash": "b27f50e69bc7496f9d22c965c7222578", "title": "PaddleVideo: Python Video Understanding Utility"}, "4087": {"path": "/setup.py:1-31", "hash": "69120aff15be69361914728a544acbb9", "title": "PaddleVideo Setup with Setuptools"}, "4088": {"path": "/setup.py:32-53", "hash": "6de2461bb05c009c2f03ba0d94284125", "title": "Setting Up PaddleVideo Package"}, "4089": {"path": "/setup.py:54-56", "hash": "8c7f15bf6206bfacc6f55a5a61fa892e", "title": "Python 3.7 Setup Metadata Classification"}, "4090": {"path": "/test_tipc/README.md", "hash": "b26f3a882d5ef5935d16edb3cc093f1b", "title": "TIPC-Enabled PaddleVideo Tutorial"}, "4091": {"path": "/test_tipc/README.md:2-30", "hash": "481458e0926b33cf1f298c7ecd06ce52", "title": "PaddleVideo TIPC Overview"}, "4092": {"path": "/test_tipc/README.md:31-55", "hash": "7ba83b1b7f5c5e2fbd89fee11f8e41c1", "title": "Test Tool for PaddleVideo: Supported Models and Configurations"}, "4093": {"path": "/test_tipc/README.md:56-76", "hash": "b579f10f7e7748f69288b4c8ffeae6a9", "title": "Directory Structure and Testing Scripts of PaddleVideo test_tipc Project"}, "4094": {"path": "/test_tipc/README.md:77-112", "hash": "e37811cf7cfff2fdfe183588fba1a0d2", "title": "Simplified TIPC Testing Process"}, "4095": {"path": "/test_tipc/README.md:114-126", "hash": "7681466dcbc76d838c627c8d01a9b2d9", "title": "Clear and Consistent Naming Conventions for PaddleVideo"}, "4096": {"path": "/test_tipc/README.md:127-133", "hash": "6fdb65f9fe4d3c65e169ff2e33e3f082", "title": "PaddleVideo Testing: Comprehensive Cases and Functionalities"}, "4097": {"path": "/test_tipc/benchmark_train.sh", "hash": "676dd55af820b6ca11b7f4553a461bf0", "title": "PaddleVideo Benchmark Training"}, "4098": {"path": "/test_tipc/benchmark_train.sh:1-42", "hash": "127b3c6ffb302d6307de31b64f850f1e", "title": "PaddlePaddle GPU Benchmark Training Script"}, "4099": {"path": "/test_tipc/benchmark_train.sh:43-86", "hash": "42b89c0307a6624111a05bcfcf42916a", "title": "Manipulating Configs for PaddleVideo"}, "4100": {"path": "/test_tipc/benchmark_train.sh:87-123", "hash": "9ac3e38ab7dc8cb6fddba34c2e633cc0", "title": "Training Model with Parameters"}, "4101": {"path": "/test_tipc/benchmark_train.sh:124-158", "hash": "e58f2d7959d8f76a875f622390a3b7e0", "title": "Benchmark/Train Environment Modification"}, "4102": {"path": "/test_tipc/benchmark_train.sh:159-197", "hash": "15969c8b3b628c9cd7e37e2b3d3ef8e1", "title": "Benchmark Configuration Code Snippet"}, "4103": {"path": "/test_tipc/benchmark_train.sh:198-220", "hash": "7b55ddc573c3274cadb0672cd23199f0", "title": "Batch Size and Precision Training: PaddleVideo Benchmark"}, "4104": {"path": "/test_tipc/benchmark_train.sh:221-234", "hash": "6892e758ef1703ffa2c45a3e0318fed9", "title": "Directory Creation and Logging Setup"}, "4105": {"path": "/test_tipc/benchmark_train.sh:235-253", "hash": "c3a04f99141ca12e1164d267ad7a3f12", "title": "Non-Profiled Script Execution"}, "4106": {"path": "/test_tipc/benchmark_train.sh:255-274", "hash": "8bc816ee649ce11a849e78f6914fd6b4", "title": "Python Log File Analysis Script"}, "4107": {"path": "/test_tipc/benchmark_train.sh:275-288", "hash": "ba860de6c5da340abbd47da2a161a0ac", "title": "Speeding Up TimeSformer Training"}, "4108": {"path": "/test_tipc/benchmark_train.sh:289-308", "hash": "a48acc439aa15e471a8e2b695a96b082", "title": "Benchmark Training Script"}, "4109": {"path": "/test_tipc/benchmark_train.sh:309-318", "hash": "718aa821101b1e883960ccc5f2fffce4", "title": "Benchmark Training Iteration"}, "4110": {"path": "/test_tipc/common_func.sh", "hash": "aa802229059de54f7ae8e5371c505f01", "title": "Common Functions for Parsing and Status Checks"}, "4111": {"path": "/test_tipc/common_func.sh:1-58", "hash": "ca557e6232da6490a3fe1971cf47a8fd", "title": "Parameter Parsing and Status Functions"}, "4112": {"path": "/test_tipc/common_func.sh:59-66", "hash": "71eea5b12cb3822076efd5475284b7a9", "title": "Status Logging Function"}, "4113": {"path": "/test_tipc/compare_results.py", "hash": "16e46ea53c41d054acf77e71f1f4325c", "title": "Log Parser and Comparer"}, "4114": {"path": "/test_tipc/compare_results.py:1-40", "hash": "ac3cd79d073180f8572211a851899826", "title": "Command-line Parser and Shell Executor"}, "4115": {"path": "/test_tipc/compare_results.py:42-64", "hash": "b27e9c5347b28181ccd023d4606c7ff7", "title": "Python/C++ Inference Result Parser"}, "4116": {"path": "/test_tipc/compare_results.py:65-89", "hash": "74d74e5946ff39655b0422d477e1c5d9", "title": "Parse Log File Function"}, "4117": {"path": "/test_tipc/compare_results.py:90-118", "hash": "a225c75073ff916a3e0ae67258707a6d", "title": "Three Functions for Ground Truth Data Processing"}, "4118": {"path": "/test_tipc/compare_results.py:119-146", "hash": "dbca1a96b4007da0cc196c2e9b6872c9", "title": "Validate Code Predictions with Ground Truth"}, "4119": {"path": "/test_tipc/compare_results.py:147-170", "hash": "2f6981aeede04715f23ef16bc8e5f72c", "title": "Compare and Validate Results"}, "4120": {"path": "/test_tipc/compare_results.py:171-171", "hash": "2815935ffc6c63a48a6cad48a5ad9032", "title": "Filename Formatting for Comparison"}, "4121": {"path": "/test_tipc/extract_loss.py", "hash": "ec06580b547bdbaa506468450a3078b6", "title": "Extract and Calculate Loss Expressions"}, "4122": {"path": "/test_tipc/extract_loss.py:1-28", "hash": "d4346c9c4c80498461ccb89ded94d95d", "title": "Loss Expression Parser"}, "4123": {"path": "/test_tipc/extract_loss.py:29-71", "hash": "c4d7b5f687fc3ce5e5ef708222dd60a7", "title": "Regular Expression Parsing and Validation Functions"}, "4124": {"path": "/test_tipc/extract_loss.py:74-102", "hash": "0a6276070770f721d91c94757640eafd", "title": "Function for Tuples Calculation and Printing"}, "4125": {"path": "/test_tipc/prepare.sh", "hash": "ddfa3049540baa3d78cfd8265e6a1a6f", "title": "Preparing Video Detection Models in PaddlePaddle"}, "4126": {"path": "/test_tipc/prepare.sh:1-44", "hash": "68debf86a8e755ddad47bf8796fc254c", "title": "Prepare Environment for PaddlePaddle Video Object Detection"}, "4127": {"path": "/test_tipc/prepare.sh:45-67", "hash": "3f7d5b52c7ab5251e7df0ed6d772fb65", "title": "Conditional Download Tasks for Models and Datasets"}, "4128": {"path": "/test_tipc/prepare.sh:68-87", "hash": "eccbb1a6918979c9a6a75245bf8f9e1b", "title": "Model-Specific Data Download Script"}, "4129": {"path": "/test_tipc/prepare.sh:88-105", "hash": "2cb3b4c3985f990f181c1d1108a13b32", "title": "Preparing Data and Weights for Models"}, "4130": {"path": "/test_tipc/prepare.sh:106-127", "hash": "8be682d0d70cf70c0a84243c364bba9b", "title": "Conditional Data Download and Extraction"}, "4131": {"path": "/test_tipc/prepare.sh:128-149", "hash": "8eeb287b9d60163884c7d3def9837db1", "title": "Model Weights and Data Preprocessing"}, "4132": {"path": "/test_tipc/prepare.sh:150-168", "hash": "052df1a31d0200a82f04728b9b4d36b0", "title": "Pretraining with Whole Data"}, "4133": {"path": "/test_tipc/prepare.sh:169-188", "hash": "8c1ebd0b83a9874234c36cc7967332b9", "title": "Download Model Weights and Data"}, "4134": {"path": "/test_tipc/prepare.sh:189-205", "hash": "5c6d21b40fb6d895f40f7f5b43c4296d", "title": "TSM Data Preparation Script"}, "4135": {"path": "/test_tipc/prepare.sh:206-223", "hash": "54c3d4f32ea8512c9cfcdb60938a8063", "title": "Model-Specific Data Preparation Script"}, "4136": {"path": "/test_tipc/prepare.sh:224-241", "hash": "cd4e3d4d94fa194e1b67d73377f14ff3", "title": "Preparing AttentionLSTM Model Environment"}, "4137": {"path": "/test_tipc/prepare.sh:242-261", "hash": "a3352396987efcf8bb2d30d1f08b7d5f", "title": "Preparing Kinetics400 for PaddleVideo"}, "4138": {"path": "/test_tipc/prepare.sh:262-285", "hash": "1e4dba7fecc18bdc57094f4848bd2475", "title": "Handling Model Pretraining Scenarios"}, "4139": {"path": "/test_tipc/prepare.sh:286-308", "hash": "d7a9408c83059130734ee9ad89ab8f3f", "title": "Model-Specific Data Download and Preparation"}, "4140": {"path": "/test_tipc/prepare.sh:309-329", "hash": "ddb3e8d94e4d904d37a76ee90e3c0345", "title": "Model-Specific Pretrained File Downloads"}, "4141": {"path": "/test_tipc/prepare.sh:329-345", "hash": "aced318c8263864ff65f39baa9d09799", "title": "Prepare Dataset for AttentionLSTM Model"}, "4142": {"path": "/test_tipc/prepare.sh:346-370", "hash": "c7ed561a7da559198e82b953e3114904", "title": "Model-Based Actions in TIPC Preparation"}, "4143": {"path": "/test_tipc/prepare.sh:371-385", "hash": "586879774a0792f4de3a092d198f7e7a", "title": "Model-Based Weights Download"}, "4144": {"path": "/test_tipc/prepare.sh:386-406", "hash": "325960f5091eff440c7749afed538e53", "title": "Script Downloads Pre-trained Model Weights"}, "4145": {"path": "/test_tipc/prepare.sh:407-427", "hash": "1f7cb9bcc2f82c2dc0fc143d1482de4c", "title": "Model Name Check and Download"}, "4146": {"path": "/test_tipc/prepare.sh:428-446", "hash": "0d6a8fc38429e2d98bf05a1a7e174044", "title": "PaddleVideo Model Weights Download"}, "4147": {"path": "/test_tipc/prepare.sh:447-468", "hash": "0f0ea3ec8ed8d2479ecad541252b412d", "title": "Model-Specific Data Downloads"}, "4148": {"path": "/test_tipc/prepare.sh:469-497", "hash": "f030b0d2310ab62f0a4a6b8cc001cd51", "title": "Model-Specific Data Preparation"}, "4149": {"path": "/test_tipc/prepare.sh:498-520", "hash": "6bf3b97f881b2d4842ca97332ca095ab", "title": "Prepare Inference Models"}, "4150": {"path": "/test_tipc/prepare.sh:521-552", "hash": "08b65176c167d85f9d37ea90ea3afe57", "title": "Model Check and Download for TIPC"}, "4151": {"path": "/test_tipc/prepare.sh:553-577", "hash": "c20268728fcd5c2ec85dea410faac0bc", "title": "Mode-Based Actions in TIPC Script"}, "4152": {"path": "/test_tipc/test_inference_cpp.sh", "hash": "d923868ce505066108dc35fff410ffe3", "title": "PaddleVideo Inference Testing"}, "4153": {"path": "/test_tipc/test_inference_cpp.sh:1-29", "hash": "9b0ed3be59f7a5d58a304b698c17093b", "title": "Bash Script for C++ Inference Parser"}, "4154": {"path": "/test_tipc/test_inference_cpp.sh:30-58", "hash": "82754e6ec777e19c8ed005a6e63692d0", "title": "PaddleVideo C++ Inference Setup"}, "4155": {"path": "/test_tipc/test_inference_cpp.sh:59-72", "hash": "692c330ff724fc3910cb4afab7362cdc", "title": "Skipping MKLDNN Quantized Tests"}, "4156": {"path": "/test_tipc/test_inference_cpp.sh:73-85", "hash": "2812e9a00914778e7e4395d43a434f94", "title": "Inference Script Configuration and Execution"}, "4157": {"path": "/test_tipc/test_inference_cpp.sh:86-101", "hash": "0129d9f6f39c2769670a5e76b045e2fe", "title": "TRT Precision Combinations Test"}, "4158": {"path": "/test_tipc/test_inference_cpp.sh:102-112", "hash": "1a65887ad8960141b38e5a0fbd9ae5c6", "title": "Inference CPP Script Execution"}, "4159": {"path": "/test_tipc/test_inference_cpp.sh:114-146", "hash": "0fe436cad971c10a5b3abe44e4f735ef", "title": "Hardware Support and OpenCV Setup"}, "4160": {"path": "/test_tipc/test_inference_cpp.sh:147-178", "hash": "ac80e48a800c8831a64703d9e5cbdabc", "title": "Building PaddleVideo Libraries and Demo"}, "4161": {"path": "/test_tipc/test_inference_cpp.sh:179-225", "hash": "dc3a5d4d111c083ca25ac6aa68619b93", "title": "Configuring PaddleVideo and Running Inference Tests"}, "4162": {"path": "/test_tipc/test_inference_cpp.sh:226-228", "hash": "e004e1b74b84a131b72461fbf15d795a", "title": "Executing C++ Inference Commands"}, "4163": {"path": "/test_tipc/test_paddle2onnx.sh", "hash": "e85b0b297d16d876f100d4f162ed5e35", "title": "Automating Paddle2ONNX Conversion in test_tipc/test_paddle2onnx.sh"}, "4164": {"path": "/test_tipc/test_paddle2onnx.sh:1-32", "hash": "12e61ed8600367ecbf6aac05410e9533", "title": "Paddle2Onnx: Extracting Model Details from Log Files"}, "4165": {"path": "/test_tipc/test_paddle2onnx.sh:33-58", "hash": "c049e83da4c036d7762e2b44846ebd4b", "title": "Setting Up Paddle2Onnx Inference"}, "4166": {"path": "/test_tipc/test_paddle2onnx.sh:59-73", "hash": "c91c304871bba1b3e5c196a117ea6603", "title": "Paddle2Onnx Conversion and Inference Logging"}, "4167": {"path": "/test_tipc/test_paddle2onnx.sh:74-81", "hash": "191569a6f35978a379d84ebbb7295318", "title": "Test: Export Count, IFS, and Echo Message"}, "4168": {"path": "/test_tipc/test_ptq_inference_python.sh", "hash": "61dcf7006e8e1ee9a254a1d739ada749", "title": "PaddleVideo GPU/CPU Inference Test"}, "4169": {"path": "/test_tipc/test_ptq_inference_python.sh:1-29", "hash": "26dd3f9ebda2934b2b48f677f3e0f743", "title": "Python Shell Script for Model Inference"}, "4170": {"path": "/test_tipc/test_ptq_inference_python.sh:30-52", "hash": "45c022fa59dcacbfb8593340ac6af1f0", "title": "Retrieving Config Values for Trainer and Inference"}, "4171": {"path": "/test_tipc/test_ptq_inference_python.sh:55-74", "hash": "7ce64950597872a130620a8b9efcbd32", "title": "Python-Powered GPU/CPU Inference Logging"}, "4172": {"path": "/test_tipc/test_ptq_inference_python.sh:74-88", "hash": "c4d876926be54ae5654d9be84f00c2a8", "title": "Looped GPU Inference Testing"}, "4173": {"path": "/test_tipc/test_ptq_inference_python.sh:89-112", "hash": "b86f37a284752fdd65039cde62d2f5a8", "title": "Hardware-Optimized PaddleVideo Inference"}, "4174": {"path": "/test_tipc/test_ptq_inference_python.sh:113-129", "hash": "fb98515f3512ec390e22765ab69a79a4", "title": "Model Export Preparation and Check"}, "4175": {"path": "/test_tipc/test_ptq_inference_python.sh:130-132", "hash": "89b379a2646fdc5b5d1d73695c5c814c", "title": "Python Inference Calling"}, "4176": {"path": "/test_tipc/test_serving_infer_cpp.sh", "hash": "ca1c74f247817532d51402f90f892958", "title": "Streamline Bash Model Serving with GPU"}, "4177": {"path": "/test_tipc/test_serving_infer_cpp.sh:1-28", "hash": "a586c1e50dcf27edf8f74e37015f1030", "title": "Custom Bash Script for Configuration and Image Classification"}, "4178": {"path": "/test_tipc/test_serving_infer_cpp.sh:29-54", "hash": "0b6d9f79d65cc7187b75cbdbdedec1da", "title": "Initialize Model and Config Files"}, "4179": {"path": "/test_tipc/test_serving_infer_cpp.sh:55-73", "hash": "c52b5a9c01a5b506dcd5f04f4c937016", "title": "Setup C++ Server and Client on GPU"}, "4180": {"path": "/test_tipc/test_serving_infer_cpp.sh:73-100", "hash": "978a719ddf231ae7cad8cb8d21a7d604", "title": "PaddlePaddle Serving Server Test"}, "4181": {"path": "/test_tipc/test_serving_infer_cpp.sh:103-107", "hash": "efc9f112c26719a3f18e1ec713ee5a56", "title": "Incrementing \"Count\" in Web Service Test"}, "4182": {"path": "/test_tipc/test_serving_infer_python.sh", "hash": "17562dd7d829c63330b67ecbbd90e37c", "title": "Automating Model Serving with Bash"}, "4183": {"path": "/test_tipc/test_serving_infer_python.sh:1-29", "hash": "ba65cba05e6787cd7ebd057d6abac8f6", "title": "Bash Script Configures Model Inference Environment"}, "4184": {"path": "/test_tipc/test_serving_infer_python.sh:30-54", "hash": "8d2ddb45efcff92e073ddd9a77112660", "title": "Model Serving Code Execution"}, "4185": {"path": "/test_tipc/test_serving_infer_python.sh:56-77", "hash": "b540ab7ed1e4f8a201b1e8035e6e0e4e", "title": "Automated Web Service Deployment with Python"}, "4186": {"path": "/test_tipc/test_serving_infer_python.sh:78-105", "hash": "4f9832f5f37bd961a0c26545d9e2f2f4", "title": "CUDA Test Environment Setup and Cleanup"}, "4187": {"path": "/test_tipc/test_train_dy2static_python.sh", "hash": "005ab5f02c7b5a1eb387c842a6f51158", "title": "Dygraph vs Dy2Static Model Comparison"}, "4188": {"path": "/test_tipc/test_train_dy2static_python.sh:1-30", "hash": "c77ac5277244c696e6a29adb9bd9e633", "title": "Configure and Initialize Environment"}, "4189": {"path": "/test_tipc/test_train_dy2static_python.sh:31-57", "hash": "9ddf5ab164f3fc06a23a9f1dcdf7d7a8", "title": "Configure, Run and Analyze Dygraph and Dy2Static Models"}, "4190": {"path": "/test_tipc/test_train_dy2static_python.sh:58-73", "hash": "6c881959c5d8f19f62190a3c48b12073", "title": "Diff and Log Comparison of Models"}, "4191": {"path": "/test_tipc/test_train_inference_python.sh", "hash": "689fc011d73300f662dc6d5c4d101248", "title": "PaddleVideo Model Optimizer"}, "4192": {"path": "/test_tipc/test_train_inference_python.sh:1-30", "hash": "86932e068fb74e763997d774b5b68d4f", "title": "Parse Training Parameters"}, "4193": {"path": "/test_tipc/test_train_inference_python.sh:31-56", "hash": "6ceebd38cbf7b06123b0ec8e48d52966", "title": "Parsing Key-Value Configurations"}, "4194": {"path": "/test_tipc/test_train_inference_python.sh:57-79", "hash": "364d284666e1df0b710af6c9662be7a7", "title": "Configuration Parser and Variable Assigner"}, "4195": {"path": "/test_tipc/test_train_inference_python.sh:80-104", "hash": "084e16c10c2fd97f30cce4ea662c3116", "title": "Config File Parsing for Inference Parameters"}, "4196": {"path": "/test_tipc/test_train_inference_python.sh:105-125", "hash": "a077d879780ad5232f863e6a01f77a9a", "title": "Configuration Extraction for Test and Train"}, "4197": {"path": "/test_tipc/test_train_inference_python.sh:126-157", "hash": "4a700de8d127a6f0212389c114c8481c", "title": "Inference Code Configuration & Logging"}, "4198": {"path": "/test_tipc/test_train_inference_python.sh:158-170", "hash": "edc035912719f70f4b86555bf8061d5a", "title": "Iterating Over Precision Values"}, "4199": {"path": "/test_tipc/test_train_inference_python.sh:171-181", "hash": "7dd34870c9ae3591419f0a34f5540ec1", "title": "Automating Test Loop with Python Script"}, "4200": {"path": "/test_tipc/test_train_inference_python.sh:182-198", "hash": "0474b2d3934d48c93fabc4e507f5af79", "title": "Optimizing Inference Parameters"}, "4201": {"path": "/test_tipc/test_train_inference_python.sh:200-212", "hash": "843ceef86da9ef6b6338fbb45cb0bca4", "title": "Inference Parameter Configuration"}, "4202": {"path": "/test_tipc/test_train_inference_python.sh:214-243", "hash": "07c31185ab4bfb120e8c96139fef1d5f", "title": "Inference Model Testing with PaddleVideo"}, "4203": {"path": "/test_tipc/test_train_inference_python.sh:244-274", "hash": "a08a0d31106ce243f151bf5129f04f5b", "title": "Multi-GPU Inference Loop"}, "4204": {"path": "/test_tipc/test_train_inference_python.sh:275-303", "hash": "8aafcd5a509d1d8c939600510c85dfb0", "title": "GPU Environment Variable Setup"}, "4205": {"path": "/test_tipc/test_train_inference_python.sh:304-325", "hash": "357114ad7c04365cd7eca6f6ce10bc86", "title": "Conditional Assignment of Train and Export Tasks"}, "4206": {"path": "/test_tipc/test_train_inference_python.sh:326-347", "hash": "5634a45760e712e4a516199874b75f25", "title": "Setting Model Training Parameters"}, "4207": {"path": "/test_tipc/test_train_inference_python.sh:348-367", "hash": "3f5dcb683cc2466b097d187eadf9c92a", "title": "Distributed PaddleVideo Training and Inference"}, "4208": {"path": "/test_tipc/test_train_inference_python.sh:368-378", "hash": "77059604b9813cf31bdc017efe660b1c", "title": "Multi-GPU/Machine Training with PaddlePaddle"}, "4209": {"path": "/test_tipc/test_train_inference_python.sh:378-395", "hash": "82ffec666068b56761076e72b5f03d11", "title": "Train PaddleVideo Model with Parameters"}, "4210": {"path": "/test_tipc/test_train_inference_python.sh:396-410", "hash": "ebaed66ff9c9dcb7810847c5759a4a8d", "title": "Evaluate Model Parameters and Commands"}, "4211": {"path": "/test_tipc/test_train_inference_python.sh:410-426", "hash": "ad031d6f0d46b7f218bf2dbe8aaedcf0", "title": "Setting up Variables for Inference"}, "4212": {"path": "/test_tipc/test_train_inference_python.sh:426-433", "hash": "8fe49fcfbae70857bee7bfc71ddc1fc0", "title": "Set CUDA Devices for Inference and Training"}, "4213": {"path": "/test_tipc/test_train_inference_python_npu.sh", "hash": "c37386bac832f03bfc6ff8eeb81cdb7b", "title": "NPU Script Updates and Config Changes"}, "4214": {"path": "/test_tipc/test_train_inference_python_npu.sh:1-39", "hash": "d3efd5ce0f96332b291375daf44e24b9", "title": "Switching to NPU Execution Script"}, "4215": {"path": "/test_tipc/test_train_inference_python_npu.sh:40-42", "hash": "2ded2853e55e8cc7f9c4c08657f9cf7a", "title": "Bash Script Execution"}, "4216": {"path": "/test_tipc/test_train_inference_python_xpu.sh", "hash": "500271acc9aabb6fffa58d587d1449c0", "title": "Update XPU Execution Script"}, "4217": {"path": "/test_tipc/test_train_inference_python_xpu.sh:1-39", "hash": "bf2d5a1d321c2777726ae0b351e900d1", "title": "PaddleVideo XPU Configuration Update"}, "4218": {"path": "/test_tipc/test_train_inference_python_xpu.sh:40-42", "hash": "23af3c2705952b485a3e5c60a900eddc", "title": "Bash Command Execution and Logging"}, "4219": {"path": "/tools/__init__.py", "hash": "4239003f054a409f26b826c8c9e993b9", "title": "Tools Package Initialization"}, "4220": {"path": "/tools/ava_predict.py", "hash": "b7a7935d51fcf24b5130f3d7b789ef65", "title": "AVA Model Inference and Action Detection"}, "4221": {"path": "/tools/ava_predict.py:1-32", "hash": "a1f24c113bf1f413d2374c749828ff33", "title": "AVA Action Unit Detection Python Script"}, "4222": {"path": "/tools/ava_predict.py:33-68", "hash": "7993f99151ac0b75fbf408830ac2d3ea", "title": "AVA Annotation Utilities"}, "4223": {"path": "/tools/ava_predict.py:69-98", "hash": "6c1158a712457d9c88fae698fe2a4082", "title": "Visualize Frames with Predicted Annotations"}, "4224": {"path": "/tools/ava_predict.py:99-125", "hash": "496ff8c1d132bec1eac74532aae588e6", "title": "Image Box Annotation Visualizer"}, "4225": {"path": "/tools/ava_predict.py:126-160", "hash": "3f5afe89575c969ecf5fb245f7b71f72", "title": "Video Frame Extractor"}, "4226": {"path": "/tools/ava_predict.py:161-191", "hash": "9f26304bd44a02c2e09669f8d54ecc4b", "title": "PaddleVideo Inference with AVA Predict"}, "4227": {"path": "/tools/ava_predict.py:192-222", "hash": "f6cbb61c58622743a5dc4cec6a734086", "title": "AVA Predict Function Arguments and Result Packaging"}, "4228": {"path": "/tools/ava_predict.py:223-264", "hash": "c5a5b1c0ae82e010d08e24e3cc9df786", "title": "Label Prediction Function"}, "4229": {"path": "/tools/ava_predict.py:267-294", "hash": "3814f7971e174f66a66bbc50296e0241", "title": "Human Detection via Frame Paths"}, "4230": {"path": "/tools/ava_predict.py:296-334", "hash": "84308b6fd183dbf8d27c84c10571ddc5", "title": "Reads Detection Results File for Bounding Box Proposals"}, "4231": {"path": "/tools/ava_predict.py:337-365", "hash": "1a396daee1246c2b0139e545b5d3447d", "title": "Extract Frames and Set Up Pipelines"}, "4232": {"path": "/tools/ava_predict.py:366-395", "hash": "915e761a7bb1cf4633086690709985e4", "title": "AVA Prediction Code Snippet"}, "4233": {"path": "/tools/ava_predict.py:396-421", "hash": "0ff08cd06459cf6d97a71477ffa679b2", "title": "SpatioTemporal Action Detection Code"}, "4234": {"path": "/tools/ava_predict.py:422-455", "hash": "ce5009a3685bc0ff1b965a50b50dcb4e", "title": "Tensorize and Predict"}, "4235": {"path": "/tools/ava_predict.py:456-481", "hash": "245fea629b9a7c5d7f9e1e492b539aa3", "title": "Action Score Thresholding in AVA Predict"}, "4236": {"path": "/tools/ava_predict.py:482-509", "hash": "7a47b3ef3a0b0202520cb22d41daff82", "title": "Video Frame Processing and Visualization Tool"}, "4237": {"path": "/tools/export_model.py", "hash": "470dd8ab24807413bc5e5191245b0efe", "title": "PaddleVideo Model Exporter"}, "4238": {"path": "/tools/export_model.py:1-32", "hash": "d84fe2c8871bed64511e5f31d6cadb84", "title": "PaddleVideo Model Export Tool"}, "4239": {"path": "/tools/export_model.py:33-57", "hash": "2d5b044c8222c90168bf3f258a658adb", "title": "Export Model Script"}, "4240": {"path": "/tools/export_model.py:58-87", "hash": "cba0b4b3a9ed545055a749bf737bbabd", "title": "Model Export and Config Trimming in PaddleVideo"}, "4241": {"path": "/tools/export_model.py:88-117", "hash": "fda2fa8a5f104e938882df2e0f5d7978", "title": "Model-Specific Input Shape Definition"}, "4242": {"path": "/tools/export_model.py:118-143", "hash": "d0e1f463bbf3a199aac953705fa3083a", "title": "Model Input Specification in PaddleVideo's Export Function"}, "4243": {"path": "/tools/export_model.py:144-172", "hash": "83820f8c1265c5b024e4164f396b150b", "title": "Input Specifications for PaddleVideo Models"}, "4244": {"path": "/tools/export_model.py:173-204", "hash": "cf8ec18bca11d170593ad88c92cc569d", "title": "Input Specifications for Various Model Names"}, "4245": {"path": "/tools/export_model.py:205-236", "hash": "dd2d1ef622e06ac9a9e7bd8547f9b6bb", "title": "Model Input Specification Generator"}, "4246": {"path": "/tools/export_model.py:237-267", "hash": "ab4cce8c1bbf4a1599c9e6b6fa9fde28", "title": "Export Model: Step-by-Step"}, "4247": {"path": "/tools/predict.py", "hash": "522fce27100f32ed99256dd075cb0e88", "title": "Paddle Video Tool: Command-Line Inference"}, "4248": {"path": "/tools/predict.py:1-32", "hash": "25c55f52523f791e967f195be211b47d", "title": "Import-Heavy Function Definition"}, "4249": {"path": "/tools/predict.py:33-59", "hash": "9faf9649001b118f02c05530ad7febc2", "title": "Command-Line Arguments for Paddle Video"}, "4250": {"path": "/tools/predict.py:60-84", "hash": "4dc334f48c9d7088311a451f77070ed8", "title": "Configuring Paddle Video Predictor Arguments"}, "4251": {"path": "/tools/predict.py:85-107", "hash": "346095242fc21c125a89c409078f9768", "title": "Optimizing PaddleVideo for Inference"}, "4252": {"path": "/tools/predict.py:108-134", "hash": "cc9aa9793cc24c73bc7a948659cca7e0", "title": "TensorRT Engine Setup for ST-GCN"}, "4253": {"path": "/tools/predict.py:136-173", "hash": "7b1c3b474eeac50408beb3d7da2ee81b", "title": "Building Paddle Predictor in Python"}, "4254": {"path": "/tools/predict.py:174-201", "hash": "ffa119223bd0b52e85cba29c6957c93e", "title": "Model Inference Processing"}, "4255": {"path": "/tools/predict.py:202-227", "hash": "6c48f1b6e04f09b9251edc4bbd7f030c", "title": "Video Prediction Pipeline"}, "4256": {"path": "/tools/predict.py:228-251", "hash": "ffcc6d55e86af57e6e08efac9e38c522", "title": "Directory Creation and Inference Processing"}, "4257": {"path": "/tools/predict.py:252-275", "hash": "b34add53fc4cbab8da9d14253673c28e", "title": "Installing auto_log and Configuring AutoLogger"}, "4258": {"path": "/tools/predict.py:276-306", "hash": "5c0baa3fc9204a18d1d7e0794dc10236", "title": "Batch Inference Tool"}, "4259": {"path": "/tools/predict.py:308-327", "hash": "7d0c3959f1dda330a84c0ab9b078aee4", "title": "Benchmarking Inference and Post-Processing Time"}, "4260": {"path": "/tools/summary.py", "hash": "f5f12a6a80e0e0c760e6c192a2c0094d", "title": "Model Summary and FLOPs Calculation"}, "4261": {"path": "/tools/summary.py:1-34", "hash": "6bb4f2234d9c73a7a4120611e3dc8194", "title": "Parsing Command Line Arguments in PaddleVideo"}, "4262": {"path": "/tools/summary.py:35-69", "hash": "7dbcbf051ae14e5539da37795e7834bb", "title": "Argument Parsing for Config File and Model Building"}, "4263": {"path": "/tools/summary.py:70-82", "hash": "5ac351fe65a4df9e85397a5c31498bdc", "title": "Model Summary and FLOPs Calculator"}, "4264": {"path": "/tools/utils.py", "hash": "cf6f260e979f2661a6a32b85666a64f1", "title": "PaddleVideo-based Action Recognition & Human Detection"}, "4265": {"path": "/tools/utils.py:1-34", "hash": "bc74bd256109c786defef4882c68cda4", "title": "Import, Error Handling and License Info"}, "4266": {"path": "/tools/utils.py:35-58", "hash": "85eadeb720de9e911e0e5291a6b865ac", "title": "Importing and Building PaddleVideo Models"}, "4267": {"path": "/tools/utils.py:60-86", "hash": "16c3e953fdeed2c0abd0489a406c96d6", "title": "Building Inference Helper with Registry"}, "4268": {"path": "/tools/utils.py:87-121", "hash": "3dcd81866e63dfb1f7266854c3383ac8", "title": "Abstract Class for Batch Preprocessing"}, "4269": {"path": "/tools/utils.py:123-147", "hash": "694c47cc5b3eac80ba5a9cabf918ade2", "title": "Softmax Postprocessing Function"}, "4270": {"path": "/tools/utils.py:148-176", "hash": "881c08ca0136a84f91d65c4ceb1a3012", "title": "Video Classifier Helper"}, "4271": {"path": "/tools/utils.py:177-211", "hash": "eedfd78877467073c8634240557e9512", "title": "Image Processing Class for PaddleVideo"}, "4272": {"path": "/tools/utils.py:212-245", "hash": "d047ccb2e00db719c2529951970cee67", "title": "Video Preprocessing Class"}, "4273": {"path": "/tools/utils.py:246-278", "hash": "a3a4ca481f28bc37efcfd29e6ac99b26", "title": "BMN Inference Helper Class and Postprocessing"}, "4274": {"path": "/tools/utils.py:279-302", "hash": "dca2029db93eaad15024d6a27e24f4fb", "title": "Calculates Snippet Xmin and Xmax Values"}, "4275": {"path": "/tools/utils.py:303-328", "hash": "2df732a70800128c27e7af197b3d9505", "title": "Non-Max Suppression for Bounding Boxes"}, "4276": {"path": "/tools/utils.py:329-362", "hash": "dd171b15a41d8d1d20530b05fe8aaf58", "title": "TokenShift Inference Helper Class"}, "4277": {"path": "/tools/utils.py:363-395", "hash": "95afe472138b676fd7bca4191ca1771e", "title": "Preprocessing for TimeSformer Inference"}, "4278": {"path": "/tools/utils.py:396-427", "hash": "8a9670e4a30870f7157389d10b8f5764", "title": "Video Processing Pipeline"}, "4279": {"path": "/tools/utils.py:428-458", "hash": "5d56db4d1f79618fcb0849166a0a59e3", "title": "Video Preprocessing Class"}, "4280": {"path": "/tools/utils.py:459-489", "hash": "5203f36d07a5d401b62827fd64dfa165", "title": "Image Preprocessing and Postprocessing Tool"}, "4281": {"path": "/tools/utils.py:490-516", "hash": "790b882f1a1ceafcdad9391cfb2c82d9", "title": "Extract Top K Classes from Tensor"}, "4282": {"path": "/tools/utils.py:517-542", "hash": "46183c597ee35452e833ad43e2e290d1", "title": "Video Frame Processing Function"}, "4283": {"path": "/tools/utils.py:543-573", "hash": "a72829b63692f2e2c17bc03466b6a9d9", "title": "Text Overlay on Video Frames"}, "4284": {"path": "/tools/utils.py:574-595", "hash": "3f33e19476c002be83beccb575e4aa18", "title": "Video Frame Processing and GIF Generation"}, "4285": {"path": "/tools/utils.py:596-620", "hash": "1a59156db17ecd823829985360a08729", "title": "Process and Save GIF with postprocess Function"}, "4286": {"path": "/tools/utils.py:621-651", "hash": "c656097f4a94b2c89f4438d2d2e8ae41", "title": "SlowFast Video Inference Helper"}, "4287": {"path": "/tools/utils.py:652-682", "hash": "148bd4fc351882d2d6d7460e1164a41e", "title": "Video Frame Preprocessing and Postprocessing Function"}, "4288": {"path": "/tools/utils.py:683-706", "hash": "3598cab474978512a2fc2de133669cee", "title": "Top Classes and Scores from STGCN Inference"}, "4289": {"path": "/tools/utils.py:707-740", "hash": "e5d0f0f996f8605cc9119ea3800d1f03", "title": "CTRGCN Inference Helper Class"}, "4290": {"path": "/tools/utils.py:741-775", "hash": "7e2cd2ee5c189825f139e25274d88988", "title": "Preprocessing Data Class"}, "4291": {"path": "/tools/utils.py:776-807", "hash": "51b1f4727c9d9094145fc6dd47cedc84", "title": "Preprocessing and MSTCN Inference Helper Classes"}, "4292": {"path": "/tools/utils.py:809-840", "hash": "07b6b9a5f05e596add3427706b41d71a", "title": "Video Feature File Handling Class"}, "4293": {"path": "/tools/utils.py:841-867", "hash": "2e53b4a2a4427f6391d8e6ff0e498eae", "title": "Video Feature Processing and Text File Generation"}, "4294": {"path": "/tools/utils.py:868-898", "hash": "72c3cfc8d7d46e6be664038022221195", "title": "Initializing ASRF Inference Helper"}, "4295": {"path": "/tools/utils.py:899-932", "hash": "7fe3d48f089063fbd03a2f82ba28f1bf", "title": "Feature Loading and Processing Class"}, "4296": {"path": "/tools/utils.py:933-959", "hash": "0315746ebfcb4fc8dac07e489893606c", "title": "Action-Labeled Video Processor"}, "4297": {"path": "/tools/utils.py:960-993", "hash": "68f2dcbbcbc20d4778420a3b0a3f554d", "title": "Attention LSTM Inference Preprocessor"}, "4298": {"path": "/tools/utils.py:994-1022", "hash": "7a2e3be7ad8235bf6f836d3f392eae00", "title": "Video Inference with TransNetV2 Model"}, "4299": {"path": "/tools/utils.py:1023-1051", "hash": "b9686a95e49e504416ac829417f0d8e8", "title": "FFmpeg Import and Frame Batching"}, "4300": {"path": "/tools/utils.py:1052-1074", "hash": "4403ff3aaff246c5598577f2185f3620", "title": "Video Frame Iterator: Converting Predictions to Scenes"}, "4301": {"path": "/tools/utils.py:1075-1103", "hash": "c2490e7df2170dbe16b3347471bae0b5", "title": "Video Scene List Processing Algorithm"}, "4302": {"path": "/tools/utils.py:1105-1133", "hash": "96334075c75a458608be6dcd65a10f19", "title": "Frame Visualization Tool"}, "4303": {"path": "/tools/utils.py:1134-1149", "hash": "e05b3f259440ce0a9fae1c2124430ed3", "title": "Single and All Frame Predictions"}, "4304": {"path": "/tools/utils.py:1150-1169", "hash": "cb4d618f806b9dd01341b5534adb320e", "title": "Shot Boundary Scene Converter"}, "4305": {"path": "/tools/utils.py:1171-1201", "hash": "9bdac883fd453a93477cb6cd6a8bc2fa", "title": "ADDS Inference Helper Initialization"}, "4306": {"path": "/tools/utils.py:1202-1237", "hash": "c4bdaf9b932388fa2cde29793473233b", "title": "Image Preprocessing Class and Method"}, "4307": {"path": "/tools/utils.py:1238-1264", "hash": "4e30f14d9794fe832259a6bbd4863e09", "title": "Post-Process Outputs and Save Depth Maps"}, "4308": {"path": "/tools/utils.py:1266-1291", "hash": "81aae45e3139064d41d4f1af4a43c6ae", "title": "Image Conversion Function and Class"}, "4309": {"path": "/tools/utils.py:1292-1321", "hash": "7988e9489cdc8dcf78513811893ecada", "title": "Init and Extract Frames for Video Analysis"}, "4310": {"path": "/tools/utils.py:1322-1344", "hash": "9112d6b71554e270483a608ed8bbc497", "title": "Preprocessing Frames and Labels"}, "4311": {"path": "/tools/utils.py:1345-1369", "hash": "350bdeef68a2ef1667be52fa12890a51", "title": "Object Detection Frame Processing"}, "4312": {"path": "/tools/utils.py:1370-1400", "hash": "5b291cb9b5781c2fe37c60f610ff1464", "title": "Data Pipeline: Append Proposals and Scores"}, "4313": {"path": "/tools/utils.py:1401-1433", "hash": "3104afcf0ca2f71cabf4b5011fd64747", "title": "Human Detection Class with Pre/Post-Processing"}, "4314": {"path": "/tools/utils.py:1434-1464", "hash": "8658c68a65b3004cccc2361b6f78485f", "title": "Iterating and Appending Predictions"}, "4315": {"path": "/tools/utils.py:1466-1490", "hash": "337931bd1a9f5a9413527792b26f17b7", "title": "Frame Sequence Visualizer"}, "4316": {"path": "/tools/utils.py:1492-1523", "hash": "c4efeab560a79895941568e51bc936c4", "title": "Pose Estimation Class for Image Processing"}, "4317": {"path": "/tools/utils.py:1524-1548", "hash": "026c860ac5f50c0095ecda510a0e99a5", "title": "PaddleVideo Image Processing"}, "4318": {"path": "/tools/utils.py:1549-1574", "hash": "584876e73f2d691646d96465a2df7839", "title": "YOWO Image Classification/Detection Initialization"}, "4319": {"path": "/tools/utils.py:1575-1606", "hash": "1b57de0a9dbd3436a66b84f490a179e3", "title": "Video Input Preprocessing: OpenCV Frame Reading and Resizing"}, "4320": {"path": "/tools/utils.py:1608-1638", "hash": "39379424242e3a3af9b6cf9c65ab5b97", "title": "Normalize and Reshape Images for Classification"}, "4321": {"path": "/tools/utils.py:1639-1660", "hash": "519b8da83cc91da8424e88f493f33f69", "title": "Object Detection and Recognition Algorithm"}, "4322": {"path": "/tools/utils.py:1661-1670", "hash": "09f64f74f5bcd79f7ec52ed509ad94d0", "title": "Video Object Detection System Algorithm"}, "4323": {"path": "/tools/wheel.py", "hash": "3aa3a7e8af74448b5a6a21ac3fe5b600", "title": "Video Classification Wheel Tool"}, "4324": {"path": "/tools/wheel.py:1-24", "hash": "367ec341c4bdab58ad852656f42f21ce", "title": "Apache License Notice"}, "4325": {"path": "/tools/wheel.py:25-64", "hash": "918ffd9f9a9b36a75a4888f848128f30", "title": "PaddleVideo Model Environment Setup"}, "4326": {"path": "/tools/wheel.py:65-93", "hash": "e8705890a76efa485d07718d3f3da972", "title": "Command Line Parser Function"}, "4327": {"path": "/tools/wheel.py:94-115", "hash": "8c13db1ccec633a0b625c0f3c4d0c93e", "title": "Initializing Argument Parser with Default Values"}, "4328": {"path": "/tools/wheel.py:116-145", "hash": "497181fe947b4ca04d37b4ae105c185b", "title": "Parse and Download with Progress"}, "4329": {"path": "/tools/wheel.py:146-168", "hash": "c53dc1da22d025529149523dfdae4919", "title": "Download and Save Inference Model"}, "4330": {"path": "/tools/wheel.py:169-197", "hash": "bcf9bed27efada6416580b25d953d62d", "title": "Initializing Paddle Predictor with Flags and Configs"}, "4331": {"path": "/tools/wheel.py:198-232", "hash": "be96333481a76367584a113fcd47c7f1", "title": "PaddleVideo Predictor Setup"}, "4332": {"path": "/tools/wheel.py:233-253", "hash": "96637bef113010199e8875c7e7ec96cd", "title": "Model Download and Configuration"}, "4333": {"path": "/tools/wheel.py:254-277", "hash": "d592df1458a8e5fe2621b58fdd0352d2", "title": "Video Label Prediction Code"}, "4334": {"path": "/tools/wheel.py:279-301", "hash": "d49bc6783f675bd26753ffc98c1770e5", "title": "URL Video Processing"}, "4335": {"path": "/tools/wheel.py:303-327", "hash": "734ec23aa6c6d01fdd6e7bd3534842ae", "title": "Batch Inference Looping"}, "4336": {"path": "/tools/wheel.py:328-353", "hash": "4f47b258f9c6bf2c473810207a55f5df", "title": "Iterating and Labeling Results in PaddleVideo"}, "4337": {"path": "/tools/wheel.py:354-354", "hash": "aea680926b3a51c05d08874baee8c9ed", "title": "Entry Point for Script Execution"}}}