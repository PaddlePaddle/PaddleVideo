# PP-AGCN模型详解

---

## 内容

- [ST-GCN模型简介](#ST-GCN模型简介)
- [PP-AGCN模型改进](#PP-AGCN模型改进)

## ST-GCN模型简介

ST-GCN模型由香港中文大学-商汤科技联合实验室在AAAI 2018中提出，不仅为解决基于人体骨架关键点的人类动作识别问题提供了新颖的思路，在标准的动作识别数据集上也取得了较大的性能提升。
时空图卷积网络模型ST-GCN通过将图卷积网络（GCN）和时间卷积网络（TCN）结合起来，扩展到时空图模型，设计出了用于行为识别的骨骼点序列通用表示，
该模型将人体骨骼表示为图，如图2所示，其中图的每个节点对应于人体的一个关节点。图中存在两种类型的边，即符合关节的自然连接的空间边（spatial edge）和在连续的时间步骤中连接相同关节的
时间边（temporal edge）。在此基础上构建多层的时空图卷积，它允许信息沿着空间和时间两个维度进行整合。

ST-GCN的网络结构大致可以分为三个部分，首先，对网络输入一个五维矩阵(N, C, T, V, M)，其中N为视频数据量；C为关节特征向量，包括(x,y,acc)；T为视频中抽取的关键帧的数量；
V表示关节的数量，在本项目中采用25个关节数量；M则是一个视频中的人数，然后再对输入数据进行Batch Normalization批量归一化，接着，通过设计ST-GCN单元，
引入ATT注意力模型并交替使用GCN图卷积网络和TCN时间卷积网络，对时间和空间维度进行变换，在这一过程中对关节的特征维度进行升维，对关键帧维度进行降维，
最后，通过调用平均池化层、全连接层，并后接SoftMax层输出，对特征进行分类。


## PP-AGCN模型详解
