{
    "5500": {
        "file_id": 450,
        "content": "    \"\"\"\n    def __init__(self,\n                 keys,\n                 meta_keys=('filename', 'label', 'original_shape', 'img_shape',\n                            'pad_shape', 'flip_direction', 'img_norm_cfg'),\n                 meta_name='img_metas'):\n        self.keys = keys\n        self.meta_keys = meta_keys\n        self.meta_name = meta_name\n    def __call__(self, results):\n        \"\"\"Performs the Collect formating.\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"\n        data = []\n        for key in self.keys:\n            data.append(results[key])\n        if len(self.meta_keys) != 0:\n            meta = {}\n            for key in self.meta_keys:\n                meta[key] = results[key]\n            data.append(meta)\n        return data\n    def __repr__(self):\n        return (f'{self.__class__.__name__}('\n                f'keys={self.keys}, meta_keys={self.meta_keys}, '\n                f'nested={self.nested})')\n@PIPELINES.register()",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1239-1275"
    },
    "5501": {
        "file_id": 450,
        "content": "The code defines a class that initializes with specified keys and optional metadata keys. It executes a call method to perform Collect formating on input results, appending each key's data into a list and adding any specified metadata as well. The __repr__ method provides a string representation of the object including its attributes. This pipeline component is registered in @PIPELINES using decorator.",
        "type": "comment"
    },
    "5502": {
        "file_id": 450,
        "content": "class GeneratePoseTarget:\n    \"\"\"Generate pseudo heatmaps based on joint coordinates and confidence.\n    Required keys are \"keypoint\", \"img_shape\", \"keypoint_score\" (optional),\n    added or modified keys are \"imgs\".\n    Args:\n        sigma (float): The sigma of the generated gaussian map. Default: 0.6.\n        use_score (bool): Use the confidence score of keypoints as the maximum\n            of the gaussian maps. Default: True.\n        with_kp (bool): Generate pseudo heatmaps for keypoints. Default: True.\n        with_limb (bool): Generate pseudo heatmaps for limbs. At least one of\n            'with_kp' and 'with_limb' should be True. Default: False.\n        skeletons (tuple[tuple]): The definition of human skeletons.\n            Default: ((0, 1), (0, 2), (1, 3), (2, 4), (0, 5), (5, 7), (7, 9),\n                      (0, 6), (6, 8), (8, 10), (5, 11), (11, 13), (13, 15),\n                      (6, 12), (12, 14), (14, 16), (11, 12)),\n            which is the definition of COCO-17p skeletons.\n        double (bool): Output both original heatmaps and flipped heatmaps.",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1276-1294"
    },
    "5503": {
        "file_id": 450,
        "content": "This code defines a class `GeneratePoseTarget` that generates pseudo heatmaps based on joint coordinates and confidence, with optional use of score, limbs, or skeletons. It takes in required keys \"keypoint\", \"img_shape\", and \"keypoint_score\" (optional). It adds or modifies keys as \"imgs\". The class has parameters like sigma, use_score, with_kp, with_limb, skeletons, and double.",
        "type": "comment"
    },
    "5504": {
        "file_id": 450,
        "content": "            Default: False.\n        left_kp (tuple[int]): Indexes of left keypoints, which is used when\n            flipping heatmaps. Default: (1, 3, 5, 7, 9, 11, 13, 15),\n            which is left keypoints in COCO-17p.\n        right_kp (tuple[int]): Indexes of right keypoints, which is used when\n            flipping heatmaps. Default: (2, 4, 6, 8, 10, 12, 14, 16),\n            which is right keypoints in COCO-17p.\n    \"\"\"\n    def __init__(self,\n                 sigma=0.6,\n                 use_score=True,\n                 with_kp=True,\n                 with_limb=False,\n                 skeletons=((0, 1), (0, 2), (1, 3), (2, 4), (0, 5), (5, 7),\n                            (7, 9), (0, 6), (6, 8), (8, 10), (5, 11), (11, 13),\n                            (13, 15), (6, 12), (12, 14), (14, 16), (11, 12)),\n                 double=False,\n                 left_kp=(1, 3, 5, 7, 9, 11, 13, 15),\n                 right_kp=(2, 4, 6, 8, 10, 12, 14, 16)):\n        self.sigma = sigma\n        self.use_score = use_score\n        self.with_kp = with_kp",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1295-1318"
    },
    "5505": {
        "file_id": 450,
        "content": "The function initializes skeleton parameters such as sigma, use_score, with_kp, with_limb, skeletons, double, left_kp, and right_kp. It sets default values for these parameters to be used in the skeleton pipeline process.",
        "type": "comment"
    },
    "5506": {
        "file_id": 450,
        "content": "        self.with_limb = with_limb\n        self.double = double\n        # an auxiliary const\n        self.eps = 1e-4\n        assert self.with_kp or self.with_limb, (\n            'At least one of \"with_limb\" '\n            'and \"with_kp\" should be set as True.')\n        self.left_kp = left_kp\n        self.right_kp = right_kp\n        self.skeletons = skeletons\n    def generate_a_heatmap(self, img_h, img_w, centers, sigma, max_values):\n        \"\"\"Generate pseudo heatmap for one keypoint in one frame.\n        Args:\n            img_h (int): The height of the heatmap.\n            img_w (int): The width of the heatmap.\n            centers (np.ndarray): The coordinates of corresponding keypoints\n                (of multiple persons).\n            sigma (float): The sigma of generated gaussian.\n            max_values (np.ndarray): The max values of each keypoint.\n        Returns:\n            np.ndarray: The generated pseudo heatmap.\n        \"\"\"\n        heatmap = np.zeros([img_h, img_w], dtype=np.float32)\n        for center, max_value in zip(centers, max_values):",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1319-1349"
    },
    "5507": {
        "file_id": 450,
        "content": "This code is part of the SkeletonPipeline class, which appears to be related to skeleton detection or tracking. The class takes in parameters such as with_limb, double, eps, left_kp, right_kp, and skeletons. It generates a heatmap for one keypoint in one frame using the generate_a_heatmap method. This method takes in img_h, img_w, centers, sigma, and max_values as parameters to create a pseudo heatmap with a zero initial state, iterates through each center-max_value pair, and fills the heatmap accordingly.",
        "type": "comment"
    },
    "5508": {
        "file_id": 450,
        "content": "            mu_x, mu_y = center[0], center[1]\n            if max_value < self.eps:\n                continue\n            st_x = max(int(mu_x - 3 * sigma), 0)\n            ed_x = min(int(mu_x + 3 * sigma) + 1, img_w)\n            st_y = max(int(mu_y - 3 * sigma), 0)\n            ed_y = min(int(mu_y + 3 * sigma) + 1, img_h)\n            x = np.arange(st_x, ed_x, 1, np.float32)\n            y = np.arange(st_y, ed_y, 1, np.float32)\n            # if the keypoint not in the heatmap coordinate system\n            if not (len(x) and len(y)):\n                continue\n            y = y[:, None]\n            patch = np.exp(-((x - mu_x)**2 + (y - mu_y)**2) / 2 / sigma**2)\n            patch = patch * max_value\n            heatmap[st_y:ed_y, st_x:ed_x] = np.maximum(\n                heatmap[st_y:ed_y, st_x:ed_x], patch)\n        return heatmap\n    def generate_a_limb_heatmap(self, img_h, img_w, starts, ends, sigma,\n                                start_values, end_values):\n        \"\"\"Generate pseudo heatmap for one limb in one frame.",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1350-1375"
    },
    "5509": {
        "file_id": 450,
        "content": "This function generates a heatmap for a limb in a frame by calculating the Gaussian kernel patch, and updating the heatmap with it. It checks if the keypoint is within the image boundaries before processing. The keypoint positions are calculated based on center coordinates and sigma values. If the keypoints are not within the image bounds, the function continues to the next iteration without updating the heatmap.",
        "type": "comment"
    },
    "5510": {
        "file_id": 450,
        "content": "        Args:\n            img_h (int): The height of the heatmap.\n            img_w (int): The width of the heatmap.\n            starts (np.ndarray): The coordinates of one keypoint in the\n                corresponding limbs (of multiple persons).\n            ends (np.ndarray): The coordinates of the other keypoint in the\n                corresponding limbs (of multiple persons).\n            sigma (float): The sigma of generated gaussian.\n            start_values (np.ndarray): The max values of one keypoint in the\n                corresponding limbs.\n            end_values (np.ndarray): The max values of the other keypoint in\n                the corresponding limbs.\n        Returns:\n            np.ndarray: The generated pseudo heatmap.\n        \"\"\"\n        heatmap = np.zeros([img_h, img_w], dtype=np.float32)\n        for start, end, start_value, end_value in zip(starts, ends,\n                                                      start_values, end_values):\n            value_coeff = min(start_value, end_value)",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1377-1398"
    },
    "5511": {
        "file_id": 450,
        "content": "This function takes in parameters such as image height, width, keypoint coordinates, and values for each limb. It then generates a pseudo heatmap by iterating through the inputs, calculates a value coefficient for each limb based on their start and end values, and returns a numpy array representing the generated heatmap.",
        "type": "comment"
    },
    "5512": {
        "file_id": 450,
        "content": "            if value_coeff < self.eps:\n                continue\n            min_x, max_x = min(start[0], end[0]), max(start[0], end[0])\n            min_y, max_y = min(start[1], end[1]), max(start[1], end[1])\n            min_x = max(int(min_x - 3 * sigma), 0)\n            max_x = min(int(max_x + 3 * sigma) + 1, img_w)\n            min_y = max(int(min_y - 3 * sigma), 0)\n            max_y = min(int(max_y + 3 * sigma) + 1, img_h)\n            x = np.arange(min_x, max_x, 1, np.float32)\n            y = np.arange(min_y, max_y, 1, np.float32)\n            if not (len(x) and len(y)):\n                continue\n            y = y[:, None]\n            x_0 = np.zeros_like(x)\n            y_0 = np.zeros_like(y)\n            # distance to start keypoints\n            d2_start = ((x - start[0])**2 + (y - start[1])**2)\n            # distance to end keypoints\n            d2_end = ((x - end[0])**2 + (y - end[1])**2)\n            # the distance between start and end keypoints.\n            d2_ab = ((start[0] - end[0])**2 + (start[1] - end[1])**2)",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1399-1427"
    },
    "5513": {
        "file_id": 450,
        "content": "This code calculates the distance between a pair of keypoints (start and end) for every pixel in the image, based on certain conditions like value_coeff and sigma. It also adjusts the x and y coordinates to avoid out-of-bounds errors. If the resulting arrays of x and y are empty, it skips processing this pair of keypoints. The calculated distances are used for further processing in the codebase.",
        "type": "comment"
    },
    "5514": {
        "file_id": 450,
        "content": "            if d2_ab < 1:\n                full_map = self.generate_a_heatmap(img_h, img_w, [start], sigma,\n                                                   [start_value])\n                heatmap = np.maximum(heatmap, full_map)\n                continue\n            coeff = (d2_start - d2_end + d2_ab) / 2. / d2_ab\n            a_dominate = coeff <= 0\n            b_dominate = coeff >= 1\n            seg_dominate = 1 - a_dominate - b_dominate\n            position = np.stack([x + y_0, y + x_0], axis=-1)\n            projection = start + np.stack([coeff, coeff],\n                                          axis=-1) * (end - start)\n            d2_line = position - projection\n            d2_line = d2_line[:, :, 0]**2 + d2_line[:, :, 1]**2\n            d2_seg = (a_dominate * d2_start + b_dominate * d2_end +\n                      seg_dominate * d2_line)\n            patch = np.exp(-d2_seg / 2. / sigma**2)\n            patch = patch * value_coeff\n            heatmap[min_y:max_y, min_x:max_x] = np.maximum(\n                heatmap[min_y:max_y, min_x:max_x], patch)",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1429-1453"
    },
    "5515": {
        "file_id": 450,
        "content": "This code calculates the dominant points and updates the heatmap by applying a Gaussian kernel. It checks if a point is within the start or end of a line segment, and if not, it computes the distance between the point and the line segment. It then uses this distance to compute a weight for each dominant point (start, end) and updates the heatmap using these weights. This ensures that the dominant points have more influence on the heatmap than the less dominant ones.",
        "type": "comment"
    },
    "5516": {
        "file_id": 450,
        "content": "        return heatmap\n    def generate_heatmap(self, img_h, img_w, kps, sigma, max_values):\n        \"\"\"Generate pseudo heatmap for all keypoints and limbs in one frame (if\n        needed).\n        Args:\n            img_h (int): The height of the heatmap.\n            img_w (int): The width of the heatmap.\n            kps (np.ndarray): The coordinates of keypoints in this frame.\n            sigma (float): The sigma of generated gaussian.\n            max_values (np.ndarray): The confidence score of each keypoint.\n        Returns:\n            np.ndarray: The generated pseudo heatmap.\n        \"\"\"\n        heatmaps = []\n        if self.with_kp:\n            num_kp = kps.shape[1]\n            for i in range(num_kp):\n                heatmap = self.generate_a_heatmap(img_h, img_w, kps[:, i],\n                                                  sigma, max_values[:, i])\n                heatmaps.append(heatmap)\n        if self.with_limb:\n            for limb in self.skeletons:\n                start_idx, end_idx = limb\n                starts = kps[:, start_idx]",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1455-1483"
    },
    "5517": {
        "file_id": 450,
        "content": "This code generates a heatmap for all keypoints and limbs in one frame. It takes the height, width, coordinates of keypoints, sigma value, and confidence scores as input. The function iterates over each keypoint to generate separate heatmaps if 'with_kp' is enabled, then appends these individual heatmaps to a list called 'heatmaps'. If 'with_limb' is also enabled, the code generates additional heatmaps for each limb defined in 'self.skeletons' by iterating over them and finding corresponding start and end indices.",
        "type": "comment"
    },
    "5518": {
        "file_id": 450,
        "content": "                ends = kps[:, end_idx]\n                start_values = max_values[:, start_idx]\n                end_values = max_values[:, end_idx]\n                heatmap = self.generate_a_limb_heatmap(\n                    img_h, img_w, starts, ends, sigma, start_values, end_values)\n                heatmaps.append(heatmap)\n        return np.stack(heatmaps, axis=-1)\n    def gen_an_aug(self, results):\n        \"\"\"Generate pseudo heatmaps for all frames.\n        Args:\n            results (dict): The dictionary that contains all info of a sample.\n        Returns:\n            list[np.ndarray]: The generated pseudo heatmaps.\n        \"\"\"\n        all_kps = results['keypoint']\n        kp_shape = all_kps.shape\n        if 'keypoint_score' in results:\n            all_kpscores = results['keypoint_score']\n        else:\n            all_kpscores = np.ones(kp_shape[:-1], dtype=np.float32)\n        img_h, img_w = results['img_shape']\n        num_frame = kp_shape[1]\n        imgs = []\n        for i in range(num_frame):\n            sigma = self.sigma",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1484-1517"
    },
    "5519": {
        "file_id": 450,
        "content": "The code defines a function that generates pseudo heatmaps for all frames in an image sequence. It extracts keypoint coordinates and scores from the input results, and then creates heatmaps by calling another function to generate limb heatmaps for each frame. These heatmaps are appended into a list and finally stacked along a specific axis to form the output.",
        "type": "comment"
    },
    "5520": {
        "file_id": 450,
        "content": "            kps = all_kps[:, i]\n            kpscores = all_kpscores[:, i]\n            max_values = np.ones(kpscores.shape, dtype=np.float32)\n            if self.use_score:\n                max_values = kpscores\n            hmap = self.generate_heatmap(img_h, img_w, kps, sigma, max_values)\n            imgs.append(hmap)\n        return imgs\n    def __call__(self, results):\n        if not self.double:\n            results['imgs'] = np.stack(self.gen_an_aug(results))\n        else:\n            results_ = cp.deepcopy(results)\n            flip = Flip_V2(\n                flip_ratio=1, left_kp=self.left_kp, right_kp=self.right_kp)\n            results_ = flip(results_)\n            results['imgs'] = np.concatenate(\n                [self.gen_an_aug(results),\n                 self.gen_an_aug(results_)])\n        results['label'] = np.array([results['label']])\n        return results\n    def __repr__(self):\n        repr_str = (f'{self.__class__.__name__}('\n                    f'sigma={self.sigma}, '\n                    f'use_score={self.use_score}, '",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1518-1547"
    },
    "5521": {
        "file_id": 450,
        "content": "This code defines a class that generates heatmaps from keypoints and applies data augmentation to images. It takes in results as input, generates image heatmaps based on the keypoints, and optionally doubles the output by applying horizontal flipping with a specified left and right keypoint. The sigma value is used for Gaussian filtering, and the use_score flag determines whether scores are considered for generating heatmaps.",
        "type": "comment"
    },
    "5522": {
        "file_id": 450,
        "content": "                    f'with_kp={self.with_kp}, '\n                    f'with_limb={self.with_limb}, '\n                    f'skeletons={self.skeletons}, '\n                    f'double={self.double}, '\n                    f'left_kp={self.left_kp}, '\n                    f'right_kp={self.right_kp})')\n        return repr_str",
        "type": "code",
        "location": "/paddlevideo/loader/pipelines/skeleton_pipeline.py:1548-1554"
    },
    "5523": {
        "file_id": 450,
        "content": "This code is formatting a string that represents the parameters for a skeleton pipeline. The parameters include whether to output keypoints and limbs, the number of skeletons, and left/right keypoint options.",
        "type": "comment"
    },
    "5524": {
        "file_id": 451,
        "content": "/paddlevideo/loader/registry.py",
        "type": "filepath"
    },
    "5525": {
        "file_id": 451,
        "content": "This code snippet is a part of the PaddleVideo framework and contains copyright information, license details, and registry definitions for pipelines and datasets. It defines two registries, \"pipeline\" and \"datasets\", using the Registry class from the utils module, allowing the creation and management of custom pipeline and dataset classes.",
        "type": "summary"
    },
    "5526": {
        "file_id": 451,
        "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom ..utils import Registry\nPIPELINES = Registry(\"pipeline\")\nDATASETS = Registry(\"datasets\")",
        "type": "code",
        "location": "/paddlevideo/loader/registry.py:1-18"
    },
    "5527": {
        "file_id": 451,
        "content": "This code snippet is a part of the PaddleVideo framework and contains copyright information, license details, and registry definitions for pipelines and datasets. It defines two registries, \"pipeline\" and \"datasets\", using the Registry class from the utils module, allowing the creation and management of custom pipeline and dataset classes.",
        "type": "comment"
    },
    "5528": {
        "file_id": 452,
        "content": "/paddlevideo/metrics/ActivityNet/__init__.py",
        "type": "filepath"
    },
    "5529": {
        "file_id": 452,
        "content": "The code imports the ANETproposal class from the \"anet_prop\" module and adds it to the __all__ list, making it a public API in the package. This allows other modules to import and use this class directly.",
        "type": "summary"
    },
    "5530": {
        "file_id": 452,
        "content": "from .anet_prop import ANETproposal\n__all__ = ['ANETproposal']",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/__init__.py:1-3"
    },
    "5531": {
        "file_id": 452,
        "content": "The code imports the ANETproposal class from the \"anet_prop\" module and adds it to the __all__ list, making it a public API in the package. This allows other modules to import and use this class directly.",
        "type": "comment"
    },
    "5532": {
        "file_id": 453,
        "content": "/paddlevideo/metrics/ActivityNet/anet_prop.py",
        "type": "filepath"
    },
    "5533": {
        "file_id": 453,
        "content": "This code imports libraries, defines a class for metrics calculation, retrieves data from ActivityNet API, compares results, creates DataFrames, evaluates proposals using AUC-RC, and calculates average recall. It extracts videos, computes proposal scores, IOU scores, handles exceptions, determines recall with thresholds, and efficiently computes IoU for target and candidate segments.",
        "type": "summary"
    },
    "5534": {
        "file_id": 453,
        "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nimport json\nimport numpy as np\nimport pandas as pd\nimport urllib.request as urllib2\nfrom paddlevideo.utils import get_logger\nlogger = get_logger(\"paddlevideo\")\nclass ANETproposal(object):\n    \"\"\"\n    This class is used for calculating AR@N and AUC;\n    Code transfer from ActivityNet Gitub repository](https://github.com/activitynet/ActivityNet.git)\n    \"\"\"\n    GROUND_TRUTH_FIELDS = ['database', 'taxonomy', 'version']\n    PROPOSAL_FIELDS = ['results', 'version', 'external_data']\n    API = 'http://ec2-52-25-205-214.us-west-2.compute.amazonaws.com/challenge19/api.py'",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:1-29"
    },
    "5535": {
        "file_id": 453,
        "content": "This code imports necessary libraries, defines a class for calculating AR@N and AUC, and sets the API URL for accessing ActivityNet data. The class uses ground truth fields and proposal fields to compare results. Code is transferred from the ActivityNet GitHub repository.",
        "type": "comment"
    },
    "5536": {
        "file_id": 453,
        "content": "    def __init__(self,\n                 ground_truth_filename=None,\n                 proposal_filename=None,\n                 ground_truth_fields=GROUND_TRUTH_FIELDS,\n                 proposal_fields=PROPOSAL_FIELDS,\n                 tiou_thresholds=np.linspace(0.5, 0.95, 10),\n                 max_avg_nr_proposals=None,\n                 subset='validation',\n                 verbose=False,\n                 check_status=True):\n        if not ground_truth_filename:\n            raise IOError('Please input a valid ground truth file.')\n        if not proposal_filename:\n            raise IOError('Please input a valid proposal file.')\n        self.subset = subset\n        self.tiou_thresholds = tiou_thresholds\n        self.max_avg_nr_proposals = max_avg_nr_proposals\n        self.verbose = verbose\n        self.gt_fields = ground_truth_fields\n        self.pred_fields = proposal_fields\n        self.recall = None\n        self.avg_recall = None\n        self.proposals_per_video = None\n        self.check_status = check_status",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:31-54"
    },
    "5537": {
        "file_id": 453,
        "content": "Initializing the class with ground truth and proposal filenames as required, setting default parameters, and checking if both files exist.",
        "type": "comment"
    },
    "5538": {
        "file_id": 453,
        "content": "        # Retrieve blocked videos from server.\n        if self.check_status:\n            self.blocked_videos = self.get_blocked_videos()\n        else:\n            self.blocked_videos = list()\n        # Import ground truth and proposals.\n        self.ground_truth, self.activity_index = self._import_ground_truth(\n            ground_truth_filename)\n        self.proposal = self._import_proposal(proposal_filename)\n        if self.verbose:\n            print('[INIT] Loaded annotations from {} subset.'.format(subset))\n            nr_gt = len(self.ground_truth)\n            print('\\tNumber of ground truth instances: {}'.format(nr_gt))\n            nr_pred = len(self.proposal)\n            print('\\tNumber of proposals: {}'.format(nr_pred))\n            print('\\tFixed threshold for tiou score: {}'.format(\n                self.tiou_thresholds))\n    def _import_ground_truth(self, ground_truth_filename):\n        \"\"\"\n        Reads ground truth file, checks if it is well formatted, and returns\n        the ground truth instances and the activity classes.",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:55-77"
    },
    "5539": {
        "file_id": 453,
        "content": "This code retrieves blocked videos from a server, imports ground truth and proposals, and checks if the ground truth file is well formatted. It also prints information about the number of ground truth instances and proposals, as well as the fixed threshold for tiou score.",
        "type": "comment"
    },
    "5540": {
        "file_id": 453,
        "content": "        Parameters:\n        ground_truth_filename (str): full path to the ground truth json file.\n        Returns:\n        ground_truth (df): Data frame containing the ground truth instances.\n        activity_index (dict): Dictionary containing class index.\n        \"\"\"\n        with open(ground_truth_filename, 'r') as fobj:\n            data = json.load(fobj)\n        # Checking format\n        if not all([field in data.keys() for field in self.gt_fields]):\n            raise IOError('Please input a valid ground truth file.')\n        # Read ground truth data.\n        activity_index, cidx = {}, 0\n        video_lst, t_start_lst, t_end_lst, label_lst = [], [], [], []\n        for videoid, v in data['database'].items():\n            if self.subset != v['subset']:\n                continue\n            if videoid in self.blocked_videos:\n                continue\n            for ann in v['annotations']:\n                if ann['label'] not in activity_index:\n                    activity_index[ann['label']] = cidx\n                    cidx += 1",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:79-102"
    },
    "5541": {
        "file_id": 453,
        "content": "This function reads a ground truth JSON file and returns a DataFrame containing the instances. It also returns a dictionary of class indices. The function checks if the input file has the required fields, skips videos not in the specified subset, and ignores blocked videos. If an activity label is not found in the activity_index, it adds it to the index and increments the counter.",
        "type": "comment"
    },
    "5542": {
        "file_id": 453,
        "content": "                video_lst.append(videoid)\n                t_start_lst.append(float(ann['segment'][0]))\n                t_end_lst.append(float(ann['segment'][1]))\n                label_lst.append(activity_index[ann['label']])\n        ground_truth = pd.DataFrame({\n            'video-id': video_lst,\n            't-start': t_start_lst,\n            't-end': t_end_lst,\n            'label': label_lst\n        })\n        return ground_truth, activity_index\n    def _import_proposal(self, proposal_filename):\n        \"\"\"\n        Reads proposal file, checks if it is well formatted, and returns\n        the proposal instances.\n        Parameters:\n        proposal_filename (str): Full path to the proposal json file.\n        Returns:\n        proposal (df): Data frame containing the proposal instances.\n        \"\"\"\n        with open(proposal_filename, 'r') as fobj:\n            data = json.load(fobj)\n        # Checking format...\n        if not all([field in data.keys() for field in self.pred_fields]):\n            raise IOError('Please input a valid proposal file.')",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:103-130"
    },
    "5543": {
        "file_id": 453,
        "content": "The code reads a proposal file, checks its format and returns proposal instances in the form of a data frame. It also generates ground truth data by appending video IDs, start and end times, and labels to lists before creating a DataFrame. The function takes a string as input for the full path to the proposal JSON file and returns a data frame containing the proposal instances.",
        "type": "comment"
    },
    "5544": {
        "file_id": 453,
        "content": "        # Read predictions.\n        video_lst, t_start_lst, t_end_lst = [], [], []\n        score_lst = []\n        for videoid, v in data['results'].items():\n            if videoid in self.blocked_videos:\n                continue\n            for result in v:\n                video_lst.append(videoid)\n                t_start_lst.append(float(result['segment'][0]))\n                t_end_lst.append(float(result['segment'][1]))\n                score_lst.append(result['score'])\n        proposal = pd.DataFrame({\n            'video-id': video_lst,\n            't-start': t_start_lst,\n            't-end': t_end_lst,\n            'score': score_lst\n        })\n        return proposal\n    def evaluate(self):\n        \"\"\"\n        Evaluates a proposal file. To measure the performance of a\n        method for the proposal task, we computes the area under the\n        average recall vs average number of proposals per video curve.\n        \"\"\"\n        recall, avg_recall, proposals_per_video = self.average_recall_vs_avg_nr_proposals(\n            self.ground_truth,",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:132-158"
    },
    "5545": {
        "file_id": 453,
        "content": "The code reads predictions from a data source, extracts relevant information (video IDs, start and end timestamps, scores), stores them in a DataFrame, and defines two functions: one for evaluating proposal files by computing area under the average recall vs average number of proposals per video curve. The evaluation function calls another function to compute this metric using ground truth data and the stored proposal data.",
        "type": "comment"
    },
    "5546": {
        "file_id": 453,
        "content": "            self.proposal,\n            max_avg_nr_proposals=self.max_avg_nr_proposals,\n            tiou_thresholds=self.tiou_thresholds)\n        area_under_curve = np.trapz(avg_recall, proposals_per_video)\n        if self.verbose:\n            print('[RESULTS] Performance on ActivityNet proposal task.')\n            with open(\"data/bmn/BMN_Test_results/auc_result.txt\",\n                      \"a\") as text_file:\n                text_file.write(\n                    '\\tArea Under the AR vs AN curve: {}% \\n'.format(\n                        100. * float(area_under_curve) /\n                        proposals_per_video[-1]))\n            print('\\tArea Under the AR vs AN curve: {}%'.format(\n                100. * float(area_under_curve) / proposals_per_video[-1]))\n        self.recall = recall\n        self.avg_recall = avg_recall\n        self.proposals_per_video = proposals_per_video\n    def average_recall_vs_avg_nr_proposals(self,\n                                           ground_truth,\n                                           proposals,",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:159-182"
    },
    "5547": {
        "file_id": 453,
        "content": "Calculates the area under the curve of recall vs average number of proposals for ActivityNet proposal task, writes result to file and stores recall, average recall, and proposals per video in class attributes.",
        "type": "comment"
    },
    "5548": {
        "file_id": 453,
        "content": "                                           max_avg_nr_proposals=None,\n                                           tiou_thresholds=np.linspace(\n                                               0.5, 0.95, 10)):\n        \"\"\"\n        Computes the average recall given an average number of\n        proposals per video.\n        Parameters:\n        ground_truth(df): Data frame containing the ground truth instances.\n            Required fields: ['video-id', 't-start', 't-end']\n        proposal(df): Data frame containing the proposal instances.\n            Required fields: ['video-id, 't-start', 't-end', 'score']\n        tiou_thresholds(1d-array | optional): array with tiou thresholds.\n        Returns:\n        recall(2d-array): recall[i,j] is recall at ith tiou threshold at the jth\n            average number of average number of proposals per video.\n        average_recall(1d-array): recall averaged over a list of tiou threshold.\n            This is equivalent to recall.mean(axis=0).\n        proposals_per_video(1d-array): average number of proposals per video.",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:183-202"
    },
    "5549": {
        "file_id": 453,
        "content": "This code defines a function that computes average recall for given average number of proposals per video. It takes ground truth and proposal data frames as input, along with optional tiou_thresholds. It returns recall and average_recall arrays.",
        "type": "comment"
    },
    "5550": {
        "file_id": 453,
        "content": "        \"\"\"\n        # Get list of videos.\n        video_lst = ground_truth['video-id'].unique()\n        if not max_avg_nr_proposals:\n            max_avg_nr_proposals = float(\n                proposals.shape[0]) / video_lst.shape[0]\n        ratio = max_avg_nr_proposals * float(\n            video_lst.shape[0]) / proposals.shape[0]\n        # Adaptation to query faster\n        ground_truth_gbvn = ground_truth.groupby('video-id')\n        proposals_gbvn = proposals.groupby('video-id')\n        # For each video, computes tiou scores among the retrieved proposals.\n        score_lst = []\n        total_nr_proposals = 0\n        for videoid in video_lst:\n            # Get ground-truth instances associated to this video.\n            ground_truth_videoid = ground_truth_gbvn.get_group(videoid)\n            this_video_ground_truth = ground_truth_videoid.loc[:, [\n                't-start', 't-end'\n            ]].values\n            # Get proposals for this video.\n            try:\n                proposals_videoid = proposals_gbvn.get_group(videoid)",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:203-231"
    },
    "5551": {
        "file_id": 453,
        "content": "This code retrieves a list of videos, calculates the maximum average number of proposals per video, groups proposals and ground truth by video ID, and then computes Tiou scores between ground-truth instances and retrieved proposals for each video.",
        "type": "comment"
    },
    "5552": {
        "file_id": 453,
        "content": "            except:\n                n = this_video_ground_truth.shape[0]\n                score_lst.append(np.zeros((n, 1)))\n                continue\n            this_video_proposals = proposals_videoid.loc[:,\n                                                         ['t-start', 't-end'\n                                                          ]].values\n            if this_video_proposals.shape[0] == 0:\n                n = this_video_ground_truth.shape[0]\n                score_lst.append(np.zeros((n, 1)))\n                continue\n            # Sort proposals by score.\n            sort_idx = proposals_videoid['score'].argsort()[::-1]\n            this_video_proposals = this_video_proposals[sort_idx, :]\n            if this_video_proposals.ndim != 2:\n                this_video_proposals = np.expand_dims(this_video_proposals,\n                                                      axis=0)\n            if this_video_ground_truth.ndim != 2:\n                this_video_ground_truth = np.expand_dims(\n                    this_video_ground_truth, axis=0)",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:232-255"
    },
    "5553": {
        "file_id": 453,
        "content": "This code block is part of a function that handles exceptions when dealing with video proposals and ground truth. It appends a zero matrix to the score list if there are no video proposals or ground truth data for the current video. If there are proposals, it sorts them by score in descending order and expands dimensions as necessary before proceeding.",
        "type": "comment"
    },
    "5554": {
        "file_id": 453,
        "content": "            nr_proposals = np.minimum(\n                int(this_video_proposals.shape[0] * ratio),\n                this_video_proposals.shape[0])\n            total_nr_proposals += nr_proposals\n            this_video_proposals = this_video_proposals[:nr_proposals, :]\n            # Compute tiou scores.\n            tiou = self.wrapper_segment_iou(this_video_proposals,\n                                            this_video_ground_truth)\n            score_lst.append(tiou)\n        # Given that the length of the videos is really varied, we\n        # compute the number of proposals in terms of a ratio of the total\n        # proposals retrieved, i.e. average recall at a percentage of proposals\n        # retrieved per video.\n        # Computes average recall.\n        pcn_lst = np.arange(1, 101) / 100.0 * (max_avg_nr_proposals * float(\n            video_lst.shape[0]) / total_nr_proposals)\n        matches = np.empty((video_lst.shape[0], pcn_lst.shape[0]))\n        positives = np.empty(video_lst.shape[0])\n        recall = np.empty((tiou_thresholds.shape[0], pcn_lst.shape[0]))",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:257-278"
    },
    "5555": {
        "file_id": 453,
        "content": "This code calculates average recall for a set of video proposals. It sets the number of proposals based on a ratio, computes IOU scores, and stores the results in lists. The average recall is computed using a predetermined maximum number of proposals and the total number of proposals retrieved, considering the variable length of videos.",
        "type": "comment"
    },
    "5556": {
        "file_id": 453,
        "content": "        # Iterates over each tiou threshold.\n        for ridx, tiou in enumerate(tiou_thresholds):\n            # Inspect positives retrieved per video at different\n            # number of proposals (percentage of the total retrieved).\n            for i, score in enumerate(score_lst):\n                # Total positives per video.\n                positives[i] = score.shape[0]\n                # Find proposals that satisfies minimum tiou threshold.\n                true_positives_tiou = score >= tiou\n                # Get number of proposals as a percentage of total retrieved.\n                pcn_proposals = np.minimum(\n                    (score.shape[1] * pcn_lst).astype(int), score.shape[1])\n                for j, nr_proposals in enumerate(pcn_proposals):\n                    # Compute the number of matches for each percentage of the proposals\n                    matches[i, j] = np.count_nonzero(\n                        (true_positives_tiou[:, :nr_proposals]).sum(axis=1))\n            # Computes recall given the set of matches per video.",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:279-298"
    },
    "5557": {
        "file_id": 453,
        "content": "Code iterates over different tiou thresholds and positive scores, computing the number of true positives based on threshold and percentage of proposals. It calculates matches per video and computes recall for each set of matches.",
        "type": "comment"
    },
    "5558": {
        "file_id": 453,
        "content": "            recall[ridx, :] = matches.sum(axis=0) / positives.sum()\n        # Recall is averaged.\n        avg_recall = recall.mean(axis=0)\n        # Get the average number of proposals per video.\n        proposals_per_video = pcn_lst * (float(total_nr_proposals) /\n                                         video_lst.shape[0])\n        return recall, avg_recall, proposals_per_video\n    def get_blocked_videos(self, api=API):\n        api_url = '{}?action=get_blocked'.format(api)\n        req = urllib2.Request(api_url)\n        response = urllib2.urlopen(req)\n        return json.loads(response.read())\n    def wrapper_segment_iou(self, target_segments, candidate_segments):\n        \"\"\"\n        Compute intersection over union btw segments\n        Parameters:\n        target_segments(nd-array): 2-dim array in format [m x 2:=[init, end]]\n        candidate_segments(nd-array): 2-dim array in format [n x 2:=[init, end]]\n        Returns:\n        tiou(nd-array): 2-dim array [n x m] with IOU ratio.\n        Note: It assumes that candidate-segments are more scarce that target-segments",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:299-324"
    },
    "5559": {
        "file_id": 453,
        "content": "The function calculates recall and average recall for detected objects in videos, based on the number of true positives and total proposals. It also returns the average number of proposals per video. The second function retrieves a list of blocked videos from an API. The third function computes intersection over union between target and candidate segments efficiently.",
        "type": "comment"
    },
    "5560": {
        "file_id": 453,
        "content": "        \"\"\"\n        if candidate_segments.ndim != 2 or target_segments.ndim != 2:\n            raise ValueError('Dimension of arguments is incorrect')\n        n, m = candidate_segments.shape[0], target_segments.shape[0]\n        tiou = np.empty((n, m))\n        for i in range(m):\n            tiou[:, i] = self.segment_iou(target_segments[i, :],\n                                          candidate_segments)\n        return tiou\n    def segment_iou(self, target_segment, candidate_segments):\n        \"\"\"\n        Compute the temporal intersection over union between a\n        target segment and all the test segments.\n        Parameters:\n        target_segment(1d-array): Temporal target segment containing [starting, ending] times.\n        candidate_segments(2d-array): Temporal candidate segments containing N x [starting, ending] times.\n        Returns:\n        tiou(1d-array): Temporal intersection over union score of the N's candidate segments.\n        \"\"\"\n        tt1 = np.maximum(target_segment[0], candidate_segments[:, 0])",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:325-349"
    },
    "5561": {
        "file_id": 453,
        "content": "This function calculates the temporal intersection over union (TIOU) between a target segment and multiple candidate segments. If the dimensions of arguments are not 2, it raises a ValueError. It loops through each candidate segment, compares their starting and ending times with the target segment's times using np.maximum, and stores the TIOU results in a 2D array.",
        "type": "comment"
    },
    "5562": {
        "file_id": 453,
        "content": "        tt2 = np.minimum(target_segment[1], candidate_segments[:, 1])\n        # Intersection including Non-negative overlap score.\n        segments_intersection = (tt2 - tt1).clip(0)\n        # Segment union.\n        segments_union = (candidate_segments[:, 1] - candidate_segments[:, 0]) \\\n                         + (target_segment[1] - target_segment[0]) - segments_intersection\n        # Compute overlap as the ratio of the intersection\n        # over union of two segments.\n        tIoU = segments_intersection.astype(float) / segments_union\n        return tIoU",
        "type": "code",
        "location": "/paddlevideo/metrics/ActivityNet/anet_prop.py:350-359"
    },
    "5563": {
        "file_id": 453,
        "content": "Computes intersection over union (IoU) of two segments by finding the minimum endpoints, calculating intersection and union, and dividing intersection by union.",
        "type": "comment"
    },
    "5564": {
        "file_id": 454,
        "content": "/paddlevideo/metrics/__init__.py",
        "type": "filepath"
    },
    "5565": {
        "file_id": 454,
        "content": "The code imports various metrics from different modules for video analysis and evaluation, including AVAMetric, VOSMetric, BMNMetric, MSRVTTMetric, SkeletonMetric, TransNetV2Metric, DepthMetric, CenterCropMetric, MultiCropMetric, HitOneMetric, and SegmentationMetric. It also imports the METRIC registry for managing these metrics.",
        "type": "summary"
    },
    "5566": {
        "file_id": 454,
        "content": "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom .bmn_metric import BMNMetric\nfrom .build import build_metric\nfrom .center_crop_metric import CenterCropMetric\nfrom .depth_metric import DepthMetric\nfrom .msrvtt_metric import MSRVTTMetric\nfrom .multi_crop_metric import MultiCropMetric\nfrom .registry import METRIC\nfrom .skeleton_metric import SkeletonMetric\nfrom .transnetv2_metric import TransNetV2Metric\nfrom .youtube8m.eval_util import HitOneMetric\nfrom .segmentation_metric import SegmentationMetric",
        "type": "code",
        "location": "/paddlevideo/metrics/__init__.py:1-25"
    },
    "5567": {
        "file_id": 454,
        "content": "The code is importing various metrics from different metric classes for video analysis and evaluation. It includes BMNMetric, MSRVTTMetric, SkeletonMetric, TransNetV2Metric, DepthMetric, CenterCropMetric, MultiCropMetric, HitOneMetric, and SegmentationMetric. The METRIC registry is also imported for managing these metrics.",
        "type": "comment"
    },
    "5568": {
        "file_id": 454,
        "content": "from .ava_metric import AVAMetric\nfrom .vos_metric import VOSMetric\nfrom .center_crop_metric_MRI import CenterCropMetric_MRI\nfrom .yowo_metric import YOWOMetric\n__all__ = [\n    'METRIC', 'build_metric', 'MultiCropMetric', 'BMNMetric',\n    'CenterCropMetric', 'SkeletonMetric', 'HitOneMetric', 'TransNetV2Metric',\n    'DepthMetric', 'MSRVTTMetric', 'VOSMetric', 'CenterCropMetric_MRI','AVAMetric',\n    'SegmentationMetric', 'YOWOMetric'\n]",
        "type": "code",
        "location": "/paddlevideo/metrics/__init__.py:26-36"
    },
    "5569": {
        "file_id": 454,
        "content": "This code imports various metrics from different modules and adds them to the __all__ list for easy access, including AVAMetric, VOSMetric, CenterCropMetric_MRI, YOWOMetric, METRIC, build_metric, MultiCropMetric, BMNMetric, CenterCropMetric, SkeletonMetric, HitOneMetric, TransNetV2Metric, DepthMetric, MSRVTTMetric.",
        "type": "comment"
    },
    "5570": {
        "file_id": 455,
        "content": "/paddlevideo/metrics/ava_evaluation/README.md",
        "type": "filepath"
    },
    "5571": {
        "file_id": 455,
        "content": "This code is from the ActivityNet repo and has been modified to reduce length, possibly for efficiency or better readability. It uses metrics and evaluation methods for action recognition tasks, likely in video analysis applications.",
        "type": "summary"
    },
    "5572": {
        "file_id": 455,
        "content": "The code under this folder is from the official [ActivityNet repo](https://github.com/activitynet/ActivityNet).\nSome unused codes are removed to minimize the length of codes added.",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/README.md:1-2"
    },
    "5573": {
        "file_id": 455,
        "content": "This code is from the ActivityNet repo and has been modified to reduce length, possibly for efficiency or better readability. It uses metrics and evaluation methods for action recognition tasks, likely in video analysis applications.",
        "type": "comment"
    },
    "5574": {
        "file_id": 456,
        "content": "/paddlevideo/metrics/ava_evaluation/metrics.py",
        "type": "filepath"
    },
    "5575": {
        "file_id": 456,
        "content": "This function calculates precision and recall metrics from scores, labels, and ground truth instances, raising ValueError for incorrect inputs. It computes average precision using valid precision and recall arrays and calculates CorLoc performance metrics for object detection with given ground truth and detected images per class.",
        "type": "summary"
    },
    "5576": {
        "file_id": 456,
        "content": "# copyright (c) 2021 PaddlePaddle Authors. All Rights Reserve.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Functions for computing metrics like precision, recall, CorLoc and etc.\"\"\"\nimport numpy as np\ndef compute_precision_recall(scores, labels, num_gt):\n    \"\"\"Compute precision and recall.\n    Args:\n        scores: A float numpy array representing detection score\n        labels: A boolean numpy array representing true/false positive labels\n        num_gt: Number of ground truth instances\n    Raises:\n        ValueError: if the input is not of the correct format",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/metrics.py:1-30"
    },
    "5577": {
        "file_id": 456,
        "content": "This code defines a function to compute precision and recall metrics based on input scores, labels, and the number of ground truth instances. It also raises a ValueError if the input is in the incorrect format.",
        "type": "comment"
    },
    "5578": {
        "file_id": 456,
        "content": "    Returns:\n        precision: Fraction of positive instances over detected ones. This\n            value is None if no ground truth labels are present.\n        recall: Fraction of detected positive instance over all positive\n            instances. This value is None if no ground truth labels are\n            present.\n    \"\"\"\n    if (not isinstance(labels, np.ndarray) or labels.dtype != np.bool\n            or len(labels.shape) != 1):\n        raise ValueError('labels must be single dimension bool numpy array')\n    if not isinstance(scores, np.ndarray) or len(scores.shape) != 1:\n        raise ValueError('scores must be single dimension numpy array')\n    if num_gt < np.sum(labels):\n        raise ValueError(\n            'Number of true positives must be smaller than num_gt.')\n    if len(scores) != len(labels):\n        raise ValueError('scores and labels must be of the same size.')\n    if num_gt == 0:\n        return None, None\n    sorted_indices = np.argsort(scores)\n    sorted_indices = sorted_indices[::-1]\n    labels = labels.astype(int)",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/metrics.py:32-58"
    },
    "5579": {
        "file_id": 456,
        "content": "This code checks if input 'labels' and 'scores' are valid arrays. It verifies that 'labels' is a one-dimensional boolean numpy array, 'scores' is a one-dimensional numpy array, the number of true positives is less than num_gt (number of ground truth labels), and the lengths of 'scores' and 'labels' are equal. If any conditions are not met, it raises a ValueError with an appropriate error message. If all checks pass and there are no ground truth labels, the function returns None for both precision and recall.",
        "type": "comment"
    },
    "5580": {
        "file_id": 456,
        "content": "    true_positive_labels = labels[sorted_indices]\n    false_positive_labels = 1 - true_positive_labels\n    cum_true_positives = np.cumsum(true_positive_labels)\n    cum_false_positives = np.cumsum(false_positive_labels)\n    precision = cum_true_positives.astype(float) / (\n        cum_true_positives + cum_false_positives)\n    recall = cum_true_positives.astype(float) / num_gt\n    return precision, recall\ndef compute_average_precision(precision, recall):\n    \"\"\"Compute Average Precision according to the definition in VOCdevkit.\n    Precision is modified to ensure that it does not decrease as recall\n    decrease.\n    Args:\n        precision: A float [N, 1] numpy array of precisions\n        recall: A float [N, 1] numpy array of recalls\n    Raises:\n        ValueError: if the input is not of the correct format\n    Returns:\n        average_precison: The area under the precision recall curve. NaN if\n            precision and recall are None.\n    \"\"\"\n    if precision is None:\n        if recall is not None:\n            raise ValueError('If precision is None, recall must also be None')",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/metrics.py:59-88"
    },
    "5581": {
        "file_id": 456,
        "content": "Computes precision and recall from sorted labels, returns both values.\nDefines a function to compute average precision using precision and recall arrays.",
        "type": "comment"
    },
    "5582": {
        "file_id": 456,
        "content": "        return np.NAN\n    if not isinstance(precision, np.ndarray) or not isinstance(\n            recall, np.ndarray):\n        raise ValueError('precision and recall must be numpy array')\n    if precision.dtype != np.float or recall.dtype != np.float:\n        raise ValueError('input must be float numpy array.')\n    if len(precision) != len(recall):\n        raise ValueError('precision and recall must be of the same size.')\n    if not precision.size:\n        return 0.0\n    if np.amin(precision) < 0 or np.amax(precision) > 1:\n        raise ValueError('Precision must be in the range of [0, 1].')\n    if np.amin(recall) < 0 or np.amax(recall) > 1:\n        raise ValueError('recall must be in the range of [0, 1].')\n    if not all(recall[i] <= recall[i + 1] for i in range(len(recall) - 1)):\n        raise ValueError('recall must be a non-decreasing array')\n    recall = np.concatenate([[0], recall, [1]])\n    precision = np.concatenate([[0], precision, [0]])\n    # Preprocess precision to be a non-decreasing array\n    for i in range(len(precision) - 2, -1, -1):",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/metrics.py:89-111"
    },
    "5583": {
        "file_id": 456,
        "content": "This function checks the data types and ranges of precision and recall arrays, ensuring they are numpy float arrays within the range [0,1] and have the same size. If all conditions pass, it then concatenates recall and precision arrays with 0 and 1 at the end respectively before preprocessing precision to be a non-decreasing array.",
        "type": "comment"
    },
    "5584": {
        "file_id": 456,
        "content": "        precision[i] = np.maximum(precision[i], precision[i + 1])\n    indices = np.where(recall[1:] != recall[:-1])[0] + 1\n    average_precision = np.sum(\n        (recall[indices] - recall[indices - 1]) * precision[indices])\n    return average_precision\ndef compute_cor_loc(num_gt_imgs_per_class,\n                    num_images_correctly_detected_per_class):\n    \"\"\"Compute CorLoc according to the definition in the following paper.\n    https://www.robots.ox.ac.uk/~vgg/rg/papers/deselaers-eccv10.pdf\n    Returns nans if there are no ground truth images for a class.\n    Args:\n        num_gt_imgs_per_class: 1D array, representing number of images\n            containing at least one object instance of a particular class\n        num_images_correctly_detected_per_class: 1D array, representing number\n            of images that are correctly detected at least one object instance\n            of a particular class\n    Returns:\n        corloc_per_class: A float numpy array represents the corloc score of\n            each class",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/metrics.py:112-137"
    },
    "5585": {
        "file_id": 456,
        "content": "This code computes the average precision and CorLoc, which is a metric used to evaluate object detection performance. It takes in arrays of ground truth images per class and correctly detected images per class. The average precision function calculates the average precision by comparing recall values, while the compute_cor_loc function calculates the CorLoc score for each class based on these inputs. If there are no ground truth images for a class, it returns NaN.",
        "type": "comment"
    },
    "5586": {
        "file_id": 456,
        "content": "    \"\"\"\n    # Divide by zero expected for classes with no gt examples.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        return np.where(\n            num_gt_imgs_per_class == 0, np.nan,\n            num_images_correctly_detected_per_class / num_gt_imgs_per_class)",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/metrics.py:138-143"
    },
    "5587": {
        "file_id": 456,
        "content": "Divides the number of images correctly detected by the number of ground truth images per class, ignoring division by zero for classes with no examples.",
        "type": "comment"
    },
    "5588": {
        "file_id": 457,
        "content": "/paddlevideo/metrics/ava_evaluation/np_box_list.py",
        "type": "filepath"
    },
    "5589": {
        "file_id": 457,
        "content": "The \"BoxList\" class manages bounding boxes, and the _is_valid_boxes function checks if data array of shape [N, 4] representing box coordinates adheres to the correct format. The function returns a boolean indicating whether all ymax are greater than or equal to ymin, all xmax are greater than or equal to xmin, and the data is not empty.",
        "type": "summary"
    },
    "5590": {
        "file_id": 457,
        "content": "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\"\"\"Numpy BoxList classes and functions.\"\"\"\nimport numpy as np\nclass BoxList:\n    \"\"\"Box collection.\n    BoxList represents a list of bounding boxes as numpy array, where each\n    bounding box is represented as a row of 4 numbers,\n    [y_min, x_min, y_max, x_max].  It is assumed that all bounding boxes within\n    a given list correspond to a single image.",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:1-26"
    },
    "5591": {
        "file_id": 457,
        "content": "The code defines a class called \"BoxList\" that represents a collection of bounding boxes as a numpy array. Each box is represented by 4 numbers: y_min, x_min, y_max, and x_max. It assumes all boxes in the list correspond to a single image.",
        "type": "comment"
    },
    "5592": {
        "file_id": 457,
        "content": "    Optionally, users can add additional related fields (such as\n    objectness/classification scores).\n    \"\"\"\n    def __init__(self, data):\n        \"\"\"Constructs box collection.\n        Args:\n            data: a numpy array of shape [N, 4] representing box coordinates\n        Raises:\n            ValueError: if bbox data is not a numpy array\n            ValueError: if invalid dimensions for bbox data\n        \"\"\"\n        if not isinstance(data, np.ndarray):\n            raise ValueError('data must be a numpy array.')\n        if len(data.shape) != 2 or data.shape[1] != 4:\n            raise ValueError('Invalid dimensions for box data.')\n        if data.dtype != np.float32 and data.dtype != np.float64:\n            raise ValueError(\n                'Invalid data type for box data: float is required.')\n        if not self._is_valid_boxes(data):\n            raise ValueError('Invalid box data. data must be a numpy array of '\n                             'N*[y_min, x_min, y_max, x_max]')\n        self.data = {'boxes': data}",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:28-52"
    },
    "5593": {
        "file_id": 457,
        "content": "This code defines a class for box collections, where users can optionally add additional related fields such as objectness or classification scores. The `__init__` method checks if the input data is a numpy array, has valid dimensions and data type (float), and raises a ValueError if any of these conditions are not met. It then stores the data in a dictionary with key \"boxes\".",
        "type": "comment"
    },
    "5594": {
        "file_id": 457,
        "content": "    def num_boxes(self):\n        \"\"\"Return number of boxes held in collections.\"\"\"\n        return self.data['boxes'].shape[0]\n    def get_extra_fields(self):\n        \"\"\"Return all non-box fields.\"\"\"\n        return [k for k in self.data if k != 'boxes']\n    def has_field(self, field):\n        return field in self.data\n    def add_field(self, field, field_data):\n        \"\"\"Add data to a specified field.\n        Args:\n            field: a string parameter used to speficy a related field to be\n                accessed.\n            field_data: a numpy array of [N, ...] representing the data\n                associated with the field.\n        Raises:\n            ValueError: if the field is already exist or the dimension of the\n                field data does not matches the number of boxes.\n        \"\"\"\n        if self.has_field(field):\n            raise ValueError('Field ' + field + 'already exists')\n        if len(field_data.shape) < 1 or field_data.shape[0] != self.num_boxes(\n        ):\n            raise ValueError('Invalid dimensions for field data')",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:54-81"
    },
    "5595": {
        "file_id": 457,
        "content": "This code defines a class with methods to handle box collections. It provides functionality for counting the number of boxes, retrieving non-box fields, checking if a specific field exists, and adding data to an existing or new field while handling errors related to field existence and data dimensions.",
        "type": "comment"
    },
    "5596": {
        "file_id": 457,
        "content": "        self.data[field] = field_data\n    def get(self):\n        \"\"\"Convenience function for accesssing box coordinates.\n        Returns:\n            a numpy array of shape [N, 4] representing box corners\n        \"\"\"\n        return self.get_field('boxes')\n    def get_field(self, field):\n        \"\"\"Accesses data associated with the specified field in the box\n        collection.\n        Args:\n            field: a string parameter used to speficy a related field to be\n                accessed.\n        Returns:\n            a numpy 1-d array representing data of an associated field\n        Raises:\n            ValueError: if invalid field\n        \"\"\"\n        if not self.has_field(field):\n            raise ValueError(f'field {field} does not exist')\n        return self.data[field]\n    def get_coordinates(self):\n        \"\"\"Get corner coordinates of boxes.\n        Returns:\n            a list of 4 1-d numpy arrays [y_min, x_min, y_max, x_max]\n        \"\"\"\n        box_coordinates = self.get()\n        y_min = box_coordinates[:, 0]",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:82-117"
    },
    "5597": {
        "file_id": 457,
        "content": "The code defines a class with methods to access box coordinates from a stored dataset. The \"get\" method returns a numpy array of shape [N, 4] representing box corners. The \"get_field\" method is used to access data related to a specific field in the box collection. If an invalid field is provided, it raises a ValueError. The \"get_coordinates\" method returns a list of 4 1-d numpy arrays containing y_min, x_min, y_max, and x_max values for each box.",
        "type": "comment"
    },
    "5598": {
        "file_id": 457,
        "content": "        x_min = box_coordinates[:, 1]\n        y_max = box_coordinates[:, 2]\n        x_max = box_coordinates[:, 3]\n        return [y_min, x_min, y_max, x_max]\n    def _is_valid_boxes(self, data):\n        \"\"\"Check whether data fullfills the format of N*[ymin, xmin, ymax,\n        xmin].\n        Args:\n            data: a numpy array of shape [N, 4] representing box coordinates\n        Returns:\n            a boolean indicating whether all ymax of boxes are equal or greater\n            than ymin, and all xmax of boxes are equal or greater than xmin.\n        \"\"\"\n        if len(data):\n            for v in data:\n                if v[0] > v[2] or v[1] > v[3]:\n                    return False\n        return True",
        "type": "code",
        "location": "/paddlevideo/metrics/ava_evaluation/np_box_list.py:118-138"
    },
    "5599": {
        "file_id": 457,
        "content": "This code defines a function `_is_valid_boxes` which checks if the data array of shape [N, 4] representing box coordinates fulfills the format N*[ymin, xmin, ymax, xmax]. It returns a boolean indicating whether all ymax of boxes are equal or greater than ymin and all xmax of boxes are equal or greater than xmin. The function also checks if the data is not empty.",
        "type": "comment"
    }
}