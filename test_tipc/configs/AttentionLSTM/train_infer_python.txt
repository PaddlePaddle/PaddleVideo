===========================train_params===========================
model_name:AttentionLSTM
python:python3.7
gpu_list:0|0,1
Global.use_gpu:null|null
Global.auto_cast:null
-o epochs:2
-o output_dir:null
-o DATASET.batch_size:64
null:null
train_model_name:null
train_infer_video_dir:null
-o DATASET.train.file_path:'data/yt8m/train_small.list' -o DATASET.valid.file_path='data/yt8m/train_small.list' -o DATASET.test.file_path='data/yt8m/train_small.list'
##
trainer:norm_train
norm_train:main.py --validate -c configs/recognition/attention_lstm/attention_lstm_youtube8m.yaml --seed 1234
pact_train:null
fpgm_train:null
distill_train:null
null:null
null:null
##
===========================eval_params===========================
eval:main.py --test -c configs/recognition/attention_lstm/attention_lstm_youtube8m.yaml
-w:./test_tipc/output/AttentionLSTM/AttentionLSTM_epoch_00001.pdparams
##
===========================infer_params===========================
-o:inference/AttentionLSTM
-p:null
norm_export:tools/export_model.py -c configs/recognition/attention_lstm/attention_lstm_youtube8m.yaml --save_name inference
quant_export:null
fpgm_export:null
distill_export:null
export1:null
export2:null
inference_dir:null
infer_model:./data/AttentionLSTM_yt8.pdparams
infer_export:tools/export_model.py -c configs/recognition/attention_lstm/attention_lstm_youtube8m.yaml
infer_quant:False
inference:tools/predict.py --config configs/recognition/attention_lstm/attention_lstm_youtube8m.yaml
--use_gpu:True|False
--enable_mkldnn:True|False
--cpu_threads:1|6
--batch_size:1|2
--use_tensorrt:False|True
--precision:fp32|fp16
--model_file:inference.pdmodel
--input_file:./data/example.pkl
null:null
--enable_benchmark:True
--params_file:inference.pdiparams
===========================infer_benchmark_params==========================
random_infer_input:[{float32,[512, 1024]},{int32,[1]},{float32,[512, 1024]},{float32,[512, 128]},{int32,[1]},{float32,[512, 128]}]
